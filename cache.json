{"2023-01-17T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.07095v1","updated":"2023-01-17T18:59:20Z","published":"2023-01-17T18:59:20Z","title":"On the State of German (Abstractive) Text Summarization","summary":"  With recent advancements in the area of Natural Language Processing, the\nfocus is slowly shifting from a purely English-centric view towards more\nlanguage-specific solutions, including German. Especially practical for\nbusinesses to analyze their growing amount of textual data are text\nsummarization systems, which transform long input documents into compressed and\nmore digestible summary texts. In this work, we assess the particular landscape\nof German abstractive text summarization and investigate the reasons why\npractically useful solutions for abstractive text summarization are still\nabsent in industry. Our focus is two-fold, analyzing a) training resources, and\nb) publicly available summarization systems. We are able to show that popular\nexisting datasets exhibit crucial flaws in their assumptions about the original\nsources, which frequently leads to detrimental effects on system generalization\nand evaluation biases. We confirm that for the most popular training dataset,\nMLSUM, over 50% of the training set is unsuitable for abstractive summarization\npurposes. Furthermore, available systems frequently fail to compare to simple\nbaselines, and ignore more effective and efficient extractive summarization\napproaches. We attribute poor evaluation quality to a variety of different\nfactors, which are investigated in more detail in this work: A lack of\nqualitative (and diverse) gold data considered for training, understudied (and\nuntreated) positional biases in some of the existing datasets, and the lack of\neasily accessible and streamlined pre-processing strategies or analysis tools.\nWe provide a comprehensive assessment of available models on the cleaned\ndatasets, and find that this can lead to a reduction of more than 20 ROUGE-1\npoints during evaluation. The code for dataset filtering and reproducing\nresults can be found online at https://github.com/dennlinger/summaries\n","authors":["Dennis Aumiller","Jing Fan","Michael Gertz"],"pdf_url":"https://arxiv.org/pdf/2301.07095v1.pdf","comment":"Accepted at the 20th Conference on Database Systems for Business,\n  Technology and Web (BTW'23)"},{"id":"http://arxiv.org/abs/2301.07094v1","updated":"2023-01-17T18:59:06Z","published":"2023-01-17T18:59:06Z","title":"Learning Customized Visual Models with Retrieval-Augmented Knowledge","summary":"  Image-text contrastive learning models such as CLIP have demonstrated strong\ntask transfer ability. The high generality and usability of these visual models\nis achieved via a web-scale data collection process to ensure broad concept\ncoverage, followed by expensive pre-training to feed all the knowledge into\nmodel weights. Alternatively, we propose REACT, REtrieval-Augmented\nCusTomization, a framework to acquire the relevant web knowledge to build\ncustomized visual models for target domains. We retrieve the most relevant\nimage-text pairs (~3% of CLIP pre-training data) from the web-scale database as\nexternal knowledge, and propose to customize the model by only training new\nmodualized blocks while freezing all the original weights. The effectiveness of\nREACT is demonstrated via extensive experiments on classification, retrieval,\ndetection and segmentation tasks, including zero, few, and full-shot settings.\nParticularly, on the zero-shot classification task, compared with CLIP, it\nachieves up to 5.4% improvement on ImageNet and 3.7% on the ELEVATER benchmark\n(20 datasets).\n","authors":["Haotian Liu","Kilho Son","Jianwei Yang","Ce Liu","Jianfeng Gao","Yong Jae Lee","Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2301.07094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07093v1","updated":"2023-01-17T18:58:58Z","published":"2023-01-17T18:58:58Z","title":"GLIGEN: Open-Set Grounded Text-to-Image Generation","summary":"  Large-scale text-to-image diffusion models have made amazing advances.\nHowever, the status quo is to use text input alone, which can impede\ncontrollability. In this work, we propose GLIGEN, Grounded-Language-to-Image\nGeneration, a novel approach that builds upon and extends the functionality of\nexisting pre-trained text-to-image diffusion models by enabling them to also be\nconditioned on grounding inputs. To preserve the vast concept knowledge of the\npre-trained model, we freeze all of its weights and inject the grounding\ninformation into new trainable layers via a gated mechanism. Our model achieves\nopen-world grounded text2img generation with caption and bounding box condition\ninputs, and the grounding ability generalizes well to novel spatial\nconfiguration and concepts. GLIGEN's zero-shot performance on COCO and LVIS\noutperforms that of existing supervised layout-to-image baselines by a large\nmargin.\n","authors":["Yuheng Li","Haotian Liu","Qingyang Wu","Fangzhou Mu","Jianwei Yang","Jianfeng Gao","Chunyuan Li","Yong Jae Lee"],"pdf_url":"https://arxiv.org/pdf/2301.07093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07088v1","updated":"2023-01-17T18:53:24Z","published":"2023-01-17T18:53:24Z","title":"Vision Learners Meet Web Image-Text Pairs","summary":"  Most recent self-supervised learning~(SSL) methods are pre-trained on the\nwell-curated ImageNet-1K dataset. In this work, we consider SSL pre-training on\nnoisy web image-text paired data due to the excellent scalability of web data.\nFirst, we conduct a benchmark study of representative SSL pre-training methods\non large-scale web data in a fair condition. Methods include single-modal ones\nsuch as MAE and multi-modal ones such as CLIP. We observe that multi-modal\nmethods cannot outperform single-modal ones on vision transfer learning tasks.\nWe derive an information-theoretical view to explain the benchmarking results,\nwhich provides insights into designing novel vision learners. Inspired by the\nabove explorations, we present a visual representation pre-training method,\nMUlti-modal Generator~(MUG), for scalable web image-text data. MUG achieves\nstate-of-the-art transferring performances on a variety of tasks and shows\npromising scaling behavior. Models and codes will be made public. Demo\navailable at https://huggingface.co/spaces/tennant/MUG_caption\n","authors":["Bingchen Zhao","Quan Cui","Hao Wu","Osamu Yoshie","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07088v1.pdf","comment":"Project page: https://bzhao.me/MUG/"},{"id":"http://arxiv.org/abs/2301.07087v1","updated":"2023-01-17T18:53:15Z","published":"2023-01-17T18:53:15Z","title":"MooseNet: A trainable metric for synthesized speech with plda backend","summary":"  We present MooseNet, a trainable speech metric that predicts listeners' Mean\nOpinion Score (MOS). We report improvements to the challenge baselines using\neasy-to-use modeling techniques, which also scales for larger self-supervised\nlearning (SSL) model. We present two models. The first model is a Neural\nNetwork (NN). As a second model, we propose a PLDA generative model on the top\nlayers of the first NN model, which improves the pure NN model. Ensembles from\nour two models achieve the top 3 or 4 VoiceMOS leaderboard places on all system\nand utterance level metrics.\n","authors":["Ondřej Plátek","Ondřej Dušek"],"pdf_url":"https://arxiv.org/pdf/2301.07087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07085v1","updated":"2023-01-17T18:51:19Z","published":"2023-01-17T18:51:19Z","title":"Are Language Models Worse than Humans at Following Prompts? It's\n  Complicated","summary":"  Prompts have been the center of progress in advancing language models'\nzero-shot and few-shot performance. However, recent work finds that models can\nperform surprisingly well when given intentionally irrelevant or misleading\nprompts. Such results may be interpreted as evidence that model behavior is not\n\"human like\". In this study, we challenge a central assumption in such work:\nthat humans would perform badly when given pathological instructions. We find\nthat humans are able to reliably ignore irrelevant instructions and thus, like\nmodels, perform well on the underlying task despite an apparent lack of signal\nregarding the task they are being asked to do. However, when given deliberately\nmisleading instructions, humans follow the instructions faithfully, whereas\nmodels do not. Thus, our conclusion is mixed with respect to prior work. We\nargue against the earlier claim that high performance with irrelevant prompts\nconstitutes evidence against models' instruction understanding, but we\nreinforce the claim that models' failure to follow misleading instructions\nraises concerns. More broadly, we caution that future research should not\nidealize human behaviors as a monolith and should not train or evaluate models\nto mimic assumptions about these behaviors without first validating humans'\nbehaviors empirically.\n","authors":["Albert Webson","Alyssa Marie Loo","Qinan Yu","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2301.07085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07069v1","updated":"2023-01-17T18:32:06Z","published":"2023-01-17T18:32:06Z","title":"Prompting Large Language Model for Machine Translation: A Case Study","summary":"  Research on prompting has shown excellent performance with little or even no\nsupervised training across many tasks. However, prompting for machine\ntranslation is still under-explored in the literature. We fill this gap by\noffering a systematic study on prompting strategies for translation, examining\nvarious factors for prompt template and demonstration example selection. We\nfurther explore the use of monolingual data and the feasibility of\ncross-lingual, cross-domain, and sentence-to-document transfer learning in\nprompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the\ntestbed show that 1) the number and the quality of prompt examples matter,\nwhere using suboptimal examples degenerates translation; 2) several features of\nprompt examples, such as semantic similarity, show significant Spearman\ncorrelation with their prompting performance; yet, none of the correlations are\nstrong enough; 3) using pseudo parallel prompt examples constructed from\nmonolingual data via zero-shot prompting could improve translation; and 4)\nimproved performance is achievable by transferring knowledge from prompt\nexamples selected in other settings. We finally provide an analysis on the\nmodel outputs and discuss several problems that prompting still suffers from.\n","authors":["Biao Zhang","Barry Haddow","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2301.07069v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2301.07067v1","updated":"2023-01-17T18:31:12Z","published":"2023-01-17T18:31:12Z","title":"Transformers as Algorithms: Generalization and Implicit Model Selection\n  in In-context Learning","summary":"  In-context learning (ICL) is a type of prompting where a transformer model\noperates on a sequence of (input, output) examples and performs inference\non-the-fly. This implicit training is in contrast to explicitly tuning the\nmodel weights based on examples. In this work, we formalize in-context learning\nas an algorithm learning problem, treating the transformer model as a learning\nalgorithm that can be specialized via training to implement-at\ninference-time-another target algorithm. We first explore the statistical\naspects of this abstraction through the lens of multitask learning: We obtain\ngeneralization bounds for ICL when the input prompt is (1) a sequence of i.i.d.\n(input, label) pairs or (2) a trajectory arising from a dynamical system. The\ncrux of our analysis is relating the excess risk to the stability of the\nalgorithm implemented by the transformer, which holds under mild assumptions.\nSecondly, we use our abstraction to show that transformers can act as an\nadaptive learning algorithm and perform model selection across different\nhypothesis classes. We provide numerical evaluations that (1) demonstrate\ntransformers can indeed implement near-optimal algorithms on classical\nregression problems with i.i.d. and dynamic data, (2) identify an inductive\nbias phenomenon where the transfer risk on unseen tasks is independent of the\ntransformer complexity, and (3) empirically verify our theoretical predictions.\n","authors":["Yingcong Li","M. Emrullah Ildiz","Dimitris Papailiopoulos","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2301.07067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07057v1","updated":"2023-01-17T18:18:51Z","published":"2023-01-17T18:18:51Z","title":"Transformer Based Implementation for Automatic Book Summarization","summary":"  Document Summarization is the procedure of generating a meaningful and\nconcise summary of a given document with the inclusion of relevant and\ntopic-important points. There are two approaches: one is picking up the most\nrelevant statements from the document itself and adding it to the Summary known\nas Extractive and the other is generating sentences for the Summary known as\nAbstractive Summarization. Training a machine learning model to perform tasks\nthat are time-consuming or very difficult for humans to evaluate is a major\nchallenge. Book Abstract generation is one of such complex tasks. Traditional\nmachine learning models are getting modified with pre-trained transformers.\nTransformer based language models trained in a self-supervised fashion are\ngaining a lot of attention; when fine-tuned for Natural Language\nProcessing(NLP) downstream task like text summarization. This work is an\nattempt to use Transformer based techniques for Abstract generation.\n","authors":["Siddhant Porwal","Laxmi Bewoor","Vivek Deshpande"],"pdf_url":"https://arxiv.org/pdf/2301.07057v1.pdf","comment":"Published at - https://ijisae.org/index.php/IJISAE/article/view/2421"},{"id":"http://arxiv.org/abs/2301.07006v1","updated":"2023-01-17T16:51:58Z","published":"2023-01-17T16:51:58Z","title":"Which Model Shall I Choose? Cost/Quality Trade-offs for Text\n  Classification Tasks","summary":"  Industry practitioners always face the problem of choosing the appropriate\nmodel for deployment under different considerations, such as to maximize a\nmetric that is crucial for production, or to reduce the total cost given\nfinancial concerns. In this work, we focus on the text classification task and\npresent a quantitative analysis for this challenge. Using classification\naccuracy as the main metric, we evaluate the classifiers' performances for a\nvariety of models, including large language models, along with their associated\ncosts, including the annotation cost, training (fine-tuning) cost, and\ninference cost. We then discuss the model choices for situations like having a\nlarge number of samples needed for inference. We hope our work will help people\nbetter understand the cost/quality trade-offs for the text classification task.\n","authors":["Shi Zong","Josh Seltzer"," Jiahua"," Pan","Kathy Cheng","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2301.07006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06985v1","updated":"2023-01-17T16:12:42Z","published":"2023-01-17T16:12:42Z","title":"Statistical analysis of word flow among five Indo-European languages","summary":"  A recent increase in data availability has allowed the possibility to perform\ndifferent statistical linguistic studies. Here we use the Google Books Ngram\ndataset to analyze word flow among English, French, German, Italian, and\nSpanish. We study what we define as ``migrant words'', a type of loanwords that\ndo not change their spelling. We quantify migrant words from one language to\nanother for different decades, and notice that most migrant words can be\naggregated in semantic fields and associated to historic events. We also study\nthe statistical properties of accumulated migrant words and their rank\ndynamics. We propose a measure of use of migrant words that could be used as a\nproxy of cultural influence. Our methodology is not exempt of caveats, but our\nresults are encouraging to promote further studies in this direction.\n","authors":["Josué Ely Molina","Jorge Flores","Carlos Gershenson","Carlos Pineda"],"pdf_url":"https://arxiv.org/pdf/2301.06985v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2301.01181v6","updated":"2023-01-17T14:32:05Z","published":"2023-01-03T16:25:52Z","title":"Large Language Models as Corporate Lobbyists","summary":"  We demonstrate a proof-of-concept of a large language model conducting\ncorporate lobbying related activities. An autoregressive large language model\n(OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are\nrelevant to specific public companies and provides explanations and confidence\nlevels. For the bills the model deems as relevant, the model drafts a letter to\nthe sponsor of the bill in an attempt to persuade the congressperson to make\nchanges to the proposed legislation. We use hundreds of novel ground-truth\nlabels of the relevance of a bill to a company to benchmark the performance of\nthe model, which outperforms the baseline of predicting the most common outcome\nof irrelevance. We also benchmark the performance of the previous OpenAI GPT-3\nmodel (text-davinci-002), which was the state-of-the-art model on many academic\nnatural language tasks until text-davinci-003 was recently released. The\nperformance of text-davinci-002 is worse than a simple benchmark. These results\nsuggest that, as large language models continue to exhibit improved natural\nlanguage understanding capabilities, performance on lobbying related tasks will\ncontinue to improve. Longer-term, if AI begins to influence law in a manner\nthat is not a direct extension of human intentions, this threatens the critical\nrole that law as information could play in aligning AI with humans. Initially,\nAI is being used to simply augment human lobbyists for a small portion of their\ndaily tasks. However, firms have an incentive to use less and less human\noversight over automated assessments of policy ideas and the written\ncommunication to regulatory agencies and Congressional staffers. The core\nquestion raised is where to draw the line between human-driven and AI-driven\npolicy influence.\n","authors":["John J. Nay"],"pdf_url":"https://arxiv.org/pdf/2301.01181v6.pdf","comment":"Our open-source code available here:\n  https://github.com/JohnNay/llm-lobbyist"},{"id":"http://arxiv.org/abs/2301.06862v1","updated":"2023-01-17T13:15:44Z","published":"2023-01-17T13:15:44Z","title":"Algorithms for Acyclic Weighted Finite-State Automata with Failure Arcs","summary":"  Weighted finite-state automata (WSFAs) are commonly used in NLP. Failure\ntransitions are a useful extension for compactly representing backoffs or\ninterpolation in $n$-gram models and CRFs, which are special cases of WFSAs.\nThe pathsum in ordinary acyclic WFSAs is efficiently computed by the backward\nalgorithm in time $O(|E|)$, where $E$ is the set of transitions. However, this\ndoes not allow failure transitions, and preprocessing the WFSA to eliminate\nfailure transitions could greatly increase $|E|$. We extend the backward\nalgorithm to handle failure transitions directly. Our approach is efficient\nwhen the average state has outgoing arcs for only a small fraction $s \\ll 1$ of\nthe alphabet $\\Sigma$. We propose an algorithm for general acyclic WFSAs which\nruns in $O{\\left(|E| + s |\\Sigma| |Q| T_\\text{max} \\log{|\\Sigma|}\\right)}$,\nwhere $Q$ is the set of states and $T_\\text{max}$ is the size of the largest\nconnected component of failure transitions. When the failure transition\ntopology satisfies a condition exemplified by CRFs, the $T_\\text{max}$ factor\ncan be dropped, and when the weight semiring is a ring, the $\\log{|\\Sigma|}$\nfactor can be dropped. In the latter case (ring-weighted acyclic WFSAs), we\nalso give an alternative algorithm with complexity $\\displaystyle O{\\left(|E| +\n|\\Sigma| |Q| \\min(1,s\\pi_\\text{max}) \\right)}$, where $\\pi_\\text{max}$ is the\nsize of the longest failure path.\n","authors":["Anej Svete","Benjamin Dayan","Tim Vieira","Ryan Cotterell","Jason Eisner"],"pdf_url":"https://arxiv.org/pdf/2301.06862v1.pdf","comment":"9 pages, Proceedings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2301.06841v1","updated":"2023-01-17T12:39:13Z","published":"2023-01-17T12:39:13Z","title":"Syntactically Robust Training on Partially-Observed Data for Open\n  Information Extraction","summary":"  Open Information Extraction models have shown promising results with\nsufficient supervision. However, these models face a fundamental challenge that\nthe syntactic distribution of training data is partially observable in\ncomparison to the real world. In this paper, we propose a syntactically robust\ntraining framework that enables models to be trained on a syntactic-abundant\ndistribution based on diverse paraphrase generation. To tackle the intrinsic\nproblem of knowledge deformation of paraphrasing, two algorithms based on\nsemantic similarity matching and syntactic tree walking are used to restore the\nexpressionally transformed knowledge. The training framework can be generally\napplied to other syntactic partial observable domains. Based on the proposed\nframework, we build a new evaluation set called CaRB-AutoPara, a syntactically\ndiverse dataset consistent with the real-world setting for validating the\nrobustness of the models. Experiments including a thorough analysis show that\nthe performance of the model degrades with the increase of the difference in\nsyntactic distribution, while our framework gives a robust boundary. The source\ncode is publicly available at https://github.com/qijimrc/RobustOIE.\n","authors":["Ji Qi","Yuxiang Chen","Lei Hou","Juanzi Li","Bin Xu"],"pdf_url":"https://arxiv.org/pdf/2301.06841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06825v1","updated":"2023-01-17T12:07:13Z","published":"2023-01-17T12:07:13Z","title":"HanoiT: Enhancing Context-aware Translation via Selective Context","summary":"  Context-aware neural machine translation aims to use the document-level\ncontext to improve translation quality. However, not all words in the context\nare helpful. The irrelevant or trivial words may bring some noise and distract\nthe model from learning the relationship between the current sentence and the\nauxiliary context. To mitigate this problem, we propose a novel end-to-end\nencoder-decoder model with a layer-wise selection mechanism to sift and refine\nthe long document context. To verify the effectiveness of our method, extensive\nexperiments and extra quantitative analysis are conducted on four\ndocument-level machine translation benchmarks. The experimental results\ndemonstrate that our model significantly outperforms previous models on all\ndatasets via the soft selection mechanism.\n","authors":["Jian Yang","Yuwei Yin","Shuming Ma","Liqun Yang","Hongcheng Guo","Haoyang Huang","Dongdong Zhang","Yutao Zeng","Zhoujun Li","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2301.06825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.14769v3","updated":"2023-01-17T10:57:43Z","published":"2021-10-27T21:00:01Z","title":"Detecting Dementia from Speech and Transcripts using Transformers","summary":"  Alzheimer's disease (AD) constitutes a neurodegenerative disease with serious\nconsequences to peoples' everyday lives, if it is not diagnosed early since\nthere is no available cure. Alzheimer's is the most common cause of dementia,\nwhich constitutes a general term for loss of memory. Due to the fact that\ndementia affects speech, existing research initiatives focus on detecting\ndementia from spontaneous speech. However, little work has been done regarding\nthe conversion of speech data to Log-Mel spectrograms and Mel-frequency\ncepstral coefficients (MFCCs) and the usage of pretrained models. Concurrently,\nlittle work has been done in terms of both the usage of transformer networks\nand the way the two modalities, i.e., speech and transcripts, are combined in a\nsingle neural network. To address these limitations, first we represent speech\nsignal as an image and employ several pretrained models, with Vision\nTransformer (ViT) achieving the highest evaluation results. Secondly, we\npropose multimodal models. More specifically, our introduced models include\nGated Multimodal Unit in order to control the influence of each modality\ntowards the final classification and crossmodal attention so as to capture in\nan effective way the relationships between the two modalities. Extensive\nexperiments conducted on the ADReSS Challenge dataset demonstrate the\neffectiveness of the proposed models and their superiority over\nstate-of-the-art approaches.\n","authors":["Loukas Ilias","Dimitris Askounis","John Psarras"],"pdf_url":"https://arxiv.org/pdf/2110.14769v3.pdf","comment":"Computer Speech & Language (Accepted)"},{"id":"http://arxiv.org/abs/2301.06790v1","updated":"2023-01-17T10:31:11Z","published":"2023-01-17T10:31:11Z","title":"2nd Swiss German Speech to Standard German Text Shared Task at SwissText\n  2022","summary":"  We present the results and findings of the 2nd Swiss German speech to\nStandard German text shared task at SwissText 2022. Participants were asked to\nbuild a sentence-level Swiss German speech to Standard German text system\nspecialized on the Grisons dialect. The objective was to maximize the BLEU\nscore on a test set of Grisons speech. 3 teams participated, with the\nbest-performing system achieving a BLEU score of 70.1.\n","authors":["Michel Plüss","Yanick Schraner","Christian Scheller","Manfred Vogel"],"pdf_url":"https://arxiv.org/pdf/2301.06790v1.pdf","comment":"3 pages, 0 figures, to appear in proceedings of SwissText 2022"},{"id":"http://arxiv.org/abs/2301.06774v1","updated":"2023-01-17T09:52:54Z","published":"2023-01-17T09:52:54Z","title":"Temporal Dynamics of Coordinated Online Behavior: Stability, Archetypes,\n  and Influence","summary":"  Large-scale online campaigns, malicious or otherwise, require a significant\ndegree of coordination among participants, which sparked interest in the study\nof coordinated online behavior. State-of-the-art methods for detecting\ncoordinated behavior perform static analyses, disregarding the temporal\ndynamics of coordination. Here, we carry out the first dynamic analysis of\ncoordinated behavior. To reach our goal we build a multiplex temporal network\nand we perform dynamic community detection to identify groups of users that\nexhibited coordinated behaviors in time. Thanks to our novel approach we find\nthat: (i) coordinated communities feature variable degrees of temporal\ninstability; (ii) dynamic analyses are needed to account for such instability,\nand results of static analyses can be unreliable and scarcely representative of\nunstable communities; (iii) some users exhibit distinct archetypal behaviors\nthat have important practical implications; (iv) content and network\ncharacteristics contribute to explaining why users leave and join coordinated\ncommunities. Our results demonstrate the advantages of dynamic analyses and\nopen up new directions of research on the unfolding of online debates, on the\nstrategies of coordinated communities, and on the patterns of online influence.\n","authors":["Serena Tardelli","Leonardo Nizzoli","Maurizio Tesconi","Mauro Conti","Preslav Nakov","Giovanni Da San Martino","Stefano Cresci"],"pdf_url":"https://arxiv.org/pdf/2301.06774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06767v1","updated":"2023-01-17T09:02:15Z","published":"2023-01-17T09:02:15Z","title":"The Recent Advances in Automatic Term Extraction: A survey","summary":"  Automatic term extraction (ATE) is a Natural Language Processing (NLP) task\nthat eases the effort of manually identifying terms from domain-specific\ncorpora by providing a list of candidate terms. As units of knowledge in a\nspecific field of expertise, extracted terms are not only beneficial for\nseveral terminographical tasks, but also support and improve several complex\ndownstream tasks, e.g., information retrieval, machine translation, topic\ndetection, and sentiment analysis. ATE systems, along with annotated datasets,\nhave been studied and developed widely for decades, but recently we observed a\nsurge in novel neural systems for the task at hand. Despite a large amount of\nnew research on ATE, systematic survey studies covering novel neural approaches\nare lacking. We present a comprehensive survey of deep learning-based\napproaches to ATE, with a focus on Transformer-based neural models. The study\nalso offers a comparison between these systems and previous ATE approaches,\nwhich were based on feature engineering and non-neural supervised learning\nalgorithms.\n","authors":["Hanh Thi Hong Tran","Matej Martinc","Jaya Caporusso","Antoine Doucet","Senja Pollak"],"pdf_url":"https://arxiv.org/pdf/2301.06767v1.pdf","comment":"25 pages,4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2301.06758v1","updated":"2023-01-17T08:46:50Z","published":"2023-01-17T08:46:50Z","title":"Tracing and Manipulating Intermediate Values in Neural Math Problem\n  Solvers","summary":"  How language models process complex input that requires multiple steps of\ninference is not well understood. Previous research has shown that information\nabout intermediate values of these inputs can be extracted from the activations\nof the models, but it is unclear where that information is encoded and whether\nthat information is indeed used during inference. We introduce a method for\nanalyzing how a Transformer model processes these inputs by focusing on simple\narithmetic problems and their intermediate values. To trace where information\nabout intermediate values is encoded, we measure the correlation between\nintermediate values and the activations of the model using principal component\nanalysis (PCA). Then, we perform a causal intervention by manipulating model\nweights. This intervention shows that the weights identified via tracing are\nnot merely correlated with intermediate values, but causally related to model\npredictions. Our findings show that the model has a locality to certain\nintermediate values, and this is useful for enhancing the interpretability of\nthe models.\n","authors":["Yuta Matsumoto","Benjamin Heinzerling","Masashi Yoshikawa","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2301.06758v1.pdf","comment":"5 pages, 4 figures, MathNLP"},{"id":"http://arxiv.org/abs/2301.06745v1","updated":"2023-01-17T08:03:32Z","published":"2023-01-17T08:03:32Z","title":"BERT-ERC: Fine-tuning BERT is Enough for Emotion Recognition in\n  Conversation","summary":"  Previous works on emotion recognition in conversation (ERC) follow a two-step\nparadigm, which can be summarized as first producing context-independent\nfeatures via fine-tuning pretrained language models (PLMs) and then analyzing\ncontextual information and dialogue structure information among the extracted\nfeatures. However, we discover that this paradigm has several limitations.\nAccordingly, we propose a novel paradigm, i.e., exploring contextual\ninformation and dialogue structure information in the fine-tuning step, and\nadapting the PLM to the ERC task in terms of input text, classification\nstructure, and training strategy. Furthermore, we develop our model BERT-ERC\naccording to the proposed paradigm, which improves ERC performance in three\naspects, namely suggestive text, fine-grained classification module, and\ntwo-stage training. Compared to existing methods, BERT-ERC achieves substantial\nimprovement on four datasets, indicating its effectiveness and generalization\ncapability. Besides, we also set up the limited resources scenario and the\nonline prediction scenario to approximate real-world scenarios. Extensive\nexperiments demonstrate that the proposed paradigm significantly outperforms\nthe previous one and can be adapted to various scenes.\n","authors":["Xiangyu Qin","Zhiyu Wu","Jinshi Cui","Tingting Zhang","Yanran Li","Jian Luan","Bin Wang","Li Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02828v2","updated":"2023-01-17T08:02:58Z","published":"2023-01-07T11:12:36Z","title":"Why do Nearest Neighbor Language Models Work?","summary":"  Language models (LMs) compute the probability of a text by sequentially\ncomputing a representation of an already-seen context and using this\nrepresentation to predict the next word. Currently, most LMs calculate these\nrepresentations through a neural network consuming the immediate previous\ncontext. However recently, retrieval-augmented LMs have shown to improve over\nstandard neural LMs, by accessing information retrieved from a large datastore,\nin addition to their standard, parametric, next-word prediction. In this paper,\nwe set out to understand why retrieval-augmented language models, and\nspecifically why k-nearest neighbor language models (kNN-LMs) perform better\nthan standard parametric LMs, even when the k-nearest neighbor component\nretrieves examples from the same training set that the LM was originally\ntrained on. To this end, we perform a careful analysis of the various\ndimensions over which kNN-LM diverges from standard LMs, and investigate these\ndimensions one by one. Empirically, we identify three main reasons why kNN-LM\nperforms better than standard LMs: using a different input representation for\npredicting the next tokens, approximate kNN search, and the importance of\nsoftmax temperature for the kNN distribution. Further, we incorporate these\ninsights into the model architecture or the training procedure of the standard\nparametric LM, improving its results without the need for an explicit retrieval\ncomponent. The code is available at https://github.com/frankxu2004/knnlm-why.\n","authors":["Frank F. Xu","Uri Alon","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2301.02828v2.pdf","comment":"Preprint, 21 pages"},{"id":"http://arxiv.org/abs/2204.03428v2","updated":"2023-01-17T07:47:19Z","published":"2022-04-07T13:18:05Z","title":"Detecting Vocal Fatigue with Neural Embeddings","summary":"  Vocal fatigue refers to the feeling of tiredness and weakness of voice due to\nextended utilization. This paper investigates the effectiveness of neural\nembeddings for the detection of vocal fatigue. We compare x-vectors,\nECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English.\nLow-dimensional mappings of the data reveal that neural embeddings capture\ninformation about the change in vocal characteristics of a speaker during\nprolonged voice usage. We show that vocal fatigue can be reliably predicted\nusing all three kinds of neural embeddings after only 50 minutes of continuous\nspeaking when temporal smoothing and normalization are applied to the extracted\nembeddings. We employ support vector machines for classification and achieve\naccuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and\n82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score\nof 76%, when the trained system is applied to a different speaker and recording\nenvironment without any adaptation.\n","authors":["Sebastian P. Bayerl","Dominik Wagner","Ilja Baumann","Korbinian Riedhammer","Tobias Bocklet"],"pdf_url":"https://arxiv.org/pdf/2204.03428v2.pdf","comment":"Accepted for Publication in the Journal of Voice"},{"id":"http://arxiv.org/abs/2301.06736v1","updated":"2023-01-17T07:29:47Z","published":"2023-01-17T07:29:47Z","title":"Syllable Subword Tokens for Open Vocabulary Speech Recognition in\n  Malayalam","summary":"  In a hybrid automatic speech recognition (ASR) system, a pronunciation\nlexicon (PL) and a language model (LM) are essential to correctly retrieve\nspoken word sequences. Being a morphologically complex language, the vocabulary\nof Malayalam is so huge and it is impossible to build a PL and an LM that cover\nall diverse word forms. Usage of subword tokens to build PL and LM, and\ncombining them to form words after decoding, enables the recovery of many out\nof vocabulary words. In this work we investigate the impact of using syllables\nas subword tokens instead of words in Malayalam ASR, and evaluate the relative\nimprovement in lexicon size, model memory requirement and word error rate.\n","authors":["Kavya Manohar","A. R. Jayan","Rajeev Rajan"],"pdf_url":"https://arxiv.org/pdf/2301.06736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06735v1","updated":"2023-01-17T07:29:26Z","published":"2023-01-17T07:29:26Z","title":"Two Stage Contextual Word Filtering for Context bias in Unified\n  Streaming and Non-streaming Transducer","summary":"  It is difficult for an end-to-end (E2E) ASR system to recognize words such as\nnamed entities appearing infrequently in the training data. A widely used\nmethod to mitigate this issue is feeding contextual information into the\nacoustic model. A contextual word list is necessary, which lists all possible\ncontextual word candidates. Previous works have proven that the size and\nquality of the list are crucial. A compact and accurate list can boost the\nperformance significantly. In this paper, we propose an efficient approach to\nobtain a high quality contextual word list for a unified streaming and\nnon-streaming based Conformer-Transducer (C-T) model. Specifically, we make use\nof the phone-level streaming output to first filter the predefined contextual\nword list. During the subsequent non-streaming inference, the words in the\nfiltered list are regarded as contextual information fused into non-casual\nencoder and decoder to generate the final recognition results. Our approach can\ntake advantage of streaming recognition hypothesis, improve the accuracy of the\ncontextual ASR system and speed up the inference process as well. Experiments\non two datasets demonstrates over 20% relative character error rate reduction\n(CERR) comparing to the baseline system. Meanwile, the RTF of our system can be\nstabilized within 0.15 when the size of the contextual word list grows over\n6,000.\n","authors":["Zhanheng Yang","Sining Sun","Xiong Wang","Yike Zhang","Long Ma","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2301.06735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12021v2","updated":"2023-01-17T03:58:21Z","published":"2022-07-25T09:57:23Z","title":"Neural Generation Meets Real People: Building a Social, Informative\n  Open-Domain Dialogue Agent","summary":"  We present Chirpy Cardinal, an open-domain social chatbot. Aiming to be both\ninformative and conversational, our bot chats with users in an authentic,\nemotionally intelligent way. By integrating controlled neural generation with\nscaffolded, hand-written dialogue, we let both the user and bot take turns\ndriving the conversation, producing an engaging and socially fluent experience.\nDeployed in the fourth iteration of the Alexa Prize Socialbot Grand Challenge,\nChirpy Cardinal handled thousands of conversations per day, placing second out\nof nine bots with an average user rating of 3.58/5.\n","authors":["Ethan A. Chi","Ashwin Paranjape","Abigail See","Caleb Chiam","Trenton Chang","Kathleen Kenealy","Swee Kiat Lim","Amelia Hardy","Chetanya Rastogi","Haojun Li","Alexander Iyabor","Yutong He","Hari Sowrirajan","Peng Qi","Kaushik Ram Sadagopan","Nguyet Minh Phu","Dilara Soylu","Jillian Tang","Avanika Narayan","Giovanni Campagna","Christopher D. Manning"],"pdf_url":"https://arxiv.org/pdf/2207.12021v2.pdf","comment":"SIGDIAL '22"},{"id":"http://arxiv.org/abs/2301.04312v2","updated":"2023-01-17T03:22:13Z","published":"2023-01-11T05:21:00Z","title":"Word-Graph2vec: An efficient word embedding approach on word\n  co-occurrence graph using random walk sampling","summary":"  Word embedding has become ubiquitous and is widely used in various text\nmining and natural language processing (NLP) tasks, such as information\nretrieval, semantic analysis, and machine translation, among many others.\nUnfortunately, it is prohibitively expensive to train the word embedding in a\nrelatively large corpus. We propose a graph-based word embedding algorithm,\ncalled Word-Graph2vec, which converts the large corpus into a word\nco-occurrence graph, then takes the word sequence samples from this graph by\nrandomly traveling and trains the word embedding on this sampling corpus in the\nend. We posit that because of the stable vocabulary, relative idioms, and fixed\nexpressions in English, the size and density of the word co-occurrence graph\nchange slightly with the increase in the training corpus. So that\nWord-Graph2vec has stable runtime on the large scale data set, and its\nperformance advantage becomes more and more obvious with the growth of the\ntraining corpus. Extensive experiments conducted on real-world datasets show\nthat the proposed algorithm outperforms traditional Skip-Gram by four-five\ntimes in terms of efficiency, while the error generated by the random walk\nsampling is small.\n","authors":["Wenting Li","Yuanzhe Cai","Jiahong Xue","Zeyu Chen"],"pdf_url":"https://arxiv.org/pdf/2301.04312v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06660v1","updated":"2023-01-17T02:00:31Z","published":"2023-01-17T02:00:31Z","title":"VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19\n  Vaccination on Twitter","summary":"  Vaccine hesitancy has been a common concern, probably since vaccines were\ncreated and, with the popularisation of social media, people started to express\ntheir concerns about vaccines online alongside those posting pro- and\nanti-vaccine content. Predictably, since the first mentions of a COVID-19\nvaccine, social media users posted about their fears and concerns or about\ntheir support and belief into the effectiveness of these rapidly developing\nvaccines. Identifying and understanding the reasons behind public hesitancy\ntowards COVID-19 vaccines is important for policy markers that need to develop\nactions to better inform the population with the aim of increasing vaccine\ntake-up. In the case of COVID-19, where the fast development of the vaccines\nwas mirrored closely by growth in anti-vaxx disinformation, automatic means of\ndetecting citizen attitudes towards vaccination became necessary. This is an\nimportant computational social sciences task that requires data analysis in\norder to gain in-depth understanding of the phenomena at hand. Annotated data\nis also necessary for training data-driven models for more nuanced analysis of\nattitudes towards vaccination. To this end, we created a new collection of over\n3,101 tweets annotated with users' attitudes towards COVID-19 vaccination\n(stance). Besides, we also develop a domain-specific language model (VaxxBERT)\nthat achieves the best predictive performance (73.0 accuracy and 69.3 F1-score)\nas compared to a robust set of baselines. To the best of our knowledge, these\nare the first dataset and model that model vaccine hesitancy as a category\ndistinct from pro- and anti-vaccine stance.\n","authors":["Yida Mu","Mali Jin","Charlie Grimshaw","Carolina Scarton","Kalina Bontcheva","Xingyi Song"],"pdf_url":"https://arxiv.org/pdf/2301.06660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07227v1","updated":"2023-01-17T23:55:50Z","published":"2023-01-17T23:55:50Z","title":"Curriculum Script Distillation for Multilingual Visual Question\n  Answering","summary":"  Pre-trained models with dual and cross encoders have shown remarkable success\nin propelling the landscape of several tasks in vision and language in Visual\nQuestion Answering (VQA). However, since they are limited by the requirements\nof gold annotated data, most of these advancements do not see the light of day\nin other languages beyond English. We aim to address this problem by\nintroducing a curriculum based on the source and target language translations\nto finetune the pre-trained models for the downstream task. Experimental\nresults demonstrate that script plays a vital role in the performance of these\nmodels. Specifically, we show that target languages that share the same script\nperform better (~6%) than other languages and mixed-script code-switched\nlanguages perform better than their counterparts (~5-12%).\n","authors":["Khyathi Raghavi Chandu","Alborz Geramifard"],"pdf_url":"https://arxiv.org/pdf/2301.07227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07209v1","updated":"2023-01-17T22:16:58Z","published":"2023-01-17T22:16:58Z","title":"Learning a Formality-Aware Japanese Sentence Representation","summary":"  While the way intermediate representations are generated in encoder-decoder\nsequence-to-sequence models typically allow them to preserve the semantics of\nthe input sentence, input features such as formality might be left out. On the\nother hand, downstream tasks such as translation would benefit from working\nwith a sentence representation that preserves formality in addition to\nsemantics, so as to generate sentences with the appropriate level of social\nformality -- the difference between speaking to a friend versus speaking with a\nsupervisor. We propose a sequence-to-sequence method for learning a\nformality-aware representation for Japanese sentences, where sentence\ngeneration is conditioned on both the original representation of the input\nsentence, and a side constraint which guides the sentence representation\ntowards preserving formality information. Additionally, we propose augmenting\nthe sentence representation with a learned representation of formality which\nfacilitates the extraction of formality in downstream tasks. We address the\nlack of formality-annotated parallel data by adapting previous works on\nprocedural formality classification of Japanese sentences. Experimental results\nsuggest that our techniques not only helps the decoder recover the formality of\nthe input sentence, but also slightly improves the preservation of input\nsentence semantics.\n","authors":["Henry Li Xinyuan","Ray Lee","Jerry Chen","Kelly Marchisio"],"pdf_url":"https://arxiv.org/pdf/2301.07209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03029v2","updated":"2023-01-17T22:00:52Z","published":"2023-01-08T12:33:58Z","title":"Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case\n  Study using Latent Dirichlet Allocation Method","summary":"  Topic Modelling (TM) is from the research branches of natural language\nunderstanding (NLU) and natural language processing (NLP) that is to facilitate\ninsightful analysis from large documents and datasets, such as a summarisation\nof main topics and the topic changes. This kind of discovery is getting more\npopular in real-life applications due to its impact on big data analytics. In\nthis study, from the social-media and healthcare domain, we apply popular\nLatent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish\nnewspaper articles about Coronavirus. We describe the corpus we created\nincluding 6515 articles, methods applied, and statistics on topic changes over\napproximately 1 year and two months period of time from 17th January 2020 to\n13th March 2021. We hope this work can be an asset for grounding applications\nof topic modelling and can be inspiring for similar case studies in an era with\npandemics, to support socio-economic impact research as well as clinical and\nhealthcare analytics. Our data and source code are openly available at\nhttps://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation\n(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding\n","authors":["Bernadeta Griciūtė","Lifeng Han","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2301.03029v2.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2102.13196v3","updated":"2023-01-17T19:52:28Z","published":"2021-02-25T22:21:30Z","title":"Named Tensor Notation","summary":"  We propose a notation for tensors with named axes, which relieves the author,\nreader, and future implementers of machine learning models from the burden of\nkeeping track of the order of axes and the purpose of each. The notation makes\nit easy to lift operations on low-order tensors to higher order ones, for\nexample, from images to minibatches of images, or from an attention mechanism\nto multiple attention heads.\n  After a brief overview and formal definition of the notation, we illustrate\nit through several examples from modern machine learning, from building blocks\nlike attention and convolution to full models like Transformers and LeNet. We\nthen discuss differential calculus in our notation and compare with some\nalternative notations. Our proposals build on ideas from many previous papers\nand software libraries. We hope that our notation will encourage more authors\nto use named tensors, resulting in clearer papers and more precise\nimplementations.\n","authors":["David Chiang","Alexander M. Rush","Boaz Barak"],"pdf_url":"https://arxiv.org/pdf/2102.13196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07491v1","updated":"2023-01-17T15:52:39Z","published":"2023-01-17T15:52:39Z","title":"The Newsbridge -Telecom SudParis VoxCeleb Speaker Recognition Challenge\n  2022 System Description","summary":"  We describe the system used by our team for the VoxCeleb Speaker Recognition\nChallenge 2022 (VoxSRC 2022) in the speaker diarization track. Our solution was\ndesigned around a new combination of voice activity detection algorithms that\nuses the strengths of several systems. We introduce a novel multi stream\napproach with a decision protocol based on classifiers entropy. We called this\nmethod a multi-stream voice activity detection and used it with standard\nbaseline diarization embeddings, clustering and resegmentation. With this work,\nwe successfully demonstrated that using a strong baseline and working only on\nvoice activity detection, one can achieved close to state-of-theart results.\n","authors":["Yannis Tevissen","Jérôme Boudy","Frédéric Petitpont"],"pdf_url":"https://arxiv.org/pdf/2301.07491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10166v1","updated":"2023-01-17T19:37:19Z","published":"2023-01-17T19:37:19Z","title":"Leveraging Vision-Language Models for Granular Market Change Prediction","summary":"  Predicting future direction of stock markets using the historical data has\nbeen a fundamental component in financial forecasting. This historical data\ncontains the information of a stock in each specific time span, such as the\nopening, closing, lowest, and highest price. Leveraging this data, the future\ndirection of the market is commonly predicted using various time-series models\nsuch as Long-Short Term Memory networks. This work proposes modeling and\npredicting market movements with a fundamentally new approach, namely by\nutilizing image and byte-based number representation of the stock data\nprocessed with the recently introduced Vision-Language models. We conduct a\nlarge set of experiments on the hourly stock data of the German share index and\nevaluate various architectures on stock price prediction using historical stock\ndata. We conduct a comprehensive evaluation of the results with various metrics\nto accurately depict the actual performance of various approaches. Our\nevaluation results show that our novel approach based on representation of\nstock data as text (bytes) and image significantly outperforms strong deep\nlearning-based baselines.\n","authors":["Christopher Wimmer","Navid Rekabsaz"],"pdf_url":"https://arxiv.org/pdf/2301.10166v1.pdf","comment":"Accepted at Multimodal AI for Financial Forecasting Workshop (Muffin)\n  at AAAI 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.07094v1","updated":"2023-01-17T18:59:06Z","published":"2023-01-17T18:59:06Z","title":"Learning Customized Visual Models with Retrieval-Augmented Knowledge","summary":"  Image-text contrastive learning models such as CLIP have demonstrated strong\ntask transfer ability. The high generality and usability of these visual models\nis achieved via a web-scale data collection process to ensure broad concept\ncoverage, followed by expensive pre-training to feed all the knowledge into\nmodel weights. Alternatively, we propose REACT, REtrieval-Augmented\nCusTomization, a framework to acquire the relevant web knowledge to build\ncustomized visual models for target domains. We retrieve the most relevant\nimage-text pairs (~3% of CLIP pre-training data) from the web-scale database as\nexternal knowledge, and propose to customize the model by only training new\nmodualized blocks while freezing all the original weights. The effectiveness of\nREACT is demonstrated via extensive experiments on classification, retrieval,\ndetection and segmentation tasks, including zero, few, and full-shot settings.\nParticularly, on the zero-shot classification task, compared with CLIP, it\nachieves up to 5.4% improvement on ImageNet and 3.7% on the ELEVATER benchmark\n(20 datasets).\n","authors":["Haotian Liu","Kilho Son","Jianwei Yang","Ce Liu","Jianfeng Gao","Yong Jae Lee","Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2301.07094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07093v1","updated":"2023-01-17T18:58:58Z","published":"2023-01-17T18:58:58Z","title":"GLIGEN: Open-Set Grounded Text-to-Image Generation","summary":"  Large-scale text-to-image diffusion models have made amazing advances.\nHowever, the status quo is to use text input alone, which can impede\ncontrollability. In this work, we propose GLIGEN, Grounded-Language-to-Image\nGeneration, a novel approach that builds upon and extends the functionality of\nexisting pre-trained text-to-image diffusion models by enabling them to also be\nconditioned on grounding inputs. To preserve the vast concept knowledge of the\npre-trained model, we freeze all of its weights and inject the grounding\ninformation into new trainable layers via a gated mechanism. Our model achieves\nopen-world grounded text2img generation with caption and bounding box condition\ninputs, and the grounding ability generalizes well to novel spatial\nconfiguration and concepts. GLIGEN's zero-shot performance on COCO and LVIS\noutperforms that of existing supervised layout-to-image baselines by a large\nmargin.\n","authors":["Yuheng Li","Haotian Liu","Qingyang Wu","Fangzhou Mu","Jianwei Yang","Jianfeng Gao","Chunyuan Li","Yong Jae Lee"],"pdf_url":"https://arxiv.org/pdf/2301.07093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07088v1","updated":"2023-01-17T18:53:24Z","published":"2023-01-17T18:53:24Z","title":"Vision Learners Meet Web Image-Text Pairs","summary":"  Most recent self-supervised learning~(SSL) methods are pre-trained on the\nwell-curated ImageNet-1K dataset. In this work, we consider SSL pre-training on\nnoisy web image-text paired data due to the excellent scalability of web data.\nFirst, we conduct a benchmark study of representative SSL pre-training methods\non large-scale web data in a fair condition. Methods include single-modal ones\nsuch as MAE and multi-modal ones such as CLIP. We observe that multi-modal\nmethods cannot outperform single-modal ones on vision transfer learning tasks.\nWe derive an information-theoretical view to explain the benchmarking results,\nwhich provides insights into designing novel vision learners. Inspired by the\nabove explorations, we present a visual representation pre-training method,\nMUlti-modal Generator~(MUG), for scalable web image-text data. MUG achieves\nstate-of-the-art transferring performances on a variety of tasks and shows\npromising scaling behavior. Models and codes will be made public. Demo\navailable at https://huggingface.co/spaces/tennant/MUG_caption\n","authors":["Bingchen Zhao","Quan Cui","Hao Wu","Osamu Yoshie","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07088v1.pdf","comment":"Project page: https://bzhao.me/MUG/"},{"id":"http://arxiv.org/abs/2209.08752v2","updated":"2023-01-17T18:51:50Z","published":"2022-09-19T04:23:20Z","title":"Keypoint-GraspNet: Keypoint-based 6-DoF Grasp Generation from the\n  Monocular RGB-D input","summary":"  Great success has been achieved in the 6-DoF grasp learning from the point\ncloud input, yet the computational cost due to the point set orderlessness\nremains a concern. Alternatively, we explore the grasp generation from the\nRGB-D input in this paper. The proposed solution, Keypoint-GraspNet, detects\nthe projection of the gripper keypoints in the image space and then recover the\nSE(3) poses with a PnP algorithm. A synthetic dataset based on the primitive\nshape and the grasp family is constructed to examine our idea. Metric-based\nevaluation reveals that our method outperforms the baselines in terms of the\ngrasp proposal accuracy, diversity, and the time cost. Finally, robot\nexperiments show high success rate, demonstrating the potential of the idea in\nthe real-world applications.\n","authors":["Yiye Chen","Yunzhi Lin","Patricio Vela"],"pdf_url":"https://arxiv.org/pdf/2209.08752v2.pdf","comment":"Accepted by ICRA2023"},{"id":"http://arxiv.org/abs/2301.07074v1","updated":"2023-01-17T18:36:57Z","published":"2023-01-17T18:36:57Z","title":"SegViz: A Federated Learning Framework for Medical Image Segmentation\n  from Distributed Datasets with Different and Incomplete Annotations","summary":"  Segmentation is one of the primary tasks in the application of deep learning\nin medical imaging, owing to its multiple downstream clinical applications. As\na result, many large-scale segmentation datasets have been curated and released\nfor the segmentation of different anatomical structures. However, these\ndatasets focus on the segmentation of a subset of anatomical structures in the\nbody, therefore, training a model for each dataset would potentially result in\nhundreds of models and thus limit their clinical translational utility.\nFurthermore, many of these datasets share the same field of view but have\ndifferent subsets of annotations, thus making individual dataset annotations\nincomplete. To that end, we developed SegViz, a federated learning framework\nfor aggregating knowledge from distributed medical image segmentation datasets\nwith different and incomplete annotations into a `global` meta-model. The\nSegViz framework was trained to build a single model capable of segmenting both\nliver and spleen aggregating knowledge from both these nodes by aggregating the\nweights after every 10 epochs. The global SegViz model was tested on an\nexternal dataset, Beyond the Cranial Vault (BTCV), comprising both liver and\nspleen annotations using the dice similarity (DS) metric. The baseline\nindividual segmentation models for spleen and liver trained on their respective\ndatasets produced a DS score of 0.834 and 0.878 on the BTCV test set. In\ncomparison, the SegViz model produced comparable mean DS scores of 0.829 and\n0.899 for the segmentation of the spleen and liver respectively. Our results\ndemonstrate SegViz as an essential first step towards training clinically\ntranslatable multi-task segmentation models from distributed datasets with\ndisjoint incomplete annotations with excellent performance.\n","authors":["Adway U. Kanhere","Pranav Kulkarni","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2301.07074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07053v1","updated":"2023-01-17T18:09:44Z","published":"2023-01-17T18:09:44Z","title":"Preserving Privacy in Surgical Video Analysis Using Artificial\n  Intelligence: A Deep Learning Classifier to Identify Out-of-Body Scenes in\n  Endoscopic Videos","summary":"  Objective: To develop and validate a deep learning model for the\nidentification of out-of-body images in endoscopic videos. Background: Surgical\nvideo analysis facilitates education and research. However, video recordings of\nendoscopic surgeries can contain privacy-sensitive information, especially if\nout-of-body scenes are recorded. Therefore, identification of out-of-body\nscenes in endoscopic videos is of major importance to preserve the privacy of\npatients and operating room staff. Methods: A deep learning model was trained\nand evaluated on an internal dataset of 12 different types of laparoscopic and\nrobotic surgeries. External validation was performed on two independent\nmulticentric test datasets of laparoscopic gastric bypass and cholecystectomy\nsurgeries. All images extracted from the video datasets were annotated as\ninside or out-of-body. Model performance was evaluated compared to human ground\ntruth annotations measuring the receiver operating characteristic area under\nthe curve (ROC AUC). Results: The internal dataset consisting of 356,267 images\nfrom 48 videos and the two multicentric test datasets consisting of 54,385 and\n58,349 images from 10 and 20 videos, respectively, were annotated. Compared to\nground truth annotations, the model identified out-of-body images with 99.97%\nROC AUC on the internal test dataset. Mean $\\pm$ standard deviation ROC AUC on\nthe multicentric gastric bypass dataset was 99.94$\\pm$0.07% and 99.71$\\pm$0.40%\non the multicentric cholecystectomy dataset, respectively. Conclusion: The\nproposed deep learning model can reliably identify out-of-body images in\nendoscopic videos. The trained model is publicly shared. This facilitates\nprivacy preservation in surgical video analysis.\n","authors":["Joël L. Lavanchy","Armine Vardazaryan","Pietro Mascagni","AI4SafeChole Consortium","Didier Mutter","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2301.07053v1.pdf","comment":"Jo\\\"el L. Lavanchy and Armine Vardazaryan contributed equally and\n  share first co-authorship"},{"id":"http://arxiv.org/abs/2301.07037v1","updated":"2023-01-17T17:43:46Z","published":"2023-01-17T17:43:46Z","title":"Explain What You See: Open-Ended Segmentation and Recognition of\n  Occluded 3D Objects","summary":"  Local-HDP (for Local Hierarchical Dirichlet Process) is a hierarchical\nBayesian method that has recently been used for open-ended 3D object category\nrecognition. This method has been proven to be efficient in real-time robotic\napplications. However, the method is not robust to a high degree of occlusion.\nWe address this limitation in two steps. First, we propose a novel semantic 3D\nobject-parts segmentation method that has the flexibility of Local-HDP. This\nmethod is shown to be suitable for open-ended scenarios where the number of 3D\nobjects or object parts is not fixed and can grow over time. We show that the\nproposed method has a higher percentage of mean intersection over union, using\na smaller number of learning instances. Second, we integrate this technique\nwith a recently introduced argumentation-based online incremental learning\nmethod, thereby enabling the model to handle a high degree of occlusion. We\nshow that the resulting model produces an explicit set of explanations for the\n3D object category recognition task.\n","authors":["H. Ayoobi","H. Kasaei","M. Cao","R. Verbrugge","B. Verheij"],"pdf_url":"https://arxiv.org/pdf/2301.07037v1.pdf","comment":"Accepted at ICRA 2023 Conference"},{"id":"http://arxiv.org/abs/2210.03205v4","updated":"2023-01-17T17:31:02Z","published":"2022-10-06T20:54:52Z","title":"Synthetic Dataset Generation for Privacy-Preserving Machine Learning","summary":"  Machine Learning (ML) has achieved enormous success in solving a variety of\nproblems in computer vision, speech recognition, object detection, to name a\nfew. The principal reason for this success is the availability of huge datasets\nfor training deep neural networks (DNNs). However, datasets cannot be publicly\nreleased if they contain sensitive information such as medical records, and\ndata privacy becomes a major concern. Encryption methods could be a possible\nsolution, however their deployment on ML applications seriously impacts\nclassification accuracy and results in substantial computational overhead.\nAlternatively, obfuscation techniques could be used, but maintaining a good\ntrade-off between visual privacy and accuracy is challenging. In this paper, we\npropose a method to generate secure synthetic datasets from the original\nprivate datasets. Given a network with Batch Normalization (BN) layers\npretrained on the original dataset, we first record the class-wise BN layer\nstatistics. Next, we generate the synthetic dataset by optimizing random noise\nsuch that the synthetic data match the layer-wise statistical distribution of\noriginal images. We evaluate our method on image classification datasets\n(CIFAR10, ImageNet) and show that synthetic data can be used in place of the\noriginal CIFAR10/ImageNet data for training networks from scratch, producing\ncomparable classification performance. Further, to analyze visual privacy\nprovided by our method, we use Image Quality Metrics and show high degree of\nvisual dissimilarity between the original and synthetic images. Moreover, we\nshow that our proposed method preserves data-privacy under various\nprivacy-leakage attacks including Gradient Matching Attack, Model Memorization\nAttack, and GAN-based Attack.\n","authors":["Efstathia Soufleri","Gobinda Saha","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2210.03205v4.pdf","comment":"There was a bug in the code. An updated version will be archived soon"},{"id":"http://arxiv.org/abs/2206.01714v6","updated":"2023-01-17T17:08:51Z","published":"2022-06-03T17:47:04Z","title":"Compositional Visual Generation with Composable Diffusion Models","summary":"  Large text-guided diffusion models, such as DALLE-2, are able to generate\nstunning photorealistic images given natural language descriptions. While such\nmodels are highly flexible, they struggle to understand the composition of\ncertain concepts, such as confusing the attributes of different objects or\nrelations between objects. In this paper, we propose an alternative structured\napproach for compositional generation using diffusion models. An image is\ngenerated by composing a set of diffusion models, with each of them modeling a\ncertain component of the image. To do this, we interpret diffusion models as\nenergy-based models in which the data distributions defined by the energy\nfunctions may be explicitly combined. The proposed method can generate scenes\nat test time that are substantially more complex than those seen in training,\ncomposing sentence descriptions, object relations, human facial attributes, and\neven generalizing to new combinations that are rarely seen in the real world.\nWe further illustrate how our approach may be used to compose pre-trained\ntext-guided diffusion models and generate photorealistic images containing all\nthe details described in the input descriptions, including the binding of\ncertain object attributes that have been shown difficult for DALLE-2. These\nresults point to the effectiveness of the proposed method in promoting\nstructured generalization for visual generation. Project page:\nhttps://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/\n","authors":["Nan Liu","Shuang Li","Yilun Du","Antonio Torralba","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2206.01714v6.pdf","comment":"ECCV 2022. First three authors contributed equally. Project website:\n  https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/"},{"id":"http://arxiv.org/abs/2301.00243v2","updated":"2023-01-17T16:50:50Z","published":"2022-12-31T16:22:24Z","title":"Approaching Peak Ground Truth","summary":"  Machine learning models are typically evaluated by computing similarity with\nreference annotations and trained by maximizing similarity with such.\nEspecially in the bio-medical domain, annotations are subjective and suffer\nfrom low inter- and intra-rater reliability. Since annotations only reflect the\nannotation entity's interpretation of the real world, this can lead to\nsub-optimal predictions even though the model achieves high similarity scores.\nHere, the theoretical concept of Peak Ground Truth (PGT) is introduced. PGT\nmarks the point beyond which an increase in similarity with the reference\nannotation stops translating to better Real World Model Performance (RWMP).\nAdditionally, a quantitative technique to approximate PGT by computing inter-\nand intra-rater reliability is proposed. Finally, three categories of PGT-aware\nstrategies to evaluate and improve model performance are reviewed.\n","authors":["Florian Kofler","Johannes Wahle","Ivan Ezhov","Sophia Wagner","Rami Al-Maskari","Emilia Gryska","Mihail Todorov","Christina Bukas","Felix Meissen","Tingying Peng","Ali Ertürk","Daniel Rueckert","Rolf Heckemann","Jan Kirschke","Claus Zimmer","Benedikt Wiestler","Bjoern Menze","Marie Piraud"],"pdf_url":"https://arxiv.org/pdf/2301.00243v2.pdf","comment":"7pages, 2 figures (this updates just affiliations and corrects figure\n  rendering)"},{"id":"http://arxiv.org/abs/2301.07002v1","updated":"2023-01-17T16:44:48Z","published":"2023-01-17T16:44:48Z","title":"Opti-CAM: Optimizing saliency maps for interpretability","summary":"  Methods based on class activation maps (CAM) provide a simple mechanism to\ninterpret predictions of convolutional neural networks by using linear\ncombinations of feature maps as saliency maps. By contrast, masking-based\nmethods optimize a saliency map directly in the image space or learn it by\ntraining another network on additional data.\n  In this work we introduce Opti-CAM, combining ideas from CAM-based and\nmasking-based approaches. Our saliency map is a linear combination of feature\nmaps, where weights are optimized per image such that the logit of the masked\nimage for a given class is maximized. We also fix a fundamental flaw in two of\nthe most common evaluation metrics of attribution methods. On several datasets,\nOpti-CAM largely outperforms other CAM-based approaches according to the most\nrelevant classification metrics. We provide empirical evidence supporting that\nlocalization and classifier interpretability are not necessarily aligned.\n","authors":["Hanwei Zhang","Felipe Torres","Ronan Sicre","Yannis Avrithis","Stephane Ayache"],"pdf_url":"https://arxiv.org/pdf/2301.07002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02240v2","updated":"2023-01-17T16:17:57Z","published":"2023-01-05T18:59:52Z","title":"Skip-Attention: Improving Vision Transformers by Paying Less Attention","summary":"  This work aims to improve the efficiency of vision transformers (ViT). While\nViTs use computationally expensive self-attention operations in every layer, we\nidentify that these operations are highly correlated across layers -- a key\nredundancy that causes unnecessary computations. Based on this observation, we\npropose SkipAt, a method to reuse self-attention computation from preceding\nlayers to approximate attention at one or more subsequent layers. To ensure\nthat reusing self-attention blocks across layers does not degrade the\nperformance, we introduce a simple parametric function, which outperforms the\nbaseline transformer's performance while running computationally faster. We\nshow the effectiveness of our method in image classification and\nself-supervised learning on ImageNet-1K, semantic segmentation on ADE20K, image\ndenoising on SIDD, and video denoising on DAVIS. We achieve improved throughput\nat the same-or-higher accuracy levels in all these tasks.\n","authors":["Shashanka Venkataramanan","Amir Ghodrati","Yuki M. Asano","Fatih Porikli","Amirhossein Habibian"],"pdf_url":"https://arxiv.org/pdf/2301.02240v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06975v1","updated":"2023-01-17T15:58:29Z","published":"2023-01-17T15:58:29Z","title":"Vision Based Machine Learning Algorithms for Out-of-Distribution\n  Generalisation","summary":"  There are many computer vision applications including object segmentation,\nclassification, object detection, and reconstruction for which machine learning\n(ML) shows state-of-the-art performance. Nowadays, we can build ML tools for\nsuch applications with real-world accuracy. However, each tool works well\nwithin the domain in which it has been trained and developed. Often, when we\ntrain a model on a dataset in one specific domain and test on another unseen\ndomain known as an out of distribution (OOD) dataset, models or ML tools show a\ndecrease in performance. For instance, when we train a simple classifier on\nreal-world images and apply that model on the same classes but with a different\ndomain like cartoons, paintings or sketches then the performance of ML tools\ndisappoints. This presents serious challenges of domain generalisation (DG),\ndomain adaptation (DA), and domain shifting. To enhance the power of ML tools,\nwe can rebuild and retrain models from scratch or we can perform transfer\nlearning. In this paper, we present a comparison study between vision-based\ntechnologies for domain-specific and domain-generalised methods. In this\nresearch we highlight that simple convolutional neural network (CNN) based deep\nlearning methods perform poorly when they have to tackle domain shifting.\nExperiments are conducted on two popular vision-based benchmarks, PACS and\nOffice-Home. We introduce an implementation pipeline for domain generalisation\nmethods and conventional deep learning models. The outcome confirms that\nCNN-based deep learning models show poor generalisation compare to other\nextensive methods.\n","authors":["Hamza Riaz","Alan F. Smeaton"],"pdf_url":"https://arxiv.org/pdf/2301.06975v1.pdf","comment":"Computing Conference, 22-23 June 2023, London, United Kingdom. 15\n  pages, 5 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2301.06962v1","updated":"2023-01-17T15:36:40Z","published":"2023-01-17T15:36:40Z","title":"Long Range Pooling for 3D Large-Scale Scene Understanding","summary":"  Inspired by the success of recent vision transformers and large kernel design\nin convolutional neural networks (CNNs), in this paper, we analyze and explore\nessential reasons for their success. We claim two factors that are critical for\n3D large-scale scene understanding: a larger receptive field and operations\nwith greater non-linearity. The former is responsible for providing long range\ncontexts and the latter can enhance the capacity of the network. To achieve the\nabove properties, we propose a simple yet effective long range pooling (LRP)\nmodule using dilation max pooling, which provides a network with a large\nadaptive receptive field. LRP has few parameters, and can be readily added to\ncurrent CNNs. Also, based on LRP, we present an entire network architecture,\nLRPNet, for 3D understanding. Ablation studies are presented to support our\nclaims, and show that the LRP module achieves better results than large kernel\nconvolution yet with reduced computation, due to its nonlinearity. We also\ndemonstrate the superiority of LRPNet on various benchmarks: LRPNet performs\nthe best on ScanNet and surpasses other CNN-based methods on S3DIS and\nMatterport3D. Code will be made publicly available.\n","authors":["Xiang-Li Li","Meng-Hao Guo","Tai-Jiang Mu","Ralph R. Martin","Shi-Min Hu"],"pdf_url":"https://arxiv.org/pdf/2301.06962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06961v1","updated":"2023-01-17T15:36:27Z","published":"2023-01-17T15:36:27Z","title":"Mixed Attention with Deep Supervision for Delineation of COVID Infection\n  in Lung CT","summary":"  The COVID-19 pandemic, with its multiple variants, has placed immense\npressure on the global healthcare system. An early effective screening and\ngrading become imperative towards optimizing the limited available resources of\nthe medical facilities. Computed tomography (CT) provides a significant\nnon-invasive screening mechanism for COVID-19 infection. An automated\nsegmentation of the infected volumes in lung CT is expected to significantly\naid in the diagnosis and care of patients. However, an accurate demarcation of\nlesions remains problematic due to their irregular structure and location(s)\nwithin the lung. A novel deep learning architecture, Mixed Attention Deeply\nSupervised Network (MiADS-Net), is proposed for delineating the infected\nregions of the lung from CT images. Incorporating dilated convolutions with\nvarying dilation rates, into a mixed attention framework, allows capture of\nmulti-scale features towards improved segmentation of lesions having different\nsizes and textures. Mixed attention helps prioritise relevant feature maps to\nbe probed, along with those regions containing crucial information within these\nmaps. Deep supervision facilitates discovery of robust and discriminatory\ncharacteristics in the hidden layers at shallower levels, while overcoming the\nvanishing gradient. This is followed by estimating the severity of the disease,\nbased on the ratio of the area of infected region in each lung with respect to\nits entire volume. Experimental results, on three publicly available datasets,\nindicate that the MiADS-Net outperforms several state-of-the-art architectures\nin the COVID-19 lesion segmentation task; particularly in defining structures\ninvolving complex geometries.\n","authors":["Pallabi Dutta","Sushmita Mitra"],"pdf_url":"https://arxiv.org/pdf/2301.06961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06958v1","updated":"2023-01-17T15:32:59Z","published":"2023-01-17T15:32:59Z","title":"Masked Visual Reconstruction in Language Semantic Space","summary":"  Both masked image modeling (MIM) and natural language supervision have\nfacilitated the progress of transferable visual pre-training. In this work, we\nseek the synergy between two paradigms and study the emerging properties when\nMIM meets natural language supervision. To this end, we present a novel masked\nvisual Reconstruction In Language semantic Space (RILS) pre-training framework,\nin which sentence representations, encoded by the text encoder, serve as\nprototypes to transform the vision-only signals into patch-sentence\nprobabilities as semantically meaningful MIM reconstruction targets. The vision\nmodels can therefore capture useful components with structured information by\npredicting proper semantic of masked tokens. Better visual representations\ncould, in turn, improve the text encoder via the image-text alignment\nobjective, which is essential for the effective MIM target transformation.\nExtensive experimental results demonstrate that our method not only enjoys the\nbest of previous MIM and CLIP but also achieves further improvements on various\ntasks due to their mutual benefits. RILS exhibits advanced transferability on\ndownstream classification, detection, and segmentation, especially for low-shot\nregimes. Code will be made available at https://github.com/hustvl/RILS.\n","authors":["Shusheng Yang","Yixiao Ge","Kun Yi","Dian Li","Ying Shan","Xiaohu Qie","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07989v2","updated":"2023-01-17T15:10:09Z","published":"2022-09-16T14:54:57Z","title":"CurveFormer: 3D Lane Detection by Curve Propagation with Curve Queries\n  and Attention","summary":"  3D lane detection is an integral part of autonomous driving systems. Previous\nCNN and Transformer-based methods usually first generate a bird's-eye-view\n(BEV) feature map from the front view image, and then use a sub-network with\nBEV feature map as input to predict 3D lanes. Such approaches require an\nexplicit view transformation between BEV and front view, which itself is still\na challenging problem. In this paper, we propose CurveFormer, a single-stage\nTransformer-based method that directly calculates 3D lane parameters and can\ncircumvent the difficult view transformation step. Specifically, we formulate\n3D lane detection as a curve propagation problem by using curve queries. A 3D\nlane query is represented by a dynamic and ordered anchor point set. In this\nway, queries with curve representation in Transformer decoder iteratively\nrefine the 3D lane detection results. Moreover, a curve cross-attention module\nis introduced to compute the similarities between curve queries and image\nfeatures. Additionally, a context sampling module that can capture more\nrelative image features of a curve query is provided to further boost the 3D\nlane detection performance. We evaluate our method for 3D lane detection on\nboth synthetic and real-world datasets, and the experimental results show that\nour method achieves promising performance compared with the state-of-the-art\napproaches. The effectiveness of each component is validated via ablation\nstudies as well.\n","authors":["Yifeng Bai","Zhirong Chen","Zhangjie Fu","Lang Peng","Pengpeng Liang","Erkang Cheng"],"pdf_url":"https://arxiv.org/pdf/2209.07989v2.pdf","comment":"Accepted at the IEEE Conference on Robotics and Automation, ICRA 2023"},{"id":"http://arxiv.org/abs/2301.06944v1","updated":"2023-01-17T15:08:32Z","published":"2023-01-17T15:08:32Z","title":"DR-WLC: Dimensionality Reduction cognition for object detection and pose\n  estimation by Watching, Learning and Checking","summary":"  Object detection and pose estimation are difficult tasks in robotics and\nautonomous driving. Existing object detection and pose estimation methods\nmostly adopt the same-dimensional data for training. For example, 2D object\ndetection usually requires a large amount of 2D annotation data with high cost.\nUsing high-dimensional information to supervise lower-dimensional tasks is a\nfeasible way to reduce datasets size. In this work, the DR-WLC, a\ndimensionality reduction cognitive model, which can perform both object\ndetection and pose estimation tasks at the same time is proposed. The model\nonly requires 3D model of objects and unlabeled environment images (with or\nwithout objects) to finish the training. In addition, a bounding boxes\ngeneration strategy is also proposed to build the relationship between 3D model\nand 2D object detection task. Experiments show that our method can qualify the\nwork without any manual annotations and it is easy to deploy for practical\napplications. Source code is at https://github.com/IN2-ViAUn/DR-WLC.\n","authors":["Yu Gao","Xi Xu","Tianji Jiang","Siyuan Chen","Yi Yang","Yufeng Yue","Mengyin Fu"],"pdf_url":"https://arxiv.org/pdf/2301.06944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06943v1","updated":"2023-01-17T15:07:20Z","published":"2023-01-17T15:07:20Z","title":"Self-supervised Domain Adaptation for Breaking the Limits of Low-quality\n  Fundus Image Quality Enhancement","summary":"  Retinal fundus images have been applied for the diagnosis and screening of\neye diseases, such as Diabetic Retinopathy (DR) or Diabetic Macular Edema\n(DME). However, both low-quality fundus images and style inconsistency\npotentially increase uncertainty in the diagnosis of fundus disease and even\nlead to misdiagnosis by ophthalmologists. Most of the existing image\nenhancement methods mainly focus on improving the image quality by leveraging\nthe guidance of high-quality images, which is difficult to be collected in\nmedical applications. In this paper, we tackle image quality enhancement in a\nfully unsupervised setting, i.e., neither paired images nor high-quality\nimages. To this end, we explore the potential of the self-supervised task for\nimproving the quality of fundus images without the requirement of high-quality\nreference images. Specifically, we construct multiple patch-wise domains via an\nauxiliary pre-trained quality assessment network and a style clustering. To\nachieve robust low-quality image enhancement and address style inconsistency,\nwe formulate two self-supervised domain adaptation tasks to disentangle the\nfeatures of image content, low-quality factor and style information by\nexploring intrinsic supervision signals within the low-quality images.\nExtensive experiments are conducted on EyeQ and Messidor datasets, and results\nshow that our DASQE method achieves new state-of-the-art performance when only\nlow-quality images are available.\n","authors":["Qingshan Hou","Peng Cao","Jiaqi Wang","Xiaoli Liu","Jinzhu Yang","Osmar R. Zaiane"],"pdf_url":"https://arxiv.org/pdf/2301.06943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06910v1","updated":"2023-01-17T14:25:40Z","published":"2023-01-17T14:25:40Z","title":"BSNet: Lane Detection via Draw B-spline Curves Nearby","summary":"  Curve-based methods are one of the classic lane detection methods. They learn\nthe holistic representation of lane lines, which is intuitive and concise.\nHowever, their performance lags behind the recent state-of-the-art methods due\nto the limitation of their lane representation and optimization. In this paper,\nwe revisit the curve-based lane detection methods from the perspectives of the\nlane representations' globality and locality. The globality of lane\nrepresentation is the ability to complete invisible parts of lanes with visible\nparts. The locality of lane representation is the ability to modify lanes\nlocally which can simplify parameter optimization. Specifically, we first\npropose to exploit the b-spline curve to fit lane lines since it meets the\nlocality and globality. Second, we design a simple yet efficient network BSNet\nto ensure the acquisition of global and local features. Third, we propose a new\ncurve distance to make the lane detection optimization objective more\nreasonable and alleviate ill-conditioned problems. The proposed methods achieve\nstate-of-the-art performance on the Tusimple, CULane, and LLAMAS datasets,\nwhich dramatically improved the accuracy of curve-based methods in the lane\ndetection task while running far beyond real-time (197FPS).\n","authors":["Haoxin Chen","Mengmeng Wang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2301.06910v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.06892v1","updated":"2023-01-17T13:58:17Z","published":"2023-01-17T13:58:17Z","title":"Cooperation Learning Enhanced Colonic Polyp Segmentation Based on\n  Transformer-CNN Fusion","summary":"  Traditional segmentation methods for colonic polyps are mainly designed based\non low-level features. They could not accurately extract the location of small\ncolonic polyps. Although the existing deep learning methods can improve the\nsegmentation accuracy, their effects are still unsatisfied. To meet the above\nchallenges, we propose a hybrid network called Fusion-Transformer-HardNetMSEG\n(i.e., Fu-TransHNet) in this study. Fu-TransHNet uses deep learning of\ndifferent mechanisms to fuse each other and is enhanced with multi-view\ncollaborative learning techniques. Firstly, the Fu-TransHNet utilizes the\nTransformer branch and the CNN branch to realize the global feature learning\nand local feature learning, respectively. Secondly, a fusion module is designed\nto integrate the features from two branches. The fusion module consists of two\nparts: 1) the Global-Local Feature Fusion (GLFF) part and 2) the Dense Fusion\nof Multi-scale features (DFM) part. The former is built to compensate the\nfeature information mission from two branches at the same scale; the latter is\nconstructed to enhance the feature representation. Thirdly, the above two\nbranches and fusion modules utilize multi-view cooperative learning techniques\nto obtain their respective weights that denote their importance and then make a\nfinal decision comprehensively. Experimental results showed that the\nFu-TransHNet network was superior to the existing methods on five widely used\nbenchmark datasets. In particular, on the ETIS-LaribPolypDB dataset containing\nmany small-target colonic polyps, the mDice obtained by Fu-TransHNet were 12.4%\nand 6.2% higher than the state-of-the-art methods HardNet-MSEG and TransFuse-s,\nrespectively.\n","authors":["Yuanyuan Wang","Zhaohong Deng","Qiongdan Lou","Shudong Hu","Kup-sze Choi","Shitong Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06892v1.pdf","comment":"This paper has been submitted to a journal"},{"id":"http://arxiv.org/abs/2301.06882v1","updated":"2023-01-17T13:39:12Z","published":"2023-01-17T13:39:12Z","title":"Multi-Biometric Fuzzy Vault based on Face and Fingerprints","summary":"  The fuzzy vault scheme has been established as cryptographic primitive\nsuitable for privacy-preserving biometric authentication. To improve accuracy\nand privacy protection, biometric information of multiple characteristics can\nbe fused at feature level prior to locking it in a fuzzy vault. We construct a\nmulti-biometric fuzzy vault based on face and multiple fingerprints. On a\nmulti-biometric database constructed from the FRGCv2 face and the MCYT-100\nfingerprint databases, a perfect recognition accuracy is achieved at a false\naccept security above 30 bits. Further, we provide a formalisation of\nfeature-level fusion in multi-biometric fuzzy vaults, on the basis of which\nrelevant security issues are elaborated. Said security issues, for which we\ndefine countermeasures, are commonly ignored and may impair the overall\nsystem's security.\n","authors":["Christian Rathgeb","Benjamin Tams","Johannes Merkle","Vanessa Nesterowicz","Ulrike Korte","Matthias Neu"],"pdf_url":"https://arxiv.org/pdf/2301.06882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11554v3","updated":"2023-01-17T13:33:13Z","published":"2022-07-23T17:00:45Z","title":"3DOS: Towards 3D Open Set Learning -- Benchmarking and Understanding\n  Semantic Novelty Detection on Point Clouds","summary":"  In recent years there has been significant progress in the field of 3D\nlearning on classification, detection and segmentation problems. The vast\nmajority of the existing studies focus on canonical closed-set conditions,\nneglecting the intrinsic open nature of the real-world. This limits the\nabilities of robots and autonomous systems involved in safety-critical\napplications that require managing novel and unknown signals. In this context\nexploiting 3D data can be a valuable asset since it provides rich information\nabout the geometry of perceived objects and scenes. With this paper we provide\nthe first broad study on 3D Open Set learning. We introduce 3DOS: a novel\ntestbed for semantic novelty detection that considers several settings with\nincreasing difficulties in terms of semantic (category) shift, and covers both\nin-domain (synthetic-to-synthetic, real-to-real) and cross-domain\n(synthetic-to-real) scenarios. Moreover, we investigate the related 2D Open Set\nliterature to understand if and how its recent improvements are effective on 3D\ndata. Our extensive benchmark positions several algorithms in the same coherent\npicture, revealing their strengths and limitations. The results of our analysis\nmay serve as a reliable foothold for future tailored 3D Open Set methods.\n","authors":["Antonio Alliegro","Francesco Cappio Borlino","Tatiana Tommasi"],"pdf_url":"https://arxiv.org/pdf/2207.11554v3.pdf","comment":"Accepted by NeurIPS 2022 Datasets and Benchmarks Track. Code:\n  https://github.com/antoalli/3D_OS"},{"id":"http://arxiv.org/abs/2301.06874v1","updated":"2023-01-17T13:30:03Z","published":"2023-01-17T13:30:03Z","title":"Training Methods of Multi-label Prediction Classifiers for Hyperspectral\n  Remote Sensing Images","summary":"  With their combined spectral depth and geometric resolution, hyperspectral\nremote sensing images embed a wealth of complex, non-linear information that\nchallenges traditional computer vision techniques. Yet, deep learning methods\nknown for their representation learning capabilities prove more suitable for\nhandling such complexities. Unlike applications that focus on single-label,\npixel-level classification methods for hyperspectral remote sensing images, we\npropose a multi-label, patch-level classification method based on a\ntwo-component deep-learning network. We use patches of reduced spatial\ndimension and a complete spectral depth extracted from the remote sensing\nimages. Additionally, we investigate three training schemes for our network:\nIterative, Joint, and Cascade. Experiments suggest that the Joint scheme is the\nbest-performing scheme; however, its application requires an expensive search\nfor the best weight combination of the loss constituents. The Iterative scheme\nenables the sharing of features between the two parts of the network at the\nearly stages of training. It performs better on complex data with multi-labels.\nFurther experiments showed that methods designed with different architectures\nperformed well when trained on patches extracted and labeled according to our\nsampling method.\n","authors":["Salma Haidar","José Oramas"],"pdf_url":"https://arxiv.org/pdf/2301.06874v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06871v1","updated":"2023-01-17T13:27:53Z","published":"2023-01-17T13:27:53Z","title":"Denoising Diffusion Probabilistic Models as a Defense against\n  Adversarial Attacks","summary":"  Neural Networks are infamously sensitive to small perturbations in their\ninputs, making them vulnerable to adversarial attacks. This project evaluates\nthe performance of Denoising Diffusion Probabilistic Models (DDPM) as a\npurification technique to defend against adversarial attacks. This works by\nadding noise to an adversarial example before removing it through the reverse\nprocess of the diffusion model. We evaluate the approach on the PatchCamelyon\ndata set for histopathologic scans of lymph node sections and find an\nimprovement of the robust accuracy by up to 88\\% of the original model's\naccuracy, constituting a considerable improvement over the vanilla model and\nour baselines. The project code is located at\nhttps://github.com/ankile/Adversarial-Diffusion.\n","authors":["Lars Lien Ankile","Anna Midgley","Sebastian Weisshaar"],"pdf_url":"https://arxiv.org/pdf/2301.06871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06869v1","updated":"2023-01-17T13:25:11Z","published":"2023-01-17T13:25:11Z","title":"SAT: Size-Aware Transformer for 3D Point Cloud Semantic Segmentation","summary":"  Transformer models have achieved promising performances in point cloud\nsegmentation. However, most existing attention schemes provide the same feature\nlearning paradigm for all points equally and overlook the enormous difference\nin size among scene objects. In this paper, we propose the Size-Aware\nTransformer (SAT) that can tailor effective receptive fields for objects of\ndifferent sizes. Our SAT achieves size-aware learning via two steps: introduce\nmulti-scale features to each attention layer and allow each point to choose its\nattentive fields adaptively. It contains two key designs: the Multi-Granularity\nAttention (MGA) scheme and the Re-Attention module. The MGA addresses two\nchallenges: efficiently aggregating tokens from distant areas and preserving\nmulti-scale features within one attention layer. Specifically, point-voxel\ncross attention is proposed to address the first challenge, and the shunted\nstrategy based on the standard multi-head self attention is applied to solve\nthe second. The Re-Attention module dynamically adjusts the attention scores to\nthe fine- and coarse-grained features output by MGA for each point. Extensive\nexperimental results demonstrate that SAT achieves state-of-the-art\nperformances on S3DIS and ScanNetV2 datasets. Our SAT also achieves the most\nbalanced performance on categories among all referred methods, which\nillustrates the superiority of modelling categories of different sizes. Our\ncode and model will be released after the acceptance of this paper.\n","authors":["Junjie Zhou","Yongping Xiong","Chinwai Chiu","Fangyu Liu","Xiangyang Gong"],"pdf_url":"https://arxiv.org/pdf/2301.06869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06866v1","updated":"2023-01-17T13:20:21Z","published":"2023-01-17T13:20:21Z","title":"Building Scalable Video Understanding Benchmarks through Sports","summary":"  Existing benchmarks for evaluating long video understanding falls short on\nmultiple aspects, either lacking in scale or quality of annotations. These\nlimitations arise from the difficulty in collecting dense annotations for long\nvideos (e.g. actions, dialogues, etc.), which are often obtained by manually\nlabeling many frames per second. In this work, we introduce an automated\nAnnotation and Video Stream Alignment Pipeline (abbreviated ASAP). We\ndemonstrate the generality of ASAP by aligning unlabeled videos of four\ndifferent sports (Cricket, Football, Basketball, and American Football) with\ntheir corresponding dense annotations (i.e. commentary) freely available on the\nweb. Our human studies indicate that ASAP can align videos and annotations with\nhigh fidelity, precision, and speed. We then leverage ASAP scalability to\ncreate LCric, a large-scale long video understanding benchmark, with over 1000\nhours of densely annotated long Cricket videos (with an average sample length\nof 50 mins) collected at virtually zero annotation cost. We benchmark and\nanalyze state-of-the-art video understanding models on LCric through a large\nset of compositional multi-choice and regression queries. We establish a human\nbaseline that indicates significant room for new research to explore.\n","authors":["Aniket Agarwal","Alex Zhang","Karthik Narasimhan","Igor Gilitschenski","Vishvak Murahari","Yash Kant"],"pdf_url":"https://arxiv.org/pdf/2301.06866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06855v1","updated":"2023-01-17T12:59:58Z","published":"2023-01-17T12:59:58Z","title":"Event-based Shape from Polarization","summary":"  State-of-the-art solutions for Shape-from-Polarization (SfP) suffer from a\nspeed-resolution tradeoff: they either sacrifice the number of polarization\nangles measured or necessitate lengthy acquisition times due to framerate\nconstraints, thus compromising either accuracy or latency. We tackle this\ntradeoff using event cameras. Event cameras operate at microseconds resolution\nwith negligible motion blur, and output a continuous stream of events that\nprecisely measures how light changes over time asynchronously. We propose a\nsetup that consists of a linear polarizer rotating at high-speeds in front of\nan event camera. Our method uses the continuous event stream caused by the\nrotation to reconstruct relative intensities at multiple polarizer angles.\nExperiments demonstrate that our method outperforms physics-based baselines\nusing frames, reducing the MAE by 25% in synthetic and real-world dataset. In\nthe real world, we observe, however, that the challenging conditions (i.e.,\nwhen few events are generated) harm the performance of physics-based solutions.\nTo overcome this, we propose a learning-based approach that learns to estimate\nsurface normals even at low event-rates, improving the physics-based approach\nby 52% on the real world dataset. The proposed system achieves an acquisition\nspeed equivalent to 50 fps (>twice the framerate of the commercial polarization\nsensor) while retaining the spatial resolution of 1MP. Our evaluation is based\non the first large-scale dataset for event-based SfP\n","authors":["Manasi Muglikar","Leonard Bauersfeld","Diederik Paul Moeys","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2301.06855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06844v1","updated":"2023-01-17T12:42:58Z","published":"2023-01-17T12:42:58Z","title":"USER: Unified Semantic Enhancement with Momentum Contrast for Image-Text\n  Retrieval","summary":"  As a fundamental and challenging task in bridging language and vision\ndomains, Image-Text Retrieval (ITR) aims at searching for the target instances\nthat are semantically relevant to the given query from the other modality, and\nits key challenge is to measure the semantic similarity across different\nmodalities. Although significant progress has been achieved, existing\napproaches typically suffer from two major limitations: (1) It hurts the\naccuracy of the representation by directly exploiting the bottom-up attention\nbased region-level features where each region is equally treated. (2) It limits\nthe scale of negative sample pairs by employing the mini-batch based end-to-end\ntraining mechanism. To address these limitations, we propose a Unified Semantic\nEnhancement Momentum Contrastive Learning (USER) method for ITR. Specifically,\nwe delicately design two simple but effective Global representation based\nSemantic Enhancement (GSE) modules. One learns the global representation via\nthe self-attention algorithm, noted as Self-Guided Enhancement (SGE) module.\nThe other module benefits from the pre-trained CLIP module, which provides a\nnovel scheme to exploit and transfer the knowledge from an off-the-shelf model,\nnoted as CLIP-Guided Enhancement (CGE) module. Moreover, we incorporate the\ntraining mechanism of MoCo into ITR, in which two dynamic queues are employed\nto enrich and enlarge the scale of negative sample pairs. Meanwhile, a Unified\nTraining Objective (UTO) is developed to learn from mini-batch based and\ndynamic queue based samples. Extensive experiments on the benchmark MSCOCO and\nFlickr30K datasets demonstrate the superiority of both retrieval accuracy and\ninference efficiency. Our source code will be released at\nhttps://github.com/zhangy0822/USER.\n","authors":["Yan Zhang","Zhong Ji","Di Wang","Yanwei Pang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2301.06844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09135v2","updated":"2023-01-17T11:33:34Z","published":"2022-07-19T09:11:43Z","title":"Shrinking the Semantic Gap: Spatial Pooling of Local Moment Invariants\n  for Copy-Move Forgery Detection","summary":"  Copy-move forgery is a manipulation of copying and pasting specific patches\nfrom and to an image, with potentially illegal or unethical uses. Recent\nadvances in the forensic methods for copy-move forgery have shown increasing\nsuccess in detection accuracy and robustness. However, for images with high\nself-similarity or strong signal corruption, the existing algorithms often\nexhibit inefficient processes and unreliable results. This is mainly due to the\ninherent semantic gap between low-level visual representation and high-level\nsemantic concept. In this paper, we present a very first study of trying to\nmitigate the semantic gap problem in copy-move forgery detection, with spatial\npooling of local moment invariants for midlevel image representation. Our\ndetection method expands the traditional works on two aspects: 1) we introduce\nthe bag-of-visual-words model into this field for the first time, may meaning a\nnew perspective of forensic study; 2) we propose a word-to-phrase feature\ndescription and matching pipeline, covering the spatial structure and visual\nsaliency information of digital images. Extensive experimental results show the\nsuperior performance of our framework over state-of-the-art algorithms in\novercoming the related problems caused by the semantic gap.\n","authors":["Chao Wang","Zhiqiu Huang","Shuren Qi","Yaoshen Yu","Guohua Shen","Yushu Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.09135v2.pdf","comment":"Accepted by IEEE Transactions on Information Forensics and Security,\n  2023, https://ieeexplore.ieee.org/document/10007894"},{"id":"http://arxiv.org/abs/2208.04952v2","updated":"2023-01-17T11:14:40Z","published":"2022-08-09T10:49:40Z","title":"Continual Prune-and-Select: Class-incremental learning with specialized\n  subnetworks","summary":"  The human brain is capable of learning tasks sequentially mostly without\nforgetting. However, deep neural networks (DNNs) suffer from catastrophic\nforgetting when learning one task after another. We address this challenge\nconsidering a class-incremental learning scenario where the DNN sees test data\nwithout knowing the task from which this data originates. During training,\nContinual-Prune-and-Select (CP&S) finds a subnetwork within the DNN that is\nresponsible for solving a given task. Then, during inference, CP&S selects the\ncorrect subnetwork to make predictions for that task. A new task is learned by\ntraining available neuronal connections of the DNN (previously untrained) to\ncreate a new subnetwork by pruning, which can include previously trained\nconnections belonging to other subnetwork(s) because it does not update shared\nconnections. This enables to eliminate catastrophic forgetting by creating\nspecialized regions in the DNN that do not conflict with each other while still\nallowing knowledge transfer across them. The CP&S strategy is implemented with\ndifferent subnetwork selection strategies, revealing superior performance to\nstate-of-the-art continual learning methods tested on various datasets\n(CIFAR-100, CUB-200-2011, ImageNet-100 and ImageNet-1000). In particular, CP&S\nis capable of sequentially learning 10 tasks from ImageNet-1000 keeping an\naccuracy around 94% with negligible forgetting, a first-of-its-kind result in\nclass-incremental learning. To the best of the authors' knowledge, this\nrepresents an improvement in accuracy above 10% when compared to the best\nalternative method.\n","authors":["Aleksandr Dekhovich","David M. J. Tax","Marcel H. F. Sluiter","Miguel A. Bessa"],"pdf_url":"https://arxiv.org/pdf/2208.04952v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.07038v3","updated":"2023-01-17T11:08:41Z","published":"2022-06-14T17:57:11Z","title":"AnimeSR: Learning Real-World Super-Resolution Models for Animation\n  Videos","summary":"  This paper studies the problem of real-world video super-resolution (VSR) for\nanimation videos, and reveals three key improvements for practical animation\nVSR. First, recent real-world super-resolution approaches typically rely on\ndegradation simulation using basic operators without any learning capability,\nsuch as blur, noise, and compression. In this work, we propose to learn such\nbasic operators from real low-quality animation videos, and incorporate the\nlearned ones into the degradation generation pipeline. Such\nneural-network-based basic operators could help to better capture the\ndistribution of real degradations. Second, a large-scale high-quality animation\nvideo dataset, AVC, is built to facilitate comprehensive training and\nevaluations for animation VSR. Third, we further investigate an efficient\nmulti-scale network structure. It takes advantage of the efficiency of\nunidirectional recurrent networks and the effectiveness of sliding-window-based\nmethods. Thanks to the above delicate designs, our method, AnimeSR, is capable\nof restoring real-world low-quality animation videos effectively and\nefficiently, achieving superior performance to previous state-of-the-art\nmethods. Codes and models are available at\nhttps://github.com/TencentARC/AnimeSR.\n","authors":["Yanze Wu","Xintao Wang","Gen Li","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2206.07038v3.pdf","comment":"NeurIPS 2022. Codes and models are available at\n  https://github.com/TencentARC/AnimeSR"},{"id":"http://arxiv.org/abs/2110.14769v3","updated":"2023-01-17T10:57:43Z","published":"2021-10-27T21:00:01Z","title":"Detecting Dementia from Speech and Transcripts using Transformers","summary":"  Alzheimer's disease (AD) constitutes a neurodegenerative disease with serious\nconsequences to peoples' everyday lives, if it is not diagnosed early since\nthere is no available cure. Alzheimer's is the most common cause of dementia,\nwhich constitutes a general term for loss of memory. Due to the fact that\ndementia affects speech, existing research initiatives focus on detecting\ndementia from spontaneous speech. However, little work has been done regarding\nthe conversion of speech data to Log-Mel spectrograms and Mel-frequency\ncepstral coefficients (MFCCs) and the usage of pretrained models. Concurrently,\nlittle work has been done in terms of both the usage of transformer networks\nand the way the two modalities, i.e., speech and transcripts, are combined in a\nsingle neural network. To address these limitations, first we represent speech\nsignal as an image and employ several pretrained models, with Vision\nTransformer (ViT) achieving the highest evaluation results. Secondly, we\npropose multimodal models. More specifically, our introduced models include\nGated Multimodal Unit in order to control the influence of each modality\ntowards the final classification and crossmodal attention so as to capture in\nan effective way the relationships between the two modalities. Extensive\nexperiments conducted on the ADReSS Challenge dataset demonstrate the\neffectiveness of the proposed models and their superiority over\nstate-of-the-art approaches.\n","authors":["Loukas Ilias","Dimitris Askounis","John Psarras"],"pdf_url":"https://arxiv.org/pdf/2110.14769v3.pdf","comment":"Computer Speech & Language (Accepted)"},{"id":"http://arxiv.org/abs/2301.06793v1","updated":"2023-01-17T10:39:39Z","published":"2023-01-17T10:39:39Z","title":"Acute ischemic stroke lesion segmentation in non-contrast CT images\n  using 3D convolutional neural networks","summary":"  In this paper, an automatic algorithm aimed at volumetric segmentation of\nacute ischemic stroke lesion in non-contrast computed tomography brain 3D\nimages is proposed. Our deep-learning approach is based on the popular 3D U-Net\nconvolutional neural network architecture, which was modified by adding the\nsqueeze-and-excitation blocks and residual connections. Robust pre-processing\nmethods were implemented to improve the segmentation accuracy. Moreover, a\nspecific patches sampling strategy was used to address the large size of\nmedical images, to smooth out the effect of the class imbalance problem and to\nstabilize neural network training. All experiments were performed using\nfive-fold cross-validation on the dataset containing non-contrast computed\ntomography volumetric brain scans of 81 patients diagnosed with acute ischemic\nstroke. Two radiology experts manually segmented images independently and then\nverified the labeling results for inconsistencies. The quantitative results of\nthe proposed algorithm and obtained segmentation were measured by the Dice\nsimilarity coefficient, sensitivity, specificity and precision metrics. Our\nproposed model achieves an average Dice of $0.628\\pm0.033$, sensitivity of\n$0.699\\pm0.039$, specificity of $0.9965\\pm0.0016$ and precision of\n$0.619\\pm0.036$, showing promising segmentation results.\n","authors":["A. V. Dobshik","S. K. Verbitskiy","I. A. Pestunov","K. M. Sherman","Yu. N. Sinyavskiy","A. A. Tulupov","V. B. Berikov"],"pdf_url":"https://arxiv.org/pdf/2301.06793v1.pdf","comment":"18 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2208.13404v2","updated":"2023-01-17T10:23:09Z","published":"2022-08-29T07:30:35Z","title":"Progressive Self-Distillation for Ground-to-Aerial Perception Knowledge\n  Transfer","summary":"  We study a practical yet hasn't been explored problem: how a drone can\nperceive in an environment from different flight heights. Unlike autonomous\ndriving, where the perception is always conducted from a ground viewpoint, a\nflying drone may flexibly change its flight height due to specific tasks,\nrequiring the capability for viewpoint invariant perception. Tackling the such\nproblem with supervised learning will incur tremendous costs for data\nannotation of different flying heights. On the other hand, current\nsemi-supervised learning methods are not effective under viewpoint differences.\nIn this paper, we introduce the ground-to-aerial perception knowledge transfer\nand propose a progressive semi-supervised learning framework that enables drone\nperception using only labeled data of ground viewpoint and unlabeled data of\nflying viewpoints. Our framework has four core components: i) a dense viewpoint\nsampling strategy that splits the range of vertical flight height into a set of\nsmall pieces with evenly-distributed intervals, ii) nearest neighbor\npseudo-labeling that infers labels of the nearest neighbor viewpoint with a\nmodel learned on the preceding viewpoint, iii) MixView that generates augmented\nimages among different viewpoints to alleviate viewpoint differences, and iv) a\nprogressive distillation strategy to gradually learn until reaching the maximum\nflying height. We collect a synthesized and a real-world dataset, and we\nperform extensive experimental analyses to show that our method yields 22.2%\nand 16.9% accuracy improvement for the synthesized dataset and the real world.\nCode and datasets are available on\nhttps://github.com/FreeformRobotics/Progressive-Self-Distillation-for-Ground-to-Aerial-Perception-Knowledge-Transfer.\n","authors":["Junjie Hu","Chenyou Fan","Mete Ozay","Hua Feng","Yuan Gao","Tin Lun Lam"],"pdf_url":"https://arxiv.org/pdf/2208.13404v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06782v1","updated":"2023-01-17T10:15:32Z","published":"2023-01-17T10:15:32Z","title":"A Large-Scale Outdoor Multi-modal Dataset and Benchmark for Novel View\n  Synthesis and Implicit Scene Reconstruction","summary":"  Neural Radiance Fields (NeRF) has achieved impressive results in single\nobject scene reconstruction and novel view synthesis, which have been\ndemonstrated on many single modality and single object focused indoor scene\ndatasets like DTU, BMVS, and NeRF Synthetic.However, the study of NeRF on\nlarge-scale outdoor scene reconstruction is still limited, as there is no\nunified outdoor scene dataset for large-scale NeRF evaluation due to expensive\ndata acquisition and calibration costs. In this paper, we propose a large-scale\noutdoor multi-modal dataset, OMMO dataset, containing complex land objects and\nscenes with calibrated images, point clouds and prompt annotations. Meanwhile,\na new benchmark for several outdoor NeRF-based tasks is established, such as\nnovel view synthesis, surface reconstruction, and multi-modal NeRF. To create\nthe dataset, we capture and collect a large number of real fly-view videos and\nselect high-quality and high-resolution clips from them. Then we design a\nquality review module to refine images, remove low-quality frames and\nfail-to-calibrate scenes through a learning-based automatic evaluation plus\nmanual review. Finally, a number of volunteers are employed to add the text\ndescriptions for each scene and key-frame to meet the potential multi-modal\nrequirements in the future. Compared with existing NeRF datasets, our dataset\ncontains abundant real-world urban and natural scenes with various scales,\ncamera trajectories, and lighting conditions. Experiments show that our dataset\ncan benchmark most state-of-the-art NeRF methods on different tasks. We will\nrelease the dataset and model weights very soon.\n","authors":["Chongshan Lu","Fukun Yin","Xin Chen","Tao Chen","Gang YU","Jiayuan Fan"],"pdf_url":"https://arxiv.org/pdf/2301.06782v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10233v2","updated":"2023-01-17T09:33:49Z","published":"2022-10-19T01:25:21Z","title":"Vision-Based Lane Detection and Tracking under Different Challenging\n  Environmental Conditions","summary":"  Lane marking detection is fundamental for both advanced driving assistance\nsystems and traffic surveillance systems. However, detecting lane is highly\nchallenging when the visibility of a road lane marking is low, obscured or\noften invisible due to real-life challenging environment and adverse weather.\nMost of the lane detection methods suffer from four types of challenges: (i)\nlight effects i.e. shadow, glare of light, reflection etc. created by different\nlight sources like streetlamp, tunnel-light, sun, wet road etc.; (ii) Obscured\nvisibility of eroded, blurred, dashed, colored and cracked lane caused by\nnatural disasters and adverse weather; (iii) lane marking occlusion by\ndifferent objects from surroundings; and (iv) presence of confusing lines e.g.,\nguardrails, pavement marking, road divider etc. In this paper, we proposed a\nsimple, real-time, and robust lane detection and tracking method to detect and\ntrack lane marking. Here, we introduced three key technologies. First, we\nintroduce a comprehensive intensity threshold range (CITR) to improve the\nperformance of the canny operator in detecting lane edges of different\nintensity. Second, we propose a robust lane verification technique, the angle\nand length-based geometric constraint (ALGC) followed by Hough Transform, to\nverify the characteristics of lane marking and to prevent incorrect lane\ndetection. Finally, we propose a novel lane tracking technique, to predict the\nlane position of next frame by defining a range of horizontal lane position\nwhich will be updating with respect to the lane position of previous frame. To\nevaluate the performance of the proposed method we used the DSDLDE [1] dataset\nwith 1080x1920 resolutions at 24 frames/sec. Experimental results show that the\naverage detection rate is 97.36%, and the average detection time is 29.06msec\nper frame, which outperformed the state-of-the-art method.\n","authors":["Samia Sultana","Boshir Ahmed","Manoranjan Paul","Muhammad Rafiqul Islam","Shamim Ahmad"],"pdf_url":"https://arxiv.org/pdf/2210.10233v2.pdf","comment":"16 pages, 10 figures, submitted to IEEE Access"},{"id":"http://arxiv.org/abs/2209.08430v3","updated":"2023-01-17T09:33:21Z","published":"2022-09-17T23:56:03Z","title":"DytanVO: Joint Refinement of Visual Odometry and Motion Segmentation in\n  Dynamic Environments","summary":"  Learning-based visual odometry (VO) algorithms achieve remarkable performance\non common static scenes, benefiting from high-capacity models and massive\nannotated data, but tend to fail in dynamic, populated environments. Semantic\nsegmentation is largely used to discard dynamic associations before estimating\ncamera motions but at the cost of discarding static features and is hard to\nscale up to unseen categories. In this paper, we leverage the mutual dependence\nbetween camera ego-motion and motion segmentation and show that both can be\njointly refined in a single learning-based framework. In particular, we present\nDytanVO, the first supervised learning-based VO method that deals with dynamic\nenvironments. It takes two consecutive monocular frames in real-time and\npredicts camera ego-motion in an iterative fashion. Our method achieves an\naverage improvement of 27.7% in ATE over state-of-the-art VO solutions in\nreal-world dynamic environments, and even performs competitively among dynamic\nvisual SLAM systems which optimize the trajectory on the backend. Experiments\non plentiful unseen environments also demonstrate our method's\ngeneralizability.\n","authors":["Shihao Shen","Yilin Cai","Wenshan Wang","Sebastian Scherer"],"pdf_url":"https://arxiv.org/pdf/2209.08430v3.pdf","comment":"Accepted for presentation at ICRA 2023 and for inclusion in the\n  conference proceedings"},{"id":"http://arxiv.org/abs/2111.12263v2","updated":"2023-01-17T09:24:37Z","published":"2021-11-24T04:38:37Z","title":"APANet: Adaptive Prototypes Alignment Network for Few-Shot Semantic\n  Segmentation","summary":"  Few-shot semantic segmentation aims to segment novel-class objects in a given\nquery image with only a few labeled support images. Most advanced solutions\nexploit a metric learning framework that performs segmentation through matching\neach query feature to a learned class-specific prototype. However, this\nframework suffers from biased classification due to incomplete feature\ncomparisons. To address this issue, we present an adaptive prototype\nrepresentation by introducing class-specific and class-agnostic prototypes and\nthus construct complete sample pairs for learning semantic alignment with query\nfeatures. The complementary features learning manner effectively enriches\nfeature comparison and helps yield an unbiased segmentation model in the\nfew-shot setting. It is implemented with a two-branch end-to-end network (i.e.,\na class-specific branch and a class-agnostic branch), which generates\nprototypes and then combines query features to perform comparisons. In\naddition, the proposed class-agnostic branch is simple yet effective. In\npractice, it can adaptively generate multiple class-agnostic prototypes for\nquery images and learn feature alignment in a self-contrastive manner.\nExtensive experiments on PASCAL-5$^i$ and COCO-20$^i$ demonstrate the\nsuperiority of our method. At no expense of inference efficiency, our model\nachieves state-of-the-art results in both 1-shot and 5-shot settings for\nsemantic segmentation.\n","authors":["Jiacheng Chen","Bin-Bin Gao","Zongqing Lu","Jing-Hao Xue","Chengjie Wang","Qingmin Liao"],"pdf_url":"https://arxiv.org/pdf/2111.12263v2.pdf","comment":"12 pages, 7 figures, Accepted to IEEE Trans. on Multimedia. arXiv\n  admin note: substantial text overlap with arXiv:2104.09216"},{"id":"http://arxiv.org/abs/2205.14575v2","updated":"2023-01-17T08:08:15Z","published":"2022-05-29T06:01:42Z","title":"3D-C2FT: Coarse-to-fine Transformer for Multi-view 3D Reconstruction","summary":"  Recently, the transformer model has been successfully employed for the\nmulti-view 3D reconstruction problem. However, challenges remain on designing\nan attention mechanism to explore the multiview features and exploit their\nrelations for reinforcing the encoding-decoding modules. This paper proposes a\nnew model, namely 3D coarse-to-fine transformer (3D-C2FT), by introducing a\nnovel coarse-to-fine(C2F) attention mechanism for encoding multi-view features\nand rectifying defective 3D objects. C2F attention mechanism enables the model\nto learn multi-view information flow and synthesize 3D surface correction in a\ncoarse to fine-grained manner. The proposed model is evaluated by ShapeNet and\nMulti-view Real-life datasets. Experimental results show that 3D-C2FT achieves\nnotable results and outperforms several competing models on these datasets.\n","authors":["Leslie Ching Ow Tiong","Dick Sigmund","Andrew Beng Jin Teoh"],"pdf_url":"https://arxiv.org/pdf/2205.14575v2.pdf","comment":"Accepted by Asian Conference on Computer Vision (ACCV) 2022"},{"id":"http://arxiv.org/abs/2301.06733v1","updated":"2023-01-17T07:24:47Z","published":"2023-01-17T07:24:47Z","title":"Face Inverse Rendering via Hierarchical Decoupling","summary":"  Previous face inverse rendering methods often require synthetic data with\nground truth and/or professional equipment like a lighting stage. However, a\nmodel trained on synthetic data or using pre-defined lighting priors is\ntypically unable to generalize well for real-world situations, due to the gap\nbetween synthetic data/lighting priors and real data. Furthermore, for common\nusers, the professional equipment and skill make the task expensive and\ncomplex. In this paper, we propose a deep learning framework to disentangle\nface images in the wild into their corresponding albedo, normal, and lighting\ncomponents. Specifically, a decomposition network is built with a hierarchical\nsubdivision strategy, which takes image pairs captured from arbitrary\nviewpoints as input. In this way, our approach can greatly mitigate the\npressure from data preparation, and significantly broaden the applicability of\nface inverse rendering. Extensive experiments are conducted to demonstrate the\nefficacy of our design, and show its superior performance in face relighting\nover other state-of-the-art alternatives. {Our code is available at\n\\url{https://github.com/AutoHDR/HD-Net.git}}\n","authors":["Meng Wang","Xiaojie Guo","Wenjing Dai","Jiawan Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.06733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06730v1","updated":"2023-01-17T07:12:34Z","published":"2023-01-17T07:12:34Z","title":"Bag of States: A Non-sequential Approach to Video-based Engagement\n  Measurement","summary":"  Automatic measurement of student engagement provides helpful information for\ninstructors to meet learning program objectives and individualize program\ndelivery. Students' behavioral and emotional states need to be analyzed at\nfine-grained time scales in order to measure their level of engagement. Many\nexisting approaches have developed sequential and spatiotemporal models, such\nas recurrent neural networks, temporal convolutional networks, and\nthree-dimensional convolutional neural networks, for measuring student\nengagement from videos. These models are trained to incorporate the order of\nbehavioral and emotional states of students into video analysis and output\ntheir level of engagement. In this paper, backed by educational psychology, we\nquestion the necessity of modeling the order of behavioral and emotional states\nof students in measuring their engagement. We develop bag-of-words-based models\nin which only the occurrence of behavioral and emotional states of students is\nmodeled and analyzed and not the order in which they occur. Behavioral and\naffective features are extracted from videos and analyzed by the proposed\nmodels to determine the level of engagement in an ordinal-output classification\nsetting. Compared to the existing sequential and spatiotemporal approaches for\nengagement measurement, the proposed non-sequential approach improves the\nstate-of-the-art results. According to experimental results, our method\nsignificantly improved engagement level classification accuracy on the IIITB\nOnline SE dataset by 26% compared to sequential models and achieved engagement\nlevel classification accuracy as high as 66.58% on the DAiSEE student\nengagement dataset.\n","authors":["Ali Abedi","Chinchu Thomas","Dinesh Babu Jayagopi","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2301.06730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15030v3","updated":"2023-01-17T06:45:44Z","published":"2022-11-28T03:29:39Z","title":"Imperceptible Adversarial Attack via Invertible Neural Networks","summary":"  Adding perturbations via utilizing auxiliary gradient information or\ndiscarding existing details of the benign images are two common approaches for\ngenerating adversarial examples. Though visual imperceptibility is the desired\nproperty of adversarial examples, conventional adversarial attacks still\ngenerate traceable adversarial perturbations. In this paper, we introduce a\nnovel Adversarial Attack via Invertible Neural Networks (AdvINN) method to\nproduce robust and imperceptible adversarial examples. Specifically, AdvINN\nfully takes advantage of the information preservation property of Invertible\nNeural Networks and thereby generates adversarial examples by simultaneously\nadding class-specific semantic information of the target class and dropping\ndiscriminant information of the original class. Extensive experiments on\nCIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN\nmethod can produce less imperceptible adversarial images than the\nstate-of-the-art methods and AdvINN yields more robust adversarial examples\nwith high confidence compared to other adversarial attacks.\n","authors":["Zihan Chen","Ziyue Wang","Junjie Huang","Wentao Zhao","Xiao Liu","Dejian Guan"],"pdf_url":"https://arxiv.org/pdf/2211.15030v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06719v1","updated":"2023-01-17T06:24:08Z","published":"2023-01-17T06:24:08Z","title":"FemtoDet: An Object Detection Baseline for Energy Versus Performance\n  Tradeoffs","summary":"  Efficient detectors for edge devices are often optimized for metrics like\nparameters or speed counts, which remain weak correlation with the energy of\ndetectors. However, among vision applications of convolutional neural networks\n(CNNs), some, such as always-on surveillance cameras, are critical for energy\nconstraints. This paper aims to serve as a baseline by designing detectors to\nreach tradeoffs between energy and performance from two perspectives: 1) We\nextensively analyze various CNNs to identify low-energy architectures,\nincluding the selection of activation functions, convolutions operators, and\nfeature fusion structures on necks. These underappreciated details in past\nworks seriously affect the energy consumption of detectors; 2) To break through\nthe dilemmatic energy-performance problem, we propose a balanced detector\ndriven by energy using discovered low-energy components named\n\\textit{FemtoDet}. In addition to the novel construction, we further improve\nFemtoDet by considering convolutions and training strategy optimizations.\nSpecifically, we develop a new instance boundary enhancement (IBE) module for\nconvolution optimization to overcome the contradiction between the limited\ncapacity of CNNs and detection tasks in diverse spatial representations, and\npropose a recursive warm-restart (RecWR) for optimizing training strategy to\nescape the sub-optimization of light-weight detectors, considering the data\nshift produced in popular augmentations. As a result, FemtoDet with only 68.77k\nparameters achieves a competitive score of 46.3 AP50 on PASCAL VOC and power of\n7.83W on RTX 3090. Extensive experiments on COCO and TJU-DHD datasets indicate\nthat the proposed method achieves competitive results in diverse scenes.\n","authors":["Peng Tu","Xu Xie","Ming Ling","Min Yang","Guo AI","Yawen Huang","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2301.06719v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2301.06715v1","updated":"2023-01-17T06:01:46Z","published":"2023-01-17T06:01:46Z","title":"SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via\n  Swin Transformer and Densely Cascaded Network","summary":"  Monocular depth estimation plays a critical role in various computer vision\nand robotics applications such as localization, mapping, and 3D object\ndetection. Recently, learning-based algorithms achieve huge success in depth\nestimation by training models with a large amount of data in a supervised\nmanner. However, it is challenging to acquire dense ground truth depth labels\nfor supervised training, and the unsupervised depth estimation using monocular\nsequences emerges as a promising alternative. Unfortunately, most studies on\nunsupervised depth estimation explore loss functions or occlusion masks, and\nthere is little change in model architecture in that ConvNet-based\nencoder-decoder structure becomes a de-facto standard for depth estimation. In\nthis paper, we employ a convolution-free Swin Transformer as an image feature\nextractor so that the network can capture both local geometric features and\nglobal semantic features for depth estimation. Also, we propose a Densely\nCascaded Multi-scale Network (DCMNet) that connects every feature map directly\nwith another from different scales via a top-down cascade pathway. This densely\ncascaded connectivity reinforces the interconnection between decoding layers\nand produces high-quality multi-scale depth outputs. The experiments on two\ndifferent datasets, KITTI and Make3D, demonstrate that our proposed method\noutperforms existing state-of-the-art unsupervised algorithms.\n","authors":["Dongseok Shim","H. Jin Kim"],"pdf_url":"https://arxiv.org/pdf/2301.06715v1.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2301.03843v2","updated":"2023-01-17T05:40:33Z","published":"2023-01-10T08:21:19Z","title":"A Privacy Preserving Method with a Random Orthogonal Matrix for\n  ConvMixer Models","summary":"  In this paper, a privacy preserving image classification method is proposed\nunder the use of ConvMixer models. To protect the visual information of test\nimages, a test image is divided into blocks, and then every block is encrypted\nby using a random orthogonal matrix. Moreover, a ConvMixer model trained with\nplain images is transformed by the random orthogonal matrix used for encrypting\ntest images, on the basis of the embedding structure of ConvMixer. The proposed\nmethod allows us not only to use the same classification accuracy as that of\nConvMixer models without considering privacy protection but to also enhance\nrobustness against various attacks compared to conventional privacy-preserving\nlearning.\n","authors":["Rei Aso","Tatsuya Chuman","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2301.03843v2.pdf","comment":"To appear in 2023 RISP International Workshop on Nonlinear Circuits,\n  Communications and Signal Processing"},{"id":"http://arxiv.org/abs/2212.05897v2","updated":"2023-01-17T05:23:24Z","published":"2022-12-12T13:52:53Z","title":"MultiAct: Long-Term 3D Human Motion Generation from Multiple Action\n  Labels","summary":"  We tackle the problem of generating long-term 3D human motion from multiple\naction labels. Two main previous approaches, such as action- and\nmotion-conditioned methods, have limitations to solve this problem. The\naction-conditioned methods generate a sequence of motion from a single action.\nHence, it cannot generate long-term motions composed of multiple actions and\ntransitions between actions. Meanwhile, the motion-conditioned methods generate\nfuture motions from initial motion. The generated future motions only depend on\nthe past, so they are not controllable by the user's desired actions. We\npresent MultiAct, the first framework to generate long-term 3D human motion\nfrom multiple action labels. MultiAct takes account of both action and motion\nconditions with a unified recurrent generation system. It repetitively takes\nthe previous motion and action label; then, it generates a smooth transition\nand the motion of the given action. As a result, MultiAct produces realistic\nlong-term motion controlled by the given sequence of multiple action labels.\nCodes are available here at https://github.com/TaeryungLee/MultiAct_RELEASE.\n","authors":["Taeryung Lee","Gyeongsik Moon","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2212.05897v2.pdf","comment":"AAAI 2023 (Oral presentation)"},{"id":"http://arxiv.org/abs/2209.11523v2","updated":"2023-01-17T05:18:16Z","published":"2022-09-23T11:07:08Z","title":"WS-3D-Lane: Weakly Supervised 3D Lane Detection With 2D Lane Labels","summary":"  Compared to 2D lanes, real 3D lane data is difficult to collect accurately.\nIn this paper, we propose a novel method for training 3D lanes with only 2D\nlane labels, called weakly supervised 3D lane detection WS-3D-Lane. By\nassumptions of constant lane width and equal height on adjacent lanes, we\nindirectly supervise 3D lane heights in the training. To overcome the problem\nof the dynamic change of the camera pitch during data collection, a camera\npitch self-calibration method is proposed. In anchor representation, we propose\na double-layer anchor with a improved non-maximum suppression (NMS) method,\nwhich enables the anchor-based method to predict two lane lines that are close.\nExperiments are conducted on the base of 3D-LaneNet under two supervision\nmethods. Under weakly supervised setting, our WS-3D-Lane outperforms previous\n3D-LaneNet: F-score rises to 92.3% on Apollo 3D synthetic dataset, and F1 rises\nto 74.5% on ONCE-3DLanes. Meanwhile, WS-3D-Lane in purely supervised setting\nmakes more increments and outperforms state-of-the-art. To the best of our\nknowledge, WS-3D-Lane is the first try of 3D lane detection under weakly\nsupervised setting.\n","authors":["Jianyong Ai","Wenbo Ding","Jiuhua Zhao","Jiachen Zhong"],"pdf_url":"https://arxiv.org/pdf/2209.11523v2.pdf","comment":"7 pages, 8 figures. Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2206.07280v2","updated":"2023-01-17T04:38:16Z","published":"2022-06-15T03:42:18Z","title":"ERNAS: An Evolutionary Neural Architecture Search for Magnetic Resonance\n  Image Reconstructions","summary":"  Magnetic resonance imaging (MRI) is one of the noninvasive imaging modalities\nthat can produce high-quality images. However, the scan procedure is relatively\nslow, which causes patient discomfort and motion artifacts in images.\nAccelerating MRI hardware is constrained by physical and physiological\nlimitations. A popular alternative approach to accelerated MRI is to\nundersample the k-space data. While undersampling speeds up the scan procedure,\nit generates artifacts in the images, and advanced reconstruction algorithms\nare needed to produce artifact-free images. Recently deep learning has emerged\nas a promising MRI reconstruction method to address this problem. However,\nstraightforward adoption of the existing deep learning neural network\narchitectures in MRI reconstructions is not usually optimal in terms of\nefficiency and reconstruction quality. In this work, MRI reconstruction from\nundersampled data was carried out using an optimized neural network using a\nnovel evolutionary neural architecture search algorithm. Brain and knee MRI\ndatasets show that the proposed algorithm outperforms manually designed neural\nnetwork-based MR reconstruction models.\n","authors":["Samira Vafay Eslahi","Jian Tao","Jim Ji"],"pdf_url":"https://arxiv.org/pdf/2206.07280v2.pdf","comment":"11 pages, 9 figures, and 4 tables"},{"id":"http://arxiv.org/abs/2301.06690v1","updated":"2023-01-17T04:09:58Z","published":"2023-01-17T04:09:58Z","title":"Audio2Gestures: Generating Diverse Gestures from Audio","summary":"  People may perform diverse gestures affected by various mental and physical\nfactors when speaking the same sentences. This inherent one-to-many\nrelationship makes co-speech gesture generation from audio particularly\nchallenging. Conventional CNNs/RNNs assume one-to-one mapping, and thus tend to\npredict the average of all possible target motions, easily resulting in\nplain/boring motions during inference. So we propose to explicitly model the\none-to-many audio-to-motion mapping by splitting the cross-modal latent code\ninto shared code and motion-specific code. The shared code is expected to be\nresponsible for the motion component that is more correlated to the audio while\nthe motion-specific code is expected to capture diverse motion information that\nis more independent of the audio. However, splitting the latent code into two\nparts poses extra training difficulties. Several crucial training\nlosses/strategies, including relaxed motion loss, bicycle constraint, and\ndiversity loss, are designed to better train the VAE.\n  Experiments on both 3D and 2D motion datasets verify that our method\ngenerates more realistic and diverse motions than previous state-of-the-art\nmethods, quantitatively and qualitatively. Besides, our formulation is\ncompatible with discrete cosine transformation (DCT) modeling and other popular\nbackbones (\\textit{i.e.} RNN, Transformer). As for motion losses and\nquantitative motion evaluation, we find structured losses/metrics\n(\\textit{e.g.} STFT) that consider temporal and/or spatial context complement\nthe most commonly used point-wise losses (\\textit{e.g.} PCK), resulting in\nbetter motion dynamics and more nuanced motion details. Finally, we demonstrate\nthat our method can be readily used to generate motion sequences with\nuser-specified motion clips on the timeline.\n","authors":["Jing Li","Di Kang","Wenjie Pei","Xuefei Zhe","Ying Zhang","Linchao Bao","Zhenyu He"],"pdf_url":"https://arxiv.org/pdf/2301.06690v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2108.06720"},{"id":"http://arxiv.org/abs/2301.06685v1","updated":"2023-01-17T03:58:12Z","published":"2023-01-17T03:58:12Z","title":"Distribution Aligned Feature Clustering for Zero-Shot Sketch-Based Image\n  Retrieval","summary":"  Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) is a challenging cross-modal\nretrieval task. In prior arts, the retrieval is conducted by sorting the\ndistance between the query sketch and each image in the gallery. However, the\ndomain gap and the zero-shot setting make neural networks hard to generalize.\nThis paper tackles the challenges from a new perspective: utilizing gallery\nimage features. We propose a Cluster-then-Retrieve (ClusterRetri) method that\nperforms clustering on the gallery images and uses the cluster centroids as\nproxies for retrieval. Furthermore, a distribution alignment loss is proposed\nto align the image and sketch features with a common Gaussian distribution,\nreducing the domain gap. Despite its simplicity, our proposed method\noutperforms the state-of-the-art methods by a large margin on popular datasets,\ne.g., up to 31% and 39% relative improvement of mAP@all on the Sketchy and\nTU-Berlin datasets.\n","authors":["Yuchen Wu","Kun Song","Fangzheng Zhao","Jiansheng Chen","Huimin Ma"],"pdf_url":"https://arxiv.org/pdf/2301.06685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06683v1","updated":"2023-01-17T03:53:29Z","published":"2023-01-17T03:53:29Z","title":"Surgical Aggregation: A Federated Learning Framework for Harmonizing\n  Distributed Datasets with Diverse Tasks","summary":"  AI-assisted characterization of chest x-rays (CXR) has the potential to\nprovide substantial benefits across many clinical applications. Many\nlarge-scale public CXR datasets have been curated for detection of\nabnormalities using deep learning. However, each of these datasets focus on\ndetecting a subset of disease labels that could be present in a CXR, thus\nlimiting their clinical utility. Furthermore, the distributed nature of these\ndatasets, along with data sharing regulations, make it difficult to share and\ncreate a complete representation of disease labels. We propose surgical\naggregation, a federated learning framework for aggregating knowledge from\ndistributed datasets with different disease labels into a 'global' deep\nlearning model. We randomly divided the NIH Chest X-Ray 14 dataset into\ntraining (70%), validation (10%), and test (20%) splits with no patient overlap\nand conducted two experiments. In the first experiment, we pruned the disease\nlabels to create two 'toy' datasets containing 11 and 8 labels respectively\nwith 4 overlapping labels. For the second experiment, we pruned the disease\nlabels to create two disjoint 'toy' datasets with 7 labels each. We observed\nthat the surgically aggregated 'global' model resulted in excellent performance\nacross both experiments when compared to a 'baseline' model trained on complete\ndisease labels. The overlapping and disjoint experiments had an AUROC of 0.87\nand 0.86 respectively, compared to the baseline AUROC of 0.87. We used surgical\naggregation to harmonize the NIH Chest X-Ray 14 and CheXpert datasets into a\n'global' model with an AUROC of 0.85 and 0.83 respectively. Our results show\nthat surgical aggregation could be used to develop clinically useful deep\nlearning models by aggregating knowledge from distributed datasets with diverse\ntasks, a step forward towards bridging the gap from bench to bedside.\n","authors":["Pranav Kulkarni","Adway Kanhere","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2301.06683v1.pdf","comment":"12 pages, 4 figures, 5 tables, submitted to MIDL 2023 conference"},{"id":"http://arxiv.org/abs/2301.06681v1","updated":"2023-01-17T03:47:01Z","published":"2023-01-17T03:47:01Z","title":"Cross-domain Unsupervised Reconstruction with Equivariance for\n  Photoacoustic Computed Tomography","summary":"  Accurate image reconstruction is crucial for photoacoustic (PA) computed\ntomography (PACT). Recently, deep learning has been used to reconstruct the PA\nimage with a supervised scheme, which requires high-quality images as ground\ntruth labels. In practice, there are inevitable trade-offs between cost and\nperformance since the use of more channels is an expensive strategy to access\nmore measurements. Here, we propose a cross-domain unsupervised reconstruction\n(CDUR) strategy with a pure transformer model, which overcomes the lack of\nground truth labels from limited PA measurements. The proposed approach\nexploits the equivariance of PACT to achieve high performance with a smaller\nnumber of channels. We implement a self-supervised reconstruction in a\nmodel-based form. Meanwhile, we also leverage the self-supervision to enforce\nthe measurement and image consistency on three partitions of measured PA data,\nby randomly masking different channels. We find that dynamically masking a high\nproportion of the channels, e.g., 80%, yields nontrivial self-supervisors in\nboth image and signal domains, which decrease the multiplicity of the pseudo\nsolution to efficiently reconstruct the image from fewer PA measurements with\nminimum error of the image. Experimental results on in-vivo PACT dataset of\nmice demonstrate the potential of our unsupervised framework. In addition, our\nmethod shows a high performance (0.83 structural similarity index (SSIM) in the\nextreme sparse case with 13 channels), which is close to that of supervised\nscheme (0.77 SSIM with 16 channels). On top of all the advantages, our method\nmay be deployed on different trainable models in an end-to-end manner.\n","authors":["Hengrong Lan","Lijie Huang","Liming Nie","Jianwen Luo"],"pdf_url":"https://arxiv.org/pdf/2301.06681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06680v1","updated":"2023-01-17T03:43:34Z","published":"2023-01-17T03:43:34Z","title":"DIGITOUR: Automatic Digital Tours for Real-Estate Properties","summary":"  A virtual or digital tour is a form of virtual reality technology which\nallows a user to experience a specific location remotely. Currently, these\nvirtual tours are created by following a 2-step strategy. First, a photographer\nclicks a 360 degree equirectangular image; then, a team of annotators manually\nlinks these images for the \"walkthrough\" user experience. The major challenge\nin the mass adoption of virtual tours is the time and cost involved in manual\nannotation/linking of images. Therefore, this paper presents an end-to-end\npipeline to automate the generation of 3D virtual tours using equirectangular\nimages for real-estate properties. We propose a novel HSV-based coloring scheme\nfor paper tags that need to be placed at different locations before clicking\nthe equirectangular images using 360 degree cameras. These tags have two\ncharacteristics: i) they are numbered to help the photographer for placement of\ntags in sequence and; ii) bi-colored, which allows better learning of tag\ndetection (using YOLOv5 architecture) in an image and digit recognition (using\ncustom MobileNet architecture) tasks. Finally, we link/connect all the\nequirectangular images based on detected tags. We show the efficiency of the\nproposed pipeline on a real-world equirectangular image dataset collected from\nthe Housing.com database.\n","authors":["Prateek Chhikara","Harshul Kuhar","Anil Goyal","Chirag Sharma"],"pdf_url":"https://arxiv.org/pdf/2301.06680v1.pdf","comment":"Published at CODS-COMAD '23"},{"id":"http://arxiv.org/abs/2301.06679v1","updated":"2023-01-17T03:43:25Z","published":"2023-01-17T03:43:25Z","title":"Rethinking Lightweight Salient Object Detection via Network Depth-Width\n  Tradeoff","summary":"  Existing salient object detection methods often adopt deeper and wider\nnetworks for better performance, resulting in heavy computational burden and\nslow inference speed. This inspires us to rethink saliency detection to achieve\na favorable balance between efficiency and accuracy. To this end, we design a\nlightweight framework while maintaining satisfying competitive accuracy.\nSpecifically, we propose a novel trilateral decoder framework by decoupling the\nU-shape structure into three complementary branches, which are devised to\nconfront the dilution of semantic context, loss of spatial structure and\nabsence of boundary detail, respectively. Along with the fusion of three\nbranches, the coarse segmentation results are gradually refined in structure\ndetails and boundary quality. Without adding additional learnable parameters,\nwe further propose Scale-Adaptive Pooling Module to obtain multi-scale\nreceptive filed. In particular, on the premise of inheriting this framework, we\nrethink the relationship among accuracy, parameters and speed via network\ndepth-width tradeoff. With these insightful considerations, we comprehensively\ndesign shallower and narrower models to explore the maximum potential of\nlightweight SOD. Our models are purposed for different application\nenvironments: 1) a tiny version CTD-S (1.7M, 125FPS) for resource constrained\ndevices, 2) a fast version CTD-M (12.6M, 158FPS) for speed-demanding scenarios,\n3) a standard version CTD-L (26.5M, 84FPS) for high-performance platforms.\nExtensive experiments validate the superiority of our method, which achieves\nbetter efficiency-accuracy balance across five benchmarks.\n","authors":["Jia Li","Shengye Qiao","Zhirui Zhao","Chenxi Xie","Xiaowu Chen","Changqun Xia"],"pdf_url":"https://arxiv.org/pdf/2301.06679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06678v1","updated":"2023-01-17T03:43:19Z","published":"2023-01-17T03:43:19Z","title":"Feature-based Image Matching for Identifying Individual Kākā","summary":"  This report investigates an unsupervised, feature-based image matching\npipeline for the novel application of identifying individual k\\=ak\\=a. Applied\nwith a similarity network for clustering, this addresses a weakness of current\nsupervised approaches to identifying individual birds which struggle to handle\nthe introduction of new individuals to the population. Our approach uses object\nlocalisation to locate k\\=ak\\=a within images and then extracts local features\nthat are invariant to rotation and scale. These features are matched between\nimages with nearest neighbour matching techniques and mismatch removal to\nproduce a similarity score for image match comparison. The results show that\nmatches obtained via the image matching pipeline achieve high accuracy of true\nmatches. We conclude that feature-based image matching could be used with a\nsimilarity network to provide a viable alternative to existing supervised\napproaches.\n","authors":["Fintan O'Sullivan","Kirita-Rose Escott","Rachael Shaw","Andrew Lensen"],"pdf_url":"https://arxiv.org/pdf/2301.06678v1.pdf","comment":"42 pages, honour's report from Victoria University of Wellington"},{"id":"http://arxiv.org/abs/2205.00214v2","updated":"2023-01-17T03:35:30Z","published":"2022-04-30T09:01:21Z","title":"Coarse-to-Fine Video Denoising with Dual-Stage Spatial-Channel\n  Transformer","summary":"  Video denoising aims to recover high-quality frames from the noisy video.\nWhile most existing approaches adopt convolutional neural networks~(CNNs) to\nseparate the noise from the original visual content, however, CNNs focus on\nlocal information and ignore the interactions between long-range regions in the\nframe. Furthermore, most related works directly take the output after basic\nspatio-temporal denoising as the final result, leading to neglect the\nfine-grained denoising process. In this paper, we propose a Dual-stage\nSpatial-Channel Transformer for coarse-to-fine video denoising, which inherits\nthe advantages of both Transformer and CNNs. Specifically, DSCT is proposed\nbased on a progressive dual-stage architecture, namely a coarse-level and a\nfine-level stage to extract dynamic features and static features, respectively.\nAt both stages, a Spatial-Channel Encoding Module is designed to model the\nlong-range contextual dependencies at both spatial and channel levels.\nMeanwhile, we design a Multi-Scale Residual Structure to preserve multiple\naspects of information at different stages, which contains a Temporal Features\nAggregation Module to summarize the dynamic representation. Extensive\nexperiments on four publicly available datasets demonstrate our proposed method\nachieves significant improvements compared to the state-of-the-art methods.\n","authors":["Wulian Yun","Mengshi Qi","Chuanming Wang","Huiyuan Fu","Huadong Ma"],"pdf_url":"https://arxiv.org/pdf/2205.00214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06675v1","updated":"2023-01-17T03:15:20Z","published":"2023-01-17T03:15:20Z","title":"Artificial intelligence as a gateway to scientific discovery: Uncovering\n  features in retinal fundus images","summary":"  Purpose: Convolutional neural networks can be trained to detect various\nconditions or patient traits based on retinal fundus photographs, some of\nwhich, such as the patient sex, are invisible to the expert human eye. Here we\npropose a methodology for explainable classification of fundus images to\nuncover the mechanism(s) by which CNNs successfully predict the labels. We used\npatient sex as a case study to validate our proposed methodology.\n  Approach: First, we used a set of 4746 fundus images, including training,\nvalidation and test partitions, to fine-tune a pre-trained CNN on the sex\nclassification task. Next, we utilized deep learning explainability tools to\nhypothesize possible ways sex differences in the retina manifest. We measured\nnumerous retinal properties relevant to our hypotheses through image\nsegmentation to identify those significantly different between males and\nfemales. To tackle the multiple comparisons problem, we shortlisted the\nparameters by testing them on a set of 100 fundus images distinct from the\nimages used for fine-tuning. Finally, we used an additional 400 images, not\nincluded in any previous set, to reveal significant sex differences in the\nretina.\n  Results: We observed that the peripapillary area is darker in males compared\nto females ($p=.023, d=.243$). We also observed that males have richer retinal\nvasculature networks by showing a higher number of branches ($p=.016, d=.272$)\nand nodes ($p=.014, d=.299$) and a larger total length of branches ($p=.045,\nd=.206$) in the vessel graph. Also, vessels cover a greater area in the\nsuperior temporal quadrant of the retina in males compared to females\n($p=0.048, d=.194$).\n  Conclusions: Our methodology reveals retinal features in fundus photographs\nthat allow CNNs to predict traits currently unknown, but meaningful to experts.\n","authors":["Parsa Delavari","Gulcenur Ozturan","Ozgur Yilmaz","Ipek Oruc"],"pdf_url":"https://arxiv.org/pdf/2301.06675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06673v1","updated":"2023-01-17T03:12:57Z","published":"2023-01-17T03:12:57Z","title":"Multi Kernel Positional Embedding ConvNeXt for Polyp Segmentation","summary":"  Medical image segmentation is the technique that helps doctor view and has a\nprecise diagnosis, particularly in Colorectal Cancer. Specifically, with the\nincrease in cases, the diagnosis and identification need to be faster and more\naccurate for many patients; in endoscopic images, the segmentation task has\nbeen vital to helping the doctor identify the position of the polyps or the\nache in the system correctly. As a result, many efforts have been made to apply\ndeep learning to automate polyp segmentation, mostly to ameliorate the U-shape\nstructure. However, the simple skip connection scheme in UNet leads to\ndeficient context information and the semantic gap between feature maps from\nthe encoder and decoder. To deal with this problem, we propose a novel\nframework composed of ConvNeXt backbone and Multi Kernel Positional Embedding\nblock. Thanks to the suggested module, our method can attain better accuracy\nand generalization in the polyps segmentation task. Extensive experiments show\nthat our model achieves the Dice coefficient of 0.8818 and the IOU score of\n0.8163 on the Kvasir-SEG dataset. Furthermore, on various datasets, we make\ncompetitive achievement results with other previous state-of-the-art methods.\n","authors":["Trong-Hieu Nguyen Mau","Quoc-Huy Trinh","Nhat-Tan Bui","Minh-Triet Tran","Hai-Dang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2301.06673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01482v2","updated":"2023-01-17T02:04:17Z","published":"2023-01-04T08:22:34Z","title":"Motion-based Post-Processing: Using Kalman Filter to Exclude Similar\n  Targets in Underwater Object Tracking","summary":"  Visual tracker includes network and post-processing. Despite the color\ndistortion and low contrast of underwater images, advanced trackers can still\nbe very competitive in underwater object tracking because deep learning\nempowers the networks to discriminate the appearance features of the target.\nHowever, underwater object tracking also faces another problem. Underwater\ntargets such as fish and dolphins, usually appear in groups, and creatures of\nthe same species usually have similar expressions of appearance features, so it\nis challenging to distinguish the weak differences characteristics only by the\nnetwork itself. The existing detection-based post-processing only reflects the\nresults of single frame detection, but cannot locate real targets among similar\ntargets. In this paper, we propose a new post-processing strategy based on\nmotion, which uses Kalman filter (KF) to maintain the motion information of the\ntarget and exclude similar targets around. Specifically, we use the KF\npredicted box and the candidate boxes in the response map and their confidence\nto calculate the candidate location score to find the real target. Our method\ndoes not change the network structure, nor does it perform additional training\nfor the tracker. It can be quickly applied to other tracking fields with\nsimilar target problem. We improved SOTA trackers based on our method, and\nproved the effectiveness of our method on UOT100 and UTB180. The AUC of our\nmethod for OSTrack on similar subsequences is improved by more than 3% on\naverage, and the precision and normalization precision are improved by more\nthan 3.5% on average. It has been proved that our method has good compatibility\nin dealing with similar target problems and can enhance performance of the\ntracker together with other methods. More details can be found in:\nhttps://github.com/LiYunfengLYF/KF_in_underwater_trackers.\n","authors":["Yunfeng Li","Bo Wang","Ye Li","Wei Huo","Zhuoyan Liu"],"pdf_url":"https://arxiv.org/pdf/2301.01482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06657v1","updated":"2023-01-17T01:46:45Z","published":"2023-01-17T01:46:45Z","title":"Free Lunch for Generating Effective Outlier Supervision","summary":"  When deployed in practical applications, computer vision systems will\nencounter numerous unexpected images (\\emph{{i.e.}}, out-of-distribution data).\nDue to the potentially raised safety risks, these aforementioned unseen data\nshould be carefully identified and handled. Generally, existing approaches in\ndealing with out-of-distribution (OOD) detection mainly focus on the\nstatistical difference between the features of OOD and in-distribution (ID)\ndata extracted by the classifiers. Although many of these schemes have brought\nconsiderable performance improvements, reducing the false positive rate (FPR)\nwhen processing open-set images, they necessarily lack reliable theoretical\nanalysis and generalization guarantees. Unlike the observed ways, in this\npaper, we investigate the OOD detection problem based on the Bayes rule and\npresent a convincing description of the reason for failures encountered by\nconventional classifiers. Concretely, our analysis reveals that refining the\nprobability distribution yielded by the vanilla neural networks is necessary\nfor OOD detection, alleviating the issues of assigning high confidence to OOD\ndata. To achieve this effortlessly, we propose an ultra-effective method to\ngenerate near-realistic outlier supervision. Extensive experiments on\nlarge-scale benchmarks reveal that our proposed \\texttt{BayesAug} significantly\nreduces the FPR95 over 12.50\\% compared with the previous schemes, boosting the\nreliability of machine learning systems. The code will be made publicly\navailable.\n","authors":["Sen Pei","Jiaxi Sun","Richard Yi Da Xu","Bin Fan","Shiming Xiang","Gaofeng Meng"],"pdf_url":"https://arxiv.org/pdf/2301.06657v1.pdf","comment":"pre-print"},{"id":"http://arxiv.org/abs/2301.06648v1","updated":"2023-01-17T00:55:12Z","published":"2023-01-17T00:55:12Z","title":"YeLan: Event Camera-Based 3D Human Pose Estimation for\n  Technology-Mediated Dancing in Challenging Environments with Comprehensive\n  Motion-to-Event Simulator","summary":"  As a beloved sport worldwide, dancing is getting integrated into traditional\nand virtual reality-based gaming platforms nowadays. It opens up new\nopportunities in the technology-mediated dancing space. These platforms\nprimarily rely on passive and continuous human pose estimation as an input\ncapture mechanism. Existing solutions are mainly based on RGB or RGB-Depth\ncameras for dance games. The former suffers in low-lighting conditions due to\nthe motion blur and low sensitivity, while the latter is too power-hungry, has\na low frame rate, and has limited working distance. With ultra-low latency,\nenergy efficiency, and wide dynamic range characteristics, the event camera is\na promising solution to overcome these shortcomings. We propose YeLan, an event\ncamera-based 3-dimensional human pose estimation(HPE) system that survives\nlow-lighting and dynamic background contents. We collected the world's first\nevent camera dance dataset and developed a fully customizable motion-to-event\nphysics-aware simulator. YeLan outperforms the baseline models in these\nchallenging conditions and demonstrated robustness against different types of\nclothing, background motion, viewing angle, occlusion, and lighting\nfluctuations.\n","authors":["Zhongyang Zhang","Kaidong Chai","Haowen Yu","Ramzi Majaj","Francesca Walsh","Edward Wang","Upal Mahbub","Hava Siegelmann","Donghyun Kim","Tauhidur Rahman"],"pdf_url":"https://arxiv.org/pdf/2301.06648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07213v1","updated":"2023-01-17T22:29:31Z","published":"2023-01-17T22:29:31Z","title":"SCARP: 3D Shape Completion in ARbitrary Poses for Improved Grasping","summary":"  Recovering full 3D shapes from partial observations is a challenging task\nthat has been extensively addressed in the computer vision community. Many deep\nlearning methods tackle this problem by training 3D shape generation networks\nto learn a prior over the full 3D shapes. In this training regime, the methods\nexpect the inputs to be in a fixed canonical form, without which they fail to\nlearn a valid prior over the 3D shapes. We propose SCARP, a model that performs\nShape Completion in ARbitrary Poses. Given a partial pointcloud of an object,\nSCARP learns a disentangled feature representation of pose and shape by relying\non rotationally equivariant pose features and geometric shape features trained\nusing a multi-tasking objective. Unlike existing methods that depend on an\nexternal canonicalization, SCARP performs canonicalization, pose estimation,\nand shape completion in a single network, improving the performance by 45% over\nthe existing baselines. In this work, we use SCARP for improving grasp\nproposals on tabletop objects. By completing partial tabletop objects directly\nin their observed poses, SCARP enables a SOTA grasp proposal network improve\ntheir proposals by 71.2% on partial shapes. Project page:\nhttps://bipashasen.github.io/scarp\n","authors":["Bipasha Sen","Aditya Agarwal","Gaurav Singh","Brojeshwar B.","Srinath Sridhar","Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2301.07213v1.pdf","comment":"Accepted at ICRA 2023"},{"id":"http://arxiv.org/abs/2112.13709v2","updated":"2023-01-17T21:47:17Z","published":"2021-12-27T14:34:25Z","title":"Rethinking the Data Annotation Process for Multi-view 3D Pose Estimation\n  with Active Learning and Self-Training","summary":"  Pose estimation of the human body and hands is a fundamental problem in\ncomputer vision, and learning-based solutions require a large amount of\nannotated data. In this work, we improve the efficiency of the data annotation\nprocess for 3D pose estimation problems with Active Learning (AL) in a\nmulti-view setting. AL selects examples with the highest value to annotate\nunder limited annotation budgets (time and cost), but choosing the selection\nstrategy is often nontrivial. We present a framework to efficiently extend\nexisting single-view AL strategies. We then propose two novel AL strategies\nthat make full use of multi-view geometry. Moreover, we demonstrate additional\nperformance gains by incorporating pseudo-labels computed during the AL\nprocess, which is a form of self-training. Our system significantly outperforms\nsimulated annotation baselines in 3D body and hand pose estimation on two\nlarge-scale benchmarks: CMU Panoptic Studio and InterHand2.6M. Notably, on CMU\nPanoptic Studio, we are able to reduce the turn-around time by 60% and\nannotation cost by 80% when compared to the conventional annotation process.\n","authors":["Qi Feng","Kun He","He Wen","Cem Keskin","Yuting Ye"],"pdf_url":"https://arxiv.org/pdf/2112.13709v2.pdf","comment":"IEEE WACV 2023 algorithms track. Code:\n  https://github.com/facebookresearch/multi_view_active_learning"},{"id":"http://arxiv.org/abs/2301.07204v1","updated":"2023-01-17T21:41:21Z","published":"2023-01-17T21:41:21Z","title":"Robotic Navigation Autonomy for Subretinal Injection via Intelligent\n  Real-Time Virtual iOCT Volume Slicing","summary":"  In the last decade, various robotic platforms have been introduced that could\nsupport delicate retinal surgeries. Concurrently, to provide semantic\nunderstanding of the surgical area, recent advances have enabled\nmicroscope-integrated intraoperative Optical Coherent Tomography (iOCT) with\nhigh-resolution 3D imaging at near video rate. The combination of robotics and\nsemantic understanding enables task autonomy in robotic retinal surgery, such\nas for subretinal injection. This procedure requires precise needle insertion\nfor best treatment outcomes. However, merging robotic systems with iOCT\nintroduces new challenges. These include, but are not limited to high demands\non data processing rates and dynamic registration of these systems during the\nprocedure. In this work, we propose a framework for autonomous robotic\nnavigation for subretinal injection, based on intelligent real-time processing\nof iOCT volumes. Our method consists of an instrument pose estimation method,\nan online registration between the robotic and the iOCT system, and trajectory\nplanning tailored for navigation to an injection target. We also introduce\nintelligent virtual B-scans, a volume slicing approach for rapid instrument\npose estimation, which is enabled by Convolutional Neural Networks (CNNs). Our\nexperiments on ex-vivo porcine eyes demonstrate the precision and repeatability\nof the method. Finally, we discuss identified challenges in this work and\nsuggest potential solutions to further the development of such systems.\n","authors":["Shervin Dehghani","Michael Sommersperger","Peiyao Zhang","Alejandro Martin-Gomez","Benjamin Busam","Peter Gehlbach","Nassir Navab","M. Ali Nasseri","Iulian Iordachita"],"pdf_url":"https://arxiv.org/pdf/2301.07204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07178v1","updated":"2023-01-17T20:37:02Z","published":"2023-01-17T20:37:02Z","title":"Using Large Text-to-Image Models with Structured Prompts for Skin\n  Disease Identification: A Case Study","summary":"  This paper investigates the potential usage of large text-to-image (LTI)\nmodels for the automated diagnosis of a few skin conditions with rarity or a\nserious lack of annotated datasets. As the input to the LTI model, we provide\nthe targeted instantiation of a generic but succinct prompt structure designed\nupon careful observations of the conditional narratives from the standard\nmedical textbooks. In this regard, we pave the path to utilizing accessible\ntextbook descriptions for automated diagnosis of conditions with data scarcity\nthrough the lens of LTI models. Experiments show the efficacy of the proposed\nframework, including much better localization of the infected regions.\nMoreover, it has the immense possibility for generalization across the medical\nsub-domains, not only to mitigate the data scarcity issue but also to debias\nautomated diagnostics from the all-pervasive racial biases.\n","authors":["Sajith Rajapaksa","Jean Marie Uwabeza Vianney","Renell Castro","Farzad Khalvati","Shubhra Aich"],"pdf_url":"https://arxiv.org/pdf/2301.07178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.12562v2","updated":"2023-01-17T20:14:34Z","published":"2021-06-23T17:42:47Z","title":"Feature Alignment as a Generative Process","summary":"  Reversibility in artificial neural networks allows us to retrieve the input\ngiven an output. We present feature alignment, a method for approximating\nreversibility in arbitrary neural networks. We train a network by minimizing\nthe distance between the output of a data point and the random output with\nrespect to a random input. We applied the technique to the MNIST, CIFAR-10,\nCelebA and STL-10 image datasets. We demonstrate that this method can roughly\nrecover images from just their latent representation without the need of a\ndecoder. By utilizing the formulation of variational autoencoders, we\ndemonstrate that it is possible to produce new images that are statistically\ncomparable to the training data. Furthermore, we demonstrate that the quality\nof the images can be improved by coupling a generator and a discriminator\ntogether. In addition, we show how this method, with a few minor modifications,\ncan be used to train networks locally, which has the potential to save\ncomputational memory resources.\n","authors":["Tiago de Souza Farias","Jonas Maziero"],"pdf_url":"https://arxiv.org/pdf/2106.12562v2.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2301.07150v1","updated":"2023-01-17T19:28:01Z","published":"2023-01-17T19:28:01Z","title":"Embodied Agents for Efficient Exploration and Smart Scene Description","summary":"  The development of embodied agents that can communicate with humans in\nnatural language has gained increasing interest over the last years, as it\nfacilitates the diffusion of robotic platforms in human-populated environments.\nAs a step towards this objective, in this work, we tackle a setting for visual\nnavigation in which an autonomous agent needs to explore and map an unseen\nindoor environment while portraying interesting scenes with natural language\ndescriptions. To this end, we propose and evaluate an approach that combines\nrecent advances in visual robotic exploration and image captioning on images\ngenerated through agent-environment interaction. Our approach can generate\nsmart scene descriptions that maximize semantic knowledge of the environment\nand avoid repetitions. Further, such descriptions offer user-understandable\ninsights into the robot's representation of the environment by highlighting the\nprominent objects and the correlation between them as encountered during the\nexploration. To quantitatively assess the performance of the proposed approach,\nwe also devise a specific score that takes into account both exploration and\ndescription skills. The experiments carried out on both photorealistic\nsimulated environments and real-world ones demonstrate that our approach can\neffectively describe the robot's point of view during exploration, improving\nthe human-friendly interpretability of its observations.\n","authors":["Roberto Bigazzi","Marcella Cornia","Silvia Cascianelli","Lorenzo Baraldi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2301.07150v1.pdf","comment":"Accepted by IEEE International Conference on Robotics and Automation\n  (ICRA 2023)"},{"id":"http://arxiv.org/abs/2301.07147v1","updated":"2023-01-17T19:23:54Z","published":"2023-01-17T19:23:54Z","title":"COVINS-G: A Generic Back-end for Collaborative Visual-Inertial SLAM","summary":"  Collaborative SLAM is at the core of perception in multi-robot systems as it\nenables the co-localization of the team of robots in a common reference frame,\nwhich is of vital importance for any coordination amongst them. The paradigm of\na centralized architecture is well established, with the robots (i.e. agents)\nrunning Visual-Inertial Odometry (VIO) onboard while communicating relevant\ndata, such as e.g. Keyframes (KFs), to a central back-end (i.e. server), which\nthen merges and optimizes the joint maps of the agents. While these frameworks\nhave proven to be successful, their capability and performance are highly\ndependent on the choice of the VIO front-end, thus limiting their flexibility.\nIn this work, we present COVINS-G, a generalized back-end building upon the\nCOVINS framework, enabling the compatibility of the server-back-end with any\narbitrary VIO front-end, including, for example, off-the-shelf cameras with\nodometry capabilities, such as the Realsense T265. The COVINS-G back-end\ndeploys a multi-camera relative pose estimation algorithm for computing the\nloop-closure constraints allowing the system to work purely on 2D image data.\nIn the experimental evaluation, we show on-par accuracy with state-of-the-art\nmulti-session and collaborative SLAM systems, while demonstrating the\nflexibility and generality of our approach by employing different front-ends\nonboard collaborating agents within the same mission. The COVINS-G codebase\nalong with a generalized front-end wrapper to allow any existing VIO front-end\nto be readily used in combination with the proposed collaborative back-end is\nopen-sourced. Video: https://youtu.be/FoJfXCfaYDw\n","authors":["Manthan Patel","Marco Karrer","Philipp Bänninger","Margarita Chli"],"pdf_url":"https://arxiv.org/pdf/2301.07147v1.pdf","comment":"6+1 Pages, 5 Figures, 2 Tables, Accepted at ICRA 2023, London"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.06974v1","updated":"2023-01-17T15:58:28Z","published":"2023-01-17T15:58:28Z","title":"Towards Improving the Explainability of Text-based Information Retrieval\n  with Knowledge Graphs","summary":"  Thanks to recent advancements in machine learning, vector-based methods have\nbeen adopted in many modern information retrieval (IR) systems. While showing\npromising retrieval performance, these approaches typically fail to explain why\na particular document is retrieved as a query result to address explainable\ninformation retrieval(XIR). Knowledge graphs record structured information\nabout entities and inherently explainable relationships. Most of existing XIR\napproaches focus exclusively on the retrieval model with little consideration\non using existing knowledge graphs for providing an explanation. In this paper,\nwe propose a general architecture to incorporate knowledge graphs for XIR in\nvarious steps of the retrieval process. Furthermore, we create two instances of\nthe architecture for different types of explanation. We evaluate our approaches\non well-known IR benchmarks using standard metrics and compare them with\nvector-based methods as baselines.\n","authors":["Boqi Chen","Kua Chen","Yujing Yang","Afshin Amini","Bharat Saxena","Cecilia Chávez-García","Majid Babaei","Amir Feizpour","Dániel Varró"],"pdf_url":"https://arxiv.org/pdf/2301.06974v1.pdf","comment":"7 pages, The 1st Workshop on Trustworthy Learning on Graphs\n  (TrustLOG)"},{"id":"http://arxiv.org/abs/2301.06877v1","updated":"2023-01-17T13:34:18Z","published":"2023-01-17T13:34:18Z","title":"Öffentliche Daten auf die nächste Stufe heben -- Vom RESTful\n  Webservice für Pflanzenschutzmittelregistrierungsdaten zur\n  anwendungsunabhängigen Ontologie (erweiterte Version)","summary":"  During the application of chemical pesticides, distance requirements have to\nbe considered. However, these have to be determined and considered by the\nfarmer manually. To support the farmer the Pesticide Application Manager\n(PAM)-Projects were conducted and a decision support system was developed. A\npart of this system, the distance requirements service was developed at the\nKTBL. To provide this service, the PAM-prozess is conducted: the pesticide\nregistration data provided via REST-API is crawled, then the data is mapped\ninto an ontology using rmlmapper and made availabe in a machine readable and\napplication-independent form via a SPARQL-Endpoint.\n","authors":["Katharina Albrecht","Kristoffer Janis Schneider","Daniel Martini"],"pdf_url":"https://arxiv.org/pdf/2301.06877v1.pdf","comment":"14 Pages, in German language, 6 figures"},{"id":"http://arxiv.org/abs/2301.06815v1","updated":"2023-01-17T11:26:34Z","published":"2023-01-17T11:26:34Z","title":"Follow Us and Become Famous! Insights and Guidelines From Instagram\n  Engagement Mechanisms","summary":"  With 1.3 billion users, Instagram (IG) has also become a business tool. IG\ninfluencer marketing, expected to generate $33.25 billion in 2022, encourages\ncompanies and influencers to create trending content. Various methods have been\nproposed for predicting a post's popularity, i.e., how much engagement (e.g.,\nLikes) it will generate. However, these methods are limited: first, they focus\non forecasting the likes, ignoring the number of comments, which became crucial\nin 2021. Secondly, studies often use biased or limited data. Third, researchers\nfocused on Deep Learning models to increase predictive performance, which are\ndifficult to interpret. As a result, end-users can only estimate engagement\nafter a post is created, which is inefficient and expensive. A better approach\nis to generate a post based on what people and IG like, e.g., by following\nguidelines.\n  In this work, we uncover part of the underlying mechanisms driving IG\nengagement. To achieve this goal, we rely on statistical analysis and\ninterpretable models rather than Deep Learning (black-box) approaches. We\nconduct extensive experiments using a worldwide dataset of 10 million posts\ncreated by 34K global influencers in nine different categories. With our simple\nyet powerful algorithms, we can predict engagement up to 94% of F1-Score,\nmaking us comparable and even superior to Deep Learning-based method.\nFurthermore, we propose a novel unsupervised algorithm for finding highly\nengaging topics on IG. Thanks to our interpretable approaches, we conclude by\noutlining guidelines for creating successful posts.\n","authors":["Pier Paolo Tricomi","Marco Chilese","Mauro Conti","Ahmad-Reza Sadeghi"],"pdf_url":"https://arxiv.org/pdf/2301.06815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06777v1","updated":"2023-01-17T10:00:17Z","published":"2023-01-17T10:00:17Z","title":"Reusable Self-Attention Recommender Systems in Fashion Industry\n  Applications","summary":"  A large number of empirical studies on applying self-attention models in the\ndomain of recommender systems are based on offline evaluation and metrics\ncomputed on standardized datasets. Moreover, many of them do not consider side\ninformation such as item and customer metadata although deep-learning\nrecommenders live up to their full potential only when numerous features of\nheterogeneous type are included. Also, normally the model is used only for a\nsingle use case. Due to these shortcomings, even if relevant, previous works\nare not always representative of their actual effectiveness in real-world\nindustry applications. In this talk, we contribute to bridging this gap by\npresenting live experimental results demonstrating improvements in user\nretention of up to 30\\%. Moreover, we share our learnings and challenges from\nbuilding a re-usable and configurable recommender system for various\napplications from the fashion industry. In particular, we focus on fashion\ninspiration use-cases, such as outfit ranking, outfit recommendation and\nreal-time personalized outfit generation.\n","authors":["Marjan Celikik","Jacek Wasilewski","Ana Peleteiro Ramallo"],"pdf_url":"https://arxiv.org/pdf/2301.06777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01737v2","updated":"2023-01-17T00:52:46Z","published":"2023-01-04T18:10:26Z","title":"Episodes Discovery Recommendation with Multi-Source Augmentations","summary":"  Recommender systems (RS) commonly retrieve potential candidate items for\nusers from a massive number of items by modeling user interests based on\nhistorical interactions. However, historical interaction data is highly sparse,\nand most items are long-tail items, which limits the representation learning\nfor item discovery. This problem is further augmented by the discovery of novel\nor cold-start items. For example, after a user displays interest in bitcoin\nfinancial investment shows in the podcast space, a recommender system may want\nto suggest, e.g., a newly released blockchain episode from a more technical\nshow. Episode correlations help the discovery, especially when interaction data\nof episodes is limited. Accordingly, we build upon the classical Two-Tower\nmodel and introduce the novel Multi-Source Augmentations using a Contrastive\nLearning framework (MSACL) to enhance episode embedding learning by\nincorporating positive episodes from numerous correlated semantics. Extensive\nexperiments on a real-world podcast recommendation dataset from a large audio\nstreaming platform demonstrate the effectiveness of the proposed framework for\nuser podcast exploration and cold-start episode recommendation.\n","authors":["Ziwei Fan","Alice Wang","Zahra Nazari"],"pdf_url":"https://arxiv.org/pdf/2301.01737v2.pdf","comment":"5 pages long for episodes discovery recommendation"},{"id":"http://arxiv.org/abs/2003.04315v5","updated":"2023-01-17T23:29:15Z","published":"2020-03-09T18:00:00Z","title":"LIMEADE: From AI Explanations to Advice Taking","summary":"  Research in human-centered AI has shown the benefits of systems that can\nexplain their predictions. Methods that allow an AI to take advice from humans\nin response to explanations are similarly useful. While both capabilities are\nwell-developed for transparent learning models (e.g., linear models and\nGA$^2$Ms), and recent techniques (e.g., LIME and SHAP) can generate\nexplanations for opaque models, little attention has been given to advice\nmethods for opaque models. This paper introduces LIMEADE, the first general\nframework that translates both positive and negative advice (expressed using\nhigh-level vocabulary such as that employed by post-hoc explanations) into an\nupdate to an arbitrary, underlying opaque model. We demonstrate the generality\nof our approach with case studies on seventy real-world models across two broad\ndomains: image classification and text recommendation. We show our method\nimproves accuracy compared to a rigorous baseline on the image classification\ndomains. For the text modality, we apply our framework to a neural recommender\nsystem for scientific papers on a public website; our user study shows that our\nframework leads to significantly higher perceived user control, trust, and\nsatisfaction.\n","authors":["Benjamin Charles Germain Lee","Doug Downey","Kyle Lo","Daniel S. Weld"],"pdf_url":"https://arxiv.org/pdf/2003.04315v5.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.12970v2","updated":"2023-01-17T22:52:09Z","published":"2022-12-25T23:19:56Z","title":"Refined Edge Usage of Graph Neural Networks for Edge Prediction","summary":"  Graph Neural Networks (GNNs), originally proposed for node classification,\nhave also motivated many recent works on edge prediction (a.k.a., link\nprediction). However, existing methods lack elaborate design regarding the\ndistinctions between two tasks that have been frequently overlooked: (i) edges\nonly constitute the topology in the node classification task but can be used as\nboth the topology and the supervisions (i.e., labels) in the edge prediction\ntask; (ii) the node classification makes prediction over each individual node,\nwhile the edge prediction is determinated by each pair of nodes. To this end,\nwe propose a novel edge prediction paradigm named Edge-aware Message PassIng\nneuRal nEtworks (EMPIRE). Concretely, we first introduce an edge splitting\ntechnique to specify use of each edge where each edge is solely used as either\nthe topology or the supervision (named as topology edge or supervision edge).\nWe then develop a new message passing mechanism that generates the messages to\nsource nodes (through topology edges) being aware of target nodes (through\nsupervision edges). In order to emphasize the differences between pairs\nconnected by supervision edges and pairs unconnected, we further weight the\nmessages to highlight the relative ones that can reflect the differences. In\naddition, we design a novel negative node-pair sampling trick that efficiently\nsamples 'hard' negative instances in the supervision instances, and can\nsignificantly improve the performance. Experimental results verify that the\nproposed method can significantly outperform existing state-of-the-art models\nregarding the edge prediction task on multiple homogeneous and heterogeneous\ngraph datasets.\n","authors":["Jiarui Jin","Yangkun Wang","Weinan Zhang","Quan Gan","Xiang Song","Yong Yu","Zheng Zhang","David Wipf"],"pdf_url":"https://arxiv.org/pdf/2212.12970v2.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2111.13621v2","updated":"2023-01-17T21:00:32Z","published":"2021-11-26T17:33:55Z","title":"An Optimal Algorithm for Finding Champions in Tournament Graphs","summary":"  A tournament graph is a complete directed graph, which can be used to model a\nround-robin tournament between $n$ players. In this paper, we address the\nproblem of finding a champion of the tournament, also known as Copeland winner,\nwhich is a player that wins the highest number of matches. In detail, we aim to\ninvestigate algorithms that find the champion by playing a low number of\nmatches. Solving this problem allows us to speed up several Information\nRetrieval and Recommender System applications, including question answering,\nconversational search, etc. Indeed, these applications often search for the\nchampion inducing a round-robin tournament among the players by employing a\nmachine learning model to estimate who wins each pairwise comparison. Our\ncontribution, thus, allows finding the champion by performing a low number of\nmodel inferences. We prove that any deterministic or randomized algorithm\nfinding a champion with constant success probability requires $\\Omega(\\ell n)$\ncomparisons, where $\\ell$ is the number of matches lost by the champion. We\nthen present an asymptotically-optimal deterministic algorithm matching this\nlower bound without knowing $\\ell$, and we extend our analysis to three\nvariants of the problem. Lastly, we conduct a comprehensive experimental\nassessment of the proposed algorithms on a question answering task on public\ndata. Results show that our proposed algorithms speed up the retrieval of the\nchampion up to $13\\times$ with respect to the state-of-the-art algorithm that\nperform the full tournament.\n","authors":["Lorenzo Beretta","Franco Maria Nardini","Roberto Trani","Rossano Venturini"],"pdf_url":"https://arxiv.org/pdf/2111.13621v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08144v1","updated":"2023-01-17T17:53:27Z","published":"2023-01-17T17:53:27Z","title":"Towards the design of user-centric strategy recommendation systems for\n  collaborative Human-AI tasks","summary":"  Artificial Intelligence is being employed by humans to collaboratively solve\ncomplicated tasks for search and rescue, manufacturing, etc. Efficient teamwork\ncan be achieved by understanding user preferences and recommending different\nstrategies for solving the particular task to humans. Prior work has focused on\npersonalization of recommendation systems for relatively well-understood tasks\nin the context of e-commerce or social networks. In this paper, we seek to\nunderstand the important factors to consider while designing user-centric\nstrategy recommendation systems for decision-making. We conducted a\nhuman-subjects experiment (n=60) for measuring the preferences of users with\ndifferent personality types towards different strategy recommendation systems.\nWe conducted our experiment across four types of strategy recommendation\nmodalities that have been established in prior work: (1) Single strategy\nrecommendation, (2) Multiple similar recommendations, (3) Multiple diverse\nrecommendations, (4) All possible strategies recommendations. While these\nstrategy recommendation schemes have been explored independently in prior work,\nour study is novel in that we employ all of them simultaneously and in the\ncontext of strategy recommendations, to provide us an in-depth overview of the\nperception of different strategy recommendation systems. We found that certain\npersonality traits, such as conscientiousness, notably impact the preference\ntowards a particular type of system (p < 0.01). Finally, we report an\ninteresting relationship between usability, alignment and perceived\nintelligence wherein greater perceived alignment of recommendations with one's\nown preferences leads to higher perceived intelligence (p < 0.01) and higher\nusability (p < 0.01).\n","authors":["Lakshita Dodeja","Pradyumna Tambwekar","Erin Hedlund-Botti","Matthew Gombolay"],"pdf_url":"https://arxiv.org/pdf/2301.08144v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.07094v1","updated":"2023-01-17T18:59:06Z","published":"2023-01-17T18:59:06Z","title":"Learning Customized Visual Models with Retrieval-Augmented Knowledge","summary":"  Image-text contrastive learning models such as CLIP have demonstrated strong\ntask transfer ability. The high generality and usability of these visual models\nis achieved via a web-scale data collection process to ensure broad concept\ncoverage, followed by expensive pre-training to feed all the knowledge into\nmodel weights. Alternatively, we propose REACT, REtrieval-Augmented\nCusTomization, a framework to acquire the relevant web knowledge to build\ncustomized visual models for target domains. We retrieve the most relevant\nimage-text pairs (~3% of CLIP pre-training data) from the web-scale database as\nexternal knowledge, and propose to customize the model by only training new\nmodualized blocks while freezing all the original weights. The effectiveness of\nREACT is demonstrated via extensive experiments on classification, retrieval,\ndetection and segmentation tasks, including zero, few, and full-shot settings.\nParticularly, on the zero-shot classification task, compared with CLIP, it\nachieves up to 5.4% improvement on ImageNet and 3.7% on the ELEVATER benchmark\n(20 datasets).\n","authors":["Haotian Liu","Kilho Son","Jianwei Yang","Ce Liu","Jianfeng Gao","Yong Jae Lee","Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2301.07094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07093v1","updated":"2023-01-17T18:58:58Z","published":"2023-01-17T18:58:58Z","title":"GLIGEN: Open-Set Grounded Text-to-Image Generation","summary":"  Large-scale text-to-image diffusion models have made amazing advances.\nHowever, the status quo is to use text input alone, which can impede\ncontrollability. In this work, we propose GLIGEN, Grounded-Language-to-Image\nGeneration, a novel approach that builds upon and extends the functionality of\nexisting pre-trained text-to-image diffusion models by enabling them to also be\nconditioned on grounding inputs. To preserve the vast concept knowledge of the\npre-trained model, we freeze all of its weights and inject the grounding\ninformation into new trainable layers via a gated mechanism. Our model achieves\nopen-world grounded text2img generation with caption and bounding box condition\ninputs, and the grounding ability generalizes well to novel spatial\nconfiguration and concepts. GLIGEN's zero-shot performance on COCO and LVIS\noutperforms that of existing supervised layout-to-image baselines by a large\nmargin.\n","authors":["Yuheng Li","Haotian Liu","Qingyang Wu","Fangzhou Mu","Jianwei Yang","Jianfeng Gao","Chunyuan Li","Yong Jae Lee"],"pdf_url":"https://arxiv.org/pdf/2301.07093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07088v1","updated":"2023-01-17T18:53:24Z","published":"2023-01-17T18:53:24Z","title":"Vision Learners Meet Web Image-Text Pairs","summary":"  Most recent self-supervised learning~(SSL) methods are pre-trained on the\nwell-curated ImageNet-1K dataset. In this work, we consider SSL pre-training on\nnoisy web image-text paired data due to the excellent scalability of web data.\nFirst, we conduct a benchmark study of representative SSL pre-training methods\non large-scale web data in a fair condition. Methods include single-modal ones\nsuch as MAE and multi-modal ones such as CLIP. We observe that multi-modal\nmethods cannot outperform single-modal ones on vision transfer learning tasks.\nWe derive an information-theoretical view to explain the benchmarking results,\nwhich provides insights into designing novel vision learners. Inspired by the\nabove explorations, we present a visual representation pre-training method,\nMUlti-modal Generator~(MUG), for scalable web image-text data. MUG achieves\nstate-of-the-art transferring performances on a variety of tasks and shows\npromising scaling behavior. Models and codes will be made public. Demo\navailable at https://huggingface.co/spaces/tennant/MUG_caption\n","authors":["Bingchen Zhao","Quan Cui","Hao Wu","Osamu Yoshie","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07088v1.pdf","comment":"Project page: https://bzhao.me/MUG/"},{"id":"http://arxiv.org/abs/2209.08752v2","updated":"2023-01-17T18:51:50Z","published":"2022-09-19T04:23:20Z","title":"Keypoint-GraspNet: Keypoint-based 6-DoF Grasp Generation from the\n  Monocular RGB-D input","summary":"  Great success has been achieved in the 6-DoF grasp learning from the point\ncloud input, yet the computational cost due to the point set orderlessness\nremains a concern. Alternatively, we explore the grasp generation from the\nRGB-D input in this paper. The proposed solution, Keypoint-GraspNet, detects\nthe projection of the gripper keypoints in the image space and then recover the\nSE(3) poses with a PnP algorithm. A synthetic dataset based on the primitive\nshape and the grasp family is constructed to examine our idea. Metric-based\nevaluation reveals that our method outperforms the baselines in terms of the\ngrasp proposal accuracy, diversity, and the time cost. Finally, robot\nexperiments show high success rate, demonstrating the potential of the idea in\nthe real-world applications.\n","authors":["Yiye Chen","Yunzhi Lin","Patricio Vela"],"pdf_url":"https://arxiv.org/pdf/2209.08752v2.pdf","comment":"Accepted by ICRA2023"},{"id":"http://arxiv.org/abs/2301.07078v1","updated":"2023-01-17T18:44:41Z","published":"2023-01-17T18:44:41Z","title":"A Fast Algorithm for Adaptive Private Mean Estimation","summary":"  We design an $(\\varepsilon, \\delta)$-differentially private algorithm to\nestimate the mean of a $d$-variate distribution, with unknown covariance\n$\\Sigma$, that is adaptive to $\\Sigma$. To within polylogarithmic factors, the\nestimator achieves optimal rates of convergence with respect to the induced\nMahalanobis norm $||\\cdot||_\\Sigma$, takes time $\\tilde{O}(n d^2)$ to compute,\nhas near linear sample complexity for sub-Gaussian distributions, allows\n$\\Sigma$ to be degenerate or low rank, and adaptively extends beyond\nsub-Gaussianity. Prior to this work, other methods required exponential\ncomputation time or the superlinear scaling $n = \\Omega(d^{3/2})$ to achieve\nnon-trivial error with respect to the norm $||\\cdot||_\\Sigma$.\n","authors":["John Duchi","Saminul Haque","Rohith Kuditipudi"],"pdf_url":"https://arxiv.org/pdf/2301.07078v1.pdf","comment":"38 pages, no figures"},{"id":"http://arxiv.org/abs/2301.07074v1","updated":"2023-01-17T18:36:57Z","published":"2023-01-17T18:36:57Z","title":"SegViz: A Federated Learning Framework for Medical Image Segmentation\n  from Distributed Datasets with Different and Incomplete Annotations","summary":"  Segmentation is one of the primary tasks in the application of deep learning\nin medical imaging, owing to its multiple downstream clinical applications. As\na result, many large-scale segmentation datasets have been curated and released\nfor the segmentation of different anatomical structures. However, these\ndatasets focus on the segmentation of a subset of anatomical structures in the\nbody, therefore, training a model for each dataset would potentially result in\nhundreds of models and thus limit their clinical translational utility.\nFurthermore, many of these datasets share the same field of view but have\ndifferent subsets of annotations, thus making individual dataset annotations\nincomplete. To that end, we developed SegViz, a federated learning framework\nfor aggregating knowledge from distributed medical image segmentation datasets\nwith different and incomplete annotations into a `global` meta-model. The\nSegViz framework was trained to build a single model capable of segmenting both\nliver and spleen aggregating knowledge from both these nodes by aggregating the\nweights after every 10 epochs. The global SegViz model was tested on an\nexternal dataset, Beyond the Cranial Vault (BTCV), comprising both liver and\nspleen annotations using the dice similarity (DS) metric. The baseline\nindividual segmentation models for spleen and liver trained on their respective\ndatasets produced a DS score of 0.834 and 0.878 on the BTCV test set. In\ncomparison, the SegViz model produced comparable mean DS scores of 0.829 and\n0.899 for the segmentation of the spleen and liver respectively. Our results\ndemonstrate SegViz as an essential first step towards training clinically\ntranslatable multi-task segmentation models from distributed datasets with\ndisjoint incomplete annotations with excellent performance.\n","authors":["Adway U. Kanhere","Pranav Kulkarni","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2301.07074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07069v1","updated":"2023-01-17T18:32:06Z","published":"2023-01-17T18:32:06Z","title":"Prompting Large Language Model for Machine Translation: A Case Study","summary":"  Research on prompting has shown excellent performance with little or even no\nsupervised training across many tasks. However, prompting for machine\ntranslation is still under-explored in the literature. We fill this gap by\noffering a systematic study on prompting strategies for translation, examining\nvarious factors for prompt template and demonstration example selection. We\nfurther explore the use of monolingual data and the feasibility of\ncross-lingual, cross-domain, and sentence-to-document transfer learning in\nprompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the\ntestbed show that 1) the number and the quality of prompt examples matter,\nwhere using suboptimal examples degenerates translation; 2) several features of\nprompt examples, such as semantic similarity, show significant Spearman\ncorrelation with their prompting performance; yet, none of the correlations are\nstrong enough; 3) using pseudo parallel prompt examples constructed from\nmonolingual data via zero-shot prompting could improve translation; and 4)\nimproved performance is achievable by transferring knowledge from prompt\nexamples selected in other settings. We finally provide an analysis on the\nmodel outputs and discuss several problems that prompting still suffers from.\n","authors":["Biao Zhang","Barry Haddow","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2301.07069v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2301.07068v1","updated":"2023-01-17T18:32:01Z","published":"2023-01-17T18:32:01Z","title":"The #DNN-Verification problem: Counting Unsafe Inputs for Deep Neural\n  Networks","summary":"  Deep Neural Networks are increasingly adopted in critical tasks that require\na high level of safety, e.g., autonomous driving. While state-of-the-art\nverifiers can be employed to check whether a DNN is unsafe w.r.t. some given\nproperty (i.e., whether there is at least one unsafe input configuration),\ntheir yes/no output is not informative enough for other purposes, such as\nshielding, model selection, or training improvements. In this paper, we\nintroduce the #DNN-Verification problem, which involves counting the number of\ninput configurations of a DNN that result in a violation of a particular safety\nproperty. We analyze the complexity of this problem and propose a novel\napproach that returns the exact count of violations. Due to the #P-completeness\nof the problem, we also propose a randomized, approximate method that provides\na provable probabilistic bound of the correct count while significantly\nreducing computational requirements. We present experimental results on a set\nof safety-critical benchmarks that demonstrate the effectiveness of our\napproximate method and evaluate the tightness of the bound.\n","authors":["Luca Marzari","Davide Corsi","Ferdinando Cicalese","Alessandro Farinelli"],"pdf_url":"https://arxiv.org/pdf/2301.07068v1.pdf","comment":"Marzari and Corsi contributed equally"},{"id":"http://arxiv.org/abs/2301.07067v1","updated":"2023-01-17T18:31:12Z","published":"2023-01-17T18:31:12Z","title":"Transformers as Algorithms: Generalization and Implicit Model Selection\n  in In-context Learning","summary":"  In-context learning (ICL) is a type of prompting where a transformer model\noperates on a sequence of (input, output) examples and performs inference\non-the-fly. This implicit training is in contrast to explicitly tuning the\nmodel weights based on examples. In this work, we formalize in-context learning\nas an algorithm learning problem, treating the transformer model as a learning\nalgorithm that can be specialized via training to implement-at\ninference-time-another target algorithm. We first explore the statistical\naspects of this abstraction through the lens of multitask learning: We obtain\ngeneralization bounds for ICL when the input prompt is (1) a sequence of i.i.d.\n(input, label) pairs or (2) a trajectory arising from a dynamical system. The\ncrux of our analysis is relating the excess risk to the stability of the\nalgorithm implemented by the transformer, which holds under mild assumptions.\nSecondly, we use our abstraction to show that transformers can act as an\nadaptive learning algorithm and perform model selection across different\nhypothesis classes. We provide numerical evaluations that (1) demonstrate\ntransformers can indeed implement near-optimal algorithms on classical\nregression problems with i.i.d. and dynamic data, (2) identify an inductive\nbias phenomenon where the transfer risk on unseen tasks is independent of the\ntransformer complexity, and (3) empirically verify our theoretical predictions.\n","authors":["Yingcong Li","M. Emrullah Ildiz","Dimitris Papailiopoulos","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2301.07067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07060v1","updated":"2023-01-17T18:21:31Z","published":"2023-01-17T18:21:31Z","title":"Monotonicity for AI ethics and society: An empirical study of the\n  monotonic neural additive model in criminology, education, health care, and\n  finance","summary":"  Algorithm fairness in the application of artificial intelligence (AI) is\nessential for a better society. As the foundational axiom of social mechanisms,\nfairness consists of multiple facets. Although the machine learning (ML)\ncommunity has focused on intersectionality as a matter of statistical parity,\nespecially in discrimination issues, an emerging body of literature addresses\nanother facet -- monotonicity. Based on domain expertise, monotonicity plays a\nvital role in numerous fairness-related areas, where violations could misguide\nhuman decisions and lead to disastrous consequences. In this paper, we first\nsystematically evaluate the significance of applying monotonic neural additive\nmodels (MNAMs), which use a fairness-aware ML algorithm to enforce both\nindividual and pairwise monotonicity principles, for the fairness of AI ethics\nand society. We have found, through a hybrid method of theoretical reasoning,\nsimulation, and extensive empirical analysis, that considering monotonicity\naxioms is essential in all areas of fairness, including criminology, education,\nhealth care, and finance. Our research contributes to the interdisciplinary\nresearch at the interface of AI ethics, explainable AI (XAI), and\nhuman-computer interactions (HCIs). By evidencing the catastrophic consequences\nif monotonicity is not met, we address the significance of monotonicity\nrequirements in AI applications. Furthermore, we demonstrate that MNAMs are an\neffective fairness-aware ML approach by imposing monotonicity restrictions\nintegrating human intelligence.\n","authors":["Dangxing Chen","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.07060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07057v1","updated":"2023-01-17T18:18:51Z","published":"2023-01-17T18:18:51Z","title":"Transformer Based Implementation for Automatic Book Summarization","summary":"  Document Summarization is the procedure of generating a meaningful and\nconcise summary of a given document with the inclusion of relevant and\ntopic-important points. There are two approaches: one is picking up the most\nrelevant statements from the document itself and adding it to the Summary known\nas Extractive and the other is generating sentences for the Summary known as\nAbstractive Summarization. Training a machine learning model to perform tasks\nthat are time-consuming or very difficult for humans to evaluate is a major\nchallenge. Book Abstract generation is one of such complex tasks. Traditional\nmachine learning models are getting modified with pre-trained transformers.\nTransformer based language models trained in a self-supervised fashion are\ngaining a lot of attention; when fine-tuned for Natural Language\nProcessing(NLP) downstream task like text summarization. This work is an\nattempt to use Transformer based techniques for Abstract generation.\n","authors":["Siddhant Porwal","Laxmi Bewoor","Vivek Deshpande"],"pdf_url":"https://arxiv.org/pdf/2301.07057v1.pdf","comment":"Published at - https://ijisae.org/index.php/IJISAE/article/view/2421"},{"id":"http://arxiv.org/abs/2301.07051v1","updated":"2023-01-17T18:06:00Z","published":"2023-01-17T18:06:00Z","title":"ActSafe: Predicting Violations of Medical Temporal Constraints for\n  Medication Adherence","summary":"  Prescription medications often impose temporal constraints on regular health\nbehaviors (RHBs) of patients, e.g., eating before taking medication. Violations\nof such medical temporal constraints (MTCs) can result in adverse effects.\nDetecting and predicting such violations before they occur can help alert the\npatient. We formulate the problem of modeling MTCs and develop a\nproof-of-concept solution, ActSafe, to predict violations of MTCs well ahead of\ntime. ActSafe utilizes a context-free grammar based approach for extracting and\nmapping MTCs from patient education materials. It also addresses the challenges\nof accurately predicting RHBs central to MTCs (e.g., medication intake). Our\nnovel behavior prediction model, HERBERT , utilizes a basis vectorization of\ntime series that is generalizable across temporal scale and duration of\nbehaviors, explicitly capturing the dependency between temporally collocated\nbehaviors. Based on evaluation using a real-world RHB dataset collected from 28\npatients in uncontrolled environments, HERBERT outperforms baseline models with\nan average of 51% reduction in root mean square error. Based on an evaluation\ninvolving patients with chronic conditions, ActSafe can predict MTC violations\na day ahead of time with an average F1 score of 0.86.\n","authors":["Parker Seegmiller","Joseph Gatto","Abdullah Mamun","Hassan Ghasemzadeh","Diane Cook","John Stankovic","Sarah Masud Preum"],"pdf_url":"https://arxiv.org/pdf/2301.07051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07050v1","updated":"2023-01-17T18:04:05Z","published":"2023-01-17T18:04:05Z","title":"An Energy-Efficient Reconfigurable Autoencoder Implementation on FPGA","summary":"  Autoencoders are unsupervised neural networks that are used to process and\ncompress input data and then reconstruct the data back to the original data\nsize. This allows autoencoders to be used for different processing applications\nsuch as data compression, image classification, image noise reduction, and\nimage coloring. Hardware-wise, re-configurable architectures like Field\nProgrammable Gate Arrays (FPGAs) have been used for accelerating computations\nfrom several domains because of their unique combination of flexibility,\nperformance, and power efficiency. In this paper, we look at the different\nautoencoders available and use the convolutional autoencoder in both FPGA and\nGPU-based implementations to process noisy static MNIST images. We compare the\ndifferent results achieved with the FPGA and GPU-based implementations and then\ndiscuss the pros and cons of each implementation. The evaluation of the\nproposed design achieved 80%accuracy and our experimental results show that the\nproposed accelerator achieves a throughput of 21.12 Giga-Operations Per Second\n(GOP/s) with a 5.93 W on-chip power consumption at 100 MHz. The comparison\nresults with off-the-shelf devices and recent state-of-the-art implementations\nillustrate that the proposed accelerator has obvious advantages in terms of\nenergy efficiency and design flexibility. We also discuss future work that can\nbe done with the use of our proposed accelerator.\n","authors":["Murat Isik","Matthew Oldland","Lifeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.07050v1.pdf","comment":"Accepted at Intelligent Systems Conference (IntelliSys) 2023"},{"id":"http://arxiv.org/abs/2301.07040v1","updated":"2023-01-17T17:49:04Z","published":"2023-01-17T17:49:04Z","title":"Optimal Algorithms for Latent Bandits with Cluster Structure","summary":"  We consider the problem of latent bandits with cluster structure where there\nare multiple users, each with an associated multi-armed bandit problem. These\nusers are grouped into \\emph{latent} clusters such that the mean reward vectors\nof users within the same cluster are identical. At each round, a user, selected\nuniformly at random, pulls an arm and observes a corresponding noisy reward.\nThe goal of the users is to maximize their cumulative rewards. This problem is\ncentral to practical recommendation systems and has received wide attention of\nlate \\cite{gentile2014online, maillard2014latent}. Now, if each user acts\nindependently, then they would have to explore each arm independently and a\nregret of $\\Omega(\\sqrt{\\mathsf{MNT}})$ is unavoidable, where $\\mathsf{M},\n\\mathsf{N}$ are the number of arms and users, respectively. Instead, we propose\nLATTICE (Latent bAndiTs via maTrIx ComplEtion) which allows exploitation of the\nlatent cluster structure to provide the minimax optimal regret of\n$\\widetilde{O}(\\sqrt{(\\mathsf{M}+\\mathsf{N})\\mathsf{T}})$, when the number of\nclusters is $\\widetilde{O}(1)$. This is the first algorithm to guarantee such a\nstrong regret bound. LATTICE is based on a careful exploitation of arm\ninformation within a cluster while simultaneously clustering users.\nFurthermore, it is computationally efficient and requires only\n$O(\\log{\\mathsf{T}})$ calls to an offline matrix completion oracle across all\n$\\mathsf{T}$ rounds.\n","authors":["Soumyabrata Pal","Arun Sai Suggala","Karthikeyan Shanmugam","Prateek Jain"],"pdf_url":"https://arxiv.org/pdf/2301.07040v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2102.10231v2","updated":"2023-01-17T17:46:48Z","published":"2021-02-20T02:24:33Z","title":"Elastic Similarity and Distance Measures for Multivariate Time Series","summary":"  This paper contributes multivariate versions of seven commonly used elastic\nsimilarity and distance measures for time series data analytics. Elastic\nsimilarity and distance measures are a class of similarity measures that can\ncompensate for misalignments in the time axis of time series data. We adapt two\nexisting strategies used in a multivariate version of the well-known Dynamic\nTime Warping (DTW), namely, Independent and Dependent DTW, to these seven\nmeasures.\n  While these measures can be applied to various time series analysis tasks, we\ndemonstrate their utility on multivariate time series classification using the\nnearest neighbor classifier. On 23 well-known datasets, we demonstrate that\neach of the measures but one achieves the highest accuracy relative to others\non at least one dataset, supporting the value of developing a suite of\nmultivariate similarity and distance measures. We also demonstrate that there\nare datasets for which either the dependent versions of all measures are more\naccurate than their independent counterparts or vice versa. In addition, we\nalso construct a nearest neighbor-based ensemble of the measures and show that\nit is competitive to other state-of-the-art single-strategy multivariate time\nseries classifiers.\n","authors":["Ahmed Shifaz","Charlotte Pelletier","Francois Petitjean","Geoffrey I. Webb"],"pdf_url":"https://arxiv.org/pdf/2102.10231v2.pdf","comment":"40 pages, 12 figures"},{"id":"http://arxiv.org/abs/2110.13330v2","updated":"2023-01-17T17:35:39Z","published":"2021-10-26T00:10:57Z","title":"Recipes for when Physics Fails: Recovering Robust Learning of Physics\n  Informed Neural Networks","summary":"  Physics-informed Neural Networks (PINNs) have been shown to be effective in\nsolving partial differential equations by capturing the physics induced\nconstraints as a part of the training loss function. This paper shows that a\nPINN can be sensitive to errors in training data and overfit itself in\ndynamically propagating these errors over the domain of the solution of the\nPDE. It also shows how physical regularizations based on continuity criteria\nand conservation laws fail to address this issue and rather introduce problems\nof their own causing the deep network to converge to a physics-obeying local\nminimum instead of the global minimum. We introduce Gaussian Process (GP) based\nsmoothing that recovers the performance of a PINN and promises a robust\narchitecture against noise/errors in measurements. Additionally, we illustrate\nan inexpensive method of quantifying the evolution of uncertainty based on the\nvariance estimation of GPs on boundary data. Robust PINN performance is also\nshown to be achievable by choice of sparse sets of inducing points based on\nsparsely induced GPs. We demonstrate the performance of our proposed methods\nand compare the results from existing benchmark models in literature for\ntime-dependent Schr\\\"odinger and Burgers' equations.\n","authors":["Chandrajit Bajaj","Luke McLennan","Timothy Andeen","Avik Roy"],"pdf_url":"https://arxiv.org/pdf/2110.13330v2.pdf","comment":"Accepted at Machine Learning: Science and Technology"},{"id":"http://arxiv.org/abs/2210.03205v4","updated":"2023-01-17T17:31:02Z","published":"2022-10-06T20:54:52Z","title":"Synthetic Dataset Generation for Privacy-Preserving Machine Learning","summary":"  Machine Learning (ML) has achieved enormous success in solving a variety of\nproblems in computer vision, speech recognition, object detection, to name a\nfew. The principal reason for this success is the availability of huge datasets\nfor training deep neural networks (DNNs). However, datasets cannot be publicly\nreleased if they contain sensitive information such as medical records, and\ndata privacy becomes a major concern. Encryption methods could be a possible\nsolution, however their deployment on ML applications seriously impacts\nclassification accuracy and results in substantial computational overhead.\nAlternatively, obfuscation techniques could be used, but maintaining a good\ntrade-off between visual privacy and accuracy is challenging. In this paper, we\npropose a method to generate secure synthetic datasets from the original\nprivate datasets. Given a network with Batch Normalization (BN) layers\npretrained on the original dataset, we first record the class-wise BN layer\nstatistics. Next, we generate the synthetic dataset by optimizing random noise\nsuch that the synthetic data match the layer-wise statistical distribution of\noriginal images. We evaluate our method on image classification datasets\n(CIFAR10, ImageNet) and show that synthetic data can be used in place of the\noriginal CIFAR10/ImageNet data for training networks from scratch, producing\ncomparable classification performance. Further, to analyze visual privacy\nprovided by our method, we use Image Quality Metrics and show high degree of\nvisual dissimilarity between the original and synthetic images. Moreover, we\nshow that our proposed method preserves data-privacy under various\nprivacy-leakage attacks including Gradient Matching Attack, Model Memorization\nAttack, and GAN-based Attack.\n","authors":["Efstathia Soufleri","Gobinda Saha","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2210.03205v4.pdf","comment":"There was a bug in the code. An updated version will be archived soon"},{"id":"http://arxiv.org/abs/2206.01714v6","updated":"2023-01-17T17:08:51Z","published":"2022-06-03T17:47:04Z","title":"Compositional Visual Generation with Composable Diffusion Models","summary":"  Large text-guided diffusion models, such as DALLE-2, are able to generate\nstunning photorealistic images given natural language descriptions. While such\nmodels are highly flexible, they struggle to understand the composition of\ncertain concepts, such as confusing the attributes of different objects or\nrelations between objects. In this paper, we propose an alternative structured\napproach for compositional generation using diffusion models. An image is\ngenerated by composing a set of diffusion models, with each of them modeling a\ncertain component of the image. To do this, we interpret diffusion models as\nenergy-based models in which the data distributions defined by the energy\nfunctions may be explicitly combined. The proposed method can generate scenes\nat test time that are substantially more complex than those seen in training,\ncomposing sentence descriptions, object relations, human facial attributes, and\neven generalizing to new combinations that are rarely seen in the real world.\nWe further illustrate how our approach may be used to compose pre-trained\ntext-guided diffusion models and generate photorealistic images containing all\nthe details described in the input descriptions, including the binding of\ncertain object attributes that have been shown difficult for DALLE-2. These\nresults point to the effectiveness of the proposed method in promoting\nstructured generalization for visual generation. Project page:\nhttps://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/\n","authors":["Nan Liu","Shuang Li","Yilun Du","Antonio Torralba","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2206.01714v6.pdf","comment":"ECCV 2022. First three authors contributed equally. Project website:\n  https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/"},{"id":"http://arxiv.org/abs/2301.07016v1","updated":"2023-01-17T17:06:48Z","published":"2023-01-17T17:06:48Z","title":"Consciousness is learning: predictive processing systems that learn by\n  binding may perceive themselves as conscious","summary":"  Machine learning algorithms have achieved superhuman performance in specific\ncomplex domains. Yet learning online from few examples and efficiently\ngeneralizing across domains remains elusive. In humans such learning proceeds\nvia declarative memory formation and is closely associated with consciousness.\nPredictive processing has been advanced as a principled Bayesian inference\nframework for understanding the cortex as implementing deep generative\nperceptual models for both sensory data and action control. However, predictive\nprocessing offers little direct insight into fast compositional learning or the\nmystery of consciousness. Here we propose that through implementing online\nlearning by hierarchical binding of unpredicted inferences, a predictive\nprocessing system may flexibly generalize in novel situations by forming\nworking memories for perceptions and actions from single examples, which can\nbecome short- and long-term declarative memories retrievable by associative\nrecall. We argue that the contents of such working memories are unified yet\ndifferentiated, can be maintained by selective attention and are consistent\nwith observations of masking, postdictive perceptual integration, and other\nparadigm cases of consciousness research. We describe how the brain could have\nevolved to use perceptual value prediction for reinforcement learning of\ncomplex action policies simultaneously implementing multiple survival and\nreproduction strategies. 'Conscious experience' is how such a learning system\nperceptually represents its own functioning, suggesting an answer to the meta\nproblem of consciousness. Our proposal naturally unifies feature binding,\nrecurrent processing, and predictive processing with global workspace, and, to\na lesser extent, the higher order theories of consciousness.\n","authors":["V. A. Aksyuk"],"pdf_url":"https://arxiv.org/pdf/2301.07016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07015v1","updated":"2023-01-17T17:05:55Z","published":"2023-01-17T17:05:55Z","title":"Simplistic Collection and Labeling Practices Limit the Utility of\n  Benchmark Datasets for Twitter Bot Detection","summary":"  Accurate bot detection is necessary for the safety and integrity of online\nplatforms. It is also crucial for research on the influence of bots in\nelections, the spread of misinformation, and financial market manipulation.\nPlatforms deploy infrastructure to flag or remove automated accounts, but their\ntools and data are not publicly available. Thus, the public must rely on\nthird-party bot detection. These tools employ machine learning and often\nachieve near perfect performance for classification on existing datasets,\nsuggesting bot detection is accurate, reliable and fit for use in downstream\napplications. We provide evidence that this is not the case and show that high\nperformance is attributable to limitations in dataset collection and labeling\nrather than sophistication of the tools. Specifically, we show that simple\ndecision rules -- shallow decision trees trained on a small number of features\n-- achieve near-state-of-the-art performance on most available datasets and\nthat bot detection datasets, even when combined together, do not generalize\nwell to out-of-sample datasets. Our findings reveal that predictions are highly\ndependent on each dataset's collection and labeling procedures rather than\nfundamental differences between bots and humans. These results have important\nimplications for both transparency in sampling and labeling procedures and\npotential biases in research using existing bot detection tools for\npre-processing.\n","authors":["Chris Hays","Zachary Schutzman","Manish Raghavan","Erin Walk","Philipp Zimmer"],"pdf_url":"https://arxiv.org/pdf/2301.07015v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.07014v1","updated":"2023-01-17T17:03:28Z","published":"2023-01-17T17:03:28Z","title":"Dataset Distillation: A Comprehensive Review","summary":"  Recent success of deep learning can be largely attributed to the huge amount\nof data used for training deep neural networks. However, the sheer amount of\ndata significantly increase the burden on storage and transmission. It would\nalso consume considerable time and computational resources to train models on\nsuch large datasets. Moreover, directly publishing raw data inevitably raise\nconcerns on privacy and copyright. Focusing on these inconveniences, dataset\ndistillation (DD), also known as dataset condensation (DC), has become a\npopular research topic in recent years. Given an original large dataset, DD\naims at a much smaller dataset containing several synthetic samples, such that\nmodels trained on the synthetic dataset can have comparable performance with\nthose trained on the original real one. This paper presents a comprehensive\nreview and summary for recent advances in DD and its application. We first\nintroduce the task in formal and propose an overall algorithmic framework\nfollowed by all existing DD methods. Then, we provide a systematic taxonomy of\ncurrent methodologies in this area. Their theoretical relationship will also be\ndiscussed. We also point out current challenges in DD through extensive\nexperiments and envision possible directions for future works.\n","authors":["Ruonan Yu","Songhua Liu","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07014v1.pdf","comment":"24 pages, 167 references, 8 figures"},{"id":"http://arxiv.org/abs/2301.00243v2","updated":"2023-01-17T16:50:50Z","published":"2022-12-31T16:22:24Z","title":"Approaching Peak Ground Truth","summary":"  Machine learning models are typically evaluated by computing similarity with\nreference annotations and trained by maximizing similarity with such.\nEspecially in the bio-medical domain, annotations are subjective and suffer\nfrom low inter- and intra-rater reliability. Since annotations only reflect the\nannotation entity's interpretation of the real world, this can lead to\nsub-optimal predictions even though the model achieves high similarity scores.\nHere, the theoretical concept of Peak Ground Truth (PGT) is introduced. PGT\nmarks the point beyond which an increase in similarity with the reference\nannotation stops translating to better Real World Model Performance (RWMP).\nAdditionally, a quantitative technique to approximate PGT by computing inter-\nand intra-rater reliability is proposed. Finally, three categories of PGT-aware\nstrategies to evaluate and improve model performance are reviewed.\n","authors":["Florian Kofler","Johannes Wahle","Ivan Ezhov","Sophia Wagner","Rami Al-Maskari","Emilia Gryska","Mihail Todorov","Christina Bukas","Felix Meissen","Tingying Peng","Ali Ertürk","Daniel Rueckert","Rolf Heckemann","Jan Kirschke","Claus Zimmer","Benedikt Wiestler","Bjoern Menze","Marie Piraud"],"pdf_url":"https://arxiv.org/pdf/2301.00243v2.pdf","comment":"7pages, 2 figures (this updates just affiliations and corrects figure\n  rendering)"},{"id":"http://arxiv.org/abs/2301.06989v1","updated":"2023-01-17T16:19:41Z","published":"2023-01-17T16:19:41Z","title":"Negative Flux Aggregation to Estimate Feature Attributions","summary":"  There are increasing demands for understanding deep neural networks' (DNNs)\nbehavior spurred by growing security and/or transparency concerns. Due to\nmulti-layer nonlinearity of the deep neural network architectures, explaining\nDNN predictions still remains as an open problem, preventing us from gaining a\ndeeper understanding of the mechanisms. To enhance the explainability of DNNs,\nwe estimate the input feature's attributions to the prediction task using\ndivergence and flux. Inspired by the divergence theorem in vector analysis, we\ndevelop a novel Negative Flux Aggregation (NeFLAG) formulation and an efficient\napproximation algorithm to estimate attribution map. Unlike the previous\ntechniques, ours doesn't rely on fitting a surrogate model nor need any path\nintegration of gradients. Both qualitative and quantitative experiments\ndemonstrate a superior performance of NeFLAG in generating more faithful\nattribution maps than the competing methods.\n","authors":["Xin Li","Deng Pan","Chengyin Li","Yao Qiang","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.06989v1.pdf","comment":"9 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2301.06987v1","updated":"2023-01-17T16:16:53Z","published":"2023-01-17T16:16:53Z","title":"The SwaNNFlight System: On-the-Fly Sim-to-Real Adaptation via Anchored\n  Learning","summary":"  Reinforcement Learning (RL) agents trained in simulated environments and then\ndeployed in the real world are often sensitive to the differences in dynamics\npresented, commonly termed the sim-to-real gap. With the goal of minimizing\nthis gap on resource-constrained embedded systems, we train and live-adapt\nagents on quadrotors built from off-the-shelf hardware. In achieving this we\ndeveloped three novel contributions. (i) SwaNNFlight, an open-source firmware\nenabling wireless data capture and transfer of agents' observations.\nFine-tuning agents with new data, and receiving and swapping onboard NN\ncontrollers -- all while in flight. We also design SwaNNFlight System (SwaNNFS)\nallowing new research in training and live-adapting learning agents on similar\nsystems. (ii) Multiplicative value composition, a technique for preserving the\nimportance of each policy optimization criterion, improving training\nperformance and variability in learnt behavior. And (iii) anchor critics to\nhelp stabilize the fine-tuning of agents during sim-to-real transfer, online\nlearning from real data while retaining behavior optimized in simulation. We\ntrain consistently flight-worthy control policies in simulation and deploy them\non real quadrotors. We then achieve live controller adaptation via over-the-air\nupdates of the onboard control policy from a ground station. Our results\nindicate that live adaptation unlocks a near-50\\% reduction in power\nconsumption, attributed to the sim-to-real gap. Finally, we tackle the issues\nof catastrophic forgetting and controller instability, showing the\neffectiveness of our novel methods.\n  Project Website: https://github.com/BU-Cyber-Physical-Systems-Lab/SwaNNFS\n","authors":["Bassel El Mabsout","Shahin Roozkhosh","Siddharth Mysore","Kate Saenko","Renato Mancuso"],"pdf_url":"https://arxiv.org/pdf/2301.06987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06975v1","updated":"2023-01-17T15:58:29Z","published":"2023-01-17T15:58:29Z","title":"Vision Based Machine Learning Algorithms for Out-of-Distribution\n  Generalisation","summary":"  There are many computer vision applications including object segmentation,\nclassification, object detection, and reconstruction for which machine learning\n(ML) shows state-of-the-art performance. Nowadays, we can build ML tools for\nsuch applications with real-world accuracy. However, each tool works well\nwithin the domain in which it has been trained and developed. Often, when we\ntrain a model on a dataset in one specific domain and test on another unseen\ndomain known as an out of distribution (OOD) dataset, models or ML tools show a\ndecrease in performance. For instance, when we train a simple classifier on\nreal-world images and apply that model on the same classes but with a different\ndomain like cartoons, paintings or sketches then the performance of ML tools\ndisappoints. This presents serious challenges of domain generalisation (DG),\ndomain adaptation (DA), and domain shifting. To enhance the power of ML tools,\nwe can rebuild and retrain models from scratch or we can perform transfer\nlearning. In this paper, we present a comparison study between vision-based\ntechnologies for domain-specific and domain-generalised methods. In this\nresearch we highlight that simple convolutional neural network (CNN) based deep\nlearning methods perform poorly when they have to tackle domain shifting.\nExperiments are conducted on two popular vision-based benchmarks, PACS and\nOffice-Home. We introduce an implementation pipeline for domain generalisation\nmethods and conventional deep learning models. The outcome confirms that\nCNN-based deep learning models show poor generalisation compare to other\nextensive methods.\n","authors":["Hamza Riaz","Alan F. Smeaton"],"pdf_url":"https://arxiv.org/pdf/2301.06975v1.pdf","comment":"Computing Conference, 22-23 June 2023, London, United Kingdom. 15\n  pages, 5 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2012.14563v2","updated":"2023-01-17T15:52:17Z","published":"2020-12-29T01:51:59Z","title":"Random Planted Forest: a directly interpretable tree ensemble","summary":"  We introduce a novel interpretable, tree based algorithm for prediction in a\nregression setting in which each tree in a classical random forest is replaced\nby a family of planted trees that grow simultaneously. The motivation for our\nalgorithm is to estimate the unknown regression function from a functional\ndecomposition perspective, where each tree corresponds to a function within\nthat decomposition. The maximal order of approximation in the decomposition can\nbe specified or left unlimited. If a first order approximation is chosen, the\nresult is an additive model. In the other extreme case, if the order of\napproximation is not limited, the resulting model places no restrictions on the\nform of the regression function. In a simulation study we find encouraging\nprediction and visualisation properties of our random planted forest method. We\nalso develop theory for an idealised version of random planted forests in cases\nwhere the maximal order of approximation is low. We show that if the order is\nsmaller than three, the idealised version achieves asymptotically optimal\nconvergence rates up to a logarithmic factor. ode is available on\nhttps://github.com/PlantedML/randomPlantedForest\n","authors":["Munir Hiabu","Enno Mammen","Joseph T. Meyer"],"pdf_url":"https://arxiv.org/pdf/2012.14563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06957v1","updated":"2023-01-17T15:32:34Z","published":"2023-01-17T15:32:34Z","title":"FewSOME: Few Shot Anomaly Detection","summary":"  Recent years have seen considerable progress in the field of Anomaly\nDetection but at the cost of increasingly complex training pipelines. Such\ntechniques require large amounts of training data, resulting in computationally\nexpensive algorithms. We propose Few Shot anomaly detection (FewSOME), a deep\nOne-Class Anomaly Detection algorithm with the ability to accurately detect\nanomalies having trained on 'few' examples of the normal class and no examples\nof the anomalous class. We describe FewSOME to be of low complexity given its\nlow data requirement and short training time. FewSOME is aided by pretrained\nweights with an architecture based on Siamese Networks. By means of an ablation\nstudy, we demonstrate how our proposed loss, 'Stop Loss', improves the\nrobustness of FewSOME. Our experiments demonstrate that FewSOME performs at\nstate-of-the-art level on benchmark datasets MNIST, CIFAR-10, F-MNIST and MVTec\nAD while training on only 30 normal samples, a minute fraction of the data that\nexisting methods are trained on. Most notably, we found that FewSOME\noutperforms even highly complex models in the setting where only few examples\nof the normal class exist. Moreover, our extensive experiments show FewSOME to\nbe robust to contaminated datasets. We also report F1 score and Balanced\nAccuracy in addition to AUC as a benchmark for future techniques to be compared\nagainst.\n","authors":["Niamh Belton","Misgina Tsighe Hagos","Aonghus Lawlor","Kathleen M. Curran"],"pdf_url":"https://arxiv.org/pdf/2301.06957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06956v1","updated":"2023-01-17T15:32:06Z","published":"2023-01-17T15:32:06Z","title":"Expected Gradients of Maxout Networks and Consequences to Parameter\n  Initialization","summary":"  We study the gradients of a maxout network with respect to inputs and\nparameters and obtain bounds for the moments depending on the architecture and\nthe parameter distribution. We observe that the distribution of the\ninput-output Jacobian depends on the input, which complicates a stable\nparameter initialization. Based on the moments of the gradients, we formulate\nparameter initialization strategies that avoid vanishing and exploding\ngradients in wide networks. Experiments with deep fully-connected and\nconvolutional networks show that this strategy improves SGD and Adam training\nof deep maxout networks. In addition, we obtain refined bounds on the expected\nnumber of linear regions, results on the expected curve length distortion, and\nresults on the NTK.\n","authors":["Hanna Tseran","Guido Montúfar"],"pdf_url":"https://arxiv.org/pdf/2301.06956v1.pdf","comment":"37 pages, 8 figures"},{"id":"http://arxiv.org/abs/2111.09537v2","updated":"2023-01-17T14:57:14Z","published":"2021-11-18T06:11:45Z","title":"The Prominence of Artificial Intelligence in COVID-19","summary":"  In December 2019, a novel virus called COVID-19 had caused an enormous number\nof causalities to date. The battle with the novel Coronavirus is baffling and\nhorrifying after the Spanish Flu 2019. While the front-line doctors and medical\nresearchers have made significant progress in controlling the spread of the\nhighly contiguous virus, technology has also proved its significance in the\nbattle. Moreover, Artificial Intelligence has been adopted in many medical\napplications to diagnose many diseases, even baffling experienced doctors.\nTherefore, this survey paper explores the methodologies proposed that can aid\ndoctors and researchers in early and inexpensive methods of diagnosis of the\ndisease. Most developing countries have difficulties carrying out tests using\nthe conventional manner, but a significant way can be adopted with Machine and\nDeep Learning. On the other hand, the access to different types of medical\nimages has motivated the researchers. As a result, a mammoth number of\ntechniques are proposed. This paper first details the background knowledge of\nthe conventional methods in the Artificial Intelligence domain. Following that,\nwe gather the commonly used datasets and their use cases to date. In addition,\nwe also show the percentage of researchers adopting Machine Learning over Deep\nLearning. Thus we provide a thorough analysis of this scenario. Lastly, in the\nresearch challenges, we elaborate on the problems faced in COVID-19 research,\nand we address the issues with our understanding to build a bright and healthy\nenvironment.\n","authors":["MD Abdullah Al Nasim","Aditi Dhali","Faria Afrin","Noshin Tasnim Zaman","Nazmul Karim"],"pdf_url":"https://arxiv.org/pdf/2111.09537v2.pdf","comment":"63 pages, 3 tables, 17 figures"},{"id":"http://arxiv.org/abs/2301.06928v1","updated":"2023-01-17T14:50:18Z","published":"2023-01-17T14:50:18Z","title":"Towards Estimating Transferability using Hard Subsets","summary":"  As transfer learning techniques are increasingly used to transfer knowledge\nfrom the source model to the target task, it becomes important to quantify\nwhich source models are suitable for a given target task without performing\ncomputationally expensive fine tuning. In this work, we propose HASTE (HArd\nSubset TransfErability), a new strategy to estimate the transferability of a\nsource model to a particular target task using only a harder subset of target\ndata. By leveraging the internal and output representations of model, we\nintroduce two techniques, one class agnostic and another class specific, to\nidentify harder subsets and show that HASTE can be used with any existing\ntransferability metric to improve their reliability. We further analyze the\nrelation between HASTE and the optimal average log likelihood as well as\nnegative conditional entropy and empirically validate our theoretical bounds.\nOur experimental results across multiple source model architectures, target\ndatasets, and transfer learning tasks show that HASTE modified metrics are\nconsistently better or on par with the state of the art transferability\nmetrics.\n","authors":["Tarun Ram Menta","Surgan Jandial","Akash Patil","Vimal KB","Saketh Bachu","Balaji Krishnamurthy","Vineeth N. Balasubramanian","Chirag Agarwal","Mausoom Sarkar"],"pdf_url":"https://arxiv.org/pdf/2301.06928v1.pdf","comment":"First three authors contributed equally"},{"id":"http://arxiv.org/abs/2301.06926v1","updated":"2023-01-17T14:48:58Z","published":"2023-01-17T14:48:58Z","title":"Memory-Augmented Theory of Mind Network","summary":"  Social reasoning necessitates the capacity of theory of mind (ToM), the\nability to contextualise and attribute mental states to others without having\naccess to their internal cognitive structure. Recent machine learning\napproaches to ToM have demonstrated that we can train the observer to read the\npast and present behaviours of other agents and infer their beliefs (including\nfalse beliefs about things that no longer exist), goals, intentions and future\nactions. The challenges arise when the behavioural space is complex, demanding\nskilful space navigation for rapidly changing contexts for an extended period.\nWe tackle the challenges by equipping the observer with novel neural memory\nmechanisms to encode, and hierarchical attention to selectively retrieve\ninformation about others. The memories allow rapid, selective querying of\ndistal related past behaviours of others to deliberatively reason about their\ncurrent mental state, beliefs and future behaviours. This results in ToMMY, a\ntheory of mind model that learns to reason while making little assumptions\nabout the underlying mental processes. We also construct a new suite of\nexperiments to demonstrate that memories facilitate the learning process and\nachieve better theory of mind performance, especially for high-demand\nfalse-belief tasks that require inferring through multiple steps of changes.\n","authors":["Dung Nguyen","Phuoc Nguyen","Hung Le","Kien Do","Svetha Venkatesh","Truyen Tran"],"pdf_url":"https://arxiv.org/pdf/2301.06926v1.pdf","comment":"Accepted for publication at AAAI 2023"},{"id":"http://arxiv.org/abs/2301.06923v1","updated":"2023-01-17T14:44:46Z","published":"2023-01-17T14:44:46Z","title":"Explainable Data Poison Attacks on Human Emotion Evaluation Systems\n  based on EEG Signals","summary":"  The major aim of this paper is to explain the data poisoning attacks using\nlabel-flipping during the training stage of the electroencephalogram (EEG)\nsignal-based human emotion evaluation systems deploying Machine Learning models\nfrom the attackers' perspective. Human emotion evaluation using EEG signals has\nconsistently attracted a lot of research attention. The identification of human\nemotional states based on EEG signals is effective to detect potential internal\nthreats caused by insider individuals. Nevertheless, EEG signal-based human\nemotion evaluation systems have shown several vulnerabilities to data poison\nattacks. The findings of the experiments demonstrate that the suggested data\npoison assaults are model-independently successful, although various models\nexhibit varying levels of resilience to the attacks. In addition, the data\npoison attacks on the EEG signal-based human emotion evaluation systems are\nexplained with several Explainable Artificial Intelligence (XAI) methods,\nincluding Shapley Additive Explanation (SHAP) values, Local Interpretable\nModel-agnostic Explanations (LIME), and Generated Decision Trees. And the codes\nof this paper are publicly available on GitHub.\n","authors":["Zhibo Zhang","Sani Umar","Ahmed Y. Al Hammadi","Sangyoung Yoon","Ernesto Damiani","Claudio Agostino Ardagna","Nicola Bena","Chan Yeob Yeun"],"pdf_url":"https://arxiv.org/pdf/2301.06923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1908.01241v4","updated":"2023-01-17T14:21:40Z","published":"2019-08-03T22:27:26Z","title":"Robust Max Entrywise Error Bounds for Tensor Estimation from Sparse\n  Observations via Similarity Based Collaborative Filtering","summary":"  Consider the task of estimating a 3-order $n \\times n \\times n$ tensor from\nnoisy observations of randomly chosen entries in the sparse regime. We\nintroduce a similarity based collaborative filtering algorithm for estimating a\ntensor from sparse observations and argue that it achieves sample complexity\nthat nearly matches the conjectured computationally efficient lower bound on\nthe sample complexity for the setting of low-rank tensors. Our algorithm uses\nthe matrix obtained from the flattened tensor to compute similarity, and\nestimates the tensor entries using a nearest neighbor estimator. We prove that\nthe algorithm recovers a finite rank tensor with maximum entry-wise error (MEE)\nand mean-squared-error (MSE) decaying to $0$ as long as each entry is observed\nindependently with probability $p = \\Omega(n^{-3/2 + \\kappa})$ for any\narbitrarily small $\\kappa > 0$. More generally, we establish robustness of the\nestimator, showing that when arbitrary noise bounded by $\\varepsilon \\geq 0$ is\nadded to each observation, the estimation error with respect to MEE and MSE\ndegrades by $\\text{poly}(\\varepsilon)$. Consequently, even if the tensor may\nnot have finite rank but can be approximated within $\\varepsilon \\geq 0$ by a\nfinite rank tensor, then the estimation error converges to\n$\\text{poly}(\\varepsilon)$. Our analysis sheds insight into the conjectured\nsample complexity lower bound, showing that it matches the connectivity\nthreshold of the graph used by our algorithm for estimating similarity between\ncoordinates.\n","authors":["Devavrat Shah","Christina Lee Yu"],"pdf_url":"https://arxiv.org/pdf/1908.01241v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06908v1","updated":"2023-01-17T14:19:51Z","published":"2023-01-17T14:19:51Z","title":"MAFUS: a Framework to predict mortality risk in MAFLD subjects","summary":"  Metabolic (dysfunction) associated fatty liver disease (MAFLD) establishes\nnew criteria for diagnosing fatty liver disease independent of alcohol\nconsumption and concurrent viral hepatitis infection. However, the long-term\noutcome of MAFLD subjects is sparse. Few articles are focused on mortality in\nMAFLD subjects, and none investigate how to predict a fatal outcome. In this\npaper, we propose an artificial intelligence-based framework named MAFUS that\nphysicians can use for predicting mortality in MAFLD subjects. The framework\nuses data from various anthropometric and biochemical sources based on Machine\nLearning (ML) algorithms. The framework has been tested on a state-of-the-art\ndataset on which five ML algorithms are trained. Support Vector Machines\nresulted in being the best model. Furthermore, an Explainable Artificial\nIntelligence (XAI) analysis has been performed to understand the SVM diagnostic\nreasoning and the contribution of each feature to the prediction. The MAFUS\nframework is easy to apply, and the required parameters are readily available\nin the dataset.\n","authors":["Domenico Lofù","Paolo Sorino","Tommaso Colafiglio","Caterina Bonfiglio","Fedelucio Narducci","Tommaso Di Noia","Eugenio Di Sciascio"],"pdf_url":"https://arxiv.org/pdf/2301.06908v1.pdf","comment":"18 pages, 20 figures"},{"id":"http://arxiv.org/abs/2301.06907v1","updated":"2023-01-17T14:18:17Z","published":"2023-01-17T14:18:17Z","title":"Deep Conditional Measure Quantization","summary":"  The quantization of a (probability) measure is replacing it by a sum of Dirac\nmasses that is close enough to it (in some metric space of probability\nmeasures). Various methods exists to do so, but the situation of quantizing a\nconditional law has been less explored. We propose a method, called DCMQ,\ninvolving a Huber-energy kernel-based approach coupled with a deep neural\nnetwork architecture. The method is tested on several examples and obtains\npromising results.\n","authors":["Gabriel Turinici"],"pdf_url":"https://arxiv.org/pdf/2301.06907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06898v1","updated":"2023-01-17T14:07:52Z","published":"2023-01-17T14:07:52Z","title":"Online Filtering over Expanding Graphs","summary":"  Data processing tasks over graphs couple the data residing over the nodes\nwith the topology through graph signal processing tools. Graph filters are one\nsuch prominent tool, having been used in applications such as denoising,\ninterpolation, and classification. However, they are mainly used on fixed\ngraphs although many networks grow in practice, with nodes continually\nattaching to the topology. Re-training the filter every time a new node\nattaches is computationally demanding; hence an online learning solution that\nadapts to the evolving graph is needed. We propose an online update of the\nfilter, based on the principles of online machine learning. To update the\nfilter, we perform online gradient descent, which has a provable regret bound\nwith respect to the filter computed offline. We show the performance of our\nmethod for signal interpolation at the incoming nodes. Numerical results on\nsynthetic and graph-based recommender systems show that the proposed approach\ncompares well to the offline baseline filter while outperforming competitive\napproaches. These findings lay the foundation for efficient filtering over\nexpanding graphs.\n","authors":["Bishwadeep Das","Elvin Isufi"],"pdf_url":"https://arxiv.org/pdf/2301.06898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06883v1","updated":"2023-01-17T13:39:26Z","published":"2023-01-17T13:39:26Z","title":"The quantum cost function concentration dependency on the\n  parametrization expressivity","summary":"  Although we are currently in the era of noisy intermediate scale quantum\ndevices, several studies are being conducted with the aim of bringing machine\nlearning to the quantum domain. Currently, quantum variational circuits are one\nof the main strategies used to build such models. However, despite its\nwidespread use, we still do not know what are the minimum resources needed to\ncreate a quantum machine learning model. In this article, we analyze how the\nexpressiveness of the parametrization affects the cost function. We\nanalytically show that the more expressive the parametrization is, the more the\ncost function will tend to concentrate around a value that depends both on the\nchosen observable and on the number of qubits used. For this, we initially\nobtain a relationship between the expressiveness of the parametrization and the\nmean value of the cost function. Afterwards, we relate the expressivity of the\nparametrization with the variance of the cost function. Finally, we show some\nnumerical simulation results that confirm our theoretical-analytical\npredictions.\n","authors":["Lucas Friedrich","Jonas Maziero"],"pdf_url":"https://arxiv.org/pdf/2301.06883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06876v1","updated":"2023-01-17T13:34:06Z","published":"2023-01-17T13:34:06Z","title":"CS-lol: a Dataset of Viewer Comment with Scene in E-sports\n  Live-streaming","summary":"  Billions of live-streaming viewers share their opinions on scenes they are\nwatching in real-time and interact with the event, commentators as well as\nother viewers via text comments. Thus, there is necessary to explore viewers'\ncomments with scenes in E-sport live-streaming events. In this paper, we\ndeveloped CS-lol, a new large-scale dataset containing comments from viewers\npaired with descriptions of game scenes in E-sports live-streaming. Moreover,\nwe propose a task, namely viewer comment retrieval, to retrieve the viewer\ncomments for the scene of the live-streaming event. Results on a series of\nbaseline retrieval methods derived from typical IR evaluation methods show our\ntask as a challenging task. Finally, we release CS-lol and baseline\nimplementation to the research community as a resource.\n","authors":["Junjie H. Xu","Yu Nakano","Lingrong Kong","Kojiro Iizuka"],"pdf_url":"https://arxiv.org/pdf/2301.06876v1.pdf","comment":"5 pages, 3 figures, In ACM SIGIR Conference on Human Information\n  Interaction and Retrieval (CHIIR 23)"},{"id":"http://arxiv.org/abs/2210.06327v3","updated":"2023-01-17T13:32:55Z","published":"2022-10-12T15:47:42Z","title":"Betting the system: Using lineups to predict football scores","summary":"  This paper aims to reduce randomness in football by analysing the role of\nlineups in final scores using machine learning prediction models we have\ndeveloped. Football clubs invest millions of dollars on lineups and knowing how\nindividual statistics translate to better outcomes can optimise investments.\nMoreover, sports betting is growing exponentially and being able to predict the\nfuture is profitable and desirable. We use machine learning models and\nhistorical player data from English Premier League (2020-2022) to predict\nscores and to understand how individual performance can improve the outcome of\na match. We compared different prediction techniques to maximise the\npossibility of finding useful models. We created heuristic and machine learning\nmodels predicting football scores to compare different techniques. We used\ndifferent sets of features and shown goalkeepers stats are more important than\nattackers stats to predict goals scored. We applied a broad evaluation process\nto assess the efficacy of the models in real world applications. We managed to\npredict correctly all relegated teams after forecast 100 consecutive matches.\nWe show that Support Vector Regression outperformed other techniques predicting\nfinal scores and that lineups do not improve predictions. Finally, our model\nwas profitable (42% return) when emulating a betting system using real world\nodds data.\n","authors":["George Peters","Diogo Pacheco"],"pdf_url":"https://arxiv.org/pdf/2210.06327v3.pdf","comment":"8 Page paper submitted for review for SDM23"},{"id":"http://arxiv.org/abs/2301.06871v1","updated":"2023-01-17T13:27:53Z","published":"2023-01-17T13:27:53Z","title":"Denoising Diffusion Probabilistic Models as a Defense against\n  Adversarial Attacks","summary":"  Neural Networks are infamously sensitive to small perturbations in their\ninputs, making them vulnerable to adversarial attacks. This project evaluates\nthe performance of Denoising Diffusion Probabilistic Models (DDPM) as a\npurification technique to defend against adversarial attacks. This works by\nadding noise to an adversarial example before removing it through the reverse\nprocess of the diffusion model. We evaluate the approach on the PatchCamelyon\ndata set for histopathologic scans of lymph node sections and find an\nimprovement of the robust accuracy by up to 88\\% of the original model's\naccuracy, constituting a considerable improvement over the vanilla model and\nour baselines. The project code is located at\nhttps://github.com/ankile/Adversarial-Diffusion.\n","authors":["Lars Lien Ankile","Anna Midgley","Sebastian Weisshaar"],"pdf_url":"https://arxiv.org/pdf/2301.06871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06870v1","updated":"2023-01-17T13:25:52Z","published":"2023-01-17T13:25:52Z","title":"Learning to solve arithmetic problems with a virtual abacus","summary":"  Acquiring mathematical skills is considered a key challenge for modern\nArtificial Intelligence systems. Inspired by the way humans discover numerical\nknowledge, here we introduce a deep reinforcement learning framework that\nallows to simulate how cognitive agents could gradually learn to solve\narithmetic problems by interacting with a virtual abacus. The proposed model\nsuccessfully learn to perform multi-digit additions and subtractions, achieving\nan error rate below 1% even when operands are much longer than those observed\nduring training. We also compare the performance of learning agents receiving a\ndifferent amount of explicit supervision, and we analyze the most common error\npatterns to better understand the limitations and biases resulting from our\ndesign choices.\n","authors":["Flavio Petruzzellis","Ling Xuan Chen","Alberto Testolin"],"pdf_url":"https://arxiv.org/pdf/2301.06870v1.pdf","comment":"Accepted at Northern Lights Deep Learning Conference 2023"},{"id":"http://arxiv.org/abs/2301.06864v1","updated":"2023-01-17T13:18:01Z","published":"2023-01-17T13:18:01Z","title":"Show me what you want: Inverse reinforcement learning to automatically\n  design robot swarms by demonstration","summary":"  Automatic design is a promising approach to generating control software for\nrobot swarms. So far, automatic design has relied on mission-specific objective\nfunctions to specify the desired collective behavior. In this paper, we explore\nthe possibility to specify the desired collective behavior via demonstrations.\nWe develop Demo-Cho, an automatic design method that combines inverse\nreinforcement learning with automatic modular design of control software for\nrobot swarms. We show that, only on the basis of demonstrations and without the\nneed to be provided with an explicit objective function, Demo-Cho successfully\ngenerated control software to perform four missions. We present results\nobtained in simulation and with physical robots.\n","authors":["Ilyes Gharbi","Jonas Kuckling","David Garzón Ramos","Mauro Birattari"],"pdf_url":"https://arxiv.org/pdf/2301.06864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06863v1","updated":"2023-01-17T13:16:16Z","published":"2023-01-17T13:16:16Z","title":"A reinforcement learning path planning approach for range-only\n  underwater target localization with autonomous vehicles","summary":"  Underwater target localization using range-only and single-beacon (ROSB)\ntechniques with autonomous vehicles has been used recently to improve the\nlimitations of more complex methods, such as long baseline and ultra-short\nbaseline systems. Nonetheless, in ROSB target localization methods, the\ntrajectory of the tracking vehicle near the localized target plays an important\nrole in obtaining the best accuracy of the predicted target position. Here, we\ninvestigate a Reinforcement Learning (RL) approach to find the optimal path\nthat an autonomous vehicle should follow in order to increase and optimize the\noverall accuracy of the predicted target localization, while reducing time and\npower consumption. To accomplish this objective, different experimental tests\nhave been designed using state-of-the-art deep RL algorithms. Our study also\ncompares the results obtained with the analytical Fisher information matrix\napproach used in previous studies. The results revealed that the policy learned\nby the RL agent outperforms trajectories based on these analytical solutions,\ne.g. the median predicted error at the beginning of the target's localisation\nis 17% less. These findings suggest that using deep RL for localizing acoustic\ntargets could be successfully applied to in-water applications that include\ntracking of acoustically tagged marine animals by autonomous underwater\nvehicles. This is envisioned as a first necessary step to validate the use of\nRL to tackle such problems, which could be used later on in a more complex\nscenarios\n","authors":["Ivan Masmitja","Mario Martin","Kakani Katija","Spartacus Gomariz","Joan Navarro"],"pdf_url":"https://arxiv.org/pdf/2301.06863v1.pdf","comment":"Accepted at CASE2022. Code at this Github repository\n  https://github.com/imasmitja/RLforUTracking"},{"id":"http://arxiv.org/abs/2103.07117v2","updated":"2023-01-17T13:15:00Z","published":"2021-03-12T07:27:42Z","title":"Genetic algorithm for feature selection of EEG heterogeneous data","summary":"  The electroencephalographic (EEG) signals provide highly informative data on\nbrain activities and functions. However, their heterogeneity and high\ndimensionality may represent an obstacle for their interpretation. The\nintroduction of a priori knowledge seems the best option to mitigate high\ndimensionality problems, but could lose some information and patterns present\nin the data, while data heterogeneity remains an open issue that often makes\ngeneralization difficult. In this study, we propose a genetic algorithm (GA)\nfor feature selection that can be used with a supervised or unsupervised\napproach. Our proposal considers three different fitness functions without\nrelying on expert knowledge. Starting from two publicly available datasets on\ncognitive workload and motor movement/imagery, the EEG signals are processed,\nnormalized and their features computed in the time, frequency and\ntime-frequency domains. The feature vector selection is performed by applying\nour GA proposal and compared with two benchmarking techniques. The results show\nthat different combinations of our proposal achieve better results in respect\nto the benchmark in terms of overall performance and feature reduction.\nMoreover, the proposed GA, based on a novel fitness function here presented,\noutperforms the benchmark when the two different datasets considered are merged\ntogether, showing the effectiveness of our proposal on heterogeneous data.\n","authors":["Aurora Saibene","Francesca Gasparini"],"pdf_url":"https://arxiv.org/pdf/2103.07117v2.pdf","comment":"accepted by Expert Systems with Applications (see\n  https://www.sciencedirect.com/science/article/abs/pii/S0957417422025076)"},{"id":"http://arxiv.org/abs/2301.06841v1","updated":"2023-01-17T12:39:13Z","published":"2023-01-17T12:39:13Z","title":"Syntactically Robust Training on Partially-Observed Data for Open\n  Information Extraction","summary":"  Open Information Extraction models have shown promising results with\nsufficient supervision. However, these models face a fundamental challenge that\nthe syntactic distribution of training data is partially observable in\ncomparison to the real world. In this paper, we propose a syntactically robust\ntraining framework that enables models to be trained on a syntactic-abundant\ndistribution based on diverse paraphrase generation. To tackle the intrinsic\nproblem of knowledge deformation of paraphrasing, two algorithms based on\nsemantic similarity matching and syntactic tree walking are used to restore the\nexpressionally transformed knowledge. The training framework can be generally\napplied to other syntactic partial observable domains. Based on the proposed\nframework, we build a new evaluation set called CaRB-AutoPara, a syntactically\ndiverse dataset consistent with the real-world setting for validating the\nrobustness of the models. Experiments including a thorough analysis show that\nthe performance of the model degrades with the increase of the difference in\nsyntactic distribution, while our framework gives a robust boundary. The source\ncode is publicly available at https://github.com/qijimrc/RobustOIE.\n","authors":["Ji Qi","Yuxiang Chen","Lei Hou","Juanzi Li","Bin Xu"],"pdf_url":"https://arxiv.org/pdf/2301.06841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.11407v2","updated":"2023-01-17T11:54:49Z","published":"2021-12-21T18:09:42Z","title":"Toward Explainable AI for Regression Models","summary":"  In addition to the impressive predictive power of machine learning (ML)\nmodels, more recently, explanation methods have emerged that enable an\ninterpretation of complex non-linear learning models such as deep neural\nnetworks. Gaining a better understanding is especially important e.g. for\nsafety-critical ML applications or medical diagnostics etc. While such\nExplainable AI (XAI) techniques have reached significant popularity for\nclassifiers, so far little attention has been devoted to XAI for regression\nmodels (XAIR). In this review, we clarify the fundamental conceptual\ndifferences of XAI for regression and classification tasks, establish novel\ntheoretical insights and analysis for XAIR, provide demonstrations of XAIR on\ngenuine practical regression problems, and finally discuss the challenges\nremaining for the field.\n","authors":["Simon Letzgus","Patrick Wagner","Jonas Lederer","Wojciech Samek","Klaus-Robert Müller","Gregoire Montavon"],"pdf_url":"https://arxiv.org/pdf/2112.11407v2.pdf","comment":"17 pages, 10 figures, published; changes: 1. references to code and\n  xai-regression.org added (p. 1/2, end of introduction), 2. adjustment of\n  sign-error in restructuring section (p. 8, just above Fig. 4)"},{"id":"http://arxiv.org/abs/2301.06820v1","updated":"2023-01-17T11:45:51Z","published":"2023-01-17T11:45:51Z","title":"Pathfinding Neural Cellular Automata","summary":"  Pathfinding makes up an important sub-component of a broad range of complex\ntasks in AI, such as robot path planning, transport routing, and game playing.\nWhile classical algorithms can efficiently compute shortest paths, neural\nnetworks could be better suited to adapting these sub-routines to more complex\nand intractable tasks. As a step toward developing such networks, we hand-code\nand learn models for Breadth-First Search (BFS), i.e. shortest path finding,\nusing the unified architectural framework of Neural Cellular Automata, which\nare iterative neural networks with equal-size inputs and outputs. Similarly, we\npresent a neural implementation of Depth-First Search (DFS), and outline how it\ncan be combined with neural BFS to produce an NCA for computing diameter of a\ngraph. We experiment with architectural modifications inspired by these\nhand-coded NCAs, training networks from scratch to solve the diameter problem\non grid mazes while exhibiting strong generalization ability. Finally, we\nintroduce a scheme in which data points are mutated adversarially during\ntraining. We find that adversarially evolving mazes leads to increased\ngeneralization on out-of-distribution examples, while at the same time\ngenerating data-sets with significantly more complex solutions for reasoning\ntasks.\n","authors":["Sam Earle","Ozlem Yildiz","Julian Togelius","Chinmay Hegde"],"pdf_url":"https://arxiv.org/pdf/2301.06820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00706v2","updated":"2023-01-17T11:30:18Z","published":"2022-06-01T18:42:02Z","title":"Split-kl and PAC-Bayes-split-kl Inequalities for Ternary Random\n  Variables","summary":"  We present a new concentration of measure inequality for sums of independent\nbounded random variables, which we name a split-kl inequality. The inequality\nis particularly well-suited for ternary random variables, which naturally show\nup in a variety of problems, including analysis of excess losses in\nclassification, analysis of weighted majority votes, and learning with\nabstention. We demonstrate that for ternary random variables the inequality is\nsimultaneously competitive with the kl inequality, the Empirical Bernstein\ninequality, and the Unexpected Bernstein inequality, and in certain regimes\noutperforms all of them. It resolves an open question by Tolstikhin and Seldin\n[2013] and Mhammedi et al. [2019] on how to match simultaneously the\ncombinatorial power of the kl inequality when the distribution happens to be\nclose to binary and the power of Bernstein inequalities to exploit low variance\nwhen the probability mass is concentrated on the middle value. We also derive a\nPAC-Bayes-split-kl inequality and compare it with the PAC-Bayes-kl,\nPAC-Bayes-Empirical-Bennett, and PAC-Bayes-Unexpected-Bernstein inequalities in\nan analysis of excess losses and in an analysis of a weighted majority vote for\nseveral UCI datasets. Last but not least, our study provides the first direct\ncomparison of the Empirical Bernstein and Unexpected Bernstein inequalities and\ntheir PAC-Bayes extensions.\n","authors":["Yi-Shan Wu","Yevgeny Seldin"],"pdf_url":"https://arxiv.org/pdf/2206.00706v2.pdf","comment":"aligned with the camera-ready version published to NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.06815v1","updated":"2023-01-17T11:26:34Z","published":"2023-01-17T11:26:34Z","title":"Follow Us and Become Famous! Insights and Guidelines From Instagram\n  Engagement Mechanisms","summary":"  With 1.3 billion users, Instagram (IG) has also become a business tool. IG\ninfluencer marketing, expected to generate $33.25 billion in 2022, encourages\ncompanies and influencers to create trending content. Various methods have been\nproposed for predicting a post's popularity, i.e., how much engagement (e.g.,\nLikes) it will generate. However, these methods are limited: first, they focus\non forecasting the likes, ignoring the number of comments, which became crucial\nin 2021. Secondly, studies often use biased or limited data. Third, researchers\nfocused on Deep Learning models to increase predictive performance, which are\ndifficult to interpret. As a result, end-users can only estimate engagement\nafter a post is created, which is inefficient and expensive. A better approach\nis to generate a post based on what people and IG like, e.g., by following\nguidelines.\n  In this work, we uncover part of the underlying mechanisms driving IG\nengagement. To achieve this goal, we rely on statistical analysis and\ninterpretable models rather than Deep Learning (black-box) approaches. We\nconduct extensive experiments using a worldwide dataset of 10 million posts\ncreated by 34K global influencers in nine different categories. With our simple\nyet powerful algorithms, we can predict engagement up to 94% of F1-Score,\nmaking us comparable and even superior to Deep Learning-based method.\nFurthermore, we propose a novel unsupervised algorithm for finding highly\nengaging topics on IG. Thanks to our interpretable approaches, we conclude by\noutlining guidelines for creating successful posts.\n","authors":["Pier Paolo Tricomi","Marco Chilese","Mauro Conti","Ahmad-Reza Sadeghi"],"pdf_url":"https://arxiv.org/pdf/2301.06815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04952v2","updated":"2023-01-17T11:14:40Z","published":"2022-08-09T10:49:40Z","title":"Continual Prune-and-Select: Class-incremental learning with specialized\n  subnetworks","summary":"  The human brain is capable of learning tasks sequentially mostly without\nforgetting. However, deep neural networks (DNNs) suffer from catastrophic\nforgetting when learning one task after another. We address this challenge\nconsidering a class-incremental learning scenario where the DNN sees test data\nwithout knowing the task from which this data originates. During training,\nContinual-Prune-and-Select (CP&S) finds a subnetwork within the DNN that is\nresponsible for solving a given task. Then, during inference, CP&S selects the\ncorrect subnetwork to make predictions for that task. A new task is learned by\ntraining available neuronal connections of the DNN (previously untrained) to\ncreate a new subnetwork by pruning, which can include previously trained\nconnections belonging to other subnetwork(s) because it does not update shared\nconnections. This enables to eliminate catastrophic forgetting by creating\nspecialized regions in the DNN that do not conflict with each other while still\nallowing knowledge transfer across them. The CP&S strategy is implemented with\ndifferent subnetwork selection strategies, revealing superior performance to\nstate-of-the-art continual learning methods tested on various datasets\n(CIFAR-100, CUB-200-2011, ImageNet-100 and ImageNet-1000). In particular, CP&S\nis capable of sequentially learning 10 tasks from ImageNet-1000 keeping an\naccuracy around 94% with negligible forgetting, a first-of-its-kind result in\nclass-incremental learning. To the best of the authors' knowledge, this\nrepresents an improvement in accuracy above 10% when compared to the best\nalternative method.\n","authors":["Aleksandr Dekhovich","David M. J. Tax","Marcel H. F. Sluiter","Miguel A. Bessa"],"pdf_url":"https://arxiv.org/pdf/2208.04952v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06806v1","updated":"2023-01-17T11:04:10Z","published":"2023-01-17T11:04:10Z","title":"Convergence of First-Order Algorithms for Meta-Learning with Moreau\n  Envelopes","summary":"  In this work, we consider the problem of minimizing the sum of Moreau\nenvelopes of given functions, which has previously appeared in the context of\nmeta-learning and personalized federated learning. In contrast to the existing\ntheory that requires running subsolvers until a certain precision is reached,\nwe only assume that a finite number of gradient steps is taken at each\niteration. As a special case, our theory allows us to show the convergence of\nFirst-Order Model-Agnostic Meta-Learning (FO-MAML) to the vicinity of a\nsolution of Moreau objective. We also study a more general family of\nfirst-order algorithms that can be viewed as a generalization of FO-MAML. Our\nmain theoretical achievement is a theoretical improvement upon the inexact SGD\nframework. In particular, our perturbed-iterate analysis allows for tighter\nguarantees that improve the dependency on the problem's conditioning. In\ncontrast to the related work on meta-learning, ours does not require any\nassumptions on the Hessian smoothness, and can leverage smoothness and\nconvexity of the reformulation based on Moreau envelopes. Furthermore, to fill\nthe gaps in the comparison of FO-MAML to the Implicit MAML (iMAML), we show\nthat the objective of iMAML is neither smooth nor convex, implying that it has\nno convergence guarantees based on the existing theory.\n","authors":["Konstantin Mishchenko","Slavomír Hanzely","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2301.06806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06794v1","updated":"2023-01-17T10:41:42Z","published":"2023-01-17T10:41:42Z","title":"Subgraph Centralization: A Necessary Step for Graph Anomaly Detection","summary":"  Graph anomaly detection has attracted a lot of interest recently. Despite\ntheir successes, existing detectors have at least two of the three weaknesses:\n(a) high computational cost which limits them to small-scale networks only; (b)\nexisting treatment of subgraphs produces suboptimal detection accuracy; and (c)\nunable to provide an explanation as to why a node is anomalous, once it is\nidentified. We identify that the root cause of these weaknesses is a lack of a\nproper treatment for subgraphs. A treatment called Subgraph Centralization for\ngraph anomaly detection is proposed to address all the above weaknesses. Its\nimportance is shown in two ways. First, we present a simple yet effective new\nframework called Graph-Centric Anomaly Detection (GCAD). The key advantages of\nGCAD over existing detectors including deep-learning detectors are: (i) better\nanomaly detection accuracy; (ii) linear time complexity with respect to the\nnumber of nodes; and (iii) it is a generic framework that admits an existing\npoint anomaly detector to be used to detect node anomalies in a network.\nSecond, we show that Subgraph Centralization can be incorporated into two\nexisting detectors to overcome the above-mentioned weaknesses.\n","authors":["Zhong Zhuang","Kai Ming Ting","Guansong Pang","Shuaibin Song"],"pdf_url":"https://arxiv.org/pdf/2301.06794v1.pdf","comment":"To be published in SDM2023"},{"id":"http://arxiv.org/abs/2301.06789v1","updated":"2023-01-17T10:30:34Z","published":"2023-01-17T10:30:34Z","title":"Multicenter automatic detection of invasive carcinoma on breast whole\n  slide images","summary":"  Breast cancer is one of the most prevalent cancers worldwide and pathologists\nare closely involved in establishing a diagnosis. Tools to assist in making a\ndiagnosis are required to manage the increasing workload. In this context,\nartificial intelligence (AI) and deep-learning based tools may be used in daily\npathology practice. However, it is challenging to develop fast and reliable\nalgorithms that can be trusted by practitioners, whatever the medical center.\nWe describe a patch-based algorithm that incorporates a convolutional neural\nnetwork to detect and locate invasive carcinoma on breast whole-slide images.\nThe network was trained on a dataset extracted from a reference acquisition\ncenter. We then performed a calibration step based on transfer learning to\nmaintain the performance when translating on a new target acquisition center by\nusing a limited amount of additional training data. Performance was evaluated\nusing classical binary measures (accuracy, recall, precision) for both centers\n(referred to as test reference dataset and test target dataset) and at two\nlevels: patch and slide level. At patch level, accuracy, recall, and precision\nof the model on the reference and target test sets were 92.1\\% and 96.3\\%, 95\\%\nand 87.8\\%, and 73.9\\% and 70.6\\%, respectively. At slide level, accuracy,\nrecall, and precision were 97.6\\% and 92.0\\%, 90.9\\% and 100\\%, and 100\\% and\n70.8\\% for test sets 1 and 2, respectively. The high performance of the\nalgorithm at both centers shows that the calibration process is efficient. This\nis performed using limited training data from the new target acquisition center\nand requires that the model is trained beforehand on a large database from a\nreference center. This methodology allows the implementation of AI diagnostic\ntools to help in routine pathology practice.\n","authors":["Rémy Peyret","Nicolas Pozin","Stéphane Sockeel","Solène-Florence Kammerer-Jacquet","Julien Adam","Claire Bocciarelli","Yoan Ditchi","Christophe Bontoux","Thomas Depoilly","Loris Guichard","Elisabeth Lanteri","Marie Sockeel","Sophie Prévot"],"pdf_url":"https://arxiv.org/pdf/2301.06789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06786v1","updated":"2023-01-17T10:29:07Z","published":"2023-01-17T10:29:07Z","title":"Ensemble Reservoir Computing for Dynamical Systems: Prediction of\n  Phase-Space Stable Region for Hadron Storage Rings","summary":"  We investigate the ability of an ensemble reservoir computing approach to\npredict the long-term behaviour of the phase-space region in which the motion\nof charged particles in hadron storage rings is bounded, the so-called dynamic\naperture. Currently, the calculation of the phase-space stability region of\nhadron storage rings is performed through direct computer simulations, which\nare resource- and time-intensive processes. Echo State Networks (ESN) are a\nclass of recurrent neural networks that are computationally effective, since\nthey avoid backpropagation and require only cross-validation. Furthermore, they\nhave been proven to be universal approximants of dynamical systems. In this\npaper, we present the performance reached by ESN based on an ensemble approach\nfor the prediction of the phase-space stability region and compare it with\nanalytical scaling laws based on the stability-time estimate of the Nekhoroshev\ntheorem for Hamiltonian systems. We observe that the proposed ESN approach is\ncapable of effectively predicting the time evolution of the extent of the\ndynamic aperture, improving the predictions by analytical scaling laws, thus\nproviding an efficient surrogate model.\n","authors":["Maxime Casanova","Barbara Dalena","Luca Bonaventura","Massimo Giovannozzi"],"pdf_url":"https://arxiv.org/pdf/2301.06786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.13624v2","updated":"2023-01-17T10:20:00Z","published":"2021-06-25T13:23:20Z","title":"Chebyshev-Cantelli PAC-Bayes-Bennett Inequality for the Weighted\n  Majority Vote","summary":"  We present a new second-order oracle bound for the expected risk of a\nweighted majority vote. The bound is based on a novel parametric form of the\nChebyshev- Cantelli inequality (a.k.a. one-sided Chebyshev's), which is\namenable to efficient minimization. The new form resolves the optimization\nchallenge faced by prior oracle bounds based on the Chebyshev-Cantelli\ninequality, the C-bounds [Germain et al., 2015], and, at the same time, it\nimproves on the oracle bound based on second order Markov's inequality\nintroduced by Masegosa et al. [2020]. We also derive a new concentration of\nmeasure inequality, which we name PAC-Bayes-Bennett, since it combines\nPAC-Bayesian bounding with Bennett's inequality. We use it for empirical\nestimation of the oracle bound. The PAC-Bayes-Bennett inequality improves on\nthe PAC-Bayes-Bernstein inequality of Seldin et al. [2012]. We provide an\nempirical evaluation demonstrating that the new bounds can improve on the work\nof Masegosa et al. [2020]. Both the parametric form of the Chebyshev-Cantelli\ninequality and the PAC-Bayes-Bennett inequality may be of independent interest\nfor the study of concentration of measure in other domains.\n","authors":["Yi-Shan Wu","Andrés R. Masegosa","Stephan S. Lorenzen","Christian Igel","Yevgeny Seldin"],"pdf_url":"https://arxiv.org/pdf/2106.13624v2.pdf","comment":"aligned with the camera-ready version published at NeurIPS 2021"},{"id":"http://arxiv.org/abs/2007.03481v5","updated":"2023-01-17T10:07:28Z","published":"2020-07-07T14:14:12Z","title":"Necessary and Sufficient Conditions for Inverse Reinforcement Learning\n  of Bayesian Stopping Time Problems","summary":"  This paper presents an inverse reinforcement learning~(IRL) framework for\nBayesian stopping time problems. By observing the actions of a Bayesian\ndecision maker, we provide a necessary and sufficient condition to identify if\nthese actions are consistent with optimizing a cost function. In a Bayesian\n(partially observed) setting, the inverse learner can at best identify\noptimality wrt the observed actions. Our IRL algorithm identifies optimality\nand then constructs set valued estimates of the cost function. To achieve this\nIRL objective, we use novel ideas from Bayesian revealed preferences stemming\nfrom microeconomics. We illustrate the proposed IRL scheme using two important\nexamples of stopping time problems, namely, sequential hypothesis testing and\nBayesian search, and also on a real-world YouTube dataset. Finally, for finite\ndatasets, we propose an IRL detection algorithm and give finite sample bounds\non its error probabilities.\n","authors":["Kunal Pattanayak","Vikram Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2007.03481v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06777v1","updated":"2023-01-17T10:00:17Z","published":"2023-01-17T10:00:17Z","title":"Reusable Self-Attention Recommender Systems in Fashion Industry\n  Applications","summary":"  A large number of empirical studies on applying self-attention models in the\ndomain of recommender systems are based on offline evaluation and metrics\ncomputed on standardized datasets. Moreover, many of them do not consider side\ninformation such as item and customer metadata although deep-learning\nrecommenders live up to their full potential only when numerous features of\nheterogeneous type are included. Also, normally the model is used only for a\nsingle use case. Due to these shortcomings, even if relevant, previous works\nare not always representative of their actual effectiveness in real-world\nindustry applications. In this talk, we contribute to bridging this gap by\npresenting live experimental results demonstrating improvements in user\nretention of up to 30\\%. Moreover, we share our learnings and challenges from\nbuilding a re-usable and configurable recommender system for various\napplications from the fashion industry. In particular, we focus on fashion\ninspiration use-cases, such as outfit ranking, outfit recommendation and\nreal-time personalized outfit generation.\n","authors":["Marjan Celikik","Jacek Wasilewski","Ana Peleteiro Ramallo"],"pdf_url":"https://arxiv.org/pdf/2301.06777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14715v2","updated":"2023-01-17T09:57:23Z","published":"2022-12-28T08:11:17Z","title":"Bayesian statistical learning using density operators","summary":"  This short study reformulates the statistical Bayesian learning problem using\na quantum mechanics framework. Density operators representing ensembles of pure\nstates of sample wave functions are used in place probability densities. We\nshow that such representation allows to formulate the statistical Bayesian\nlearning problem in different coordinate systems on the sample space. We\nfurther show that such representation allows to learn projections of density\noperators using a kernel trick. In particular, the study highlights that\ndecomposing wave functions rather than probability densities, as it is done in\nkernel embedding, allows to preserve the nature of probability operators.\nResults are illustrated with a simple example using discrete orthogonal wavelet\ntransform of density operators.\n","authors":["Yann Berquin"],"pdf_url":"https://arxiv.org/pdf/2212.14715v2.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.06769v1","updated":"2023-01-17T09:24:32Z","published":"2023-01-17T09:24:32Z","title":"Geometric ergodicity of SGLD via reflection coupling","summary":"  We consider the geometric ergodicity of the Stochastic Gradient Langevin\nDynamics (SGLD) algorithm under nonconvexity settings. Via the technique of\nreflection coupling, we prove the Wasserstein contraction of SGLD when the\ntarget distribution is log-concave only outside some compact set. The time\ndiscretization and the minibatch in SGLD introduce several difficulties when\napplying the reflection coupling, which are addressed by a series of careful\nestimates of conditional expectations. As a direct corollary, the SGLD with\nconstant step size has an invariant distribution and we are able to obtain its\ngeometric ergodicity in terms of $W_1$ distance. The generalization to\nnon-gradient drifts is also included.\n","authors":["Lei Li","Jian-Guo Liu","Yuliang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09682v2","updated":"2023-01-17T09:18:14Z","published":"2022-07-20T06:27:06Z","title":"Quantized Training of Gradient Boosting Decision Trees","summary":"  Recent years have witnessed significant success in Gradient Boosting Decision\nTrees (GBDT) for a wide range of machine learning applications. Generally, a\nconsensus about GBDT's training algorithms is gradients and statistics are\ncomputed based on high-precision floating points. In this paper, we investigate\nan essentially important question which has been largely ignored by the\nprevious literature: how many bits are needed for representing gradients in\ntraining GBDT? To solve this mystery, we propose to quantize all the\nhigh-precision gradients in a very simple yet effective way in the GBDT's\ntraining algorithm. Surprisingly, both our theoretical analysis and empirical\nstudies show that the necessary precisions of gradients without hurting any\nperformance can be quite low, e.g., 2 or 3 bits. With low-precision gradients,\nmost arithmetic operations in GBDT training can be replaced by integer\noperations of 8, 16, or 32 bits. Promisingly, these findings may pave the way\nfor much more efficient training of GBDT from several aspects: (1) speeding up\nthe computation of gradient statistics in histograms; (2) compressing the\ncommunication cost of high-precision statistical information during distributed\ntraining; (3) the inspiration of utilization and development of hardware\narchitectures which well support low-precision computation for GBDT training.\nBenchmarked on CPUs, GPUs, and distributed clusters, we observe up to 2$\\times$\nspeedup of our simple quantization strategy compared with SOTA GBDT systems on\nextensive datasets, demonstrating the effectiveness and potential of the\nlow-precision training of GBDT. The code will be released to the official\nrepository of LightGBM.\n","authors":["Yu Shi","Guolin Ke","Zhuoming Chen","Shuxin Zheng","Tie-Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2207.09682v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06768v1","updated":"2023-01-17T09:15:37Z","published":"2023-01-17T09:15:37Z","title":"FedCliP: Federated Learning with Client Pruning","summary":"  Federated learning (FL) is a newly emerging distributed learning paradigm\nthat allows numerous participating clients to train machine learning models\ncollaboratively, each with its data distribution and without sharing their\ndata. One fundamental bottleneck in FL is the heavy communication overheads of\nhigh-dimensional models between the distributed clients and the central server.\nPrevious works often condense models into compact formats by gradient\ncompression or distillation to overcome communication limitations. In contrast,\nwe propose FedCliP in this work, the first communication efficient FL training\nframework from a macro perspective, which can position valid clients\nparticipating in FL quickly and constantly prune redundant clients.\nSpecifically, We first calculate the reliability score based on the training\nloss and model divergence as an indicator to measure the client pruning. We\npropose a valid client determination approximation framework based on the\nreliability score with Gaussian Scale Mixture (GSM) modeling for federated\nparticipating clients pruning. Besides, we develop a communication efficient\nclient pruning training method in the FL scenario. Experimental results on\nMNIST dataset show that FedCliP has up to 10%~70% communication costs for\nconverged models at only a 0.2% loss in accuracy.\n","authors":["Beibei Li","Zerui Shao","Ao Liu","Peiran Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06768v1.pdf","comment":"8 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2210.12375v2","updated":"2023-01-17T09:02:47Z","published":"2022-10-22T07:08:17Z","title":"torchode: A Parallel ODE Solver for PyTorch","summary":"  We introduce an ODE solver for the PyTorch ecosystem that can solve multiple\nODEs in parallel independently from each other while achieving significant\nperformance gains. Our implementation tracks each ODE's progress separately and\nis carefully optimized for GPUs and compatibility with PyTorch's JIT compiler.\nIts design lets researchers easily augment any aspect of the solver and collect\nand analyze internal solver statistics. In our experiments, our implementation\nis up to 4.3 times faster per step than other ODE solvers and it is robust\nagainst within-batch interactions that lead other solvers to take up to 4 times\nas many steps.\n  Code available at https://github.com/martenlienen/torchode\n","authors":["Marten Lienen","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2210.12375v2.pdf","comment":"Accepted at The Symbiosis of Deep Learning and Differential Equations\n  Workshop, NeurIPS, 2022"},{"id":"http://arxiv.org/abs/2301.06758v1","updated":"2023-01-17T08:46:50Z","published":"2023-01-17T08:46:50Z","title":"Tracing and Manipulating Intermediate Values in Neural Math Problem\n  Solvers","summary":"  How language models process complex input that requires multiple steps of\ninference is not well understood. Previous research has shown that information\nabout intermediate values of these inputs can be extracted from the activations\nof the models, but it is unclear where that information is encoded and whether\nthat information is indeed used during inference. We introduce a method for\nanalyzing how a Transformer model processes these inputs by focusing on simple\narithmetic problems and their intermediate values. To trace where information\nabout intermediate values is encoded, we measure the correlation between\nintermediate values and the activations of the model using principal component\nanalysis (PCA). Then, we perform a causal intervention by manipulating model\nweights. This intervention shows that the weights identified via tracing are\nnot merely correlated with intermediate values, but causally related to model\npredictions. Our findings show that the model has a locality to certain\nintermediate values, and this is useful for enhancing the interpretability of\nthe models.\n","authors":["Yuta Matsumoto","Benjamin Heinzerling","Masashi Yoshikawa","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2301.06758v1.pdf","comment":"5 pages, 4 figures, MathNLP"},{"id":"http://arxiv.org/abs/2109.03467v2","updated":"2023-01-17T08:24:00Z","published":"2021-09-08T07:27:39Z","title":"A Deep Reinforcement Learning Approach for Online Parcel Assignment","summary":"  In this paper, we investigate the online parcel assignment (OPA) problem, in\nwhich each stochastically generated parcel needs to be assigned to a candidate\nroute for delivery to minimize the total cost subject to certain business\nconstraints. The OPA problem is challenging due to its stochastic nature: each\nparcel's candidate routes, which depends on the parcel's origin, destination,\nweight, etc., are unknown until its order is placed, and the total parcel\nvolume is uncertain in advance. To tackle this challenge, we propose the\nPPO-OPA algorithm based on deep reinforcement learning that shows competitive\nperformance. More specifically, we introduce a novel Markov Decision Process\n(MDP) framework to model the OPA problem, and develop a policy gradient\nalgorithm that adopts attention networks for policy evaluation. By designing a\ndedicated reward function, our proposed algorithm can achieve a lower total\ncost with smaller violation of constraints, comparing to the traditional method\nwhich assigns parcels to candidate routes proportionally. In addition, the\nperformances of our proposed algorithm and the Primal-Dual algorithm are\ncomparable, while the later assumes a known total parcel volume in advance,\nwhich is unrealistic in practice.\n","authors":["Hao Zeng","Qiong Wu","Kunpeng Han","Junying He","Haoyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2109.03467v2.pdf","comment":"8 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2205.14575v2","updated":"2023-01-17T08:08:15Z","published":"2022-05-29T06:01:42Z","title":"3D-C2FT: Coarse-to-fine Transformer for Multi-view 3D Reconstruction","summary":"  Recently, the transformer model has been successfully employed for the\nmulti-view 3D reconstruction problem. However, challenges remain on designing\nan attention mechanism to explore the multiview features and exploit their\nrelations for reinforcing the encoding-decoding modules. This paper proposes a\nnew model, namely 3D coarse-to-fine transformer (3D-C2FT), by introducing a\nnovel coarse-to-fine(C2F) attention mechanism for encoding multi-view features\nand rectifying defective 3D objects. C2F attention mechanism enables the model\nto learn multi-view information flow and synthesize 3D surface correction in a\ncoarse to fine-grained manner. The proposed model is evaluated by ShapeNet and\nMulti-view Real-life datasets. Experimental results show that 3D-C2FT achieves\nnotable results and outperforms several competing models on these datasets.\n","authors":["Leslie Ching Ow Tiong","Dick Sigmund","Andrew Beng Jin Teoh"],"pdf_url":"https://arxiv.org/pdf/2205.14575v2.pdf","comment":"Accepted by Asian Conference on Computer Vision (ACCV) 2022"},{"id":"http://arxiv.org/abs/2301.02828v2","updated":"2023-01-17T08:02:58Z","published":"2023-01-07T11:12:36Z","title":"Why do Nearest Neighbor Language Models Work?","summary":"  Language models (LMs) compute the probability of a text by sequentially\ncomputing a representation of an already-seen context and using this\nrepresentation to predict the next word. Currently, most LMs calculate these\nrepresentations through a neural network consuming the immediate previous\ncontext. However recently, retrieval-augmented LMs have shown to improve over\nstandard neural LMs, by accessing information retrieved from a large datastore,\nin addition to their standard, parametric, next-word prediction. In this paper,\nwe set out to understand why retrieval-augmented language models, and\nspecifically why k-nearest neighbor language models (kNN-LMs) perform better\nthan standard parametric LMs, even when the k-nearest neighbor component\nretrieves examples from the same training set that the LM was originally\ntrained on. To this end, we perform a careful analysis of the various\ndimensions over which kNN-LM diverges from standard LMs, and investigate these\ndimensions one by one. Empirically, we identify three main reasons why kNN-LM\nperforms better than standard LMs: using a different input representation for\npredicting the next tokens, approximate kNN search, and the importance of\nsoftmax temperature for the kNN distribution. Further, we incorporate these\ninsights into the model architecture or the training procedure of the standard\nparametric LM, improving its results without the need for an explicit retrieval\ncomponent. The code is available at https://github.com/frankxu2004/knnlm-why.\n","authors":["Frank F. Xu","Uri Alon","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2301.02828v2.pdf","comment":"Preprint, 21 pages"},{"id":"http://arxiv.org/abs/2208.06270v2","updated":"2023-01-17T07:40:30Z","published":"2022-08-12T13:37:05Z","title":"RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence","summary":"  Contrastive representation learning seeks to acquire useful representations\nby estimating the shared information between multiple views of data. Here, the\nchoice of data augmentation is sensitive to the quality of learned\nrepresentations: as harder the data augmentations are applied, the views share\nmore task-relevant information, but also task-irrelevant one that can hinder\nthe generalization capability of representation. Motivated by this, we present\na new robust contrastive learning scheme, coined R\\'enyiCL, which can\neffectively manage harder augmentations by utilizing R\\'enyi divergence. Our\nmethod is built upon the variational lower bound of R\\'enyi divergence, but a\nna\\\"ive usage of a variational method is impractical due to the large variance.\nTo tackle this challenge, we propose a novel contrastive objective that\nconducts variational estimation of a skew R\\'enyi divergence and provide a\ntheoretical guarantee on how variational estimation of skew divergence leads to\nstable training. We show that R\\'enyi contrastive learning objectives perform\ninnate hard negative sampling and easy positive sampling simultaneously so that\nit can selectively learn useful features and ignore nuisance features. Through\nexperiments on ImageNet, we show that R\\'enyi contrastive learning with\nstronger augmentations outperforms other self-supervised methods without extra\nregularization or computational overhead. Moreover, we also validate our method\non other domains such as graph and tabular, showing empirical gain over other\ncontrastive methods.\n","authors":["Kyungmin Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2208.06270v2.pdf","comment":"Camera-ready version"},{"id":"http://arxiv.org/abs/2301.06732v1","updated":"2023-01-17T07:22:54Z","published":"2023-01-17T07:22:54Z","title":"Coronal Hole Analysis and Prediction using Computer Vision and LSTM\n  Neural Network","summary":"  As humanity has begun to explore space, the significance of space weather has\nbecome apparent. It has been established that coronal holes, a type of space\nweather phenomenon, can impact the operation of aircraft and satellites. The\ncoronal hole is an area on the sun characterized by open magnetic field lines\nand relatively low temperatures, which result in the emission of the solar wind\nat higher than average rates. In this study, To prepare for the impact of\ncoronal holes on the Earth, we use computer vision to detect the coronal hole\nregion and calculate its size based on images from the Solar Dynamics\nObservatory (SDO). We then implement deep learning techniques, specifically the\nLong Short-Term Memory (LSTM) method, to analyze trends in the coronal hole\narea data and predict its size for different sun regions over 7 days. By\nanalyzing time series data on the coronal hole area, this study aims to\nidentify patterns and trends in coronal hole behavior and understand how they\nmay impact space weather events. This research represents an important step\ntowards improving our ability to predict and prepare for space weather events\nthat can affect Earth and technological systems.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2301.06732v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2104.09015v3","updated":"2023-01-17T06:34:36Z","published":"2021-04-19T02:15:25Z","title":"Labels, Information, and Computation: Efficient Learning Using\n  Sufficient Labels","summary":"  In supervised learning, obtaining a large set of fully-labeled training data\nis expensive. We show that we do not always need full label information on\nevery single training example to train a competent classifier. Specifically,\ninspired by the principle of sufficiency in statistics, we present a statistic\n(a summary) of the fully-labeled training set that captures almost all the\nrelevant information for classification but at the same time is easier to\nobtain directly. We call this statistic \"sufficiently-labeled data\" and prove\nits sufficiency and efficiency for finding the optimal hidden representations,\non which competent classifier heads can be trained using as few as a single\nrandomly-chosen fully-labeled example per class. Sufficiently-labeled data can\nbe obtained from annotators directly without collecting the fully-labeled data\nfirst. And we prove that it is easier to directly obtain sufficiently-labeled\ndata than obtaining fully-labeled data. Furthermore, sufficiently-labeled data\nis naturally more secure since it stores relative, instead of absolute,\ninformation. Extensive experimental results are provided to support our theory.\n","authors":["Shiyu Duan","Spencer Chang","Jose C. Principe"],"pdf_url":"https://arxiv.org/pdf/2104.09015v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06715v1","updated":"2023-01-17T06:01:46Z","published":"2023-01-17T06:01:46Z","title":"SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via\n  Swin Transformer and Densely Cascaded Network","summary":"  Monocular depth estimation plays a critical role in various computer vision\nand robotics applications such as localization, mapping, and 3D object\ndetection. Recently, learning-based algorithms achieve huge success in depth\nestimation by training models with a large amount of data in a supervised\nmanner. However, it is challenging to acquire dense ground truth depth labels\nfor supervised training, and the unsupervised depth estimation using monocular\nsequences emerges as a promising alternative. Unfortunately, most studies on\nunsupervised depth estimation explore loss functions or occlusion masks, and\nthere is little change in model architecture in that ConvNet-based\nencoder-decoder structure becomes a de-facto standard for depth estimation. In\nthis paper, we employ a convolution-free Swin Transformer as an image feature\nextractor so that the network can capture both local geometric features and\nglobal semantic features for depth estimation. Also, we propose a Densely\nCascaded Multi-scale Network (DCMNet) that connects every feature map directly\nwith another from different scales via a top-down cascade pathway. This densely\ncascaded connectivity reinforces the interconnection between decoding layers\nand produces high-quality multi-scale depth outputs. The experiments on two\ndifferent datasets, KITTI and Make3D, demonstrate that our proposed method\noutperforms existing state-of-the-art unsupervised algorithms.\n","authors":["Dongseok Shim","H. Jin Kim"],"pdf_url":"https://arxiv.org/pdf/2301.06715v1.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2205.06491v3","updated":"2023-01-17T05:25:52Z","published":"2022-05-13T07:46:43Z","title":"Tighter Regret Analysis and Optimization of Online Federated Learning","summary":"  In federated learning (FL), it is commonly assumed that all data are placed\nat clients in the beginning of machine learning (ML) optimization (i.e.,\noffline learning). However, in many real-world applications, it is expected to\nproceed in an online fashion. To this end, online FL (OFL) has been introduced,\nwhich aims at learning a sequence of global models from decentralized streaming\ndata such that the so-called cumulative regret is minimized. Combining online\ngradient descent and model averaging, in this framework, FedOGD is constructed\nas the counterpart of FedSGD in FL. While it can enjoy an optimal sublinear\nregret, FedOGD suffers from heavy communication costs. In this paper, we\npresent a communication-efficient method (named OFedIQ) by means of\nintermittent transmission (enabled by client subsampling and periodic\ntransmission) and quantization. For the first time, we derive the regret bound\nthat captures the impact of data-heterogeneity and the communication-efficient\ntechniques. Through this, we efficiently optimize the parameters of OFedIQ such\nas sampling rate, transmission period, and quantization levels. Also, it is\nproved that the optimized OFedIQ can asymptotically achieve the performance of\nFedOGD while reducing the communication costs by 99%. Via experiments with real\ndatasets, we demonstrate the effectiveness of the optimized OFedIQ.\n","authors":["Dohyeok Kwon","Jonghwan Park","Songnam Hong"],"pdf_url":"https://arxiv.org/pdf/2205.06491v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04430v3","updated":"2023-01-17T05:22:42Z","published":"2022-09-09T17:48:36Z","title":"Investigation of a Machine learning methodology for the SKA pulsar\n  search pipeline","summary":"  The SKA pulsar search pipeline will be used for real time detection of\npulsars. Modern radio telescopes such as SKA will be generating petabytes of\ndata in their full scale of operation. Hence experience-based and data-driven\nalgorithms become indispensable for applications such as candidate detection.\nHere we describe our findings from testing a state of the art object detection\nalgorithm called Mask R-CNN to detect candidate signatures in the SKA pulsar\nsearch pipeline. We have trained the Mask R-CNN model to detect candidate\nimages. A custom annotation tool was developed to mark the regions of interest\nin large datasets efficiently. We have successfully demonstrated this algorithm\nby detecting candidate signatures on a simulation dataset. The paper presents\ndetails of this work with a highlight on the future prospects.\n","authors":["Shashank Sanjay Bhat","Thiagaraj Prabu","Ben Stappers","Atul Ghalame","Snehanshu Saha","T. S. B Sudarshan","Zafiirah Hosenie"],"pdf_url":"https://arxiv.org/pdf/2209.04430v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01104v2","updated":"2023-01-17T05:04:24Z","published":"2023-01-03T13:58:39Z","title":"KoopmanLab: machine learning for solving complex physics equations","summary":"  Numerous physics theories are rooted in partial differential equations\n(PDEs). However, the increasingly intricate physics equations, especially those\nthat lack analytic solutions or closed forms, have impeded the further\ndevelopment of physics. Computationally solving PDEs by classic numerical\napproaches suffers from the trade-off between accuracy and efficiency and is\nnot applicable to the empirical data generated by unknown latent PDEs. To\novercome this challenge, we present KoopmanLab, an efficient module of the\nKoopman neural operator family, for learning PDEs without analytic solutions or\nclosed forms. Our module consists of multiple variants of the Koopman neural\noperator (KNO), a kind of mesh-independent neural-network-based PDE solvers\ndeveloped following dynamic system theory. The compact variants of KNO can\naccurately solve PDEs with small model sizes while the large variants of KNO\nare more competitive in predicting highly complicated dynamic systems govern by\nunknown, high-dimensional, and non-linear PDEs. All variants are validated by\nmesh-independent and long-term prediction experiments implemented on\nrepresentative PDEs (e.g., the Navier-Stokes equation and the Bateman-Burgers\nequation in fluid mechanics) and ERA5 (i.e., one of the largest high-resolution\nglobal-scale climate data sets in earth physics). These demonstrations suggest\nthe potential of KoopmanLab to be a fundamental tool in diverse physics studies\nrelated to equations or dynamic systems.\n","authors":["Wei Xiong","Muyuan Ma","Ziyang Zhang","Pei Sun","Yang Tian"],"pdf_url":"https://arxiv.org/pdf/2301.01104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06701v1","updated":"2023-01-17T04:57:31Z","published":"2023-01-17T04:57:31Z","title":"Neural Operator Framework for Digital Twin and Complex Engineering\n  Systems","summary":"  With modern computational advancements and statistical analysis methods,\nmachine learning algorithms have become a vital part of engineering modeling.\nNeural Operator Networks (ONets) is an emerging machine learning algorithm as a\n\"faster surrogate\" for approximating solutions to partial differential\nequations (PDEs) due to their ability to approximate mathematical operators\nversus the direct approximation of Neural Networks (NN). ONets use the\nUniversal Approximation Theorem to map finite-dimensional inputs to\ninfinite-dimensional space using the branch-trunk architecture, which encodes\ndomain and feature information separately before using a dot product to combine\nthe information. ONets are expected to occupy a vital niche for surrogate\nmodeling in physical systems and Digital Twin (DT) development. Three test\ncases are evaluated using ONets for operator approximation, including a\n1-dimensional ordinary differential equations (ODE), general diffusion system,\nand convection-diffusion (Burger) system. Solutions for ODE and diffusion\nsystems yield accurate and reliable results (R2>0.95), while solutions for\nBurger systems need further refinement in the ONet algorithm.\n","authors":["Kazuma Kobayashi","James Daniell","Syed B. Alam"],"pdf_url":"https://arxiv.org/pdf/2301.06701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13006v2","updated":"2023-01-17T04:43:26Z","published":"2022-08-27T13:16:43Z","title":"Neural Observer with Lyapunov Stability Guarantee for Uncertain\n  Nonlinear Systems","summary":"  In this paper, we propose a novel nonlinear observer based on neural\nnetworks, called neural observer, for observation tasks of linear\ntime-invariant (LTI) systems and uncertain nonlinear systems. In particular,\nthe neural observer designed for uncertain systems is inspired by the active\ndisturbance rejection control, which can measure the uncertainty in real-time.\nThe stability analysis (e.g., exponential convergence rate) of LTI and\nuncertain nonlinear systems (involving neural observers) are presented and\nguaranteed, where it is shown that the observation problems can be solved only\nusing the linear matrix inequalities (LMIs). Also, it is revealed that the\nobservability and controllability of the system matrices are required to\ndemonstrate the existence of solutions of LMIs. Finally, the effectiveness of\nneural observers is verified on three simulation cases, including the X-29A\naircraft model, the nonlinear pendulum, and the four-wheel steering vehicle.\n","authors":["Song Chen","Shengze Cai","Tehuan Chen","Chao Xu","Jian Chu"],"pdf_url":"https://arxiv.org/pdf/2208.13006v2.pdf","comment":"15 pages, submitted to IEEE journal for possible publication"},{"id":"http://arxiv.org/abs/2112.03555v3","updated":"2023-01-17T04:25:30Z","published":"2021-12-07T08:04:12Z","title":"FedDAG: Federated DAG Structure Learning","summary":"  To date, most directed acyclic graphs (DAGs) structure learning approaches\nrequire data to be stored in a central server. However, due to the\nconsideration of privacy protection, data owners gradually refuse to share\ntheir personalized raw data to avoid private information leakage, making this\ntask more troublesome by cutting off the first step. Thus, a puzzle arises:\n\\textit{how do we discover the underlying DAG structure from decentralized\ndata?} In this paper, focusing on the additive noise models (ANMs) assumption\nof data generation, we take the first step in developing a gradient-based\nlearning framework named FedDAG, which can learn the DAG structure without\ndirectly touching the local data and also can naturally handle the data\nheterogeneity. Our method benefits from a two-level structure of each local\nmodel. The first level structure learns the edges and directions of the graph\nand communicates with the server to get the model information from other\nclients during the learning procedure, while the second level structure\napproximates the mechanisms among variables and personally updates on its own\ndata to accommodate the data heterogeneity. Moreover, FedDAG formulates the\noverall learning task as a continuous optimization problem by taking advantage\nof an equality acyclicity constraint, which can be solved by gradient descent\nmethods to boost the searching efficiency. Extensive experiments on both\nsynthetic and real-world datasets verify the efficacy of the proposed method.\n","authors":["Erdun Gao","Junjia Chen","Li Shen","Tongliang Liu","Mingming Gong","Howard Bondell"],"pdf_url":"https://arxiv.org/pdf/2112.03555v3.pdf","comment":"Accepted to Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2110.11736v2","updated":"2023-01-17T04:24:03Z","published":"2021-10-22T12:14:16Z","title":"MANDERA: Malicious Node Detection in Federated Learning via Ranking","summary":"  Byzantine attacks hinder the deployment of federated learning algorithms.\nAlthough we know that the benign gradients and Byzantine attacked gradients are\ndistributed differently, to detect the malicious gradients is challenging due\nto (1) the gradient is high-dimensional and each dimension has its unique\ndistribution and (2) the benign gradients and the attacked gradients are always\nmixed (two-sample test methods cannot apply directly). To address the above,\nfor the first time, we propose MANDERA which is theoretically guaranteed to\nefficiently detect all malicious gradients under Byzantine attacks with no\nprior knowledge or history about the number of attacked nodes. More\nspecifically, we transfer the original updating gradient space into a ranking\nmatrix. By such an operation, the scales of different dimensions of the\ngradients in the ranking space become identical. The high-dimensional benign\ngradients and the malicious gradients can be easily separated. The\neffectiveness of MANDERA is further confirmed by experimentation on four\nByzantine attack implementations (Gaussian, Zero Gradient, Sign Flipping,\nShifted Mean), comparing with state-of-the-art defenses. The experiments cover\nboth IID and Non-IID datasets.\n","authors":["Wanchuang Zhu","Benjamin Zi Hao Zhao","Simon Luo","Tongliang Liu","Ke Deng"],"pdf_url":"https://arxiv.org/pdf/2110.11736v2.pdf","comment":"17 pages, 11 figures, ICML"},{"id":"http://arxiv.org/abs/2205.13869v3","updated":"2023-01-17T04:21:39Z","published":"2022-05-27T09:59:46Z","title":"MissDAG: Causal Discovery in the Presence of Missing Data with\n  Continuous Additive Noise Models","summary":"  State-of-the-art causal discovery methods usually assume that the\nobservational data is complete. However, the missing data problem is pervasive\nin many practical scenarios such as clinical trials, economics, and biology.\nOne straightforward way to address the missing data problem is first to impute\nthe data using off-the-shelf imputation methods and then apply existing causal\ndiscovery methods. However, such a two-step method may suffer from\nsuboptimality, as the imputation algorithm may introduce bias for modeling the\nunderlying data distribution. In this paper, we develop a general method, which\nwe call MissDAG, to perform causal discovery from data with incomplete\nobservations. Focusing mainly on the assumptions of ignorable missingness and\nthe identifiable additive noise models (ANMs), MissDAG maximizes the expected\nlikelihood of the visible part of observations under the\nexpectation-maximization (EM) framework. In the E-step, in cases where\ncomputing the posterior distributions of parameters in closed-form is not\nfeasible, Monte Carlo EM is leveraged to approximate the likelihood. In the\nM-step, MissDAG leverages the density transformation to model the noise\ndistributions with simpler and specific formulations by virtue of the ANMs and\nuses a likelihood-based causal discovery algorithm with directed acyclic graph\nconstraint. We demonstrate the flexibility of MissDAG for incorporating various\ncausal discovery algorithms and its efficacy through extensive simulations and\nreal data experiments.\n","authors":["Erdun Gao","Ignavier Ng","Mingming Gong","Li Shen","Wei Huang","Tongliang Liu","Kun Zhang","Howard Bondell"],"pdf_url":"https://arxiv.org/pdf/2205.13869v3.pdf","comment":"Accepted to NeurIPS22"},{"id":"http://arxiv.org/abs/2301.06695v1","updated":"2023-01-17T04:20:33Z","published":"2023-01-17T04:20:33Z","title":"Quantifying and Managing Impacts of Concept Drifts on IoT Traffic\n  Inference in Residential ISP Networks","summary":"  Millions of vulnerable consumer IoT devices in home networks are the enabler\nfor cyber crimes putting user privacy and Internet security at risk. Internet\nservice providers (ISPs) are best poised to play key roles in mitigating risks\nby automatically inferring active IoT devices per household and notifying users\nof vulnerable ones. Developing a scalable inference method that can perform\nrobustly across thousands of home networks is a non-trivial task. This paper\nfocuses on the challenges of developing and applying data-driven inference\nmodels when labeled data of device behaviors is limited and the distribution of\ndata changes (concept drift) across time and space domains. Our contributions\nare three-fold: (1) We collect and analyze network traffic of 24 types of\nconsumer IoT devices from 12 real homes over six weeks to highlight the\nchallenge of temporal and spatial concept drifts in network behavior of IoT\ndevices; (2) We analyze the performance of two inference strategies, namely\n\"global inference\" (a model trained on a combined set of all labeled data from\ntraining homes) and \"contextualized inference\" (several models each trained on\nthe labeled data from a training home) in the presence of concept drifts; and\n(3) To manage concept drifts, we develop a method that dynamically applies the\n``closest'' model (from a set) to network traffic of unseen homes during the\ntesting phase, yielding better performance in 20% of scenarios.\n","authors":["Aarman Pashamokhtari","Norihiro Okui","Masataka Nakahara","Ayumu Kubota","Gustavo Batista","Hassan Habibi Gharakheili"],"pdf_url":"https://arxiv.org/pdf/2301.06695v1.pdf","comment":"Submitted to IEEE IoT Journal"},{"id":"http://arxiv.org/abs/2301.06687v1","updated":"2023-01-17T04:01:47Z","published":"2023-01-17T04:01:47Z","title":"DQNAS: Neural Architecture Search using Reinforcement Learning","summary":"  Convolutional Neural Networks have been used in a variety of image related\napplications after their rise in popularity due to ImageNet competition.\nConvolutional Neural Networks have shown remarkable results in applications\nincluding face recognition, moving target detection and tracking,\nclassification of food based on the calorie content and many more. Designing of\nConvolutional Neural Networks requires experts having a cross domain knowledge\nand it is laborious, which requires a lot of time for testing different values\nfor different hyperparameter along with the consideration of different\nconfigurations of existing architectures. Neural Architecture Search is an\nautomated way of generating Neural Network architectures which saves\nresearchers from all the brute-force testing trouble, but with the drawback of\nconsuming a lot of computational resources for a prolonged period. In this\npaper, we propose an automated Neural Architecture Search framework DQNAS,\nguided by the principles of Reinforcement Learning along with One-shot Training\nwhich aims to generate neural network architectures that show superior\nperformance and have minimum scalability problem.\n","authors":["Anshumaan Chauhan","Siddhartha Bhattacharyya","S. Vadivel"],"pdf_url":"https://arxiv.org/pdf/2301.06687v1.pdf","comment":"15 Pages, 6 Tables, 9 figures"},{"id":"http://arxiv.org/abs/2205.13972v3","updated":"2023-01-17T04:01:01Z","published":"2022-05-27T13:40:50Z","title":"Counterfactual Fairness with Partially Known Causal Graph","summary":"  Fair machine learning aims to avoid treating individuals or sub-populations\nunfavourably based on \\textit{sensitive attributes}, such as gender and race.\nThose methods in fair machine learning that are built on causal inference\nascertain discrimination and bias through causal effects. Though\ncausality-based fair learning is attracting increasing attention, current\nmethods assume the true causal graph is fully known. This paper proposes a\ngeneral method to achieve the notion of counterfactual fairness when the true\ncausal graph is unknown. To be able to select features that lead to\ncounterfactual fairness, we derive the conditions and algorithms to identify\nancestral relations between variables on a \\textit{Partially Directed Acyclic\nGraph (PDAG)}, specifically, a class of causal DAGs that can be learned from\nobservational data combined with domain knowledge. Interestingly, we find that\ncounterfactual fairness can be achieved as if the true causal graph were fully\nknown, when specific background knowledge is provided: the sensitive attributes\ndo not have ancestors in the causal graph. Results on both simulated and\nreal-world datasets demonstrate the effectiveness of our method.\n","authors":["Aoqi Zuo","Susan Wei","Tongliang Liu","Bo Han","Kun Zhang","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2205.13972v3.pdf","comment":"Accepted to NeurIPS22"},{"id":"http://arxiv.org/abs/2206.07085v3","updated":"2023-01-17T03:58:13Z","published":"2022-06-14T18:19:05Z","title":"Understanding the Generalization Benefit of Normalization Layers:\n  Sharpness Reduction","summary":"  Normalization layers (e.g., Batch Normalization, Layer Normalization) were\nintroduced to help with optimization difficulties in very deep nets, but they\nclearly also help generalization, even in not-so-deep nets. Motivated by the\nlong-held belief that flatter minima lead to better generalization, this paper\ngives mathematical analysis and supporting experiments suggesting that\nnormalization (together with accompanying weight-decay) encourages GD to reduce\nthe sharpness of loss surface. Here \"sharpness\" is carefully defined given that\nthe loss is scale-invariant, a known consequence of normalization.\nSpecifically, for a fairly broad class of neural nets with normalization, our\ntheory explains how GD with a finite learning rate enters the so-called Edge of\nStability (EoS) regime, and characterizes the trajectory of GD in this regime\nvia a continuous sharpness-reduction flow.\n","authors":["Kaifeng Lyu","Zhiyuan Li","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2206.07085v3.pdf","comment":"76 pages, many figures; NeurIPS 2022 camera-ready version; fixes\n  minor typos"},{"id":"http://arxiv.org/abs/2301.06683v1","updated":"2023-01-17T03:53:29Z","published":"2023-01-17T03:53:29Z","title":"Surgical Aggregation: A Federated Learning Framework for Harmonizing\n  Distributed Datasets with Diverse Tasks","summary":"  AI-assisted characterization of chest x-rays (CXR) has the potential to\nprovide substantial benefits across many clinical applications. Many\nlarge-scale public CXR datasets have been curated for detection of\nabnormalities using deep learning. However, each of these datasets focus on\ndetecting a subset of disease labels that could be present in a CXR, thus\nlimiting their clinical utility. Furthermore, the distributed nature of these\ndatasets, along with data sharing regulations, make it difficult to share and\ncreate a complete representation of disease labels. We propose surgical\naggregation, a federated learning framework for aggregating knowledge from\ndistributed datasets with different disease labels into a 'global' deep\nlearning model. We randomly divided the NIH Chest X-Ray 14 dataset into\ntraining (70%), validation (10%), and test (20%) splits with no patient overlap\nand conducted two experiments. In the first experiment, we pruned the disease\nlabels to create two 'toy' datasets containing 11 and 8 labels respectively\nwith 4 overlapping labels. For the second experiment, we pruned the disease\nlabels to create two disjoint 'toy' datasets with 7 labels each. We observed\nthat the surgically aggregated 'global' model resulted in excellent performance\nacross both experiments when compared to a 'baseline' model trained on complete\ndisease labels. The overlapping and disjoint experiments had an AUROC of 0.87\nand 0.86 respectively, compared to the baseline AUROC of 0.87. We used surgical\naggregation to harmonize the NIH Chest X-Ray 14 and CheXpert datasets into a\n'global' model with an AUROC of 0.85 and 0.83 respectively. Our results show\nthat surgical aggregation could be used to develop clinically useful deep\nlearning models by aggregating knowledge from distributed datasets with diverse\ntasks, a step forward towards bridging the gap from bench to bedside.\n","authors":["Pranav Kulkarni","Adway Kanhere","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2301.06683v1.pdf","comment":"12 pages, 4 figures, 5 tables, submitted to MIDL 2023 conference"},{"id":"http://arxiv.org/abs/2103.17203v3","updated":"2023-01-17T03:49:52Z","published":"2021-03-31T16:30:58Z","title":"Universal Prediction Band via Semi-Definite Programming","summary":"  We propose a computationally efficient method to construct nonparametric,\nheteroscedastic prediction bands for uncertainty quantification, with or\nwithout any user-specified predictive model. Our approach provides an\nalternative to the now-standard conformal prediction for uncertainty\nquantification, with novel theoretical insights and computational advantages.\nThe data-adaptive prediction band is universally applicable with minimal\ndistributional assumptions, has strong non-asymptotic coverage properties, and\nis easy to implement using standard convex programs. Our approach can be viewed\nas a novel variance interpolation with confidence and further leverages\ntechniques from semi-definite programming and sum-of-squares optimization.\nTheoretical and numerical performances for the proposed approach for\nuncertainty quantification are analyzed.\n","authors":["Tengyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2103.17203v3.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.06680v1","updated":"2023-01-17T03:43:34Z","published":"2023-01-17T03:43:34Z","title":"DIGITOUR: Automatic Digital Tours for Real-Estate Properties","summary":"  A virtual or digital tour is a form of virtual reality technology which\nallows a user to experience a specific location remotely. Currently, these\nvirtual tours are created by following a 2-step strategy. First, a photographer\nclicks a 360 degree equirectangular image; then, a team of annotators manually\nlinks these images for the \"walkthrough\" user experience. The major challenge\nin the mass adoption of virtual tours is the time and cost involved in manual\nannotation/linking of images. Therefore, this paper presents an end-to-end\npipeline to automate the generation of 3D virtual tours using equirectangular\nimages for real-estate properties. We propose a novel HSV-based coloring scheme\nfor paper tags that need to be placed at different locations before clicking\nthe equirectangular images using 360 degree cameras. These tags have two\ncharacteristics: i) they are numbered to help the photographer for placement of\ntags in sequence and; ii) bi-colored, which allows better learning of tag\ndetection (using YOLOv5 architecture) in an image and digit recognition (using\ncustom MobileNet architecture) tasks. Finally, we link/connect all the\nequirectangular images based on detected tags. We show the efficiency of the\nproposed pipeline on a real-world equirectangular image dataset collected from\nthe Housing.com database.\n","authors":["Prateek Chhikara","Harshul Kuhar","Anil Goyal","Chirag Sharma"],"pdf_url":"https://arxiv.org/pdf/2301.06680v1.pdf","comment":"Published at CODS-COMAD '23"},{"id":"http://arxiv.org/abs/2301.06678v1","updated":"2023-01-17T03:43:19Z","published":"2023-01-17T03:43:19Z","title":"Feature-based Image Matching for Identifying Individual Kākā","summary":"  This report investigates an unsupervised, feature-based image matching\npipeline for the novel application of identifying individual k\\=ak\\=a. Applied\nwith a similarity network for clustering, this addresses a weakness of current\nsupervised approaches to identifying individual birds which struggle to handle\nthe introduction of new individuals to the population. Our approach uses object\nlocalisation to locate k\\=ak\\=a within images and then extracts local features\nthat are invariant to rotation and scale. These features are matched between\nimages with nearest neighbour matching techniques and mismatch removal to\nproduce a similarity score for image match comparison. The results show that\nmatches obtained via the image matching pipeline achieve high accuracy of true\nmatches. We conclude that feature-based image matching could be used with a\nsimilarity network to provide a viable alternative to existing supervised\napproaches.\n","authors":["Fintan O'Sullivan","Kirita-Rose Escott","Rachael Shaw","Andrew Lensen"],"pdf_url":"https://arxiv.org/pdf/2301.06678v1.pdf","comment":"42 pages, honour's report from Victoria University of Wellington"},{"id":"http://arxiv.org/abs/2301.04838v2","updated":"2023-01-17T03:23:40Z","published":"2023-01-12T06:49:55Z","title":"LB-SimTSC: An Efficient Similarity-Aware Graph Neural Network for\n  Semi-Supervised Time Series Classification","summary":"  Time series classification is an important data mining task that has received\na lot of interest in the past two decades. Due to the label scarcity in\npractice, semi-supervised time series classification with only a few labeled\nsamples has become popular. Recently, Similarity-aware Time Series\nClassification (SimTSC) is proposed to address this problem by using a graph\nneural network classification model on the graph generated from pairwise\nDynamic Time Warping (DTW) distance of batch data. It shows excellent accuracy\nand outperforms state-of-the-art deep learning models in several few-label\nsettings. However, since SimTSC relies on pairwise DTW distances, the quadratic\ncomplexity of DTW limits its usability to only reasonably sized datasets. To\naddress this challenge, we propose a new efficient semi-supervised time series\nclassification technique, LB-SimTSC, with a new graph construction module.\nInstead of using DTW, we propose to utilize a lower bound of DTW, LB_Keogh, to\napproximate the dissimilarity between instances in linear time, while retaining\nthe relative proximity relationships one would have obtained via computing DTW.\nWe construct the pairwise distance matrix using LB_Keogh and build a graph for\nthe graph neural network. We apply this approach to the ten largest datasets\nfrom the well-known UCR time series classification archive. The results\ndemonstrate that this approach can be up to 104x faster than SimTSC when\nconstructing the graph on large datasets without significantly decreasing\nclassification accuracy.\n","authors":["Wenjie Xi","Arnav Jain","Li Zhang","Jessica Lin"],"pdf_url":"https://arxiv.org/pdf/2301.04838v2.pdf","comment":"Accpeted by DLG-AAAI'23"},{"id":"http://arxiv.org/abs/2301.06676v1","updated":"2023-01-17T03:17:07Z","published":"2023-01-17T03:17:07Z","title":"Explainable, Interpretable & Trustworthy AI for Intelligent Digital\n  Twin: Case Study on Remaining Useful Life","summary":"  Machine learning (ML) and Artificial Intelligence (AI) are increasingly used\nin energy and engineering systems, but these models must be fair, unbiased, and\nexplainable. It is critical to have confidence in AI's trustworthiness. ML\ntechniques have been useful in predicting important parameters and improving\nmodel performance. However, for these AI techniques to be useful for making\ndecisions, they need to be audited, accounted for, and easy to understand.\nTherefore, the use of Explainable AI (XAI) and interpretable machine learning\n(IML) is crucial for the accurate prediction of prognostics, such as remaining\nuseful life (RUL) in a digital twin system to make it intelligent while\nensuring that the AI model is transparent in its decision-making processes and\nthat the predictions it generates can be understood and trusted by users. By\nusing AI that is explainable, interpretable, and trustworthy, intelligent\ndigital twin systems can make more accurate predictions of RUL, leading to\nbetter maintenance and repair planning and, ultimately, improved system\nperformance. The objective of this paper is to understand the idea of XAI and\nIML and justify the important role of ML/AI in the Digital Twin framework and\ncomponents, which requires XAI to understand the prediction better. This paper\nexplains the importance of XAI and IML in both local and global aspects to\nensure the use of trustworthy ML/AI applications for RUL prediction. This paper\nused the RUL prediction for the XAI and IML studies and leveraged the\nintegrated python toolbox for interpretable machine learning (PiML).\n","authors":["Kazuma Kobayashi","Bader Almutairi","Md Nazmus Sakib","Souvik Chakraborty","Syed B. Alam"],"pdf_url":"https://arxiv.org/pdf/2301.06676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06674v1","updated":"2023-01-17T03:13:45Z","published":"2023-01-17T03:13:45Z","title":"Multi-fidelity surrogate modeling for temperature field prediction using\n  deep convolution neural network","summary":"  Temperature field prediction is of great importance in the thermal design of\nsystems engineering, and building the surrogate model is an effective way for\nthe task. Generally, large amounts of labeled data are required to guarantee a\ngood prediction performance of the surrogate model, especially the deep\nlearning model, which have more parameters and better representational ability.\nHowever, labeled data, especially high-fidelity labeled data, are usually\nexpensive to obtain and sometimes even impossible. To solve this problem, this\npaper proposes a pithy deep multi-fidelity model (DMFM) for temperature field\nprediction, which takes advantage of low-fidelity data to boost the performance\nwith less high-fidelity data. First, a pre-train and fine-tune paradigm are\ndeveloped in DMFM to train the low-fidelity and high-fidelity data, which\nsignificantly reduces the complexity of the deep surrogate model. Then, a\nself-supervised learning method for training the physics-driven deep\nmulti-fidelity model (PD-DMFM) is proposed, which fully utilizes the physics\ncharacteristics of the engineering systems and reduces the dependence on large\namounts of labeled low-fidelity data in the training process. Two diverse\ntemperature field prediction problems are constructed to validate the\neffectiveness of DMFM and PD-DMFM, and the result shows that the proposed\nmethod can greatly reduce the dependence of the model on high-fidelity data.\n","authors":["Yunyang Zhang","Zhiqiang Gong","Weien Zhou","Xiaoyu Zhao","Xiaohu Zheng","Wen Yao"],"pdf_url":"https://arxiv.org/pdf/2301.06674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06662v1","updated":"2023-01-17T02:14:57Z","published":"2023-01-17T02:14:57Z","title":"Graph Topology Learning Under Privacy Constraints","summary":"  Graph learning, which aims to infer the underlying topology behind high\ndimension data, has attracted intense attention. In this study, we shed a new\nlight on graph learning by considering a pragmatic scenario where data are\nprivacy sensitive and located in separated clients (devices or organizations).\nThe main difficulty in learning graphs in this scenario is that we cannot\nprocess all the data in a central server, because the data are not allowed to\nleave the local clients due to privacy concerns. The problem becomes more\nchallenging when data of different clients are non-IID, since it is\nunreasonable to learn a global graph for heterogeneous data. To address these\nissues, we propose a novel framework in which a personalized graph for each\nclient and a consensus graph are jointly learned in a federated fashion.\nSpecifically, we commute model updates instead of raw data to the central\nserver in the proposed federated algorithm. A provable convergence analysis\nshows that the algorithm enjoys $\\mathcal{O}(1/T)$ convergence rate. To further\nenhance privacy, we design a deferentially privacy algorithm to prevent the\ninformation of the raw data from being leaked when transferring model updates.\nA theoretical guidance is provided on how to ensure that the algorithm\nsatisfies differential privacy. We also analyze the impact of differential\nprivacy on the convergence of our algorithm. Finally, extensive experiments on\nboth synthetic and real world data are carried out to validate the proposed\nmodels and algorithms. Experimental results illustrate that our framework is\nable to learn graphs effectively in the target scenario.\n","authors":["Xiang Zhang. Qiao Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06662v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2104.10569v3","updated":"2023-01-17T01:25:47Z","published":"2021-04-21T14:51:33Z","title":"GraphTheta: A Distributed Graph Neural Network Learning System With\n  Flexible Training Strategy","summary":"  Graph neural networks (GNNs) have been demonstrated as a powerful tool for\nanalyzing non-Euclidean graph data. However, the lack of efficient distributed\ngraph learning systems severely hinders applications of GNNs, especially when\ngraphs are big and GNNs are relatively deep. Herein, we present GraphTheta, the\nfirst distributed and scalable graph learning system built upon vertex-centric\ndistributed graph processing with neural network operators implemented as\nuser-defined functions. This system supports multiple training strategies and\nenables efficient and scalable big-graph learning on distributed (virtual)\nmachines with low memory. To facilitate graph convolutions, GraphTheta puts\nforward a new graph learning abstraction named NN-TGAR to bridge the gap\nbetween graph processing and graph deep learning. A distributed graph engine is\nproposed to conduct the stochastic gradient descent optimization with a\nhybrid-parallel execution, and a new cluster-batched training strategy is\nsupported. We evaluate GraphTheta using several datasets with network sizes\nranging from small-, modest- to large-scale. Experimental results show that\nGraphTheta can scale well to 1,024 workers for training an in-house developed\nGNN on an industry-scale Alipay dataset of 1.4 billion nodes and 4.1 billion\nattributed edges, with a cluster of CPU virtual machines (dockers) of small\nmemory each (5$\\sim$12GB). Moreover, GraphTheta can outperform DistDGL by up to\n$2.02\\times$, with better scalability, and GraphLearn by up to $30.56\\times$.\nAs for model accuracy, GraphTheta is capable of learning as good GNNs as\nexisting frameworks. To the best of our knowledge, this work presents the\nlargest edge-attributed GNN learning task in the literature.\n","authors":["Yongchao Liu","Houyi Li","Guowei Zhang","Xintan Zeng","Yongyong Li","Bin Huang","Peng Zhang","Zhao Li","Xiaowei Zhu","Changhua He","Wenguang Chen"],"pdf_url":"https://arxiv.org/pdf/2104.10569v3.pdf","comment":"19 pages, 13 figures, 8 tables"},{"id":"http://arxiv.org/abs/2301.06650v1","updated":"2023-01-17T01:12:44Z","published":"2023-01-17T01:12:44Z","title":"Enhancing Deep Traffic Forecasting Models with Dynamic Regression","summary":"  A common assumption in deep learning-based multivariate and multistep traffic\ntime series forecasting models is that residuals are independent, isotropic,\nand uncorrelated in space and time. While this assumption provides a\nstraightforward loss function (such as MAE/MSE), it is inevitable that residual\nprocesses will exhibit strong autocorrelation and structured spatiotemporal\ncorrelation. In this paper, we propose a complementary dynamic regression (DR)\nframework to enhance existing deep multistep traffic forecasting frameworks\nthrough structured specifications and learning for the residual process.\nSpecifically, we assume the residuals of the base model (i.e., a well-developed\ntraffic forecasting model) are governed by a matrix-variate seasonal\nautoregressive (AR) model, which can be seamlessly integrated into the training\nprocess by redesigning the overall loss function. Parameters in the DR\nframework can be jointly learned with the base model. We evaluate the\neffectiveness of the proposed framework in enhancing several state-of-the-art\ndeep traffic forecasting models on both speed and flow datasets. Our experiment\nresults show that the DR framework not only improves existing traffic\nforecasting models but also offers interpretable regression coefficients and\nspatiotemporal covariance matrices.\n","authors":["Vincent Zhihao Zheng","Seongjin Choi","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2301.06650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01737v2","updated":"2023-01-17T00:52:46Z","published":"2023-01-04T18:10:26Z","title":"Episodes Discovery Recommendation with Multi-Source Augmentations","summary":"  Recommender systems (RS) commonly retrieve potential candidate items for\nusers from a massive number of items by modeling user interests based on\nhistorical interactions. However, historical interaction data is highly sparse,\nand most items are long-tail items, which limits the representation learning\nfor item discovery. This problem is further augmented by the discovery of novel\nor cold-start items. For example, after a user displays interest in bitcoin\nfinancial investment shows in the podcast space, a recommender system may want\nto suggest, e.g., a newly released blockchain episode from a more technical\nshow. Episode correlations help the discovery, especially when interaction data\nof episodes is limited. Accordingly, we build upon the classical Two-Tower\nmodel and introduce the novel Multi-Source Augmentations using a Contrastive\nLearning framework (MSACL) to enhance episode embedding learning by\nincorporating positive episodes from numerous correlated semantics. Extensive\nexperiments on a real-world podcast recommendation dataset from a large audio\nstreaming platform demonstrate the effectiveness of the proposed framework for\nuser podcast exploration and cold-start episode recommendation.\n","authors":["Ziwei Fan","Alice Wang","Zahra Nazari"],"pdf_url":"https://arxiv.org/pdf/2301.01737v2.pdf","comment":"5 pages long for episodes discovery recommendation"},{"id":"http://arxiv.org/abs/2301.06646v1","updated":"2023-01-17T00:43:34Z","published":"2023-01-17T00:43:34Z","title":"Async-HFL: Efficient and Robust Asynchronous Federated Learning in\n  Hierarchical IoT Networks","summary":"  Federated Learning (FL) has gained increasing interest in recent years as a\ndistributed on-device learning paradigm. However, multiple challenges remain to\nbe addressed for deploying FL in real-world Internet-of-Things (IoT) networks\nwith hierarchies. Although existing works have proposed various approaches to\naccount data heterogeneity, system heterogeneity, unexpected stragglers and\nscalibility, none of them provides a systematic solution to address all of the\nchallenges in a hierarchical and unreliable IoT network. In this paper, we\npropose an asynchronous and hierarchical framework (Async-HFL) for performing\nFL in a common three-tier IoT network architecture. In response to the largely\nvaried delays, Async-HFL employs asynchronous aggregations at both the gateway\nand the cloud levels thus avoids long waiting time. To fully unleash the\npotential of Async-HFL in converging speed under system heterogeneities and\nstragglers, we design device selection at the gateway level and device-gateway\nassociation at the cloud level. Device selection chooses edge devices to\ntrigger local training in real-time while device-gateway association determines\nthe network topology periodically after several cloud epochs, both satisfying\nbandwidth limitation. We evaluate Async-HFL's convergence speedup using\nlarge-scale simulations based on ns-3 and a network topology from NYCMesh. Our\nresults show that Async-HFL converges 1.08-1.31x faster in wall-clock time and\nsaves up to 21.6% total communication cost compared to state-of-the-art\nasynchronous FL algorithms (with client selection). We further validate\nAsync-HFL on a physical deployment and observe robust convergence under\nunexpected stragglers.\n","authors":["Xiaofan Yu","Ludmila Cherkasova","Harsh Vardhan","Quanling Zhao","Emily Ekaireb","Xiyuan Zhang","Arya Mazumdar","Tajana Rosing"],"pdf_url":"https://arxiv.org/pdf/2301.06646v1.pdf","comment":"Submitted for review"},{"id":"http://arxiv.org/abs/2301.06641v1","updated":"2023-01-17T00:08:03Z","published":"2023-01-17T00:08:03Z","title":"Scaling Deep Networks with the Mesh Adaptive Direct Search algorithm","summary":"  Deep neural networks are getting larger. Their implementation on edge and IoT\ndevices becomes more challenging and moved the community to design lighter\nversions with similar performance. Standard automatic design tools such as\n\\emph{reinforcement learning} and \\emph{evolutionary computing} fundamentally\nrely on cheap evaluations of an objective function. In the neural network\ndesign context, this objective is the accuracy after training, which is\nexpensive and time-consuming to evaluate. We automate the design of a light\ndeep neural network for image classification using the \\emph{Mesh Adaptive\nDirect Search}(MADS) algorithm, a mature derivative-free optimization method\nthat effectively accounts for the expensive blackbox nature of the objective\nfunction to explore the design space, even in the presence of constraints.Our\ntests show competitive compression rates with reduced numbers of trials.\n","authors":["Dounia Lakhmiri","Mahdi Zolnouri","Vahid Partovi Nia","Christophe Tribes","Sébastien Le Digabel"],"pdf_url":"https://arxiv.org/pdf/2301.06641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02939v2","updated":"2023-01-17T23:38:36Z","published":"2022-12-06T12:53:22Z","title":"Quantification of geogrid lateral restraint using transparent sand and\n  deep learning-based image segmentation","summary":"  An experimental technique is presented to quantify the lateral restraint\nprovided by a geogrid embedded in granular soil at the particle level. Repeated\nload triaxial tests were done on transparent sand specimens with geosynthetic\ninclusions simulating geogrids. Particle outlines on laser illuminated planes\nthrough the specimens were segmented using a deep learning-based segmentation\nalgorithm. The particle outlines were characterized in terms of Fourier shape\ndescriptors and tracked across sequentially captured images. The accuracy of\nthe particle displacement measurements was validated against Digital Image\nCorrelation (DIC) measurements. In addition, the method's resolution and\nrepeatability is presented. Based on the measured particle displacements and\nrotations, a state boundary line between probable and improbable particle\nmotions was identified for each test. The size of the zone of probable motions\ncould be used to quantify the lateral restraint provided by the inclusions.\nOverall, the tests results revealed that the geosynthetic inclusions restricted\nboth particle displacements and rotations. However, the particle displacements\nwere found to be restrained more significantly than the rotations. Finally, a\nunique relationship was found between the magnitude of the permanent strains of\nthe specimens and the size of the zone of probable motions.\n","authors":["David Marx","Krishna Kumar","Jorge Zornberg"],"pdf_url":"https://arxiv.org/pdf/2212.02939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2003.04315v5","updated":"2023-01-17T23:29:15Z","published":"2020-03-09T18:00:00Z","title":"LIMEADE: From AI Explanations to Advice Taking","summary":"  Research in human-centered AI has shown the benefits of systems that can\nexplain their predictions. Methods that allow an AI to take advice from humans\nin response to explanations are similarly useful. While both capabilities are\nwell-developed for transparent learning models (e.g., linear models and\nGA$^2$Ms), and recent techniques (e.g., LIME and SHAP) can generate\nexplanations for opaque models, little attention has been given to advice\nmethods for opaque models. This paper introduces LIMEADE, the first general\nframework that translates both positive and negative advice (expressed using\nhigh-level vocabulary such as that employed by post-hoc explanations) into an\nupdate to an arbitrary, underlying opaque model. We demonstrate the generality\nof our approach with case studies on seventy real-world models across two broad\ndomains: image classification and text recommendation. We show our method\nimproves accuracy compared to a rigorous baseline on the image classification\ndomains. For the text modality, we apply our framework to a neural recommender\nsystem for scientific papers on a public website; our user study shows that our\nframework leads to significantly higher perceived user control, trust, and\nsatisfaction.\n","authors":["Benjamin Charles Germain Lee","Doug Downey","Kyle Lo","Daniel S. Weld"],"pdf_url":"https://arxiv.org/pdf/2003.04315v5.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.12970v2","updated":"2023-01-17T22:52:09Z","published":"2022-12-25T23:19:56Z","title":"Refined Edge Usage of Graph Neural Networks for Edge Prediction","summary":"  Graph Neural Networks (GNNs), originally proposed for node classification,\nhave also motivated many recent works on edge prediction (a.k.a., link\nprediction). However, existing methods lack elaborate design regarding the\ndistinctions between two tasks that have been frequently overlooked: (i) edges\nonly constitute the topology in the node classification task but can be used as\nboth the topology and the supervisions (i.e., labels) in the edge prediction\ntask; (ii) the node classification makes prediction over each individual node,\nwhile the edge prediction is determinated by each pair of nodes. To this end,\nwe propose a novel edge prediction paradigm named Edge-aware Message PassIng\nneuRal nEtworks (EMPIRE). Concretely, we first introduce an edge splitting\ntechnique to specify use of each edge where each edge is solely used as either\nthe topology or the supervision (named as topology edge or supervision edge).\nWe then develop a new message passing mechanism that generates the messages to\nsource nodes (through topology edges) being aware of target nodes (through\nsupervision edges). In order to emphasize the differences between pairs\nconnected by supervision edges and pairs unconnected, we further weight the\nmessages to highlight the relative ones that can reflect the differences. In\naddition, we design a novel negative node-pair sampling trick that efficiently\nsamples 'hard' negative instances in the supervision instances, and can\nsignificantly improve the performance. Experimental results verify that the\nproposed method can significantly outperform existing state-of-the-art models\nregarding the edge prediction task on multiple homogeneous and heterogeneous\ngraph datasets.\n","authors":["Jiarui Jin","Yangkun Wang","Weinan Zhang","Quan Gan","Xiang Song","Yong Yu","Zheng Zhang","David Wipf"],"pdf_url":"https://arxiv.org/pdf/2212.12970v2.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2301.07210v1","updated":"2023-01-17T22:18:53Z","published":"2023-01-17T22:18:53Z","title":"Causal Falsification of Digital Twins","summary":"  Digital twins hold substantial promise in many applications, but rigorous\nprocedures for assessing their accuracy are essential for their widespread\ndeployment in safety-critical settings. By formulating this task within the\nframework of causal inference, we show it is not possible to certify that a\ntwin is \"correct\" using real-world observational data unless potentially\ntenuous assumptions are made about the data-generating process. To avoid these\nassumptions, we propose an assessment strategy that instead aims to find cases\nwhere the twin is not correct, and present a general-purpose statistical\nprocedure for doing so that may be used across a wide variety of applications\nand twin models. Our approach yields reliable and actionable information about\nthe twin under only the assumption of an i.i.d. dataset of real-world\nobservations, and in particular remains sound even in the presence of arbitrary\nunmeasured confounding. We demonstrate the effectiveness of our methodology via\na large-scale case study involving sepsis modelling within the Pulse Physiology\nEngine, which we assess using the MIMIC-III dataset of ICU patients.\n","authors":["Rob Cornish","Muhammad Faaiz Taufiq","Arnaud Doucet","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2301.07210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07209v1","updated":"2023-01-17T22:16:58Z","published":"2023-01-17T22:16:58Z","title":"Learning a Formality-Aware Japanese Sentence Representation","summary":"  While the way intermediate representations are generated in encoder-decoder\nsequence-to-sequence models typically allow them to preserve the semantics of\nthe input sentence, input features such as formality might be left out. On the\nother hand, downstream tasks such as translation would benefit from working\nwith a sentence representation that preserves formality in addition to\nsemantics, so as to generate sentences with the appropriate level of social\nformality -- the difference between speaking to a friend versus speaking with a\nsupervisor. We propose a sequence-to-sequence method for learning a\nformality-aware representation for Japanese sentences, where sentence\ngeneration is conditioned on both the original representation of the input\nsentence, and a side constraint which guides the sentence representation\ntowards preserving formality information. Additionally, we propose augmenting\nthe sentence representation with a learned representation of formality which\nfacilitates the extraction of formality in downstream tasks. We address the\nlack of formality-annotated parallel data by adapting previous works on\nprocedural formality classification of Japanese sentences. Experimental results\nsuggest that our techniques not only helps the decoder recover the formality of\nthe input sentence, but also slightly improves the preservation of input\nsentence semantics.\n","authors":["Henry Li Xinyuan","Ray Lee","Jerry Chen","Kelly Marchisio"],"pdf_url":"https://arxiv.org/pdf/2301.07209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07206v1","updated":"2023-01-17T21:50:35Z","published":"2023-01-17T21:50:35Z","title":"Dual-sPLS: a family of Dual Sparse Partial Least Squares regressions for\n  feature selection and prediction with tunable sparsity; evaluation on\n  simulated and near-infrared (NIR) data","summary":"  Relating a set of variables X to a response y is crucial in chemometrics. A\nquantitative prediction objective can be enriched by qualitative data\ninterpretation, for instance by locating the most influential features. When\nhigh-dimensional problems arise, dimension reduction techniques can be used.\nMost notable are projections (e.g. Partial Least Squares or PLS ) or variable\nselections (e.g. lasso). Sparse partial least squares combine both strategies,\nby blending variable selection into PLS. The variant presented in this paper,\nDual-sPLS, generalizes the classical PLS1 algorithm. It provides balance\nbetween accurate prediction and efficient interpretation. It is based on\npenalizations inspired by classical regression methods (lasso, group lasso,\nleast squares, ridge) and uses the dual norm notion. The resulting sparsity is\nenforced by an intuitive shrinking ratio parameter. Dual-sPLS favorably\ncompares to similar regression methods, on simulated and real chemical data.\nCode is provided as an open-source package in R:\n\\url{https://CRAN.R-project.org/package=dual.spls}.\n","authors":["Louna Alsouki","Laurent Duval","Clément Marteau","Rami El Haddad","François Wahl"],"pdf_url":"https://arxiv.org/pdf/2301.07206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07187v1","updated":"2023-01-17T20:52:48Z","published":"2023-01-17T20:52:48Z","title":"Artificial Neuronal Ensembles with Learned Context Dependent Gating","summary":"  Biological neural networks are capable of recruiting different sets of\nneurons to encode different memories. However, when training artificial neural\nnetworks on a set of tasks, typically, no mechanism is employed for selectively\nproducing anything analogous to these neuronal ensembles. Further, artificial\nneural networks suffer from catastrophic forgetting, where the network's\nperformance rapidly deteriorates as tasks are learned sequentially. By\ncontrast, sequential learning is possible for a range of biological organisms.\nWe introduce Learned Context Dependent Gating (LXDG), a method to flexibly\nallocate and recall `artificial neuronal ensembles', using a particular network\nstructure and a new set of regularization terms. Activities in the hidden\nlayers of the network are modulated by gates, which are dynamically produced\nduring training. The gates are outputs of networks themselves, trained with a\nsigmoid output activation. The regularization terms we have introduced\ncorrespond to properties exhibited by biological neuronal ensembles. The first\nterm penalizes low gate sparsity, ensuring that only a specified fraction of\nthe network is used. The second term ensures that previously learned gates are\nrecalled when the network is presented with input from previously learned\ntasks. Finally, there is a regularization term responsible for ensuring that\nnew tasks are encoded in gates that are as orthogonal as possible from\npreviously used ones. We demonstrate the ability of this method to alleviate\ncatastrophic forgetting on continual learning benchmarks. When the new\nregularization terms are included in the model along with Elastic Weight\nConsolidation (EWC) it achieves better performance on the benchmark `permuted\nMNIST' than with EWC alone. The benchmark `rotated MNIST' demonstrates how\nsimilar tasks recruit similar neurons to the artificial neuronal ensemble.\n","authors":["Matthew James Tilley","Michelle Miller","David Freedman"],"pdf_url":"https://arxiv.org/pdf/2301.07187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.04273v2","updated":"2023-01-17T20:47:19Z","published":"2022-04-08T19:54:52Z","title":"Weight Matrix Dimensionality Reduction in Deep Learning via Kronecker\n  Multi-layer Architectures","summary":"  Deep learning using neural networks is an effective technique for generating\nmodels of complex data. However, training such models can be expensive when\nnetworks have large model capacity resulting from a large number of layers and\nnodes. For training in such a computationally prohibitive regime,\ndimensionality reduction techniques ease the computational burden, and allow\nimplementations of more robust networks. We propose a novel type of such\ndimensionality reduction via a new deep learning architecture based on fast\nmatrix multiplication of a Kronecker product decomposition; in particular our\nnetwork construction can be viewed as a Kronecker product-induced\nsparsification of an \"extended\" fully connected network. Analysis and practical\nexamples show that this architecture allows a neural network to be trained and\nimplemented with a significant reduction in computational time and resources,\nwhile achieving a similar error level compared to a traditional feedforward\nneural network.\n","authors":["Jarom D. Hogue","Robert M. Kirby","Akil Narayan"],"pdf_url":"https://arxiv.org/pdf/2204.04273v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.12562v2","updated":"2023-01-17T20:14:34Z","published":"2021-06-23T17:42:47Z","title":"Feature Alignment as a Generative Process","summary":"  Reversibility in artificial neural networks allows us to retrieve the input\ngiven an output. We present feature alignment, a method for approximating\nreversibility in arbitrary neural networks. We train a network by minimizing\nthe distance between the output of a data point and the random output with\nrespect to a random input. We applied the technique to the MNIST, CIFAR-10,\nCelebA and STL-10 image datasets. We demonstrate that this method can roughly\nrecover images from just their latent representation without the need of a\ndecoder. By utilizing the formulation of variational autoencoders, we\ndemonstrate that it is possible to produce new images that are statistically\ncomparable to the training data. Furthermore, we demonstrate that the quality\nof the images can be improved by coupling a generator and a discriminator\ntogether. In addition, we show how this method, with a few minor modifications,\ncan be used to train networks locally, which has the potential to save\ncomputational memory resources.\n","authors":["Tiago de Souza Farias","Jonas Maziero"],"pdf_url":"https://arxiv.org/pdf/2106.12562v2.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2301.07156v1","updated":"2023-01-17T19:57:03Z","published":"2023-01-17T19:57:03Z","title":"A Combinatorial Semi-Bandit Approach to Charging Station Selection for\n  Electric Vehicles","summary":"  In this work, we address the problem of long-distance navigation for battery\nelectric vehicles (BEVs), where one or more charging sessions are required to\nreach the intended destination. We consider the availability and performance of\nthe charging stations to be unknown and stochastic, and develop a combinatorial\nsemi-bandit framework for exploring the road network to learn the parameters of\nthe queue time and charging power distributions. Within this framework, we\nfirst outline a pre-processing for the road network graph to handle the\nconstrained combinatorial optimization problem in an efficient way. Then, for\nthe pre-processed graph, we use a Bayesian approach to model the stochastic\nedge weights, utilizing conjugate priors for the one-parameter exponential and\ntwo-parameter gamma distributions, the latter of which is novel to multi-armed\nbandit literature. Finally, we apply combinatorial versions of Thompson\nSampling, BayesUCB and Epsilon-greedy to the problem. We demonstrate the\nperformance of our framework on long-distance navigation problem instances in\ncountry-sized road networks, with simulation experiments in Norway, Sweden and\nFinland.\n","authors":["Niklas Åkerblom","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2301.07156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.13196v3","updated":"2023-01-17T19:52:28Z","published":"2021-02-25T22:21:30Z","title":"Named Tensor Notation","summary":"  We propose a notation for tensors with named axes, which relieves the author,\nreader, and future implementers of machine learning models from the burden of\nkeeping track of the order of axes and the purpose of each. The notation makes\nit easy to lift operations on low-order tensors to higher order ones, for\nexample, from images to minibatches of images, or from an attention mechanism\nto multiple attention heads.\n  After a brief overview and formal definition of the notation, we illustrate\nit through several examples from modern machine learning, from building blocks\nlike attention and convolution to full models like Transformers and LeNet. We\nthen discuss differential calculus in our notation and compare with some\nalternative notations. Our proposals build on ideas from many previous papers\nand software libraries. We hope that our notation will encourage more authors\nto use named tensors, resulting in clearer papers and more precise\nimplementations.\n","authors":["David Chiang","Alexander M. Rush","Boaz Barak"],"pdf_url":"https://arxiv.org/pdf/2102.13196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05933v2","updated":"2023-01-17T19:51:24Z","published":"2022-12-08T08:03:26Z","title":"Nostradamus: Weathering Worth","summary":"  Nostradamus, inspired by the French astrologer and reputed seer, is a\ndetailed study exploring relations between environmental factors and changes in\nthe stock market. In this paper, we analyze associative correlation and\ncausation between environmental elements (including natural disasters, climate\nand weather conditions) and stock prices, using historical stock market data,\nhistorical climate data, and various climate indicators such as carbon dioxide\nemissions. We have conducted our study based on the US financial market, global\nclimate trends, and daily weather records to demonstrate a significant\nrelationship between climate and stock price fluctuation. Our analysis covers\nboth short-term and long-term rises and dips in company stock performances.\nLastly, we take four natural disasters as a case study to observe the effect\nthey have on people's emotional state and their influence on the stock market.\n","authors":["Alapan Chaudhuri","Zeeshan Ahmed","Ashwin Rao","Shivansh Subramanian","Shreyas Pradhan","Abhishek Mittal"],"pdf_url":"https://arxiv.org/pdf/2212.05933v2.pdf","comment":"13 pages, 13 figures; updated abstract; updated format to Springer\n  LNCS"},{"id":"http://arxiv.org/abs/2301.07143v1","updated":"2023-01-17T19:15:06Z","published":"2023-01-17T19:15:06Z","title":"Revisiting mass-radius relationships for exoplanet populations: a\n  machine learning insight","summary":"  The growing number of exoplanet discoveries and advances in machine learning\ntechniques allow us to find, explore, and understand characteristics of these\nnew worlds beyond our Solar System. We analyze the dataset of 762 confirmed\nexoplanets and eight Solar System planets using efficient machine-learning\napproaches to characterize their fundamental quantities. By adopting different\nunsupervised clustering algorithms, the data are divided into two main classes:\nplanets with $\\log R_{p}\\leq0.91R_{\\oplus}$ and $\\log M_{p}\\leq1.72M_{\\oplus}$\nas class 1 and those with $\\log R_{p}>0.91R_{\\oplus}$ and $\\log\nM_{p}>1.72M_{\\oplus}$ as class 2. Various regression models are used to reveal\ncorrelations between physical parameters and evaluate their performance. We\nfind that planetary mass, orbital period, and stellar mass play preponderant\nroles in predicting exoplanet radius. The validation metrics (RMSE, MAE, and\n$R^{2}$) suggest that the Support Vector Regression has, by and large, better\nperformance than other models and is a promising model for obtaining planetary\nradius. Not only do we improve the prediction accuracy in logarithmic space,\nbut also we derive parametric equations using the M5P and Markov Chain Monte\nCarlo methods. Planets of class 1 are shown to be consistent with a positive\nlinear mass-radius relation, while for planets of class 2, the planetary radius\nrepresents a strong correlation with their host stars' masses.\n","authors":["Mahdiyar Mousavi-Sadr","Davood M. Jassur","Ghassem Gozaliasl"],"pdf_url":"https://arxiv.org/pdf/2301.07143v1.pdf","comment":"Submitted to MNRAS. 15 pages, 17 figures"},{"id":"http://arxiv.org/abs/2301.07137v1","updated":"2023-01-17T19:05:17Z","published":"2023-01-17T19:05:17Z","title":"Heterogeneous Multi-Robot Reinforcement Learning","summary":"  Cooperative multi-robot tasks can benefit from heterogeneity in the robots'\nphysical and behavioral traits. In spite of this, traditional Multi-Agent\nReinforcement Learning (MARL) frameworks lack the ability to explicitly\naccommodate policy heterogeneity, and typically constrain agents to share\nneural network parameters. This enforced homogeneity limits application in\ncases where the tasks benefit from heterogeneous behaviors. In this paper, we\ncrystallize the role of heterogeneity in MARL policies. Towards this end, we\nintroduce Heterogeneous Graph Neural Network Proximal Policy Optimization\n(HetGPPO), a paradigm for training heterogeneous MARL policies that leverages a\nGraph Neural Network for differentiable inter-agent communication. HetGPPO\nallows communicating agents to learn heterogeneous behaviors while enabling\nfully decentralized training in partially observable environments. We\ncomplement this with a taxonomical overview that exposes more heterogeneity\nclasses than previously identified. To motivate the need for our model, we\npresent a characterization of techniques that homogeneous models can leverage\nto emulate heterogeneous behavior, and show how this \"apparent heterogeneity\"\nis brittle in real-world conditions. Through simulations and real-world\nexperiments, we show that: (i) when homogeneous methods fail due to strong\nheterogeneous requirements, HetGPPO succeeds, and, (ii) when homogeneous\nmethods are able to learn apparently heterogeneous behaviors, HetGPPO achieves\nhigher resilience to both training and deployment noise.\n","authors":["Matteo Bettini","Ajay Shankar","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2301.07137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07487v1","updated":"2023-01-17T16:54:33Z","published":"2023-01-17T16:54:33Z","title":"Adversarial Robust Deep Reinforcement Learning Requires Redefining\n  Robustness","summary":"  Learning from raw high dimensional data via interaction with a given\nenvironment has been effectively achieved through the utilization of deep\nneural networks. Yet the observed degradation in policy performance caused by\nimperceptible worst-case policy dependent translations along high sensitivity\ndirections (i.e. adversarial perturbations) raises concerns on the robustness\nof deep reinforcement learning policies. In our paper, we show that these high\nsensitivity directions do not lie only along particular worst-case directions,\nbut rather are more abundant in the deep neural policy landscape and can be\nfound via more natural means in a black-box setting. Furthermore, we show that\nvanilla training techniques intriguingly result in learning more robust\npolicies compared to the policies learnt via the state-of-the-art adversarial\ntraining techniques. We believe our work lays out intriguing properties of the\ndeep reinforcement learning policy manifold and our results can help to build\nrobust and generalizable deep reinforcement learning policies.\n","authors":["Ezgi Korkmaz"],"pdf_url":"https://arxiv.org/pdf/2301.07487v1.pdf","comment":"Published in AAAI 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.06993v1","updated":"2023-01-17T16:22:30Z","published":"2023-01-17T16:22:30Z","title":"Your Day in Your Pocket: Complex Activity Recognition from Smartphone\n  Accelerometers","summary":"  Human Activity Recognition (HAR) enables context-aware user experiences where\nmobile apps can alter content and interactions depending on user activities.\nHence, smartphones have become valuable for HAR as they allow large, and\ndiversified data collection. Although previous work in HAR managed to detect\nsimple activities (i.e., sitting, walking, running) with good accuracy using\ninertial sensors (i.e., accelerometer), the recognition of complex daily\nactivities remains an open problem, specially in remote work/study settings\nwhen people are more sedentary. Moreover, understanding the everyday activities\nof a person can support the creation of applications that aim to support their\nwell-being. This paper investigates the recognition of complex activities\nexclusively using smartphone accelerometer data. We used a large smartphone\nsensing dataset collected from over 600 users in five countries during the\npandemic and showed that deep learning-based, binary classification of eight\ncomplex activities (sleeping, eating, watching videos, online communication,\nattending a lecture, sports, shopping, studying) can be achieved with AUROC\nscores up to 0.76 with partially personalized models. This shows encouraging\nsigns toward assessing complex activities only using phone accelerometer data\nin the post-pandemic world.\n","authors":["Emma Bouton--Bessac","Lakmal Meegahapola","Daniel Gatica-Perez"],"pdf_url":"https://arxiv.org/pdf/2301.06993v1.pdf","comment":"16th EAI International Conference on Pervasive Computing Technologies\n  for Healthcare (PervasiveHealth) 2022"},{"id":"http://arxiv.org/abs/2301.06876v1","updated":"2023-01-17T13:34:06Z","published":"2023-01-17T13:34:06Z","title":"CS-lol: a Dataset of Viewer Comment with Scene in E-sports\n  Live-streaming","summary":"  Billions of live-streaming viewers share their opinions on scenes they are\nwatching in real-time and interact with the event, commentators as well as\nother viewers via text comments. Thus, there is necessary to explore viewers'\ncomments with scenes in E-sport live-streaming events. In this paper, we\ndeveloped CS-lol, a new large-scale dataset containing comments from viewers\npaired with descriptions of game scenes in E-sports live-streaming. Moreover,\nwe propose a task, namely viewer comment retrieval, to retrieve the viewer\ncomments for the scene of the live-streaming event. Results on a series of\nbaseline retrieval methods derived from typical IR evaluation methods show our\ntask as a challenging task. Finally, we release CS-lol and baseline\nimplementation to the research community as a resource.\n","authors":["Junjie H. Xu","Yu Nakano","Lingrong Kong","Kojiro Iizuka"],"pdf_url":"https://arxiv.org/pdf/2301.06876v1.pdf","comment":"5 pages, 3 figures, In ACM SIGIR Conference on Human Information\n  Interaction and Retrieval (CHIIR 23)"}]},"2023-01-18T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2211.09800v2","updated":"2023-01-18T17:31:52Z","published":"2022-11-17T18:58:43Z","title":"InstructPix2Pix: Learning to Follow Image Editing Instructions","summary":"  We propose a method for editing images from human instructions: given an\ninput image and a written instruction that tells the model what to do, our\nmodel follows these instructions to edit the image. To obtain training data for\nthis problem, we combine the knowledge of two large pretrained models -- a\nlanguage model (GPT-3) and a text-to-image model (Stable Diffusion) -- to\ngenerate a large dataset of image editing examples. Our conditional diffusion\nmodel, InstructPix2Pix, is trained on our generated data, and generalizes to\nreal images and user-written instructions at inference time. Since it performs\nedits in the forward pass and does not require per example fine-tuning or\ninversion, our model edits images quickly, in a matter of seconds. We show\ncompelling editing results for a diverse collection of input images and written\ninstructions.\n","authors":["Tim Brooks","Aleksander Holynski","Alexei A. Efros"],"pdf_url":"https://arxiv.org/pdf/2211.09800v2.pdf","comment":"Project page with code:\n  https://www.timothybrooks.com/instruct-pix2pix"},{"id":"http://arxiv.org/abs/2210.12874v3","updated":"2023-01-18T16:47:51Z","published":"2022-10-23T22:35:02Z","title":"Global Contrastive Batch Sampling via Optimization on Sample\n  Permutations","summary":"  Contrastive Learning has recently achieved state-of-the-art performance in a\nwide range of tasks. Many contrastive learning approaches use mined hard\nnegatives to make batches more informative during training but these approaches\nare inefficient as they increase epoch length proportional to the number of\nmined negatives and require frequent updates of nearest neighbor indices or\nmining from recent batches. In this work, we provide an alternative to hard\nnegative mining, Global Contrastive Batch Sampling (GCBS), an efficient\napproximation to the batch assignment problem that upper bounds the gap between\nthe global and training losses, $\\mathcal{L}^{Global} - \\mathcal{L}^{Train}$,\nin contrastive learning settings. Through experimentation we find GCBS improves\nstate-of-the-art performance in sentence embedding and code-search tasks.\nAdditionally, GCBS is easy to implement as it requires only a few additional\nlines of code, does not maintain external data structures such as nearest\nneighbor indices, is more computationally efficient than the most minimal hard\nnegative mining approaches, and makes no changes to the model being trained.\n","authors":["Vin Sachidananda","Ziyi Yang","Chenguang Zhu"],"pdf_url":"https://arxiv.org/pdf/2210.12874v3.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/1809.10736v4","updated":"2023-01-18T16:29:59Z","published":"2018-09-27T19:33:54Z","title":"Controllable Neural Story Plot Generation via Reward Shaping","summary":"  Language-modeling--based approaches to story plot generation attempt to\nconstruct a plot by sampling from a language model (LM) to predict the next\ncharacter, word, or sentence to add to the story. LM techniques lack the\nability to receive guidance from the user to achieve a specific goal, resulting\nin stories that don't have a clear sense of progression and lack coherence. We\npresent a reward-shaping technique that analyzes a story corpus and produces\nintermediate rewards that are backpropagated into a pre-trained LM in order to\nguide the model towards a given goal. Automated evaluations show our technique\ncan create a model that generates story plots which consistently achieve a\nspecified goal. Human-subject studies show that the generated stories have more\nplausible event ordering than baseline plot generation techniques.\n","authors":["Pradyumna Tambwekar","Murtaza Dhuliawala","Lara J. Martin","Animesh Mehta","Brent Harrison","Mark O. Riedl"],"pdf_url":"https://arxiv.org/pdf/1809.10736v4.pdf","comment":"Pradyumna Tambwekar & Murtaza Dhuliawala contributed equally"},{"id":"http://arxiv.org/abs/2210.07448v2","updated":"2023-01-18T16:26:48Z","published":"2022-10-14T01:24:21Z","title":"Evaluating Out-of-Distribution Performance on Document Image Classifiers","summary":"  The ability of a document classifier to handle inputs that are drawn from a\ndistribution different from the training distribution is crucial for robust\ndeployment and generalizability. The RVL-CDIP corpus is the de facto standard\nbenchmark for document classification, yet to our knowledge all studies that\nuse this corpus do not include evaluation on out-of-distribution documents. In\nthis paper, we curate and release a new out-of-distribution benchmark for\nevaluating out-of-distribution performance for document classifiers. Our new\nout-of-distribution benchmark consists of two types of documents: those that\nare not part of any of the 16 in-domain RVL-CDIP categories (RVL-CDIP-O), and\nthose that are one of the 16 in-domain categories yet are drawn from a\ndistribution different from that of the original RVL-CDIP dataset (RVL-CDIP-N).\nWhile prior work on document classification for in-domain RVL-CDIP documents\nreports high accuracy scores, we find that these models exhibit accuracy drops\nof between roughly 15-30% on our new out-of-domain RVL-CDIP-N benchmark, and\nfurther struggle to distinguish between in-domain RVL-CDIP-N and out-of-domain\nRVL-CDIP-O inputs. Our new benchmark provides researchers with a valuable new\nresource for analyzing out-of-distribution performance on document classifiers.\nOur new out-of-distribution data can be found at\nhttps://github.com/gxlarson/rvl-cdip-ood.\n","authors":["Stefan Larson","Gordon Lim","Yutong Ai","David Kuang","Kevin Leach"],"pdf_url":"https://arxiv.org/pdf/2210.07448v2.pdf","comment":"NeurIPS D&B 2022"},{"id":"http://arxiv.org/abs/2301.07597v1","updated":"2023-01-18T15:23:25Z","published":"2023-01-18T15:23:25Z","title":"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation,\n  and Detection","summary":"  The introduction of ChatGPT has garnered widespread attention in both\nacademic and industrial communities. ChatGPT is able to respond effectively to\na wide range of human questions, providing fluent and comprehensive answers\nthat significantly surpass previous public chatbots in terms of security and\nusefulness. On one hand, people are curious about how ChatGPT is able to\nachieve such strength and how far it is from human experts. On the other hand,\npeople are starting to worry about the potential negative impacts that large\nlanguage models (LLMs) like ChatGPT could have on society, such as fake news,\nplagiarism, and social security issues. In this work, we collected tens of\nthousands of comparison responses from both human experts and ChatGPT, with\nquestions ranging from open-domain, financial, medical, legal, and\npsychological areas. We call the collected dataset the Human ChatGPT Comparison\nCorpus (HC3). Based on the HC3 dataset, we study the characteristics of\nChatGPT's responses, the differences and gaps from human experts, and future\ndirections for LLMs. We conducted comprehensive human evaluations and\nlinguistic analyses of ChatGPT-generated content compared with that of humans,\nwhere many interesting results are revealed. After that, we conduct extensive\nexperiments on how to effectively detect whether a certain text is generated by\nChatGPT or humans. We build three different detection systems, explore several\nkey factors that influence their effectiveness, and evaluate them in different\nscenarios. The dataset, code, and models are all publicly available at\nhttps://github.com/Hello-SimpleAI/chatgpt-comparison-detection.\n","authors":["Biyang Guo","Xin Zhang","Ziyuan Wang","Minqi Jiang","Jinran Nie","Yuxuan Ding","Jianwei Yue","Yupeng Wu"],"pdf_url":"https://arxiv.org/pdf/2301.07597v1.pdf","comment":"https://github.com/Hello-SimpleAI/chatgpt-comparison-detection"},{"id":"http://arxiv.org/abs/2301.07558v1","updated":"2023-01-18T14:23:29Z","published":"2023-01-18T14:23:29Z","title":"Towards a Holistic Understanding of Mathematical Questions with\n  Contrastive Pre-training","summary":"  Understanding mathematical questions effectively is a crucial task, which can\nbenefit many applications, such as difficulty estimation. Researchers have\ndrawn much attention to designing pre-training models for question\nrepresentations due to the scarcity of human annotations (e.g., labeling\ndifficulty). However, unlike general free-format texts (e.g., user comments),\nmathematical questions are generally designed with explicit purposes and\nmathematical logic, and usually consist of more complex content, such as\nformulas, and related mathematical knowledge (e.g., Function). Therefore, the\nproblem of holistically representing mathematical questions remains\nunderexplored. To this end, in this paper, we propose a novel contrastive\npre-training approach for mathematical question representations, namely QuesCo,\nwhich attempts to bring questions with more similar purposes closer.\nSpecifically, we first design two-level question augmentations, including\ncontent-level and structure-level, which generate literally diverse question\npairs with similar purposes. Then, to fully exploit hierarchical information of\nknowledge concepts, we propose a knowledge hierarchy-aware rank strategy\n(KHAR), which ranks the similarities between questions in a fine-grained\nmanner. Next, we adopt a ranking contrastive learning task to optimize our\nmodel based on the augmented and ranked questions. We conduct extensive\nexperiments on two real-world mathematical datasets. The experimental results\ndemonstrate the effectiveness of our model.\n","authors":["Yuting Ning","Zhenya Huang","Xin Lin","Enhong Chen","Shiwei Tong","Zheng Gong","Shijin Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07558v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2301.07535v1","updated":"2023-01-18T13:55:08Z","published":"2023-01-18T13:55:08Z","title":"A Quantitative Exploration of Natural Language Processing Applications\n  for Electricity Demand Analysis","summary":"  The relationship between electricity demand and weather has been established\nfor a long time and is one of the cornerstones in load prediction for operation\nand planning, along with behavioral and social aspects such as calendars or\nsignificant events. This paper explores how and why the social information\ncontained in the news can be used better to understand aggregate population\nbehaviour in terms of energy demand. The work is done through experiments\nanalysing the impact of predicting features extracted from national news on\nday-ahead electric demand prediction. The results are compared to a benchmark\nmodel trained exclusively on the calendar and meteorological information.\nExperimental results showed that the best-performing model reduced the official\nstandard errors around 4%, 11%, and 10% in terms of RMSE, MAE, and SMAPE. The\nbest-performing methods are: word frequency identified COVID-19-related\nkeywords; topic distribution that identified news on the pandemic and internal\npolitics; global word embeddings that identified news about international\nconflicts. This study brings a new perspective to traditional electricity\ndemand analysis and confirms the feasibility of improving its predictions with\nunstructured information contained in texts, with potential consequences in\nsociology and economics.\n","authors":["Yun Bai","Simon Camal","Andrea Michiorri"],"pdf_url":"https://arxiv.org/pdf/2301.07535v1.pdf","comment":"10 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2301.07507v1","updated":"2023-01-18T13:29:05Z","published":"2023-01-18T13:29:05Z","title":"Graphix-T5: Mixing Pre-Trained Transformers with Graph-Aware Layers for\n  Text-to-SQL Parsing","summary":"  The task of text-to-SQL parsing, which aims at converting natural language\nquestions into executable SQL queries, has garnered increasing attention in\nrecent years, as it can assist end users in efficiently extracting vital\ninformation from databases without the need for technical background. One of\nthe major challenges in text-to-SQL parsing is domain generalization, i.e., how\nto generalize well to unseen databases. Recently, the pre-trained text-to-text\ntransformer model, namely T5, though not specialized for text-to-SQL parsing,\nhas achieved state-of-the-art performance on standard benchmarks targeting\ndomain generalization. In this work, we explore ways to further augment the\npre-trained T5 model with specialized components for text-to-SQL parsing. Such\ncomponents are expected to introduce structural inductive bias into text-to-SQL\nparsers thus improving model's capacity on (potentially multi-hop) reasoning,\nwhich is critical for generating structure-rich SQLs. To this end, we propose a\nnew architecture GRAPHIX-T5, a mixed model with the standard pre-trained\ntransformer model augmented by some specially-designed graph-aware layers.\nExtensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5\nacross four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5\nsurpass all other T5-based parsers with a significant margin, achieving new\nstate-of-the-art performance. Notably, GRAPHIX-T5-large reach performance\nsuperior to the original T5-large by 5.7% on exact match (EM) accuracy and 6.6%\non execution accuracy (EX). This even outperforms the T5-3B by 1.2% on EM and\n1.5% on EX.\n","authors":["Jinyang Li","Binyuan Hui","Reynold Cheng","Bowen Qin","Chenhao Ma","Nan Huo","Fei Huang","Wenyu Du","Luo Si","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2301.07507v1.pdf","comment":"Accepted to AAAI 2023 main conference (oral)"},{"id":"http://arxiv.org/abs/2211.11554v3","updated":"2023-01-18T13:05:10Z","published":"2022-11-21T15:20:45Z","title":"Programming by Example and Text-to-Code Translation for Conversational\n  Code Generation","summary":"  Dialogue systems is an increasingly popular task of natural language\nprocessing. However, the dialogue paths tend to be deterministic, restricted to\nthe system rails, regardless of the given request or input text. Recent\nadvances in program synthesis have led to systems which can synthesize programs\nfrom very general search spaces, e.g. Programming by Example, and to systems\nwith very accessible interfaces for writing programs, e.g. text-to-code\ntranslation, but have not achieved both of these qualities in the same system.\nWe propose Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a\nmethod for integrating Programming by Example and text-to-code systems which\noffers an accessible natural language interface for synthesizing general\nprograms. We present a program representation that allows our method to be\napplied to the problem of task-oriented dialogue. Finally, we demo MPaTHS using\nour program representation.\n","authors":["Eli Whitehouse","William Gerard","Yauhen Klimovich","Marc Franco-Salvador"],"pdf_url":"https://arxiv.org/pdf/2211.11554v3.pdf","comment":"13 pages, 2 figures, conference preprint"},{"id":"http://arxiv.org/abs/2301.07069v2","updated":"2023-01-18T11:30:05Z","published":"2023-01-17T18:32:06Z","title":"Prompting Large Language Model for Machine Translation: A Case Study","summary":"  Research on prompting has shown excellent performance with little or even no\nsupervised training across many tasks. However, prompting for machine\ntranslation is still under-explored in the literature. We fill this gap by\noffering a systematic study on prompting strategies for translation, examining\nvarious factors for prompt template and demonstration example selection. We\nfurther explore the use of monolingual data and the feasibility of\ncross-lingual, cross-domain, and sentence-to-document transfer learning in\nprompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the\ntestbed show that 1) the number and the quality of prompt examples matter,\nwhere using suboptimal examples degenerates translation; 2) several features of\nprompt examples, such as semantic similarity, show significant Spearman\ncorrelation with their prompting performance; yet, none of the correlations are\nstrong enough; 3) using pseudo parallel prompt examples constructed from\nmonolingual data via zero-shot prompting could improve translation; and 4)\nimproved performance is achievable by transferring knowledge from prompt\nexamples selected in other settings. We finally provide an analysis on the\nmodel outputs and discuss several problems that prompting still suffers from.\n","authors":["Biao Zhang","Barry Haddow","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2301.07069v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2301.07341v1","updated":"2023-01-18T07:11:56Z","published":"2023-01-18T07:11:56Z","title":"KILDST: Effective Knowledge-Integrated Learning for Dialogue State\n  Tracking using Gazetteer and Speaker Information","summary":"  Dialogue State Tracking (DST) is core research in dialogue systems and has\nreceived much attention. In addition, it is necessary to define a new problem\nthat can deal with dialogue between users as a step toward the conversational\nAI that extracts and recommends information from the dialogue between users.\nSo, we introduce a new task - DST from dialogue between users about scheduling\nan event (DST-USERS). The DST-USERS task is much more challenging since it\nrequires the model to understand and track dialogue states in the dialogue\nbetween users and to understand who suggested the schedule and who agreed to\nthe proposed schedule. To facilitate DST-USERS research, we develop dialogue\ndatasets between users that plan a schedule. The annotated slot values which\nneed to be extracted in the dialogue are date, time, and location. Previous\napproaches, such as Machine Reading Comprehension (MRC) and traditional DST\ntechniques, have not achieved good results in our extensive evaluations. By\nadopting the knowledge-integrated learning method, we achieve exceptional\nresults. The proposed model architecture combines gazetteer features and\nspeaker information efficiently. Our evaluations of the dialogue datasets\nbetween users that plan a schedule show that our model outperforms the baseline\nmodel.\n","authors":["Hyungtak Choi","Hyeonmok Ko","Gurpreet Kaur","Lohith Ravuru","Kiranmayi Gandikota","Manisha Jhawar","Simma Dharani","Pranamya Patil"],"pdf_url":"https://arxiv.org/pdf/2301.07341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08708v2","updated":"2023-01-18T05:15:26Z","published":"2022-10-17T02:48:58Z","title":"Teacher Forcing Recovers Reward Functions for Text Generation","summary":"  Reinforcement learning (RL) has been widely used in text generation to\nalleviate the exposure bias issue or to utilize non-parallel datasets. The\nreward function plays an important role in making RL training successful.\nHowever, previous reward functions are typically task-specific and sparse,\nrestricting the use of RL. In our work, we propose a task-agnostic approach\nthat derives a step-wise reward function directly from a model trained with\nteacher forcing. We additionally propose a simple modification to stabilize the\nRL training on non-parallel datasets with our induced reward function.\nEmpirical results show that our method outperforms self-training and reward\nregression methods on several text generation tasks, confirming the\neffectiveness of our reward function.\n","authors":["Yongchang Hao","Yuxin Liu","Lili Mou"],"pdf_url":"https://arxiv.org/pdf/2210.08708v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2106.02359v3","updated":"2023-01-18T04:23:03Z","published":"2021-06-04T09:17:15Z","title":"How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social\n  Impact","summary":"  Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via the moral philosophy definition of social good, propose a\nframework to evaluate the direct and indirect real-world impact of NLP tasks,\nand adopt the methodology of global priorities research to identify priority\ncauses for NLP research. Finally, we use our theoretical framework to provide\nsome practical guidelines for future NLP research for social good. Our data and\ncode are available at http://github.com/zhijing-jin/nlp4sg_acl2021. In\naddition, we curate a list of papers and resources on NLP for social good at\nhttps://github.com/zhijing-jin/NLP4SocialGood_Papers.\n","authors":["Zhijing Jin","Geeticka Chauhan","Brian Tse","Mrinmaya Sachan","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2106.02359v3.pdf","comment":"Findings of ACL 2021; also accepted at the NLP for Positive Impact\n  workshop@ACL 2021"},{"id":"http://arxiv.org/abs/2301.07295v1","updated":"2023-01-18T03:57:53Z","published":"2023-01-18T03:57:53Z","title":"Adapting Multilingual Speech Representation Model for a New,\n  Underresourced Language through Multilingual Fine-tuning and Continued\n  Pretraining","summary":"  In recent years, neural models learned through self-supervised pretraining on\nlarge scale multilingual text or speech data have exhibited promising results\nfor underresourced languages, especially when a relatively large amount of data\nfrom related language(s) is available. While the technology has a potential for\nfacilitating tasks carried out in language documentation projects, such as\nspeech transcription, pretraining a multilingual model from scratch for every\nnew language would be highly impractical. We investigate the possibility for\nadapting an existing multilingual wav2vec 2.0 model for a new language,\nfocusing on actual fieldwork data from a critically endangered tongue: Ainu.\nSpecifically, we (i) examine the feasibility of leveraging data from similar\nlanguages also in fine-tuning; (ii) verify whether the model's performance can\nbe improved by further pretraining on target language data. Our results show\nthat continued pretraining is the most effective method to adapt a wav2vec 2.0\nmodel for a new language and leads to considerable reduction in error rates.\nFurthermore, we find that if a model pretrained on a related speech variety or\nan unrelated language with similar phonological characteristics is available,\nmultilingual fine-tuning using additional data from that language can have\npositive impact on speech recognition performance when there is very little\nlabeled data in the target language.\n","authors":["Karol Nowakowski","Michal Ptaszynski","Kyoko Murasaki","Jagna Nieuważny"],"pdf_url":"https://arxiv.org/pdf/2301.07295v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2301.07779v1","updated":"2023-01-18T20:43:13Z","published":"2023-01-18T20:43:13Z","title":"Understanding and Detecting Hallucinations in Neural Machine Translation\n  via Model Introspection","summary":"  Neural sequence generation models are known to \"hallucinate\", by producing\noutputs that are unrelated to the source text. These hallucinations are\npotentially harmful, yet it remains unclear in what conditions they arise and\nhow to mitigate their impact. In this work, we first identify internal model\nsymptoms of hallucinations by analyzing the relative token contributions to the\ngeneration in contrastive hallucinated vs. non-hallucinated outputs generated\nvia source perturbations. We then show that these symptoms are reliable\nindicators of natural hallucinations, by using them to design a lightweight\nhallucination detector which outperforms both model-free baselines and strong\nclassifiers based on quality estimation or large pre-trained models on manually\nannotated English-Chinese and German-English translation test beds.\n","authors":["Weijia Xu","Sweta Agrawal","Eleftheria Briakou","Marianna J. Martindale","Marine Carpuat"],"pdf_url":"https://arxiv.org/pdf/2301.07779v1.pdf","comment":"Accepted at TACL"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2210.07675v3","updated":"2023-01-18T18:49:26Z","published":"2022-10-14T10:00:36Z","title":"Learning image representations for anomaly detection: application to\n  discovery of histological alterations in drug development","summary":"  We present a system for anomaly detection in histopathological images. In\nhistology, normal samples are usually abundant, whereas anomalous\n(pathological) cases are scarce or not available. Under such settings,\none-class classifiers trained on healthy data can detect out-of-distribution\nanomalous samples. Such approaches combined with pre-trained Convolutional\nNeural Network (CNN) representations of images were previously employed for\nanomaly detection (AD). However, pre-trained off-the-shelf CNN representations\nmay not be sensitive to abnormal conditions in tissues, while natural\nvariations of healthy tissue may result in distant representations. To adapt\nrepresentations to relevant details in healthy tissue we propose training a CNN\non an auxiliary task that discriminates healthy tissue of different species,\norgans, and staining reagents. Almost no additional labeling workload is\nrequired, since healthy samples come automatically with aforementioned labels.\nDuring training we enforce compact image representations with a center-loss\nterm, which further improves representations for AD. The proposed system\noutperforms established AD methods on a published dataset of liver anomalies.\nMoreover, it provided comparable results to conventional methods specifically\ntailored for quantification of liver anomalies. We show that our approach can\nbe used for toxicity assessment of candidate drugs at early development stages\nand thereby may reduce expensive late-stage drug attrition.\n","authors":["Igor Zingman","Birgit Stierstorfer","Charlotte Lempp","Fabian Heinemann"],"pdf_url":"https://arxiv.org/pdf/2210.07675v3.pdf","comment":"14 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2301.07702v1","updated":"2023-01-18T18:47:46Z","published":"2023-01-18T18:47:46Z","title":"Learning 3D-aware Image Synthesis with Unknown Pose Distribution","summary":"  Existing methods for 3D-aware image synthesis largely depend on the 3D pose\ndistribution pre-estimated on the training set. An inaccurate estimation may\nmislead the model into learning faulty geometry. This work proposes PoF3D that\nfrees generative radiance fields from the requirements of 3D pose priors. We\nfirst equip the generator with an efficient pose learner, which is able to\ninfer a pose from a latent code, to approximate the underlying true pose\ndistribution automatically. We then assign the discriminator a task to learn\npose distribution under the supervision of the generator and to differentiate\nreal and synthesized images with the predicted pose as the condition. The\npose-free generator and the pose-aware discriminator are jointly trained in an\nadversarial manner. Extensive results on a couple of datasets confirm that the\nperformance of our approach, regarding both image quality and geometry quality,\nis on par with state of the art. To our best knowledge, PoF3D demonstrates the\nfeasibility of learning high-quality 3D-aware image synthesis without using 3D\npose priors for the first time.\n","authors":["Zifan Shi","Yujun Shen","Yinghao Xu","Sida Peng","Yiyi Liao","Sheng Guo","Qifeng Chen","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2301.07702v1.pdf","comment":"Project page: https://vivianszf.github.io/pof3d/"},{"id":"http://arxiv.org/abs/2301.07700v1","updated":"2023-01-18T18:42:59Z","published":"2023-01-18T18:42:59Z","title":"Attention2Minority: A salient instance inference-based multiple instance\n  learning for classifying small lesions in whole slide images","summary":"  Multiple instance learning (MIL) models have achieved remarkable success in\nanalyzing whole slide images (WSIs) for disease classification problems.\nHowever, with regard to gigapixel WSI classification problems, current MIL\nmodels are often incapable of differentiating a WSI with extremely small tumor\nlesions. This minute tumor-to-normal area ratio in a MIL bag inhibits the\nattention mechanism from properly weighting the areas corresponding to minor\ntumor lesions. To overcome this challenge, we propose salient instance\ninference MIL (SiiMIL), a weakly-supervised MIL model for WSI classification.\nOur method initially learns representations of normal WSIs, and it then\ncompares the normal WSIs representations with all the input patches to infer\nthe salient instances of the input WSI. Finally, it employs attention-based MIL\nto perform the slide-level classification based on the selected patches of the\nWSI. Our experiments imply that SiiMIL can accurately identify tumor instances,\nwhich could only take up less than 1% of a WSI, so that the ratio of tumor to\nnormal instances within a bag can increase by two to four times. It is worth\nmentioning that it performs equally well for large tumor lesions. As a result,\nSiiMIL achieves a significant improvement in performance over the\nstate-of-the-art MIL methods.\n","authors":["Ziyu Su","Mostafa Rezapour","Usama Sajjad","Metin Nafi Gurcan","Muhammad Khalid Khan Niazi"],"pdf_url":"https://arxiv.org/pdf/2301.07700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07525v1","updated":"2023-01-18T18:14:18Z","published":"2023-01-18T18:14:18Z","title":"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic\n  Perception, Reconstruction and Generation","summary":"  Recent advances in modeling 3D objects mostly rely on synthetic datasets due\nto the lack of large-scale realscanned 3D databases. To facilitate the\ndevelopment of 3D perception, reconstruction, and generation in the real world,\nwe propose OmniObject3D, a large vocabulary 3D object dataset with massive\nhigh-quality real-scanned 3D objects. OmniObject3D has several appealing\nproperties: 1) Large Vocabulary: It comprises 6,000 scanned objects in 190\ndaily categories, sharing common classes with popular 2D datasets (e.g.,\nImageNet and LVIS), benefiting the pursuit of generalizable 3D representations.\n2) Rich Annotations: Each 3D object is captured with both 2D and 3D sensors,\nproviding textured meshes, point clouds, multiview rendered images, and\nmultiple real-captured videos. 3) Realistic Scans: The professional scanners\nsupport highquality object scans with precise shapes and realistic appearances.\nWith the vast exploration space offered by OmniObject3D, we carefully set up\nfour evaluation tracks: a) robust 3D perception, b) novel-view synthesis, c)\nneural surface reconstruction, and d) 3D object generation. Extensive studies\nare performed on these four benchmarks, revealing new observations, challenges,\nand opportunities for future research in realistic 3D vision.\n","authors":["Tong Wu","Jiarui Zhang","Xiao Fu","Yuxin Wang","Jiawei Ren","Liang Pan","Wayne Wu","Lei Yang","Jiaqi Wang","Chen Qian","Dahua Lin","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2301.07525v1.pdf","comment":"Project page: https://omniobject3d.github.io/"},{"id":"http://arxiv.org/abs/2301.07681v1","updated":"2023-01-18T18:00:29Z","published":"2023-01-18T18:00:29Z","title":"Reduced-Reference Quality Assessment of Point Clouds via\n  Content-Oriented Saliency Projection","summary":"  Many dense 3D point clouds have been exploited to represent visual objects\ninstead of traditional images or videos. To evaluate the perceptual quality of\nvarious point clouds, in this letter, we propose a novel and efficient\nReduced-Reference quality metric for point clouds, which is based on\nContent-oriented sAliency Projection (RR-CAP). Specifically, we make the first\nattempt to simplify reference and distorted point clouds into projected\nsaliency maps with a downsampling operation. Through this process, we tackle\nthe issue of transmitting large-volume original point clouds to user-ends for\nquality assessment. Then, motivated by the characteristics of the human visual\nsystem (HVS), the objective quality scores of distorted point clouds are\nproduced by combining content-oriented similarity and statistical correlation\nmeasurements. Finally, extensive experiments are conducted on SJTU-PCQA and WPC\ndatabases. The experimental results demonstrate that our proposed algorithm\noutperforms existing reduced-reference and no-reference quality metrics, and\nsignificantly reduces the performance gap between state-of-the-art\nfull-reference quality assessment methods. In addition, we show the performance\nvariation of each proposed technical component by ablation tests.\n","authors":["Wei Zhou","Guanghui Yue","Ruizeng Zhang","Yipeng Qin","Hantao Liu"],"pdf_url":"https://arxiv.org/pdf/2301.07681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07673v1","updated":"2023-01-18T17:47:13Z","published":"2023-01-18T17:47:13Z","title":"OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD\n  Models","summary":"  We propose a new method for object pose estimation without CAD models. The\nprevious feature-matching-based method OnePose has shown promising results\nunder a one-shot setting which eliminates the need for CAD models or\nobject-specific training. However, OnePose relies on detecting repeatable image\nkeypoints and is thus prone to failure on low-textured objects. We propose a\nkeypoint-free pose estimation pipeline to remove the need for repeatable\nkeypoint detection. Built upon the detector-free feature matching method LoFTR,\nwe devise a new keypoint-free SfM method to reconstruct a semi-dense\npoint-cloud model for the object. Given a query image for object pose\nestimation, a 2D-3D matching network directly establishes 2D-3D correspondences\nbetween the query image and the reconstructed point-cloud model without first\ndetecting keypoints in the image. Experiments show that the proposed pipeline\noutperforms existing one-shot CAD-model-free methods by a large margin and is\ncomparable to CAD-model-based methods on LINEMOD even for low-textured objects.\nWe also collect a new dataset composed of 80 sequences of 40 low-textured\nobjects to facilitate future research on one-shot object pose estimation. The\nsupplementary material, code and dataset are available on the project page:\nhttps://zju3dv.github.io/onepose_plus_plus/.\n","authors":["Xingyi He","Jiaming Sun","Yuang Wang","Di Huang","Hujun Bao","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.07673v1.pdf","comment":"Accepted to NeurIPS 2022"},{"id":"http://arxiv.org/abs/2211.09800v2","updated":"2023-01-18T17:31:52Z","published":"2022-11-17T18:58:43Z","title":"InstructPix2Pix: Learning to Follow Image Editing Instructions","summary":"  We propose a method for editing images from human instructions: given an\ninput image and a written instruction that tells the model what to do, our\nmodel follows these instructions to edit the image. To obtain training data for\nthis problem, we combine the knowledge of two large pretrained models -- a\nlanguage model (GPT-3) and a text-to-image model (Stable Diffusion) -- to\ngenerate a large dataset of image editing examples. Our conditional diffusion\nmodel, InstructPix2Pix, is trained on our generated data, and generalizes to\nreal images and user-written instructions at inference time. Since it performs\nedits in the forward pass and does not require per example fine-tuning or\ninversion, our model edits images quickly, in a matter of seconds. We show\ncompelling editing results for a diverse collection of input images and written\ninstructions.\n","authors":["Tim Brooks","Aleksander Holynski","Alexei A. Efros"],"pdf_url":"https://arxiv.org/pdf/2211.09800v2.pdf","comment":"Project page with code:\n  https://www.timothybrooks.com/instruct-pix2pix"},{"id":"http://arxiv.org/abs/2301.07670v1","updated":"2023-01-18T17:25:55Z","published":"2023-01-18T17:25:55Z","title":"Active learning for medical image segmentation with stochastic batches","summary":"  The performance of learning-based algorithms improves with the amount of\nlabelled data used for training. Yet, manually annotating data can be tedious\nand expensive, especially in medical image segmentation. To reduce manual\nlabelling, active learning (AL) targets the most informative samples from the\nunlabelled set to annotate and add to the labelled training set. On one hand,\nmost active learning works have focused on the classification or limited\nsegmentation of natural images, despite active learning being highly desirable\nin the difficult task of medical image segmentation. On the other hand,\nuncertainty-based AL approaches notoriously offer sub-optimal batch-query\nstrategies, while diversity-based methods tend to be computationally expensive.\nOver and above methodological hurdles, random sampling has proven an extremely\ndifficult baseline to outperform when varying learning and sampling conditions.\nThis work aims to take advantage of the diversity and speed offered by random\nsampling to improve the selection of uncertainty-based AL methods for\nsegmenting medical images. More specifically, we propose to compute uncertainty\nat the level of batches instead of samples through an original use of\nstochastic batches during sampling in AL. Exhaustive experiments on medical\nimage segmentation, with an illustration on MRI prostate imaging, show that the\nbenefits of stochastic batches during sample selection are robust to a variety\nof changes in the training and sampling procedures.\n","authors":["Mélanie Gaillochet","Christian Desrosiers","Hervé Lombaert"],"pdf_url":"https://arxiv.org/pdf/2301.07670v1.pdf","comment":"Submitted to Medical Image Analysis, 13 pages"},{"id":"http://arxiv.org/abs/2301.07668v1","updated":"2023-01-18T17:24:01Z","published":"2023-01-18T17:24:01Z","title":"Behind the Scenes: Density Fields for Single View Reconstruction","summary":"  Inferring a meaningful geometric scene representation from a single image is\na fundamental problem in computer vision. Approaches based on traditional depth\nmap prediction can only reason about areas that are visible in the image.\nCurrently, neural radiance fields (NeRFs) can capture true 3D including color\nbut are too complex to be generated from a single image. As an alternative, we\nintroduce a neural network that predicts an implicit density field from a\nsingle image. It maps every location in the frustum of the image to volumetric\ndensity. Our network can be trained through self-supervision from only video\ndata. By not storing color in the implicit volume, but directly sampling color\nfrom the available views during training, our scene representation becomes\nsignificantly less complex compared to NeRFs, and we can train neural networks\nto predict it. Thus, we can apply volume rendering to perform both depth\nprediction and novel view synthesis. In our experiments, we show that our\nmethod is able to predict meaningful geometry for regions that are occluded in\nthe input image. Additionally, we demonstrate the potential of our approach on\nthree datasets for depth prediction and novel-view synthesis.\n","authors":["Felix Wimbauer","Nan Yang","Christian Rupprecht","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2301.07668v1.pdf","comment":"Project Page: https://fwmb.github.io/bts/"},{"id":"http://arxiv.org/abs/2301.07666v1","updated":"2023-01-18T17:20:08Z","published":"2023-01-18T17:20:08Z","title":"DDS: Decoupled Dynamic Scene-Graph Generation Network","summary":"  Scene-graph generation involves creating a structural representation of the\nrelationships between objects in a scene by predicting subject-object-relation\ntriplets from input data. However, existing methods show poor performance in\ndetecting triplets outside of a predefined set, primarily due to their reliance\non dependent feature learning. To address this issue we propose DDS -- a\ndecoupled dynamic scene-graph generation network -- that consists of two\nindependent branches that can disentangle extracted features. The key\ninnovation of the current paper is the decoupling of the features representing\nthe relationships from those of the objects, which enables the detection of\nnovel object-relationship combinations. The DDS model is evaluated on three\ndatasets and outperforms previous methods by a significant margin, especially\nin detecting previously unseen triplets.\n","authors":["A S M Iftekhar","Raphael Ruschel","Satish Kumar","Suya You","B. S. Manjunath"],"pdf_url":"https://arxiv.org/pdf/2301.07666v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.05566v3","updated":"2023-01-18T17:09:00Z","published":"2022-12-11T18:15:40Z","title":"YoloCurvSeg: You Only Label One Noisy Skeleton for Vessel-style\n  Curvilinear Structure Segmentation","summary":"  Weakly-supervised learning (WSL) has been proposed to alleviate the conflict\nbetween data annotation cost and model performance through employing\nsparsely-grained (i.e., point-, box-, scribble-wise) supervision and has shown\npromising performance, particularly in the image segmentation field. However,\nit is still a very challenging task due to the limited supervision, especially\nwhen only a small number of labeled samples are available. Additionally, almost\nall existing WSL segmentation methods are designed for star-convex structures\nwhich are very different from curvilinear structures such as vessels and\nnerves. In this paper, we propose a novel sparsely annotated segmentation\nframework for curvilinear structures, named YoloCurvSeg. A very essential\ncomponent of YoloCurvSeg is image synthesis. Specifically, a background\ngenerator delivers image backgrounds that closely match the real distributions\nthrough inpainting dilated skeletons. The extracted backgrounds are then\ncombined with randomly emulated curves generated by a Space Colonization\nAlgorithm-based foreground generator and through a multilayer patch-wise\ncontrastive learning synthesizer. In this way, a synthetic dataset with both\nimages and curve segmentation labels is obtained, at the cost of only one or a\nfew noisy skeleton annotations. Finally, a segmenter is trained with the\ngenerated dataset and possibly an unlabeled dataset. The proposed YoloCurvSeg\nis evaluated on four publicly available datasets (OCTA500, CORN, DRIVE and\nCHASEDB1) and the results show that YoloCurvSeg outperforms state-of-the-art\nWSL segmentation methods by large margins. With only one noisy skeleton\nannotation (respectively 0.14%, 0.03%, 1.40%, and 0.65% of the full\nannotation), YoloCurvSeg achieves more than 97% of the fully-supervised\nperformance on each dataset. Code and datasets will be released at\nhttps://github.com/llmir/YoloCurvSeg.\n","authors":["Li Lin","Linkai Peng","Huaqing He","Pujin Cheng","Jiewei Wu","Kenneth K. Y. Wong","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2212.05566v3.pdf","comment":"15 pages, 10 figures, submitted to MEDIA"},{"id":"http://arxiv.org/abs/2301.07652v1","updated":"2023-01-18T16:55:15Z","published":"2023-01-18T16:55:15Z","title":"HMDO: Markerless Multi-view Hand Manipulation Capture with Deformable\n  Objects","summary":"  We construct the first markerless deformable interaction dataset recording\ninteractive motions of the hands and deformable objects, called HMDO (Hand\nManipulation with Deformable Objects). With our built multi-view capture\nsystem, it captures the deformable interactions with multiple perspectives,\nvarious object shapes, and diverse interactive forms. Our motivation is the\ncurrent lack of hand and deformable object interaction datasets, as 3D hand and\ndeformable object reconstruction is challenging. Mainly due to mutual\nocclusion, the interaction area is difficult to observe, the visual features\nbetween the hand and the object are entangled, and the reconstruction of the\ninteraction area deformation is difficult. To tackle this challenge, we propose\na method to annotate our captured data. Our key idea is to collaborate with\nestimated hand features to guide the object global pose estimation, and then\noptimize the deformation process of the object by analyzing the relationship\nbetween the hand and the object. Through comprehensive evaluation, the proposed\nmethod can reconstruct interactive motions of hands and deformable objects with\nhigh quality. HMDO currently consists of 21600 frames over 12 sequences. In the\nfuture, this dataset could boost the research of learning-based reconstruction\nof deformable interaction scenes.\n","authors":["Wei Xie","Zhipeng Yu","Zimeng Zhao","Binghui Zuo","Yangang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07650v1","updated":"2023-01-18T16:52:40Z","published":"2023-01-18T16:52:40Z","title":"Facial Thermal and Blood Perfusion Patterns of Human Emotions:\n  Proof-of-Concept","summary":"  The objective of the work was to realize a preliminary study of\nproof-of-concept to evaluate emotions using thermographic images and blood\nperfusion algorithm; the images were obtained for baseline and positive and\nnegative valence according to the protocol of the Geneva Affective Picture\nDatabase. The blood perfusion algorithm is based on the heat transport\nequation. The average temperature and blood perfusion in forehead, periorbital\neyes, cheeks, nose and upper lips were determined. Absolute and percentage\ndifferences between the valences and the baseline were calculated. For negative\nvalence, a decrease in temperature and blood perfusion was observed in the\nROIs, and the effect was greater on the left side than on the right side. In\npositive valence, the temperature and blood perfusion increased in some cases,\nshowing a complex pattern. The temperature and perfusion of the nose was\nreduced for both valences, which is indicative of the arousal dimension. The\nblood perfusion images were found to be greater contrast; the percentage\ndifferences in the blood perfusion images are greater than those obtained in\nthermographic images. Moreover, the blood perfusion images, and vasomotor\nanswer are consistent, therefore, they can be a better biomarker than\nthermographic analysis in identifying emotions.\n","authors":["Victor H. Aristizabal-Tique","Marcela Henao-Pérez","Diana Carolina López-Medina","Renato Zambrano-Cruz","Gloria Díaz-Londoñod"],"pdf_url":"https://arxiv.org/pdf/2301.07650v1.pdf","comment":"20 pages, 11 figures"},{"id":"http://arxiv.org/abs/2210.07448v2","updated":"2023-01-18T16:26:48Z","published":"2022-10-14T01:24:21Z","title":"Evaluating Out-of-Distribution Performance on Document Image Classifiers","summary":"  The ability of a document classifier to handle inputs that are drawn from a\ndistribution different from the training distribution is crucial for robust\ndeployment and generalizability. The RVL-CDIP corpus is the de facto standard\nbenchmark for document classification, yet to our knowledge all studies that\nuse this corpus do not include evaluation on out-of-distribution documents. In\nthis paper, we curate and release a new out-of-distribution benchmark for\nevaluating out-of-distribution performance for document classifiers. Our new\nout-of-distribution benchmark consists of two types of documents: those that\nare not part of any of the 16 in-domain RVL-CDIP categories (RVL-CDIP-O), and\nthose that are one of the 16 in-domain categories yet are drawn from a\ndistribution different from that of the original RVL-CDIP dataset (RVL-CDIP-N).\nWhile prior work on document classification for in-domain RVL-CDIP documents\nreports high accuracy scores, we find that these models exhibit accuracy drops\nof between roughly 15-30% on our new out-of-domain RVL-CDIP-N benchmark, and\nfurther struggle to distinguish between in-domain RVL-CDIP-N and out-of-domain\nRVL-CDIP-O inputs. Our new benchmark provides researchers with a valuable new\nresource for analyzing out-of-distribution performance on document classifiers.\nOur new out-of-distribution data can be found at\nhttps://github.com/gxlarson/rvl-cdip-ood.\n","authors":["Stefan Larson","Gordon Lim","Yutong Ai","David Kuang","Kevin Leach"],"pdf_url":"https://arxiv.org/pdf/2210.07448v2.pdf","comment":"NeurIPS D&B 2022"},{"id":"http://arxiv.org/abs/2301.07634v1","updated":"2023-01-18T16:22:40Z","published":"2023-01-18T16:22:40Z","title":"Training Semantic Segmentation on Heterogeneous Datasets","summary":"  We explore semantic segmentation beyond the conventional, single-dataset\nhomogeneous training and bring forward the problem of Heterogeneous Training of\nSemantic Segmentation (HTSS). HTSS involves simultaneous training on multiple\nheterogeneous datasets, i.e. datasets with conflicting label spaces and\ndifferent (weak) annotation types from the perspective of semantic\nsegmentation. The HTSS formulation exposes deep networks to a larger and\npreviously unexplored aggregation of information that can potentially enhance\nsemantic segmentation in three directions: i) performance: increased\nsegmentation metrics on seen datasets, ii) generalization: improved\nsegmentation metrics on unseen datasets, and iii) knowledgeability: increased\nnumber of recognizable semantic concepts. To research these benefits of HTSS,\nwe propose a unified framework, that incorporates heterogeneous datasets in a\nsingle-network training pipeline following the established FCN standard. Our\nframework first curates heterogeneous datasets to bring them into a common\nformat and then trains a single-backbone FCN on all of them simultaneously. To\nachieve this, it transforms weak annotations, which are incompatible with\nsemantic segmentation, to per-pixel labels, and hierarchizes their label spaces\ninto a universal taxonomy. The trained HTSS models demonstrate performance and\ngeneralization gains over a wide range of datasets and extend the inference\nlabel space entailing hundreds of semantic classes.\n","authors":["Panagiotis Meletis","Gijs Dubbelman"],"pdf_url":"https://arxiv.org/pdf/2301.07634v1.pdf","comment":"Submitted 2021 (under review)"},{"id":"http://arxiv.org/abs/2207.09442v3","updated":"2023-01-18T16:20:27Z","published":"2022-07-19T17:57:40Z","title":"Theseus: A Library for Differentiable Nonlinear Optimization","summary":"  We present Theseus, an efficient application-agnostic open source library for\ndifferentiable nonlinear least squares (DNLS) optimization built on PyTorch,\nproviding a common framework for end-to-end structured learning in robotics and\nvision. Existing DNLS implementations are application specific and do not\nalways incorporate many ingredients important for efficiency. Theseus is\napplication-agnostic, as we illustrate with several example applications that\nare built using the same underlying differentiable components, such as\nsecond-order optimizers, standard costs functions, and Lie groups. For\nefficiency, Theseus incorporates support for sparse solvers, automatic\nvectorization, batching, GPU acceleration, and gradient computation with\nimplicit differentiation and direct loss minimization. We do extensive\nperformance evaluation in a set of applications, demonstrating significant\nefficiency gains and better scalability when these features are incorporated.\nProject page: https://sites.google.com/view/theseus-ai\n","authors":["Luis Pineda","Taosha Fan","Maurizio Monge","Shobha Venkataraman","Paloma Sodhi","Ricky T. Q. Chen","Joseph Ortiz","Daniel DeTone","Austin Wang","Stuart Anderson","Jing Dong","Brandon Amos","Mustafa Mukadam"],"pdf_url":"https://arxiv.org/pdf/2207.09442v3.pdf","comment":"Advances in Neural Information Processing Systems (NeurIPS), 2022"},{"id":"http://arxiv.org/abs/2205.03721v2","updated":"2023-01-18T16:14:07Z","published":"2022-05-07T20:59:44Z","title":"Category-Independent Articulated Object Tracking with Factor Graphs","summary":"  Robots deployed in human-centric environments may need to manipulate a\ndiverse range of articulated objects, such as doors, dishwashers, and cabinets.\nArticulated objects often come with unexpected articulation mechanisms that are\ninconsistent with categorical priors: for example, a drawer might rotate about\na hinge joint instead of sliding open. We propose a category-independent\nframework for predicting the articulation models of unknown objects from\nsequences of RGB-D images. The prediction is performed by a two-step process:\nfirst, a visual perception module tracks object part poses from raw images, and\nsecond, a factor graph takes these poses and infers the articulation model\nincluding the current configuration between the parts as a 6D twist. We also\npropose a manipulation-oriented metric to evaluate predicted joint twists in\nterms of how well a compliant robot controller would be able to manipulate the\narticulated object given the predicted twist. We demonstrate that our visual\nperception and factor graph modules outperform baselines on simulated data and\nshow the applicability of our factor graph on real world data.\n","authors":["Nick Heppert","Toki Migimatsu","Brent Yi","Claire Chen","Jeannette Bohg"],"pdf_url":"https://arxiv.org/pdf/2205.03721v2.pdf","comment":"V2: Camera-ready IROS 2022 version 11 pages, 10 figures, IROS 2022"},{"id":"http://arxiv.org/abs/2301.07627v1","updated":"2023-01-18T16:11:09Z","published":"2023-01-18T16:11:09Z","title":"A novel dataset and a two-stage mitosis nuclei detection method based on\n  hybrid anchor branch","summary":"  Mitosis detection is one of the challenging problems in computational\npathology, and mitotic count is an important index of cancer grading for\npathologists. However, current counts of mitotic nuclei rely on pathologists\nlooking microscopically at the number of mitotic nuclei in hot spots, which is\nsubjective and time-consuming. In this paper, we propose a two-stage cascaded\nnetwork, named FoCasNet, for mitosis detection. In the first stage, a detection\nnetwork named M_det is proposed to detect as many mitoses as possible. In the\nsecond stage, a classification network M_class is proposed to refine the\nresults of the first stage. In addition, the attention mechanism, normalization\nmethod, and hybrid anchor branch classification subnet are introduced to\nimprove the overall detection performance. Our method achieves the current\nhighest F1-score of 0.888 on the public dataset ICPR 2012. We also evaluated\nour method on the GZMH dataset released by our research team for the first time\nand reached the highest F1-score of 0.563, which is also better than multiple\nclassic detection networks widely used at present. It confirmed the\neffectiveness and generalization of our method. The code will be available at:\nhttps://github.com/antifen/mitosis-nuclei-detection.\n","authors":["Huadeng Wang","Hao Xu","Bingbing Li","Xipeng Pan","Lingqi Zeng","Rushi Lan","Xiaonan Luo"],"pdf_url":"https://arxiv.org/pdf/2301.07627v1.pdf","comment":"22 pages,10 figures, 8 tables"},{"id":"http://arxiv.org/abs/2301.07613v1","updated":"2023-01-18T15:45:33Z","published":"2023-01-18T15:45:33Z","title":"Development, Optimization, and Deployment of Thermal Forward Vision\n  Systems for Advance Vehicular Applications on Edge Devices","summary":"  In this research work, we have proposed a thermal tiny-YOLO multi-class\nobject detection (TTYMOD) system as a smart forward sensing system that should\nremain effective in all weather and harsh environmental conditions using an\nend-to-end YOLO deep learning framework. It provides enhanced safety and\nimproved awareness features for driver assistance. The system is trained on\nlarge-scale thermal public datasets as well as newly gathered novel\nopen-sourced dataset comprising of more than 35,000 distinct thermal frames.\nFor optimal training and convergence of YOLO-v5 tiny network variant on thermal\ndata, we have employed different optimizers which include stochastic decent\ngradient (SGD), Adam, and its variant AdamW which has an improved\nimplementation of weight decay. The performance of thermally tuned tiny\narchitecture is further evaluated on the public as well as locally gathered\ntest data in diversified and challenging weather and environmental conditions.\nThe efficacy of a thermally tuned nano network is quantified using various\nqualitative metrics which include mean average precision, frames per second\nrate, and average inference time. Experimental outcomes show that the network\nachieved the best mAP of 56.4% with an average inference time/ frame of 4\nmilliseconds. The study further incorporates optimization of tiny network\nvariant using the TensorFlow Lite quantization tool this is beneficial for the\ndeployment of deep learning architectures on the edge and mobile devices. For\nthis study, we have used a raspberry pi 4 computing board for evaluating the\nreal-time feasibility performance of an optimized version of the thermal object\ndetection network for the automotive sensor suite. The source code, trained and\noptimized models and complete validation/ testing results are publicly\navailable at\nhttps://github.com/MAli-Farooq/Thermal-YOLO-And-Model-Optimization-Using-TensorFlowLite.\n","authors":["Muhammad Ali Farooq","Waseem Shariff","Faisal Khan","Peter Corcoran"],"pdf_url":"https://arxiv.org/pdf/2301.07613v1.pdf","comment":"The paper is accepted and in the publication phase at ICMV 2022\n  Conference. Link: http://icmv.org/"},{"id":"http://arxiv.org/abs/2210.10120v2","updated":"2023-01-18T15:32:12Z","published":"2022-10-18T19:31:00Z","title":"Initial Orbit Determination from Only Heading Measurements","summary":"  This work introduces the problem of initial orbit determination (IOD) from\nonly heading measurements. Such a problem occurs in practice when estimating\nthe orbit of a spacecraft using visual odometry measurements from an optical\ncamera. After reviewing the problem geometry, a simple solution is developed in\nthe form of an iterative scheme on the parameters describing the orbital\nhodograph. Numerical results are presented for an example spacecraft in low\nlunar orbit. The principal intent of this brief study is to communicate the\nexistence of a new class of IOD problem to the community and to encourage the\nbroader study of hodographs and heading-only IOD.\n","authors":["John A. Christian"],"pdf_url":"https://arxiv.org/pdf/2210.10120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14851v2","updated":"2023-01-18T15:29:19Z","published":"2022-05-30T04:56:33Z","title":"Exposing Fine-Grained Adversarial Vulnerability of Face Anti-Spoofing\n  Models","summary":"  Face anti-spoofing aims to discriminate the spoofing face images (e.g.,\nprinted photos) from live ones. However, adversarial examples greatly challenge\nits credibility, where adding some perturbation noise can easily change the\npredictions. Previous works conducted adversarial attack methods to evaluate\nthe face anti-spoofing performance without any fine-grained analysis that which\nmodel architecture or auxiliary feature is vulnerable to the adversary. To\nhandle this problem, we propose a novel framework to expose the fine-grained\nadversarial vulnerability of the face anti-spoofing models, which consists of a\nmultitask module and a semantic feature augmentation (SFA) module. The\nmultitask module can obtain different semantic features for further evaluation,\nbut only attacking these semantic features fails to reflect the\ndiscrimination-related vulnerability. We then design the SFA module to\nintroduce the data distribution prior for more discrimination-related gradient\ndirections for generating adversarial examples. Comprehensive experiments show\nthat SFA module increases the attack success rate by nearly 40$\\%$ on average.\nWe conduct this fine-grained adversarial analysis on different annotations,\ngeometric maps, and backbone networks (e.g., Resnet network). These\nfine-grained adversarial examples can be used for selecting robust backbone\nnetworks and auxiliary features. They also can be used for adversarial\ntraining, which makes it practical to further improve the accuracy and\nrobustness of the face anti-spoofing models.\n","authors":["Songlin Yang","Wei Wang","Chenye Xu","Ziwen He","Bo Peng","Jing Dong"],"pdf_url":"https://arxiv.org/pdf/2205.14851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03155v2","updated":"2023-01-18T15:25:22Z","published":"2023-01-09T03:00:20Z","title":"Instance Segmentation Based Graph Extraction for Handwritten Circuit\n  Diagram Images","summary":"  Handwritten circuit diagrams from educational scenarios or historic sources\nusually exist on analogue media. For deriving their functional principles or\nflaws automatically, they need to be digitized, extracting their electrical\ngraph. Recently, the base technologies for automated pipelines facilitating\nthis process shifted from computer vision to machine learning. This paper\ndescribes an approach for extracting both the electrical components (including\ntheir terminals and describing texts) as well their interconnections (including\njunctions and wire hops) by the means of instance segmentation and keypoint\nextraction. Consequently, the resulting graph extraction process consists of a\nsimple two-step process of model inference and trivial geometric keypoint\nmatching. The dataset itself, its preparation, model training and\npost-processing are described and publicly available.\n","authors":["Johannes Bayer","Amit Kumar Roy","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2301.03155v2.pdf","comment":"As submitted to ICPRAM23"},{"id":"http://arxiv.org/abs/2301.07584v1","updated":"2023-01-18T15:02:07Z","published":"2023-01-18T15:02:07Z","title":"Joint Representation Learning for Text and 3D Point Cloud","summary":"  Recent advancements in vision-language pre-training (e.g. CLIP) have shown\nthat vision models can benefit from language supervision. While many models\nusing language modality have achieved great success on 2D vision tasks, the\njoint representation learning of 3D point cloud with text remains\nunder-explored due to the difficulty of 3D-Text data pair acquisition and the\nirregularity of 3D data structure. In this paper, we propose a novel Text4Point\nframework to construct language-guided 3D point cloud models. The key idea is\nutilizing 2D images as a bridge to connect the point cloud and the language\nmodalities. The proposed Text4Point follows the pre-training and fine-tuning\nparadigm. During the pre-training stage, we establish the correspondence of\nimages and point clouds based on the readily available RGB-D data and use\ncontrastive learning to align the image and point cloud representations.\nTogether with the well-aligned image and text features achieved by CLIP, the\npoint cloud features are implicitly aligned with the text embeddings. Further,\nwe propose a Text Querying Module to integrate language information into 3D\nrepresentation learning by querying text embeddings with point cloud features.\nFor fine-tuning, the model learns task-specific 3D representations under\ninformative language guidance from the label set without 2D images. Extensive\nexperiments demonstrate that our model shows consistent improvement on various\ndownstream tasks, such as point cloud semantic segmentation, instance\nsegmentation, and object detection. The code will be available here:\nhttps://github.com/LeapLabTHU/Text4Point\n","authors":["Rui Huang","Xuran Pan","Henry Zheng","Haojun Jiang","Zhifeng Xie","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2301.07584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07583v1","updated":"2023-01-18T15:01:36Z","published":"2023-01-18T15:01:36Z","title":"A Survey of Advanced Computer Vision Techniques for Sports","summary":"  Computer Vision developments are enabling significant advances in many\nfields, including sports. Many applications built on top of Computer Vision\ntechnologies, such as tracking data, are nowadays essential for every top-level\nanalyst, coach, and even player. In this paper, we survey Computer Vision\ntechniques that can help many sports-related studies gather vast amounts of\ndata, such as Object Detection and Pose Estimation. We provide a use case for\nsuch data: building a model for shot speed estimation with pose data obtained\nusing only Computer Vision models. Our model achieves a correlation of 67%. The\npossibility of estimating shot speeds enables much deeper studies about\nenabling the creation of new metrics and recommendation systems that will help\nathletes improve their performance, in any sport. The proposed methodology is\neasily replicable for many technical movements and is only limited by the\navailability of video data.\n","authors":["Tiago Mendes-Neves","Luís Meireles","João Mendes-Moreira"],"pdf_url":"https://arxiv.org/pdf/2301.07583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07581v1","updated":"2023-01-18T14:58:32Z","published":"2023-01-18T14:58:32Z","title":"Blur Invariants for Image Recognition","summary":"  Blur is an image degradation that is difficult to remove. Invariants with\nrespect to blur offer an alternative way of a~description and recognition of\nblurred images without any deblurring. In this paper, we present an original\nunified theory of blur invariants. Unlike all previous attempts, the new theory\ndoes not require any prior knowledge of the blur type. The invariants are\nconstructed in the Fourier domain by means of orthogonal projection operators\nand moment expansion is used for efficient and stable computation. It is shown\nthat all blur invariants published earlier are just particular cases of this\napproach. Experimental comparison to concurrent approaches shows the advantages\nof the proposed theory.\n","authors":["Jan Flusser","Matej Lebl","Matteo Pedone","Filip Sroubek","Jitka Kostkova"],"pdf_url":"https://arxiv.org/pdf/2301.07581v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2301.07565v1","updated":"2023-01-18T14:36:22Z","published":"2023-01-18T14:36:22Z","title":"Gated-ViGAT: Efficient Bottom-Up Event Recognition and Explanation Using\n  a New Frame Selection Policy and Gating Mechanism","summary":"  In this paper, Gated-ViGAT, an efficient approach for video event\nrecognition, utilizing bottom-up (object) information, a new frame sampling\npolicy and a gating mechanism is proposed. Specifically, the frame sampling\npolicy uses weighted in-degrees (WiDs), derived from the adjacency matrices of\ngraph attention networks (GATs), and a dissimilarity measure to select the most\nsalient and at the same time diverse frames representing the event in the\nvideo. Additionally, the proposed gating mechanism fetches the selected frames\nsequentially, and commits early-exiting when an adequately confident decision\nis achieved. In this way, only a few frames are processed by the\ncomputationally expensive branch of our network that is responsible for the\nbottom-up information extraction. The experimental evaluation on two large,\npublicly available video datasets (MiniKinetics, ActivityNet) demonstrates that\nGated-ViGAT provides a large computational complexity reduction in comparison\nto our previous approach (ViGAT), while maintaining the excellent event\nrecognition and explainability performance. Gated-ViGAT source code is made\npublicly available at https://github.com/bmezaris/Gated-ViGAT\n","authors":["Nikolaos Gkalelis","Dimitrios Daskalakis","Vasileios Mezaris"],"pdf_url":"https://arxiv.org/pdf/2301.07565v1.pdf","comment":"Accepted for publication in the proceedings of IEEE Int. Symposium on\n  Multimedia (ISM), Naples, Italy, Dec. 2022"},{"id":"http://arxiv.org/abs/1905.05055v3","updated":"2023-01-18T14:23:50Z","published":"2019-05-13T14:26:50Z","title":"Object Detection in 20 Years: A Survey","summary":"  Object detection, as of one the most fundamental and challenging problems in\ncomputer vision, has received great attention in recent years. Over the past\ntwo decades, we have seen a rapid technological evolution of object detection\nand its profound impact on the entire computer vision field. If we consider\ntoday's object detection technique as a revolution driven by deep learning,\nthen back in the 1990s, we would see the ingenious thinking and long-term\nperspective design of early computer vision. This paper extensively reviews\nthis fast-moving research field in the light of technical evolution, spanning\nover a quarter-century's time (from the 1990s to 2022). A number of topics have\nbeen covered in this paper, including the milestone detectors in history,\ndetection datasets, metrics, fundamental building blocks of the detection\nsystem, speed-up techniques, and the recent state-of-the-art detection methods.\n","authors":["Zhengxia Zou","Keyan Chen","Zhenwei Shi","Yuhong Guo","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/1905.05055v3.pdf","comment":"Accepted by Proceedings of the IEEE"},{"id":"http://arxiv.org/abs/2301.05892v2","updated":"2023-01-18T14:21:07Z","published":"2023-01-14T11:20:27Z","title":"Object Detection performance variation on compressed satellite image\n  datasets with iquaflow","summary":"  A lot of work has been done to reach the best possible performance of\npredictive models on images. There are fewer studies about the resilience of\nthese models when they are trained on image datasets that suffer modifications\naltering their original quality. Yet this is a common problem that is often\nencountered in the industry. A good example of that is with earth observation\nsatellites that are capturing many images. The energy and time of connection to\nthe earth of an orbiting satellite are limited and must be carefully used. An\napproach to mitigate that is to compress the images on board before\ndownloading. The compression can be regulated depending on the intended usage\nof the image and the requirements of this application. We present a new\nsoftware tool with the name iquaflow that is designed to study image quality\nand model performance variation given an alteration of the image dataset.\nFurthermore, we do a showcase study about oriented object detection models\nadoption on a public image dataset DOTA Xia_2018_CVPR given different\ncompression levels. The optimal compression point is found and the usefulness\nof iquaflow becomes evident.\n","authors":["Pau Gallés","Katalin Takats","Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2301.05892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07533v1","updated":"2023-01-18T13:49:35Z","published":"2023-01-18T13:49:35Z","title":"A Multi-Scale Framework for Out-of-Distribution Detection in Dermoscopic\n  Images","summary":"  The automatic detection of skin diseases via dermoscopic images can improve\nthe efficiency in diagnosis and help doctors make more accurate judgments.\nHowever, conventional skin disease recognition systems may produce high\nconfidence for out-of-distribution (OOD) data, which may become a major\nsecurity vulnerability in practical applications. In this paper, we propose a\nmulti-scale detection framework to detect out-of-distribution skin disease\nimage data to ensure the robustness of the system. Our framework extracts\nfeatures from different layers of the neural network. In the early layers,\nrectified activation is used to make the output features closer to the\nwell-behaved distribution, and then an one-class SVM is trained to detect OOD\ndata; in the penultimate layer, an adapted Gram matrix is used to calculate the\nfeatures after rectified activation, and finally the layer with the best\nperformance is chosen to compute a normality score. Experiments show that the\nproposed framework achieves superior performance when compared with other\nstate-of-the-art methods in the task of skin disease recognition.\n","authors":["Zhongzheng Huang","Tao Wang","Yuanzheng Cai","Lingyu Liang"],"pdf_url":"https://arxiv.org/pdf/2301.07533v1.pdf","comment":"Paper accepted by the 4th International Conference on Machine\n  Learning for Cyber Security (ML4CS 2022), Guangzhou, China"},{"id":"http://arxiv.org/abs/2301.07475v1","updated":"2023-01-18T12:41:12Z","published":"2023-01-18T12:41:12Z","title":"Curvilinear object segmentation in medical images based on ODoS filter\n  and deep learning network","summary":"  Automatic segmentation of curvilinear objects in medical images plays an\nimportant role in the diagnosis and evaluation of human diseases, yet it is a\nchallenging uncertainty for the complex segmentation task due to different\nissues like various image appearance, low contrast between curvilinear objects\nand their surrounding backgrounds, thin and uneven curvilinear structures, and\nimproper background illumination. To overcome these challenges, we present a\nunique curvilinear structure segmentation framework based on oriented\nderivative of stick (ODoS) filter and deep learning network for curvilinear\nobject segmentation in medical images. Currently, a large number of deep\nlearning models emphasis on developing deep architectures and ignore capturing\nthe structural features of curvature objects, which may lead to unsatisfactory\nresults. In consequence, a new approach that incorporates the ODoS filter as\npart of a deep learning network is presented to improve the spatial attention\nof curvilinear objects. In which, the original image is considered as principal\npart to describe various image appearance and complex background illumination,\nthe multi-step strategy is used to enhance contrast between curvilinear objects\nand their surrounding backgrounds, and the vector field is applied to\ndiscriminate thin and uneven curvilinear structures. Subsequently, a deep\nlearning framework is employed to extract varvious structural features for\ncurvilinear object segmentation in medical images. The performance of the\ncomputational model was validated in experiments with publicly available DRIVE,\nSTARE and CHASEDB1 datasets. Experimental results indicate that the presented\nmodel has yielded surprising results compared with some state-of-the-art\nmethods.\n","authors":["Yuanyuan Peng","Lin Pan","Pengpeng Luan","Hongbin Tu","Xiong Li"],"pdf_url":"https://arxiv.org/pdf/2301.07475v1.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.07468v1","updated":"2023-01-18T12:23:10Z","published":"2023-01-18T12:23:10Z","title":"Model-based inexact graph matching on top of CNNs for semantic scene\n  understanding","summary":"  Deep learning based pipelines for semantic segmentation often ignore\nstructural information available on annotated images used for training. We\npropose a novel post-processing module enforcing structural knowledge about the\nobjects of interest to improve segmentation results provided by deep learning.\nThis module corresponds to a \"many-to-one-or-none\" inexact graph matching\napproach, and is formulated as a quadratic assignment problem. Our approach is\ncompared to a CNN-based segmentation (for various CNN backbones) on two public\ndatasets, one for face segmentation from 2D RGB images (FASSEG), and the other\nfor brain segmentation from 3D MRIs (IBSR). Evaluations are performed using two\ntypes of structural information (distances and directional relations, , this\nchoice being a hyper-parameter of our generic framework). On FASSEG data,\nresults show that our module improves accuracy of the CNN by about 6.3% (the\nHausdorff distance decreases from 22.11 to 20.71). On IBSR data, the\nimprovement is of 51% (the Hausdorff distance decreases from 11.01 to 5.4). In\naddition, our approach is shown to be resilient to small training datasets that\noften limit the performance of deep learning methods: the improvement increases\nas the size of the training dataset decreases.\n","authors":["Jérémy Chopin","Jean-Baptiste Fasquel","Harold Mouchère","Rozenn Dahyot","Isabelle Bloch"],"pdf_url":"https://arxiv.org/pdf/2301.07468v1.pdf","comment":"27 pages, 10 figures, 7 tables"},{"id":"http://arxiv.org/abs/2301.07464v1","updated":"2023-01-18T12:16:19Z","published":"2023-01-18T12:16:19Z","title":"CLIPTER: Looking at the Bigger Picture in Scene Text Recognition","summary":"  Understanding the scene is often essential for reading text in real-world\nscenarios. However, current scene text recognizers operate on cropped text\nimages, unaware of the bigger picture. In this work, we harness the\nrepresentative power of recent vision-language models, such as CLIP, to provide\nthe crop-based recognizer with scene, image-level information. Specifically, we\nobtain a rich representation of the entire image and fuse it with the\nrecognizer word-level features via cross-attention. Moreover, a gated mechanism\nis introduced that gradually shifts to the context-enriched representation,\nenabling simply fine-tuning a pretrained recognizer. We implement our\nmodel-agnostic framework, named CLIPTER - CLIP Text Recognition, on several\nleading text recognizers and demonstrate consistent performance gains,\nachieving state-of-the-art results over multiple benchmarks. Furthermore, an\nin-depth analysis reveals improved robustness to out-of-vocabulary words and\nenhanced generalization in low-data regimes.\n","authors":["Aviad Aberdam","David Bensaïd","Alona Golts","Roy Ganz","Oren Nuriel","Royee Tichauer","Shai Mazor","Ron Litman"],"pdf_url":"https://arxiv.org/pdf/2301.07464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07463v1","updated":"2023-01-18T12:15:47Z","published":"2023-01-18T12:15:47Z","title":"Temporal Perceiving Video-Language Pre-training","summary":"  Video-Language Pre-training models have recently significantly improved\nvarious multi-modal downstream tasks. Previous dominant works mainly adopt\ncontrastive learning to achieve global feature alignment across modalities.\nHowever, the local associations between videos and texts are not modeled,\nrestricting the pre-training models' generality, especially for tasks requiring\nthe temporal video boundary for certain query texts. This work introduces a\nnovel text-video localization pre-text task to enable fine-grained temporal and\nsemantic alignment such that the trained model can accurately perceive temporal\nboundaries in videos given the text description. Specifically, text-video\nlocalization consists of moment retrieval, which predicts start and end\nboundaries in videos given the text description, and text localization which\nmatches the subset of texts with the video features. To produce temporal\nboundaries, frame features in several videos are manually merged into a long\nvideo sequence that interacts with a text sequence. With the localization task,\nour method connects the fine-grained frame representations with the word\nrepresentations and implicitly distinguishes representations of different\ninstances in the single modality. Notably, comprehensive experimental results\nshow that our method significantly improves the state-of-the-art performance on\nvarious benchmarks, covering text-to-video retrieval, video question answering,\nvideo captioning, temporal action localization and temporal moment retrieval.\nThe code will be released soon.\n","authors":["Fan Ma","Xiaojie Jin","Heng Wang","Jingjia Huang","Linchao Zhu","Jiashi Feng","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06052v2","updated":"2023-01-18T11:56:01Z","published":"2023-01-15T09:34:42Z","title":"T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete\n  Representations","summary":"  In this work, we investigate a simple and must-known conditional generative\nframework based on Vector Quantised-Variational AutoEncoder (VQ-VAE) and\nGenerative Pre-trained Transformer (GPT) for human motion generation from\ntextural descriptions. We show that a simple CNN-based VQ-VAE with commonly\nused training recipes (EMA and Code Reset) allows us to obtain high-quality\ndiscrete representations. For GPT, we incorporate a simple corruption strategy\nduring the training to alleviate training-testing discrepancy. Despite its\nsimplicity, our T2M-GPT shows better performance than competitive approaches,\nincluding recent diffusion-based approaches. For example, on HumanML3D, which\nis currently the largest dataset, we achieve comparable performance on the\nconsistency between text and generated motion (R-Precision), but with FID 0.116\nlargely outperforming MotionDiffuse of 0.630. Additionally, we conduct analyses\non HumanML3D and observe that the dataset size is a limitation of our approach.\nOur work suggests that VQ-VAE still remains a competitive approach for human\nmotion generation.\n","authors":["Jianrong Zhang","Yangsong Zhang","Xiaodong Cun","Shaoli Huang","Yong Zhang","Hongwei Zhao","Hongtao Lu","Xi Shen"],"pdf_url":"https://arxiv.org/pdf/2301.06052v2.pdf","comment":"14 pages. Project page: https://mael-zys.github.io/T2M-GPT/"},{"id":"http://arxiv.org/abs/2301.07431v1","updated":"2023-01-18T11:00:45Z","published":"2023-01-18T11:00:45Z","title":"Sharp Eyes: A Salient Object Detector Working The Same Way as Human\n  Visual Characteristics","summary":"  Current methods aggregate multi-level features or introduce edge and skeleton\nto get more refined saliency maps. However, little attention is paid to how to\nobtain the complete salient object in cluttered background, where the targets\nare usually similar in color and texture to the background. To handle this\ncomplex scene, we propose a sharp eyes network (SENet) that first seperates the\nobject from scene, and then finely segments it, which is in line with human\nvisual characteristics, i.e., to look first and then focus. Different from\nprevious methods which directly integrate edge or skeleton to supplement the\ndefects of objects, the proposed method aims to utilize the expanded objects to\nguide the network obtain complete prediction. Specifically, SENet mainly\nconsists of target separation (TS) brach and object segmentation (OS) branch\ntrained by minimizing a new hierarchical difference aware (HDA) loss. In the TS\nbranch, we construct a fractal structure to produce saliency features with\nexpanded boundary via the supervision of expanded ground truth, which can\nenlarge the detail difference between foreground and background. In the OS\nbranch, we first aggregate multi-level features to adaptively select\ncomplementary components, and then feed the saliency features with expanded\nboundary into aggregated features to guide the network obtain complete\nprediction. Moreover, we propose the HDA loss to further improve the structural\nintegrity and local details of the salient objects, which assigns weight to\neach pixel according to its distance from the boundary hierarchically. Hard\npixels with similar appearance in border region will be given more attention\nhierarchically to emphasize their importance in completeness prediction.\nComprehensive experimental results on five datasets demonstrate that the\nproposed approach outperforms the state-of-the-art methods both quantitatively\nand qualitatively.\n","authors":["Ge Zhu","Jinbao Li","Yahong Guo"],"pdf_url":"https://arxiv.org/pdf/2301.07431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07409v1","updated":"2023-01-18T10:13:29Z","published":"2023-01-18T10:13:29Z","title":"Representing Noisy Image Without Denoising","summary":"  A long-standing topic in artificial intelligence is the effective recognition\nof patterns from noisy images. In this regard, the recent data-driven paradigm\nconsiders 1) improving the representation robustness by adding noisy samples in\ntraining phase (i.e., data augmentation) or 2) pre-processing the noisy image\nby learning to solve the inverse problem (i.e., image denoising). However, such\nmethods generally exhibit inefficient process and unstable result, limiting\ntheir practical applications. In this paper, we explore a non-learning paradigm\nthat aims to derive robust representation directly from noisy images, without\nthe denoising as pre-processing. Here, the noise-robust representation is\ndesigned as Fractional-order Moments in Radon space (FMR), with also beneficial\nproperties of orthogonality and rotation invariance. Unlike earlier\ninteger-order methods, our work is a more generic design taking such classical\nmethods as special cases, and the introduced fractional-order parameter offers\ntime-frequency analysis capability that is not available in classical methods.\nFormally, both implicit and explicit paths for constructing the FMR are\ndiscussed in detail. Extensive simulation experiments and an image security\napplication are provided to demonstrate the uniqueness and usefulness of our\nFMR, especially for noise robustness, rotation invariance, and time-frequency\ndiscriminability.\n","authors":["Shuren Qi","Yushu Zhang","Chao Wang","Tao Xiang","Xiaochun Cao","Yong Xiang"],"pdf_url":"https://arxiv.org/pdf/2301.07409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07407v1","updated":"2023-01-18T10:05:28Z","published":"2023-01-18T10:05:28Z","title":"TAME: Attention Mechanism Based Feature Fusion for Generating\n  Explanation Maps of Convolutional Neural Networks","summary":"  The apparent ``black box'' nature of neural networks is a barrier to adoption\nin applications where explainability is essential. This paper presents TAME\n(Trainable Attention Mechanism for Explanations), a method for generating\nexplanation maps with a multi-branch hierarchical attention mechanism. TAME\ncombines a target model's feature maps from multiple layers using an attention\nmechanism, transforming them into an explanation map. TAME can easily be\napplied to any convolutional neural network (CNN) by streamlining the\noptimization of the attention mechanism's training method and the selection of\ntarget model's feature maps. After training, explanation maps can be computed\nin a single forward pass. We apply TAME to two widely used models, i.e. VGG-16\nand ResNet-50, trained on ImageNet and show improvements over previous\ntop-performing methods. We also provide a comprehensive ablation study\ncomparing the performance of different variations of TAME's architecture. TAME\nsource code is made publicly available at https://github.com/bmezaris/TAME\n","authors":["Mariano Ntrougkas","Nikolaos Gkalelis","Vasileios Mezaris"],"pdf_url":"https://arxiv.org/pdf/2301.07407v1.pdf","comment":"Accepted for publication in the proceedings of IEEE Int. Symposium on\n  Multimedia (ISM), Naples, Italy, Dec. 2022"},{"id":"http://arxiv.org/abs/2301.07405v1","updated":"2023-01-18T10:00:59Z","published":"2023-01-18T10:00:59Z","title":"HiDAnet: RGB-D Salient Object Detection via Hierarchical Depth Awareness","summary":"  RGB-D saliency detection aims to fuse multi-modal cues to accurately localize\nsalient regions. Existing works often adopt attention modules for feature\nmodeling, with few methods explicitly leveraging fine-grained details to merge\nwith semantic cues. Thus, despite the auxiliary depth information, it is still\nchallenging for existing models to distinguish objects with similar appearances\nbut at distinct camera distances. In this paper, from a new perspective, we\npropose a novel Hierarchical Depth Awareness network (HiDAnet) for RGB-D\nsaliency detection. Our motivation comes from the observation that the\nmulti-granularity properties of geometric priors correlate well with the neural\nnetwork hierarchies. To realize multi-modal and multi-level fusion, we first\nuse a granularity-based attention scheme to strengthen the discriminatory power\nof RGB and depth features separately. Then we introduce a unified cross\ndual-attention module for multi-modal and multi-level fusion in a\ncoarse-to-fine manner. The encoded multi-modal features are gradually\naggregated into a shared decoder. Further, we exploit a multi-scale loss to\ntake full advantage of the hierarchical information. Extensive experiments on\nchallenging benchmark datasets demonstrate that our HiDAnet performs favorably\nover the state-of-the-art methods by large margins.\n","authors":["Zongwei Wu","Guillaume Allibert","Fabrice Meriaudeau","Chao Ma","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2301.07405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07389v1","updated":"2023-01-18T09:36:41Z","published":"2023-01-18T09:36:41Z","title":"Towards Models that Can See and Read","summary":"  Visual Question Answering (VQA) and Image Captioning (CAP), which are among\nthe most popular vision-language tasks, have analogous scene-text versions that\nrequire reasoning from the text in the image. Despite the obvious resemblance\nbetween them, the two are treated independently, yielding task-specific methods\nthat can either see or read, but not both. In this work, we conduct an in-depth\nanalysis of this phenomenon and propose UniTNT, a Unified Text-Non-Text\napproach, which grants existing multimodal architectures scene-text\nunderstanding capabilities. Specifically, we treat scene-text information as an\nadditional modality, fusing it with any pretrained encoder-decoder-based\narchitecture via designated modules. Thorough experiments reveal that UniTNT\nleads to the first single model that successfully handles both task types.\nMoreover, we show that scene-text understanding capabilities can boost\nvision-language models' performance on VQA and CAP by up to 3.49% and 0.7\nCIDEr, respectively.\n","authors":["Roy Ganz","Oren Nuriel","Aviad Aberdam","Yair Kittenplon","Shai Mazor","Ron Litman"],"pdf_url":"https://arxiv.org/pdf/2301.07389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07385v1","updated":"2023-01-18T09:28:59Z","published":"2023-01-18T09:28:59Z","title":"Three-dimensional reconstruction and characterization of bladder\n  deformations","summary":"  Background and Objective: Pelvic floor disorders are prevalent diseases and\npatient care remains difficult as the dynamics of the pelvic floor remains\npoorly known. So far, only 2D dynamic observations of straining exercises at\nexcretion are available in the clinics and the understanding of\nthree-dimensional pelvic organs mechanical defects is not yet achievable. In\nthis context, we proposed a complete methodology for the 3D representation of\nthe non-reversible bladder deformations during exercises, directly combined\nwith synthesized 3D representation of the location of the highest strain areas\non the organ surface. Methods: Novel image segmentation and registration\napproaches have been combined with three geometrical configurations of\nup-to-date rapid dynamic multi-slices MRI acquisition for the reconstruction of\nreal-time dynamic bladder volumes. Results: For the first time, we proposed\nreal-time 3D deformation fields of the bladder under strain from in-bore forced\nbreathing exercises. The potential of our method was assessed on eight control\nsubjects undergoing forced breathing exercises. We obtained average volume\ndeviation of the reconstructed dynamic volume of bladders around 2.5\\% and high\nregistration accuracy with mean distance values of 0.4 $\\pm$ 0.3 mm and\nHausdorff distance values of 2.2 $\\pm$ 1.1 mm. Conclusions: Immediately\ntransferable to the clinics with rapid acquisitions, the proposed framework\nrepresents a real advance in the field of pelvic floor disorders as it\nprovides, for the first time, a proper 3D+t spatial tracking of bladder\nnon-reversible deformations. This work is intended to be extended to patients\nwith cavities filling and excretion to better characterize the degree of\nseverity of pelvic floor pathologies for diagnostic assistance or in\npreoperative surgical planning.\n","authors":["Augustin C. Ogier","Stanislas Rapacchi","Marc-Emmanuel Bellemare"],"pdf_url":"https://arxiv.org/pdf/2301.07385v1.pdf","comment":"17 pages, 7 figures, full article paper"},{"id":"http://arxiv.org/abs/2301.07382v1","updated":"2023-01-18T09:25:21Z","published":"2023-01-18T09:25:21Z","title":"ViT-AE++: Improving Vision Transformer Autoencoder for Self-supervised\n  Medical Image Representations","summary":"  Self-supervised learning has attracted increasing attention as it learns\ndata-driven representation from data without annotations. Vision\ntransformer-based autoencoder (ViT-AE) by He et al. (2021) is a recent\nself-supervised learning technique that employs a patch-masking strategy to\nlearn a meaningful latent space. In this paper, we focus on improving ViT-AE\n(nicknamed ViT-AE++) for a more effective representation of both 2D and 3D\nmedical images. We propose two new loss functions to enhance the representation\nduring the training stage. The first loss term aims to improve\nself-reconstruction by considering the structured dependencies and hence\nindirectly improving the representation. The second loss term leverages\ncontrastive loss to directly optimize the representation from two randomly\nmasked views. As an independent contribution, we extended ViT-AE++ to a 3D\nfashion for volumetric medical images. We extensively evaluate ViT-AE++ on both\nnatural images and medical images, demonstrating consistent improvement over\nvanilla ViT-AE and its superiority over other contrastive learning approaches.\n","authors":["Chinmay Prabhakar","Hongwei Bran Li","Jiancheng Yang","Suprosana Shit","Benedikt Wiestler","Bjoern Menze"],"pdf_url":"https://arxiv.org/pdf/2301.07382v1.pdf","comment":"under review. C. Prabhakar and H. B. Li contribute equally. Codes\n  will be available soon"},{"id":"http://arxiv.org/abs/2104.02230v6","updated":"2023-01-18T09:24:01Z","published":"2021-04-06T01:45:07Z","title":"Achieving Domain Generalization in Underwater Object Detection by Domain\n  Mixup and Contrastive Learning","summary":"  The performance of existing underwater object detection methods degrades\nseriously when facing domain shift caused by complicated underwater\nenvironments. Due to the limitation of the number of domains in the dataset,\ndeep detectors easily memorize a few seen domains, which leads to low\ngeneralization ability. There are two common ideas to improve the domain\ngeneralization performance. First, it can be inferred that the detector trained\non as many domains as possible is domain-invariant. Second, for the images with\nthe same semantic content in different domains, their hidden features should be\nequivalent. This paper further excavates these two ideas and proposes a domain\ngeneralization framework (named DMC) that learns how to generalize across\ndomains from Domain Mixup and Contrastive Learning. First, based on the\nformation of underwater images, an image in an underwater environment is the\nlinear transformation of another underwater environment. Thus, a style transfer\nmodel, which outputs a linear transformation matrix instead of the whole image,\nis proposed to transform images from one source domain to another, enriching\nthe domain diversity of the training data. Second, mixup operation interpolates\ndifferent domains on the feature level, sampling new domains on the domain\nmanifold. Third, contrastive loss is selectively applied to features from\ndifferent domains to force the model to learn domain invariant features but\nretain the discriminative capacity. With our method, detectors will be robust\nto domain shift. Also, a domain generalization benchmark S-UODAC2020 for\ndetection is set up to measure the performance of our method. Comprehensive\nexperiments on S-UODAC2020 and two object recognition benchmarks (PACS and\nVLCS) demonstrate that the proposed method is able to learn domain-invariant\nrepresentations, and outperforms other domain generalization methods.\n","authors":["Yang Chen","Pinhao Song","Hong Liu","Linhui Dai","Xiaochuan Zhang","Runwei Ding","Shengquan Li"],"pdf_url":"https://arxiv.org/pdf/2104.02230v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07901v2","updated":"2023-01-18T08:00:01Z","published":"2022-02-16T07:09:04Z","title":"Auxiliary Cross-Modal Representation Learning with Triplet Loss\n  Functions for Online Handwriting Recognition","summary":"  Cross-modal representation learning learns a shared embedding between two or\nmore modalities to improve performance in a given task compared to using only\none of the modalities. Cross-modal representation learning from different data\ntypes -- such as images and time-series data (e.g., audio or text data) --\nrequires a deep metric learning loss that minimizes the distance between the\nmodality embeddings. In this paper, we propose to use the triplet loss, which\nuses positive and negative identities to create sample pairs with different\nlabels, for cross-modal representation learning between image and time-series\nmodalities (CMR-IS). By adapting the triplet loss for cross-modal\nrepresentation learning, higher accuracy in the main (time-series\nclassification) task can be achieved by exploiting additional information of\nthe auxiliary (image classification) task. Our experiments on synthetic data\nand handwriting recognition data from sensor-enhanced pens show improved\nclassification accuracy, faster convergence, and better generalizability.\n","authors":["Felix Ott","David Rügamer","Lucas Heublein","Bernd Bischl","Christopher Mutschler"],"pdf_url":"https://arxiv.org/pdf/2202.07901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07354v1","updated":"2023-01-18T07:55:22Z","published":"2023-01-18T07:55:22Z","title":"MADAv2: Advanced Multi-Anchor Based Active Domain Adaptation\n  Segmentation","summary":"  Unsupervised domain adaption has been widely adopted in tasks with scarce\nannotated data. Unfortunately, mapping the target-domain distribution to the\nsource-domain unconditionally may distort the essential structural information\nof the target-domain data, leading to inferior performance. To address this\nissue, we firstly propose to introduce active sample selection to assist domain\nadaptation regarding the semantic segmentation task. By innovatively adopting\nmultiple anchors instead of a single centroid, both source and target domains\ncan be better characterized as multimodal distributions, in which way more\ncomplementary and informative samples are selected from the target domain. With\nonly a little workload to manually annotate these active samples, the\ndistortion of the target-domain distribution can be effectively alleviated,\nachieving a large performance gain. In addition, a powerful semi-supervised\ndomain adaptation strategy is proposed to alleviate the long-tail distribution\nproblem and further improve the segmentation performance. Extensive experiments\nare conducted on public datasets, and the results demonstrate that the proposed\napproach outperforms state-of-the-art methods by large margins and achieves\nsimilar performance to the fully-supervised upperbound, i.e., 71.4% mIoU on\nGTA5 and 71.8% mIoU on SYNTHIA. The effectiveness of each component is also\nverified by thorough ablation studies.\n","authors":["Munan Ning","Donghuan Lu","Yujia Xie","Dongdong Chen","Dong Wei","Yefeng Zheng","Yonghong Tian","Shuicheng Yan","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.07354v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2108.08012"},{"id":"http://arxiv.org/abs/2301.07340v1","updated":"2023-01-18T07:11:24Z","published":"2023-01-18T07:11:24Z","title":"Semi-Supervised Semantic Segmentation via Gentle Teaching Assistant","summary":"  Semi-Supervised Semantic Segmentation aims at training the segmentation model\nwith limited labeled data and a large amount of unlabeled data. To effectively\nleverage the unlabeled data, pseudo labeling, along with the teacher-student\nframework, is widely adopted in semi-supervised semantic segmentation. Though\nproved to be effective, this paradigm suffers from incorrect pseudo labels\nwhich inevitably exist and are taken as auxiliary training data. To alleviate\nthe negative impact of incorrect pseudo labels, we delve into the current\nSemi-Supervised Semantic Segmentation frameworks. We argue that the unlabeled\ndata with pseudo labels can facilitate the learning of representative features\nin the feature extractor, but it is unreliable to supervise the mask predictor.\nMotivated by this consideration, we propose a novel framework, Gentle Teaching\nAssistant (GTA-Seg) to disentangle the effects of pseudo labels on feature\nextractor and mask predictor of the student model. Specifically, in addition to\nthe original teacher-student framework, our method introduces a teaching\nassistant network which directly learns from pseudo labels generated by the\nteacher network. The gentle teaching assistant (GTA) is coined gentle since it\nonly transfers the beneficial feature representation knowledge in the feature\nextractor to the student model in an Exponential Moving Average (EMA) manner,\nprotecting the student model from the negative influences caused by unreliable\npseudo labels in the mask predictor. The student model is also supervised by\nreliable labeled data to train an accurate mask predictor, further facilitating\nfeature representation. Extensive experiment results on benchmark datasets\nvalidate that our method shows competitive performance against previous\nmethods. Code is available at https://github.com/Jin-Ying/GTA-Seg.\n","authors":["Ying Jin","Jiaqi Wang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2301.07340v1.pdf","comment":"NeurIPS2022 camera ready"},{"id":"http://arxiv.org/abs/2301.07336v1","updated":"2023-01-18T06:55:02Z","published":"2023-01-18T06:55:02Z","title":"Class Enhancement Losses with Pseudo Labels for Zero-shot Semantic\n  Segmentation","summary":"  Recent mask proposal models have significantly improved the performance of\nzero-shot semantic segmentation. However, the use of a `background' embedding\nduring training in these methods is problematic as the resulting model tends to\nover-learn and assign all unseen classes as the background class instead of\ntheir correct labels. Furthermore, they ignore the semantic relationship of\ntext embeddings, which arguably can be highly informative for zero-shot\nprediction as seen classes may have close relationship with unseen classes. To\nthis end, this paper proposes novel class enhancement losses to bypass the use\nof the background embbedding during training, and simultaneously exploit the\nsemantic relationship between text embeddings and mask proposals by ranking the\nsimilarity scores. To further capture the relationship between seen and unseen\nclasses, we propose an effective pseudo label generation pipeline using\npretrained vision-language model. Extensive experiments on several benchmark\ndatasets show that our method achieves overall the best performance for\nzero-shot semantic segmentation. Our method is flexible, and can also be\napplied to the challenging open-vocabulary semantic segmentation problem.\n","authors":["Son Duy Dao","Hengcan Shi","Dinh Phung","Jianfei Cai"],"pdf_url":"https://arxiv.org/pdf/2301.07336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07330v1","updated":"2023-01-18T06:37:24Z","published":"2023-01-18T06:37:24Z","title":"FPANet: Frequency-based Video Demoireing using Frame-level Post\n  Alignment","summary":"  Interference between overlapping gird patterns creates moire patterns,\ndegrading the visual quality of an image that captures a screen of a digital\ndisplay device by an ordinary digital camera. Removing such moire patterns is\nchallenging due to their complex patterns of diverse sizes and color\ndistortions. Existing approaches mainly focus on filtering out in the spatial\ndomain, failing to remove a large-scale moire pattern. In this paper, we\npropose a novel model called FPANet that learns filters in both frequency and\nspatial domains, improving the restoration quality by removing various sizes of\nmoire patterns. To further enhance, our model takes multiple consecutive\nframes, learning to extract frame-invariant content features and outputting\nbetter quality temporally consistent images. We demonstrate the effectiveness\nof our proposed method with a publicly available large-scale dataset, observing\nthat ours outperforms the state-of-the-art approaches, including ESDNet,\nVDmoire, MBCNN, WDNet, UNet, and DMCNN, in terms of the image and video quality\nmetrics, such as PSNR, SSIM, LPIPS, FVD, and FSIM.\n","authors":["Gyeongrok Oh","Heon Gu","Sangpil Kim","Jinkyu Kim"],"pdf_url":"https://arxiv.org/pdf/2301.07330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07329v1","updated":"2023-01-18T06:37:21Z","published":"2023-01-18T06:37:21Z","title":"Deep Dynamic Scene Deblurring from Optical Flow","summary":"  Deblurring can not only provide visually more pleasant pictures and make\nphotography more convenient, but also can improve the performance of objection\ndetection as well as tracking. However, removing dynamic scene blur from images\nis a non-trivial task as it is difficult to model the non-uniform blur\nmathematically. Several methods first use single or multiple images to estimate\noptical flow (which is treated as an approximation of blur kernels) and then\nadopt non-blind deblurring algorithms to reconstruct the sharp images. However,\nthese methods cannot be trained in an end-to-end manner and are usually\ncomputationally expensive. In this paper, we explore optical flow to remove\ndynamic scene blur by using the multi-scale spatially variant recurrent neural\nnetwork (RNN). We utilize FlowNets to estimate optical flow from two\nconsecutive images in different scales. The estimated optical flow provides the\nRNN weights in different scales so that the weights can better help RNNs to\nremove blur in the feature spaces. Finally, we develop a convolutional neural\nnetwork (CNN) to restore the sharp images from the deblurred features. Both\nquantitative and qualitative evaluations on the benchmark datasets demonstrate\nthat the proposed method performs favorably against state-of-the-art algorithms\nin terms of accuracy, speed, and model size.\n","authors":["Jiawei Zhang","Jinshan Pan","Daoye Wang","Shangchen Zhou","Xing Wei","Furong Zhao","Jianbo Liu","Jimmy Ren"],"pdf_url":"https://arxiv.org/pdf/2301.07329v1.pdf","comment":"accepted by tcsvt"},{"id":"http://arxiv.org/abs/2301.07322v1","updated":"2023-01-18T05:54:02Z","published":"2023-01-18T05:54:02Z","title":"HSTFormer: Hierarchical Spatial-Temporal Transformers for 3D Human Pose\n  Estimation","summary":"  Transformer-based approaches have been successfully proposed for 3D human\npose estimation (HPE) from 2D pose sequence and achieved state-of-the-art\n(SOTA) performance. However, current SOTAs have difficulties in modeling\nspatial-temporal correlations of joints at different levels simultaneously.\nThis is due to the poses' spatial-temporal complexity. Poses move at various\nspeeds temporarily with various joints and body-parts movement spatially.\nHence, a cookie-cutter transformer is non-adaptable and can hardly meet the\n\"in-the-wild\" requirement. To mitigate this issue, we propose Hierarchical\nSpatial-Temporal transFormers (HSTFormer) to capture multi-level joints'\nspatial-temporal correlations from local to global gradually for accurate 3D\nHPE. HSTFormer consists of four transformer encoders (TEs) and a fusion module.\nTo the best of our knowledge, HSTFormer is the first to study hierarchical TEs\nwith multi-level fusion. Extensive experiments on three datasets (i.e.,\nHuman3.6M, MPI-INF-3DHP, and HumanEva) demonstrate that HSTFormer achieves\ncompetitive and consistent performance on benchmarks with various scales and\ndifficulties. Specifically, it surpasses recent SOTAs on the challenging\nMPI-INF-3DHP dataset and small-scale HumanEva dataset, with a highly\ngeneralized systematic approach. The code is available at:\nhttps://github.com/qianxiaoye825/HSTFormer.\n","authors":["Xiaoye Qian","Youbao Tang","Ning Zhang","Mei Han","Jing Xiao","Ming-Chun Huang","Ruei-Sung Lin"],"pdf_url":"https://arxiv.org/pdf/2301.07322v1.pdf","comment":"The first two authors have equal contribution"},{"id":"http://arxiv.org/abs/2301.07320v1","updated":"2023-01-18T05:46:48Z","published":"2023-01-18T05:46:48Z","title":"Robust Knowledge Adaptation for Federated Unsupervised Person ReID","summary":"  Person Re-identification (ReID) has been extensively studied in recent years\ndue to the increasing demand in public security. However, collecting and\ndealing with sensitive personal data raises privacy concerns. Therefore,\nfederated learning has been explored for Person ReID, which aims to share\nminimal sensitive data between different parties (clients). However, existing\nfederated learning based person ReID methods generally rely on laborious and\ntime-consuming data annotations and it is difficult to guarantee cross-domain\nconsistency. Thus, in this work, a federated unsupervised cluster-contrastive\n(FedUCC) learning method is proposed for Person ReID. FedUCC introduces a\nthree-stage modelling strategy following a coarse-to-fine manner. In detail,\ngeneric knowledge, specialized knowledge and patch knowledge are discovered\nusing a deep neural network. This enables the sharing of mutual knowledge among\nclients while retaining local domain-specific knowledge based on the kinds of\nnetwork layers and their parameters. Comprehensive experiments on 8 public\nbenchmark datasets demonstrate the state-of-the-art performance of our proposed\nmethod.\n","authors":["Jianfeng Weng","Kun Hu","Tingting Yao","Jingya Wang","Zhiyong Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07316v1","updated":"2023-01-18T05:36:06Z","published":"2023-01-18T05:36:06Z","title":"Adaptively Integrated Knowledge Distillation and Prediction Uncertainty\n  for Continual Learning","summary":"  Current deep learning models often suffer from catastrophic forgetting of old\nknowledge when continually learning new knowledge. Existing strategies to\nalleviate this issue often fix the trade-off between keeping old knowledge\n(stability) and learning new knowledge (plasticity). However, the\nstability-plasticity trade-off during continual learning may need to be\ndynamically changed for better model performance. In this paper, we propose two\nnovel ways to adaptively balance model stability and plasticity. The first one\nis to adaptively integrate multiple levels of old knowledge and transfer it to\neach block level in the new model. The second one uses prediction uncertainty\nof old knowledge to naturally tune the importance of learning new knowledge\nduring model training. To our best knowledge, this is the first time to connect\nmodel prediction uncertainty and knowledge distillation for continual learning.\nIn addition, this paper applies a modified CutMix particularly to augment the\ndata for old knowledge, further alleviating the catastrophic forgetting issue.\nExtensive evaluations on the CIFAR100 and the ImageNet datasets confirmed the\neffectiveness of the proposed method for continual learning.\n","authors":["Kanghao Chen","Sijia Liu","Ruixuan Wang","Wei-Shi Zheng"],"pdf_url":"https://arxiv.org/pdf/2301.07316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07315v1","updated":"2023-01-18T05:34:57Z","published":"2023-01-18T05:34:57Z","title":"Face Recognition in the age of CLIP & Billion image datasets","summary":"  CLIP (Contrastive Language-Image Pre-training) models developed by OpenAI\nhave achieved outstanding results on various image recognition and retrieval\ntasks, displaying strong zero-shot performance. This means that they are able\nto perform effectively on tasks for which they have not been explicitly\ntrained. Inspired by the success of OpenAI CLIP, a new publicly available\ndataset called LAION-5B was collected which resulted in the development of open\nViT-H/14, ViT-G/14 models that outperform the OpenAI L/14 model. The LAION-5B\ndataset also released an approximate nearest neighbor index, with a web\ninterface for search & subset creation.\n  In this paper, we evaluate the performance of various CLIP models as\nzero-shot face recognizers. Our findings show that CLIP models perform well on\nface recognition tasks, but increasing the size of the CLIP model does not\nnecessarily lead to improved accuracy. Additionally, we investigate the\nrobustness of CLIP models against data poisoning attacks by testing their\nperformance on poisoned data. Through this analysis, we aim to understand the\npotential consequences and misuse of search engines built using CLIP models,\nwhich could potentially function as unintentional face recognition engines.\n","authors":["Aaditya Bhat","Shrey Jain"],"pdf_url":"https://arxiv.org/pdf/2301.07315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07306v1","updated":"2023-01-18T04:54:58Z","published":"2023-01-18T04:54:58Z","title":"Improve Noise Tolerance of Robust Loss via Noise-Awareness","summary":"  Robust loss minimization is an important strategy for handling robust\nlearning issue on noisy labels. Current robust losses, however, inevitably\ninvolve hyperparameters to be tuned for different datasets with noisy labels,\nmanually or heuristically through cross validation, which makes them fairly\nhard to be generally applied in practice. Existing robust loss methods usually\nassume that all training samples share common hyperparameters, which are\nindependent of instances. This limits the ability of these methods on\ndistinguishing individual noise properties of different samples, making them\nhardly adapt to different noise structures. To address above issues, we propose\nto assemble robust loss with instance-dependent hyperparameters to improve\ntheir noise-tolerance with theoretical guarantee. To achieve setting such\ninstance-dependent hyperparameters for robust loss, we propose a meta-learning\nmethod capable of adaptively learning a hyperparameter prediction function,\ncalled Noise-Aware-Robust-Loss-Adjuster (NARL-Adjuster). Specifically, through\nmutual amelioration between hyperparameter prediction function and classifier\nparameters in our method, both of them can be simultaneously finely ameliorated\nand coordinated to attain solutions with good generalization capability. Four\nkinds of SOTA robust losses are attempted to be integrated with our algorithm,\nand experiments substantiate the general availability and effectiveness of the\nproposed method in both its noise tolerance and generalization performance.\nMeanwhile, the explicit parameterized structure makes the meta-learned\nprediction function capable of being readily transferrable and plug-and-play to\nunseen datasets with noisy labels. Specifically, we transfer our meta-learned\nNARL-Adjuster to unseen tasks, including several real noisy datasets, and\nachieve better performance compared with conventional hyperparameter tuning\nstrategy.\n","authors":["Kehui Ding","Jun Shu","Deyu Meng","Zongben Xu"],"pdf_url":"https://arxiv.org/pdf/2301.07306v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2002.06482"},{"id":"http://arxiv.org/abs/2301.07301v1","updated":"2023-01-18T04:35:49Z","published":"2023-01-18T04:35:49Z","title":"PTA-Det: Point Transformer Associating Point cloud and Image for 3D\n  Object Detection","summary":"  In autonomous driving, 3D object detection based on multi-modal data has\nbecome an indispensable approach when facing complex environments around the\nvehicle. During multi-modal detection, LiDAR and camera are simultaneously\napplied for capturing and modeling. However, due to the intrinsic discrepancies\nbetween the LiDAR point and camera image, the fusion of the data for object\ndetection encounters a series of problems. Most multi-modal detection methods\nperform even worse than LiDAR-only methods. In this investigation, we propose a\nmethod named PTA-Det to improve the performance of multi-modal detection.\nAccompanied by PTA-Det, a Pseudo Point Cloud Generation Network is proposed,\nwhich can convert image information including texture and semantic features by\npseudo points. Thereafter, through a transformer-based Point Fusion Transition\n(PFT) module, the features of LiDAR points and pseudo points from image can be\ndeeply fused under a unified point-based representation. The combination of\nthese modules can conquer the major obstacle in feature fusion across\nmodalities and realizes a complementary and discriminative representation for\nproposal generation. Extensive experiments on the KITTI dataset show the\nPTA-Det achieves a competitive result and support its effectiveness.\n","authors":["Rui Wan","Tianyun Zhao","Wei Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.07301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.14563v3","updated":"2023-01-18T04:17:47Z","published":"2020-06-25T17:06:47Z","title":"Dynamically Mitigating Data Discrepancy with Balanced Focal Loss for\n  Replay Attack Detection","summary":"  It becomes urgent to design effective anti-spoofing algorithms for vulnerable\nautomatic speaker verification systems due to the advancement of high-quality\nplayback devices. Current studies mainly treat anti-spoofing as a binary\nclassification problem between bonafide and spoofed utterances, while lack of\nindistinguishable samples makes it difficult to train a robust spoofing\ndetector. In this paper, we argue that for anti-spoofing, it needs more\nattention for indistinguishable samples over easily-classified ones in the\nmodeling process, to make correct discrimination a top priority. Therefore, to\nmitigate the data discrepancy between training and inference, we propose D3M,\nto leverage a balanced focal loss function as the training objective to\ndynamically scale the loss based on the traits of the sample itself. Besides,\nin the experiments, we select three kinds of features that contain both\nmagnitude-based and phase-based information to form complementary and\ninformative features. Experimental results on the ASVspoof2019 dataset\ndemonstrate the superiority of the proposed methods by comparison between our\nsystems and top-performing ones. Systems trained with the balanced focal loss\nperform significantly better than conventional cross-entropy loss. With\ncomplementary features, our fusion system with only three kinds of features\noutperforms other systems containing five or more complex single models by\n22.5% for min-tDCF and 7% for EER, achieving a min-tDCF and an EER of 0.0124\nand 0.55% respectively. Furthermore, we present and discuss the evaluation\nresults on real replay data apart from the simulated ASVspoof2019 data,\nindicating that research for anti-spoofing still has a long way to go. Source\ncode, analysis data, and other details are publicly available at\nhttps://github.com/asvspoof/D3M.\n","authors":["Yongqiang Dou","Haocheng Yang","Maolin Yang","Yanyan Xu","Dengfeng Ke"],"pdf_url":"https://arxiv.org/pdf/2006.14563v3.pdf","comment":"The 25th International Conference on Pattern Recognition (ICPR2020)"},{"id":"http://arxiv.org/abs/2301.07294v1","updated":"2023-01-18T03:56:17Z","published":"2023-01-18T03:56:17Z","title":"Enhancing Self-Training Methods","summary":"  Semi-supervised learning approaches train on small sets of labeled data along\nwith large sets of unlabeled data. Self-training is a semi-supervised\nteacher-student approach that often suffers from the problem of \"confirmation\nbias\" that occurs when the student model repeatedly overfits to incorrect\npseudo-labels given by the teacher model for the unlabeled data. This bias\nimpedes improvements in pseudo-label accuracy across self-training iterations,\nleading to unwanted saturation in model performance after just a few\niterations. In this work, we describe multiple enhancements to improve the\nself-training pipeline to mitigate the effect of confirmation bias. We evaluate\nour enhancements over multiple datasets showing performance gains over existing\nself-training design choices. Finally, we also study the extendability of our\nenhanced approach to Open Set unlabeled data (containing classes not seen in\nlabeled data).\n","authors":["Aswathnarayan Radhakrishnan","Jim Davis","Zachary Rabin","Benjamin Lewis","Matthew Scherreik","Roman Ilin"],"pdf_url":"https://arxiv.org/pdf/2301.07294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06080v2","updated":"2023-01-18T03:44:49Z","published":"2022-12-14T16:53:26Z","title":"Comprehensive Literature Survey on Deep Learning used in Image\n  Memorability Prediction and Modification","summary":"  As humans, we can remember certain visuals in great detail, and sometimes\neven after viewing them once. What is even more interesting is that humans tend\nto remember and forget the same things, suggesting that there might be some\ngeneral internal characteristics of an image to encode and discard similar\ntypes of information. Research suggests that some pictures tend to be memorized\nmore than others. The ability of an image to be remembered by different viewers\nis one of its intrinsic properties. In visualization and photography, creating\nmemorable images is a difficult task. Hence, to solve the problem, various\ntechniques predict visual memorability and manipulate images' memorability. We\npresent a comprehensive literature survey to assess the deep learning\ntechniques used to predict and modify memorability. In particular, we analyze\nthe use of Convolutional Neural Networks, Recurrent Neural Networks, and\nGenerative Adversarial Networks for image memorability prediction and\nmodification.\n","authors":["Ananya Sadana","Nikita Thakur","Nikita Poria","Astika Anand","Seeja K. R"],"pdf_url":"https://arxiv.org/pdf/2301.06080v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07286v1","updated":"2023-01-18T03:22:47Z","published":"2023-01-18T03:22:47Z","title":"Reslicing Ultrasound Images for Data Augmentation and Vessel\n  Reconstruction","summary":"  Robot-guided catheter insertion has the potential to deliver urgent medical\ncare in situations where medical personnel are unavailable. However, this\ntechnique requires accurate and reliable segmentation of anatomical landmarks\nin the body. For the ultrasound imaging modality, obtaining large amounts of\ntraining data for a segmentation model is time-consuming and expensive. This\npaper introduces RESUS (RESlicing of UltraSound Images), a weak supervision\ndata augmentation technique for ultrasound images based on slicing\nreconstructed 3D volumes from tracked 2D images. This technique allows us to\ngenerate views which cannot be easily obtained in vivo due to physical\nconstraints of ultrasound imaging, and use these augmented ultrasound images to\ntrain a semantic segmentation model. We demonstrate that RESUS achieves\nstatistically significant improvement over training with non-augmented images\nand highlight qualitative improvements through vessel reconstruction.\n","authors":["Cecilia Morales","Jason Yao","Tejas Rane","Robert Edman","Howie Choset","Artur Dubrawski"],"pdf_url":"https://arxiv.org/pdf/2301.07286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07283v1","updated":"2023-01-18T03:14:14Z","published":"2023-01-18T03:14:14Z","title":"Contrastive Learning for Self-Supervised Pre-Training of Point Cloud\n  Segmentation Networks With Image Data","summary":"  Reducing the quantity of annotations required for supervised training is\nvital when labels are scarce and costly. This reduction is particularly\nimportant for semantic segmentation tasks involving 3D datasets, which are\noften significantly smaller and more challenging to annotate than their\nimage-based counterparts. Self-supervised pre-training on unlabelled data is\none way to reduce the amount of manual annotations needed. Previous work has\nfocused on pre-training with point clouds exclusively. While useful, this\napproach often requires two or more registered views. In the present work, we\ncombine image and point cloud modalities by first learning self-supervised\nimage features and then using these features to train a 3D model. By\nincorporating image data, which is often included in many 3D datasets, our\npre-training method only requires a single scan of a scene and can be applied\nto cases where localization information is unavailable. We demonstrate that our\npre-training approach, despite using single scans, achieves comparable\nperformance to other multi-scan, point cloud-only methods.\n","authors":["Andrej Janda","Brandon Wagstaff","Edwin G. Ng","Jonathan Kelly"],"pdf_url":"https://arxiv.org/pdf/2301.07283v1.pdf","comment":"Submitted to the IEEE Conference on Computer and Robot Vision\n  (CRV'23), Montreal, Canada, June 6-8, 2023. arXiv admin note: text overlap\n  with arXiv:2211.11801"},{"id":"http://arxiv.org/abs/2301.07279v1","updated":"2023-01-18T02:58:39Z","published":"2023-01-18T02:58:39Z","title":"SensorX2car: Sensors-to-car calibration for autonomous driving in road\n  scenarios","summary":"  The performance of sensors in the autonomous driving system is fundamentally\nlimited by the quality of sensor calibration. Sensors must be well-located with\nrespect to the car-body frame before they can provide meaningful localization\nand environmental perception. However, while many online methods are proposed\nto calibrate the extrinsic parameters between sensors, few studies focus on the\ncalibration between sensor and vehicle coordinate system. To this end, we\npresent SensorX2car, a calibration toolbox for the online calibration of\nsensor-to-car coordinate systems in road scenes. It contains four commonly used\nsensors: IMU (Inertial Measurement Unit), GNSS (Global Navigation Satellite\nSystem), LiDAR (Light Detection and Ranging), Camera, and millimeter-wave\nRadar. We design a method for each sensor respectively and mainly calibrate its\nrotation to the car-body. Real-world and simulated experiments demonstrate the\naccuracy and generalization capabilities of the proposed method. Meanwhile, the\nrelated codes have been open-sourced to benefit the community. To the best of\nour knowledge, SensorX2car is the first open-source sensor-to-car calibration\ntoolbox. The code is available at https://github.com/OpenCalib/SensorX2car.\n","authors":["Guohang Yan","Zhaotong Luo","Zhuochun Liu","Yikang Li"],"pdf_url":"https://arxiv.org/pdf/2301.07279v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.06267v2","updated":"2023-01-18T02:13:43Z","published":"2023-01-16T05:40:42Z","title":"Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with\n  Multimodal Models","summary":"  The ability to quickly learn a new task with minimal instruction - known as\nfew-shot learning - is a central aspect of intelligent agents. Classical\nfew-shot benchmarks make use of few-shot samples from a single modality, but\nsuch samples may not be sufficient to characterize an entire concept class. In\ncontrast, humans use cross-modal information to learn new concepts efficiently.\nIn this work, we demonstrate that one can indeed build a better ${\\bf visual}$\ndog classifier by ${\\bf read}$ing about dogs and ${\\bf listen}$ing to them\nbark. To do so, we exploit the fact that recent multimodal foundation models\nsuch as CLIP are inherently cross-modal, mapping different modalities to the\nsame representation space. Specifically, we propose a simple cross-modal\nadaptation approach that learns from few-shot examples spanning different\nmodalities. By repurposing class names as additional one-shot training samples,\nwe achieve SOTA results with an embarrassingly simple linear classifier for\nvision-language adaptation. Furthermore, we show that our approach can benefit\nexisting methods such as prefix tuning, adapters, and classifier ensembling.\nFinally, to explore other modalities beyond vision and language, we construct\nthe first (to our knowledge) audiovisual few-shot benchmark and use cross-modal\ntraining to improve the performance of both image and audio classification.\n","authors":["Zhiqiu Lin","Samuel Yu","Zhiyi Kuang","Deepak Pathak","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2301.06267v2.pdf","comment":"Project website: https://linzhiqiu.github.io/papers/cross_modal/"},{"id":"http://arxiv.org/abs/2301.07266v1","updated":"2023-01-18T02:13:43Z","published":"2023-01-18T02:13:43Z","title":"ACQ: Improving Generative Data-free Quantization Via Attention\n  Correction","summary":"  Data-free quantization aims to achieve model quantization without accessing\nany authentic sample. It is significant in an application-oriented context\ninvolving data privacy. Converting noise vectors into synthetic samples through\na generator is a popular data-free quantization method, which is called\ngenerative data-free quantization. However, there is a difference in attention\nbetween synthetic samples and authentic samples. This is always ignored and\nrestricts the quantization performance. First, since synthetic samples of the\nsame class are prone to have homogenous attention, the quantized network can\nonly learn limited modes of attention. Second, synthetic samples in eval mode\nand training mode exhibit different attention. Hence, the batch-normalization\nstatistics matching tends to be inaccurate. ACQ is proposed in this paper to\nfix the attention of synthetic samples. An attention center position-condition\ngenerator is established regarding the homogenization of intra-class attention.\nRestricted by the attention center matching loss, the attention center position\nis treated as the generator's condition input to guide synthetic samples in\nobtaining diverse attention. Moreover, we design adversarial loss of paired\nsynthetic samples under the same condition to prevent the generator from paying\novermuch attention to the condition, which may result in mode collapse. To\nimprove the attention similarity of synthetic samples in different network\nmodes, we introduce a consistency penalty to guarantee accurate BN statistics\nmatching. The experimental results demonstrate that ACQ effectively improves\nthe attention problems of synthetic samples. Under various training settings,\nACQ achieves the best quantization performance. For the 4-bit quantization of\nResnet18 and Resnet50, ACQ reaches 67.55% and 72.23% accuracy, respectively.\n","authors":["Jixing Li","Xiaozhou Guo","Benzhe Dai","Guoliang Gong","Min Jin","Gang Chen","Wenyu Mao","Huaxiang Lu"],"pdf_url":"https://arxiv.org/pdf/2301.07266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07247v1","updated":"2023-01-18T01:19:36Z","published":"2023-01-18T01:19:36Z","title":"Tailor: Altering Skip Connections for Resource-Efficient Inference","summary":"  Deep neural networks use skip connections to improve training convergence.\nHowever, these skip connections are costly in hardware, requiring extra buffers\nand increasing on- and off-chip memory utilization and bandwidth requirements.\nIn this paper, we show that skip connections can be optimized for hardware when\ntackled with a hardware-software codesign approach. We argue that while a\nnetwork's skip connections are needed for the network to learn, they can later\nbe removed or shortened to provide a more hardware efficient implementation\nwith minimal to no accuracy loss. We introduce Tailor, a codesign tool whose\nhardware-aware training algorithm gradually removes or shortens a fully trained\nnetwork's skip connections to lower their hardware cost. The optimized hardware\ndesigns improve resource utilization by up to 34% for BRAMs, 13% for FFs, and\n16% for LUTs.\n","authors":["Olivia Weng","Gabriel Marcano","Vladimir Loncar","Alireza Khodamoradi","Nojan Sheybani","Farinaz Koushanfar","Kristof Denolf","Javier Mauricio Duarte","Ryan Kastner"],"pdf_url":"https://arxiv.org/pdf/2301.07247v1.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2301.07236v1","updated":"2023-01-18T00:22:49Z","published":"2023-01-18T00:22:49Z","title":"Effective End-to-End Vision Language Pretraining with Semantic Visual\n  Loss","summary":"  Current vision language pretraining models are dominated by methods using\nregion visual features extracted from object detectors. Given their good\nperformance, the extract-then-process pipeline significantly restricts the\ninference speed and therefore limits their real-world use cases. However,\ntraining vision language models from raw image pixels is difficult, as the raw\nimage pixels give much less prior knowledge than region features. In this\npaper, we systematically study how to leverage auxiliary visual pretraining\ntasks to help training end-to-end vision language models. We introduce three\ntypes of visual losses that enable much faster convergence and better\nfinetuning accuracy. Compared with region feature models, our end-to-end models\ncould achieve similar or better performance on downstream tasks and run more\nthan 10 times faster during inference. Compared with other end-to-end models,\nour proposed method could achieve similar or better performance when pretrained\nfor only 10% of the pretraining GPU hours.\n","authors":["Xiaofeng Yang","Fayao Liu","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2301.07236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07234v1","updated":"2023-01-18T00:16:30Z","published":"2023-01-18T00:16:30Z","title":"Deep Unsupervised Phase-based 3D Incompressible Motion Estimation in\n  Tagged-MRI","summary":"  Tagged magnetic resonance imaging (MRI) has been used for decades to observe\nand quantify the detailed motion of deforming tissue. However, this technique\nfaces several challenges such as tag fading, large motion, long computation\ntimes, and difficulties in obtaining diffeomorphic incompressible flow fields.\nTo address these issues, this paper presents a novel unsupervised phase-based\n3D motion estimation technique for tagged MRI. We introduce two key\ninnovations. First, we apply a sinusoidal transformation to the harmonic phase\ninput, which enables end-to-end training and avoids the need for phase\ninterpolation. Second, we propose a Jacobian determinant-based learning\nobjective to encourage incompressible flow fields for deforming biological\ntissues. Our method efficiently estimates 3D motion fields that are accurate,\ndense, and approximately diffeomorphic and incompressible. The efficacy of the\nmethod is assessed using human tongue motion during speech, and includes both\nhealthy controls and patients that have undergone glossectomy. We show that the\nmethod outperforms existing approaches, and also exhibits improvements in\nspeed, robustness to tag fading, and large tongue motion.\n","authors":["Zhangxing Bian","Fangxu Xing","Jinglun Yu","Muhan Shao","Yihao Liu","Aaron Carass","Jonghye Woo","Jerry L. Prince"],"pdf_url":"https://arxiv.org/pdf/2301.07234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10682v2","updated":"2023-01-18T00:06:28Z","published":"2022-12-20T22:55:46Z","title":"Privacy-Protecting Behaviours of Risk Detection in People with Dementia\n  using Videos","summary":"  People living with dementia often exhibit behavioural and psychological\nsymptoms of dementia that can put their and others' safety at risk. Existing\nvideo surveillance systems in long-term care facilities can be used to monitor\nsuch behaviours of risk to alert the staff to prevent potential injuries or\ndeath in some cases. However, these behaviours of risk events are heterogeneous\nand infrequent in comparison to normal events. Moreover, analyzing raw videos\ncan also raise privacy concerns. In this paper, we present two novel\nprivacy-protecting video-based anomaly detection approaches to detect\nbehaviours of risks in people with dementia. We either extracted body pose\ninformation as skeletons or used semantic segmentation masks to replace\nmultiple humans in the scene with their semantic boundaries. Our work differs\nfrom most existing approaches for video anomaly detection that focus on\nappearance-based features, which can put the privacy of a person at risk and is\nalso susceptible to pixel-based noise, including illumination and viewing\ndirection. We used anonymized videos of normal activities to train customized\nspatio-temporal convolutional autoencoders and identify behaviours of risk as\nanomalies. We showed our results on a real-world study conducted in a dementia\ncare unit with patients with dementia, containing approximately 21 hours of\nnormal activities data for training and 9 hours of data containing normal and\nbehaviours of risk events for testing. We compared our approaches with the\noriginal RGB videos and obtained a similar area under the receiver operating\ncharacteristic curve performance of 0.807 for the skeleton-based approach and\n0.823 for the segmentation mask-based approach.\n","authors":["Pratik K. Mishra","Andrea Iaboni","Bing Ye","Kristine Newman","Alex Mihailidis","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2212.10682v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.12490v2","updated":"2023-01-18T23:40:47Z","published":"2022-04-26T17:59:51Z","title":"From One Hand to Multiple Hands: Imitation Learning for Dexterous\n  Manipulation from Single-Camera Teleoperation","summary":"  We propose to perform imitation learning for dexterous manipulation with\nmulti-finger robot hand from human demonstrations, and transfer the policy to\nthe real robot hand. We introduce a novel single-camera teleoperation system to\ncollect the 3D demonstrations efficiently with only an iPad and a computer. One\nkey contribution of our system is that we construct a customized robot hand for\neach user in the physical simulator, which is a manipulator resembling the same\nkinematics structure and shape of the operator's hand. This provides an\nintuitive interface and avoid unstable human-robot hand retargeting for data\ncollection, leading to large-scale and high quality data. Once the data is\ncollected, the customized robot hand trajectories can be converted to different\nspecified robot hands (models that are manufactured) to generate training\ndemonstrations. With imitation learning using our data, we show large\nimprovement over baselines with multiple complex manipulation tasks.\nImportantly, we show our learned policy is significantly more robust when\ntransferring to the real robot. More videos can be found in the\nhttps://yzqin.github.io/dex-teleop-imitation .\n","authors":["Yuzhe Qin","Hao Su","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2204.12490v2.pdf","comment":"https://yzqin.github.io/dex-teleop-imitation/"},{"id":"http://arxiv.org/abs/2301.07807v1","updated":"2023-01-18T22:38:03Z","published":"2023-01-18T22:38:03Z","title":"Measuring uncertainty in human visual segmentation","summary":"  Segmenting visual stimuli into distinct groups of features and visual objects\nis central to visual function. Classical psychophysical methods have helped\nuncover many rules of human perceptual segmentation, and recent progress in\nmachine learning has produced successful algorithms. Yet, the computational\nlogic of human segmentation remains unclear, partially because we lack\nwell-controlled paradigms to measure perceptual segmentation maps and compare\nmodels quantitatively. Here we propose a new, integrated approach: given an\nimage, we measure multiple pixel-based same-different judgments and perform\nmodel--based reconstruction of the underlying segmentation map. The\nreconstruction is robust to several experimental manipulations and captures the\nvariability of individual participants. We demonstrate the validity of the\napproach on human segmentation of natural images and composite textures. We\nshow that image uncertainty affects measured human variability, and it\ninfluences how participants weigh different visual features. Because any\nputative segmentation algorithm can be inserted to perform the reconstruction,\nour paradigm affords quantitative tests of theories of perception as well as\nnew benchmarks for segmentation algorithms.\n","authors":["Jonathan Vacher","Claire Launay","Pascal Mamassian","Ruben Coen-Cagli"],"pdf_url":"https://arxiv.org/pdf/2301.07807v1.pdf","comment":"22 pages, 8 figures, 4 appendix, 4 figures in appendix"},{"id":"http://arxiv.org/abs/2301.07805v1","updated":"2023-01-18T22:27:08Z","published":"2023-01-18T22:27:08Z","title":"Multi-target multi-camera vehicle tracking using transformer-based\n  camera link model and spatial-temporal information","summary":"  Multi-target multi-camera tracking (MTMCT) of vehicles, i.e. tracking\nvehicles across multiple cameras, is a crucial application for the development\nof smart city and intelligent traffic system. The main challenges of MTMCT of\nvehicles include the intra-class variability of the same vehicle and\ninter-class similarity between different vehicles and how to associate the same\nvehicle accurately across different cameras under large search space. Previous\nmethods for MTMCT usually use hierarchical clustering of trajectories to\nconduct cross camera association. However, the search space can be large and\ndoes not take spatial and temporal information into consideration. In this\npaper, we proposed a transformer-based camera link model with spatial and\ntemporal filtering to conduct cross camera tracking. Achieving 73.68% IDF1 on\nthe Nvidia Cityflow V2 dataset test set, showing the effectiveness of our\ncamera link model on multi-target multi-camera tracking.\n","authors":["Hsiang-Wei Huang","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2301.07805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07799v1","updated":"2023-01-18T21:58:54Z","published":"2023-01-18T21:58:54Z","title":"A Domain-Agnostic Approach for Characterization of Lifelong Learning\n  Systems","summary":"  Despite the advancement of machine learning techniques in recent years,\nstate-of-the-art systems lack robustness to \"real world\" events, where the\ninput distributions and tasks encountered by the deployed systems will not be\nlimited to the original training context, and systems will instead need to\nadapt to novel distributions and tasks while deployed. This critical gap may be\naddressed through the development of \"Lifelong Learning\" systems that are\ncapable of 1) Continuous Learning, 2) Transfer and Adaptation, and 3)\nScalability. Unfortunately, efforts to improve these capabilities are typically\ntreated as distinct areas of research that are assessed independently, without\nregard to the impact of each separate capability on other aspects of the\nsystem. We instead propose a holistic approach, using a suite of metrics and an\nevaluation framework to assess Lifelong Learning in a principled way that is\nagnostic to specific domains or system techniques. Through five case studies,\nwe show that this suite of metrics can inform the development of varied and\ncomplex Lifelong Learning systems. We highlight how the proposed suite of\nmetrics quantifies performance trade-offs present during Lifelong Learning\nsystem development - both the widely discussed Stability-Plasticity dilemma and\nthe newly proposed relationship between Sample Efficient and Robust Learning.\nFurther, we make recommendations for the formulation and use of metrics to\nguide the continuing development of Lifelong Learning systems and assess their\nprogress in the future.\n","authors":["Megan M. Baker","Alexander New","Mario Aguilar-Simon","Ziad Al-Halah","Sébastien M. R. Arnold","Ese Ben-Iwhiwhu","Andrew P. Brna","Ethan Brooks","Ryan C. Brown","Zachary Daniels","Anurag Daram","Fabien Delattre","Ryan Dellana","Eric Eaton","Haotian Fu","Kristen Grauman","Jesse Hostetler","Shariq Iqbal","Cassandra Kent","Nicholas Ketz","Soheil Kolouri","George Konidaris","Dhireesha Kudithipudi","Erik Learned-Miller","Seungwon Lee","Michael L. Littman","Sandeep Madireddy","Jorge A. Mendez","Eric Q. Nguyen","Christine D. Piatko","Praveen K. Pilly","Aswin Raghavan","Abrar Rahman","Santhosh Kumar Ramakrishnan","Neale Ratzlaff","Andrea Soltoggio","Peter Stone","Indranil Sur","Zhipeng Tang","Saket Tiwari","Kyle Vedder","Felix Wang","Zifan Xu","Angel Yanguas-Gil","Harel Yedidsion","Shangqun Yu","Gautam K. Vallabha"],"pdf_url":"https://arxiv.org/pdf/2301.07799v1.pdf","comment":"To appear in Neural Networks"},{"id":"http://arxiv.org/abs/2206.13632v2","updated":"2023-01-18T20:42:54Z","published":"2022-06-27T21:09:55Z","title":"Omni-Seg: A Scale-aware Dynamic Network for Renal Pathological Image\n  Segmentation","summary":"  Comprehensive semantic segmentation on renal pathological images is\nchallenging due to the heterogeneous scales of the objects. For example, on a\nwhole slide image (WSI), the cross-sectional areas of glomeruli can be 64 times\nlarger than that of the peritubular capillaries, making it impractical to\nsegment both objects on the same patch, at the same scale. To handle this\nscaling issue, prior studies have typically trained multiple segmentation\nnetworks in order to match the optimal pixel resolution of heterogeneous tissue\ntypes. This multi-network solution is resource-intensive and fails to model the\nspatial relationship between tissue types. In this paper, we propose the\nOmni-Seg+ network, a scale-aware dynamic neural network that achieves\nmulti-object (six tissue types) and multi-scale (5X to 40X scale) pathological\nimage segmentation via a single neural network. The contribution of this paper\nis three-fold: (1) a novel scale-aware controller is proposed to generalize the\ndynamic neural network from single-scale to multi-scale; (2) semi-supervised\nconsistency regularization of pseudo-labels is introduced to model the\ninter-scale correlation of unannotated tissue types into a single end-to-end\nlearning paradigm; and (3) superior scale-aware generalization is evidenced by\ndirectly applying a model trained on human kidney images to mouse kidney\nimages, without retraining. By learning from ~150,000 human pathological image\npatches from six tissue types at three different resolutions, our approach\nachieved superior segmentation performance according to human visual assessment\nand evaluation of image-omics (i.e., spatial transcriptomics). The official\nimplementation is available at https://github.com/ddrrnn123/Omni-Seg.\n","authors":["Ruining Deng","Quan Liu","Can Cui","Tianyuan Yao","Jun Long","Zuhayr Asad","R. Michael Womick","Zheyu Zhu","Agnes B. Fogo","Shilin Zhao","Haichun Yang","Yuankai Huo"],"pdf_url":"https://arxiv.org/pdf/2206.13632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15059v2","updated":"2023-01-18T20:28:42Z","published":"2022-10-26T22:02:45Z","title":"Automated Reconstruction of 3D Open Surfaces from Sparse Point Clouds","summary":"  Real-world 3D data may contain intricate details defined by salient surface\ngaps. Automated reconstruction of these open surfaces (e.g., non-watertight\nmeshes) is a challenging problem for environment synthesis in mixed reality\napplications. Current learning-based implicit techniques can achieve high\nfidelity on closed-surface reconstruction. However, their dependence on the\ndistinction between the inside and outside of a surface makes them incapable of\nreconstructing open surfaces. Recently, a new class of implicit functions have\nshown promise in reconstructing open surfaces by regressing an unsigned\ndistance field. Yet, these methods rely on a discretized representation of the\nraw data, which loses important surface details and can lead to outliers in the\nreconstruction. We propose IPVNet, a learning-based implicit model that\npredicts the unsigned distance between a surface and a query point in 3D space\nby leveraging both raw point cloud data and its discretized voxel counterpart.\nExperiments on synthetic and real-world public datasets demonstrates that\nIPVNet outperforms the state of the art while producing far fewer outliers in\nthe reconstruction.\n","authors":["Mohammad Samiul Arshad","William J. Beksi"],"pdf_url":"https://arxiv.org/pdf/2210.15059v2.pdf","comment":"To be presented at the 2022 IEEE International Symposium on Mixed and\n  Augmented Reality (ISMAR) Workshop on Photorealistic Image and Environment\n  Synthesis for Mixed Reality (PIES-MR)"},{"id":"http://arxiv.org/abs/2301.05804v2","updated":"2023-01-18T19:48:16Z","published":"2023-01-14T01:47:09Z","title":"Salient Sign Detection In Safe Autonomous Driving: AI Which Reasons Over\n  Full Visual Context","summary":"  Detecting road traffic signs and accurately determining how they can affect\nthe driver's future actions is a critical task for safe autonomous driving\nsystems. However, various traffic signs in a driving scene have an unequal\nimpact on the driver's decisions, making detecting the salient traffic signs a\nmore important task. Our research addresses this issue, constructing a traffic\nsign detection model which emphasizes performance on salient signs, or signs\nthat influence the decisions of a driver. We define a traffic sign salience\nproperty and use it to construct the LAVA Salient Signs Dataset, the first\ntraffic sign dataset that includes an annotated salience property. Next, we use\na custom salience loss function, Salience-Sensitive Focal Loss, to train a\nDeformable DETR object detection model in order to emphasize stronger\nperformance on salient signs. Results show that a model trained with\nSalience-Sensitive Focal Loss outperforms a model trained without, with regards\nto recall of both salient signs and all signs combined. Further, the\nperformance margin on salient signs compared to all signs is largest for the\nmodel trained with Salience-Sensitive Focal Loss.\n","authors":["Ross Greer","Akshay Gopalkrishnan","Nachiket Deo","Akshay Rangesh","Mohan Trivedi"],"pdf_url":"https://arxiv.org/pdf/2301.05804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05805v2","updated":"2023-01-18T19:47:34Z","published":"2023-01-14T01:53:48Z","title":"Safe Control Transitions: Machine Vision Based Observable Readiness\n  Index and Data-Driven Takeover Time Prediction","summary":"  To make safe transitions from autonomous to manual control, a vehicle must\nhave a representation of the awareness of driver state; two metrics which\nquantify this state are the Observable Readiness Index and Takeover Time. In\nthis work, we show that machine learning models which predict these two metrics\nare robust to multiple camera views, expanding from the limited view angles in\nprior research. Importantly, these models take as input feature vectors\ncorresponding to hand location and activity as well as gaze location, and we\nexplore the tradeoffs of different views in generating these feature vectors.\nFurther, we introduce two metrics to evaluate the quality of control\ntransitions following the takeover event (the maximal lateral deviation and\nvelocity deviation) and compute correlations of these post-takeover metrics to\nthe pre-takeover predictive metrics.\n","authors":["Ross Greer","Nachiket Deo","Akshay Rangesh","Pujitha Gunaratne","Mohan Trivedi"],"pdf_url":"https://arxiv.org/pdf/2301.05805v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05838v2","updated":"2023-01-18T19:46:47Z","published":"2023-01-14T07:22:12Z","title":"(Safe) SMART Hands: Hand Activity Analysis and Distraction Alerts Using\n  a Multi-Camera Framework","summary":"  Manual (hand-related) activity is a significant source of crash risk while\ndriving. Accordingly, analysis of hand position and hand activity occupation is\na useful component to understanding a driver's readiness to take control of a\nvehicle. Visual sensing through cameras provides a passive means of observing\nthe hands, but its effectiveness varies depending on camera location. We\nintroduce an algorithmic framework, SMART Hands, for accurate hand\nclassification with an ensemble of camera views using machine learning. We\nillustrate the effectiveness of this framework in a 4-camera setup, reaching\n98% classification accuracy on a variety of locations and held objects for both\nof the driver's hands. We conclude that this multi-camera framework can be\nextended to additional tasks such as gaze and pose analysis, with further\napplications in driver and passenger safety.\n","authors":["Ross Greer","Lulua Rakla","Anish Gopalan","Mohan Trivedi"],"pdf_url":"https://arxiv.org/pdf/2301.05838v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05842v2","updated":"2023-01-18T19:45:51Z","published":"2023-01-14T07:28:05Z","title":"CHAMP: Crowdsourced, History-Based Advisory of Mapped Pedestrians for\n  Safer Driver Assistance Systems","summary":"  Vehicles are constantly approaching and sharing the road with pedestrians,\nand as a result it is critical for vehicles to prevent any collisions with\npedestrians. Current methods for pedestrian collision prevention focus on\nintegrating visual pedestrian detectors with Automatic Emergency Braking (AEB)\nsystems which can trigger warnings and apply brakes as a pedestrian enters a\nvehicle's path. Unfortunately, pedestrian-detection-based systems can be\nhindered in certain situations such as nighttime or when pedestrians are\noccluded. Our system, CHAMP (Crowdsourced, History-based Advisories of Mapped\nPedestrians), addresses such issues using an online, map-based pedestrian\ndetection system where pedestrian locations are aggregated into a dataset after\nrepeated passes of locations. Using this dataset, we are able to learn\npedestrian zones and generate advisory notices when a vehicle is approaching a\npedestrian despite challenges like dark lighting or pedestrian occlusion. We\ncollected and carefully annotated pedestrian data in La Jolla, CA to construct\ntraining and test sets of pedestrian locations. Moreover, we use the number of\ncorrect advisories, false advisories, and missed advisories to define precision\nand recall performance metrics to evaluate CHAMP. This approach can be tuned\nsuch that we achieve a maximum of 100% precision and 75% recall on the\nexperimental dataset, with performance enhancement options through further data\ncollection.\n","authors":["Ross Greer","Lulua Rakla","Samveed Desai","Afnan Alofi","Akshay Gopalkrishnan","Mohan Trivedi"],"pdf_url":"https://arxiv.org/pdf/2301.05842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08556v1","updated":"2023-01-18T23:25:27Z","published":"2023-01-18T23:25:27Z","title":"NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via\n  Novel-View Synthesis","summary":"  Expert demonstrations are a rich source of supervision for training visual\nrobotic manipulation policies, but imitation learning methods often require\neither a large number of demonstrations or expensive online expert supervision\nto learn reactive closed-loop behaviors. In this work, we introduce SPARTN\n(Synthetic Perturbations for Augmenting Robot Trajectories via NeRF): a\nfully-offline data augmentation scheme for improving robot policies that use\neye-in-hand cameras. Our approach leverages neural radiance fields (NeRFs) to\nsynthetically inject corrective noise into visual demonstrations, using NeRFs\nto generate perturbed viewpoints while simultaneously calculating the\ncorrective actions. This requires no additional expert supervision or\nenvironment interaction, and distills the geometric information in NeRFs into a\nreal-time reactive RGB-only policy. In a simulated 6-DoF visual grasping\nbenchmark, SPARTN improves success rates by 2.8$\\times$ over imitation learning\nwithout the corrective augmentations and even outperforms some methods that use\nonline supervision. It additionally closes the gap between RGB-only and RGB-D\nsuccess rates, eliminating the previous need for depth sensors. In real-world\n6-DoF robotic grasping experiments from limited human demonstrations, our\nmethod improves absolute success rates by $22.5\\%$ on average, including\nobjects that are traditionally challenging for depth-based methods. See video\nresults at \\url{https://bland.website/spartn}.\n","authors":["Allan Zhou","Moo Jin Kim","Lirui Wang","Pete Florence","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2301.08556v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.07639v1","updated":"2023-01-18T16:29:05Z","published":"2023-01-18T16:29:05Z","title":"A Comparative Analysis of Bias Amplification in Graph Neural Network\n  Approaches for Recommender Systems","summary":"  Recommender Systems (RSs) are used to provide users with personalized item\nrecommendations and help them overcome the problem of information overload.\nCurrently, recommendation methods based on deep learning are gaining ground\nover traditional methods such as matrix factorization due to their ability to\nrepresent the complex relationships between users and items and to incorporate\nadditional information. The fact that these data have a graph structure and the\ngreater capability of Graph Neural Networks (GNNs) to learn from these\nstructures has led to their successful incorporation into recommender systems.\nHowever, the bias amplification issue needs to be investigated while using\nthese algorithms. Bias results in unfair decisions, which can negatively affect\nthe company reputation and financial status due to societal disappointment and\nenvironmental harm. In this paper, we aim to comprehensively study this problem\nthrough a literature review and an analysis of the behavior against biases of\ndifferent GNN-based algorithms compared to state-of-the-art methods. We also\nintend to explore appropriate solutions to tackle this issue with the least\npossible impact on the model performance.\n","authors":["Nikzad Chizari","Niloufar Shoeibi","María N. Moreno-García"],"pdf_url":"https://arxiv.org/pdf/2301.07639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07483v1","updated":"2023-01-18T12:53:28Z","published":"2023-01-18T12:53:28Z","title":"Biases in Scholarly Recommender Systems: Impact, Prevalence, and\n  Mitigation","summary":"  With the remarkable increase in the number of scientific entities such as\npublications, researchers, and scientific topics, and the associated\ninformation overload in science, academic recommender systems have become\nincreasingly important for millions of researchers and science enthusiasts.\nHowever, it is often overlooked that these systems are subject to various\nbiases. In this article, we first break down the biases of academic recommender\nsystems and characterize them according to their impact and prevalence. In\ndoing so, we distinguish between biases originally caused by humans and biases\ninduced by the recommender system. Second, we provide an overview of methods\nthat have been used to mitigate these biases in the scholarly domain. Based on\nthis, third, we present a framework that can be used by researchers and\ndevelopers to mitigate biases in scholarly recommender systems and to evaluate\nrecommender systems fairly. Finally, we discuss open challenges and possible\nresearch directions related to scholarly biases.\n","authors":["Michael Färber","Melissa Coutinho","Shuzhou Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.07483v1.pdf","comment":"44 pages, 6 figures. To be published in Scientometrics"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2210.07675v3","updated":"2023-01-18T18:49:26Z","published":"2022-10-14T10:00:36Z","title":"Learning image representations for anomaly detection: application to\n  discovery of histological alterations in drug development","summary":"  We present a system for anomaly detection in histopathological images. In\nhistology, normal samples are usually abundant, whereas anomalous\n(pathological) cases are scarce or not available. Under such settings,\none-class classifiers trained on healthy data can detect out-of-distribution\nanomalous samples. Such approaches combined with pre-trained Convolutional\nNeural Network (CNN) representations of images were previously employed for\nanomaly detection (AD). However, pre-trained off-the-shelf CNN representations\nmay not be sensitive to abnormal conditions in tissues, while natural\nvariations of healthy tissue may result in distant representations. To adapt\nrepresentations to relevant details in healthy tissue we propose training a CNN\non an auxiliary task that discriminates healthy tissue of different species,\norgans, and staining reagents. Almost no additional labeling workload is\nrequired, since healthy samples come automatically with aforementioned labels.\nDuring training we enforce compact image representations with a center-loss\nterm, which further improves representations for AD. The proposed system\noutperforms established AD methods on a published dataset of liver anomalies.\nMoreover, it provided comparable results to conventional methods specifically\ntailored for quantification of liver anomalies. We show that our approach can\nbe used for toxicity assessment of candidate drugs at early development stages\nand thereby may reduce expensive late-stage drug attrition.\n","authors":["Igor Zingman","Birgit Stierstorfer","Charlotte Lempp","Fabian Heinemann"],"pdf_url":"https://arxiv.org/pdf/2210.07675v3.pdf","comment":"14 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2207.11640v3","updated":"2023-01-18T18:41:22Z","published":"2022-07-24T02:38:54Z","title":"Reliable amortized variational inference with physics-based latent\n  distribution correction","summary":"  Bayesian inference for high-dimensional inverse problems is computationally\ncostly and requires selecting a suitable prior distribution. Amortized\nvariational inference addresses these challenges via a neural network that\napproximates the posterior distribution not only for one instance of data, but\na distribution of data pertaining to a specific inverse problem. During\ninference, the neural network -- in our case a conditional normalizing flow --\nprovides posterior samples at virtually no cost. However, the accuracy of\namortized variational inference relies on the availability of high-fidelity\ntraining data, which seldom exists in geophysical inverse problems due to the\nEarth's heterogeneity. In addition, the network is prone to errors if evaluated\nover out-of-distribution data. As such, we propose to increase the resilience\nof amortized variational inference in the presence of moderate data\ndistribution shifts. We achieve this via a correction to the latent\ndistribution that improves the posterior distribution approximation for the\ndata at hand. The correction involves relaxing the standard Gaussian assumption\non the latent distribution and parameterizing it via a Gaussian distribution\nwith an unknown mean and (diagonal) covariance. These unknowns are then\nestimated by minimizing the Kullback-Leibler divergence between the corrected\nand the (physics-based) true posterior distributions. While generic and\napplicable to other inverse problems, by means of a linearized seismic imaging\nexample, we show that our correction step improves the robustness of amortized\nvariational inference with respect to changes in the number of seismic sources,\nnoise variance, and shifts in the prior distribution. This approach provides a\nseismic image with limited artifacts and an assessment of its uncertainty at\napproximately the same cost as five reverse-time migrations.\n","authors":["Ali Siahkoohi","Gabrio Rizzuti","Rafael Orozco","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2207.11640v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14302v2","updated":"2023-01-18T18:25:37Z","published":"2022-11-25T18:58:28Z","title":"Neural DAEs: Constrained neural networks","summary":"  In this article we investigate the effect of explicitly adding auxiliary\ntrajectory information to neural networks for dynamical systems. We draw\ninspiration from the field of differential-algebraic equations and differential\nequations on manifolds and implement similar methods in residual neural\nnetworks. We discuss constraints through stabilization as well as projection\nmethods, and show when to use which method based on experiments involving\nsimulations of multi-body pendulums and molecular dynamics scenarios. Several\nof our methods are easy to implement in existing code and have limited impact\non training performance while giving significant boosts in terms of inference.\n","authors":["Tue Boesen","Eldad Haber","Uri M. Ascher"],"pdf_url":"https://arxiv.org/pdf/2211.14302v2.pdf","comment":"Updated the experiments and preparing for submission to JCP"},{"id":"http://arxiv.org/abs/2211.07533v3","updated":"2023-01-18T18:24:27Z","published":"2022-11-14T17:03:56Z","title":"Generalized Balancing Weights via Deep Neural Networks","summary":"  We present generalized balancing weights, Neural Balancing Weights (NBW), to\nestimate the causal effects for an arbitrary mixture of discrete and continuous\ninterventions. The weights were obtained by directly estimating the density\nratio between the source and balanced distributions by optimizing the\nvariational representation of $f$-divergence. For this, we selected\n$\\alpha$-divergence since it has good properties for optimization: It has a\n$\\sqrt{N}$-consistency estimator and unbiased mini-batch gradients and is\nadvantageous for the vanishing gradient problem. In addition, we provide a\nmethod for checking the balance of the distribution changed by the weights. If\nthe balancing is imperfect, the weights can be improved by adding new balancing\nweights. Our method can be conveniently implemented with any present\ndeep-learning libraries, and weights can be used in most state-of-the-art\nsupervised algorithms.\n","authors":["Yoshiaki Kitazawa"],"pdf_url":"https://arxiv.org/pdf/2211.07533v3.pdf","comment":"The main theorem and algorithms are partially changed, because errors\n  were found in the proof of the theorem"},{"id":"http://arxiv.org/abs/1903.05347v3","updated":"2023-01-18T18:10:10Z","published":"2019-03-13T07:54:58Z","title":"What relations are reliably embeddable in Euclidean space?","summary":"  We consider the problem of embedding a relation, represented as a directed\ngraph, into Euclidean space. For three types of embeddings motivated by the\nrecent literature on knowledge graphs, we obtain characterizations of which\nrelations they are able to capture, as well as bounds on the minimal\ndimensionality and precision needed.\n","authors":["Robi Bhattacharjee","Sanjoy Dasgupta"],"pdf_url":"https://arxiv.org/pdf/1903.05347v3.pdf","comment":"Published at ALT 2020"},{"id":"http://arxiv.org/abs/2012.10794v3","updated":"2023-01-18T18:06:14Z","published":"2020-12-19T22:04:59Z","title":"Sample Complexity of Adversarially Robust Linear Classification on\n  Separated Data","summary":"  We consider the sample complexity of learning with adversarial robustness.\nMost prior theoretical results for this problem have considered a setting where\ndifferent classes in the data are close together or overlapping. Motivated by\nsome real applications, we consider, in contrast, the well-separated case where\nthere exists a classifier with perfect accuracy and robustness, and show that\nthe sample complexity narrates an entirely different story. Specifically, for\nlinear classifiers, we show a large class of well-separated distributions where\nthe expected robust loss of any algorithm is at least $\\Omega(\\frac{d}{n})$,\nwhereas the max margin algorithm has expected standard loss $O(\\frac{1}{n})$.\nThis shows a gap in the standard and robust losses that cannot be obtained via\nprior techniques. Additionally, we present an algorithm that, given an instance\nwhere the robustness radius is much smaller than the gap between the classes,\ngives a solution with expected robust loss is $O(\\frac{1}{n})$. This shows that\nfor very well-separated data, convergence rates of $O(\\frac{1}{n})$ are\nachievable, which is not the case otherwise. Our results apply to robustness\nmeasured in any $\\ell_p$ norm with $p > 1$ (including $p = \\infty$).\n","authors":["Robi Bhattacharjee","Somesh Jha","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2012.10794v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06331v2","updated":"2023-01-18T18:03:06Z","published":"2023-01-16T09:53:26Z","title":"Hybrid quantum-classical convolutional neural networks to improve\n  molecular protein binding affinity predictions","summary":"  One of the main challenges in drug discovery is to find molecules that bind\nspecifically and strongly to their target protein while having minimal binding\nto other proteins. By predicting binding affinity, it is possible to identify\nthe most promising candidates from a large pool of potential compounds,\nreducing the number of compounds that need to be tested experimentally.\nRecently, deep learning methods have shown superior performance than\ntraditional computational methods for making accurate predictions on large\ndatasets. However, the complexity and time-consuming nature of these methods\nhave limited their usage and development. Quantum machine learning is an\nemerging technology that has the potential to improve many classical machine\nlearning algorithms. In this work we present a hybrid quantum-classical\nconvolutional neural network, which is able to reduce by 20% the complexity of\nthe classical network while maintaining optimal performance in the predictions.\nAdditionally, it results in a significant time savings of up to 40% in the\ntraining process, which means a meaningful speed up of the drug discovery\nprocess.\n","authors":["L. Domingo","M. Djukic","C. Johnson","F. Borondo"],"pdf_url":"https://arxiv.org/pdf/2301.06331v2.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2102.09086v3","updated":"2023-01-18T18:02:20Z","published":"2021-02-18T00:44:07Z","title":"Consistent Non-Parametric Methods for Maximizing Robustness","summary":"  Learning classifiers that are robust to adversarial examples has received a\ngreat deal of recent attention. A major drawback of the standard robust\nlearning framework is there is an artificial robustness radius $r$ that applies\nto all inputs. This ignores the fact that data may be highly heterogeneous, in\nwhich case it is plausible that robustness regions should be larger in some\nregions of data, and smaller in others. In this paper, we address this\nlimitation by proposing a new limit classifier, called the neighborhood optimal\nclassifier, that extends the Bayes optimal classifier outside its support by\nusing the label of the closest in-support point. We then argue that this\nclassifier maximizes the size of its robustness regions subject to the\nconstraint of having accuracy equal to the Bayes optimal. We then present\nsufficient conditions under which general non-parametric methods that can be\nrepresented as weight functions converge towards this limit, and show that both\nnearest neighbors and kernel classifiers satisfy them under certain conditions.\n","authors":["Robi Bhattacharjee","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2102.09086v3.pdf","comment":"accepted to Nuerips 2021"},{"id":"http://arxiv.org/abs/2012.14512v2","updated":"2023-01-18T17:58:50Z","published":"2020-12-28T22:35:44Z","title":"No-substitution k-means Clustering with Adversarial Order","summary":"  We investigate $k$-means clustering in the online no-substitution setting\nwhen the input arrives in \\emph{arbitrary} order. In this setting, points\narrive one after another, and the algorithm is required to instantly decide\nwhether to take the current point as a center before observing the next point.\nDecisions are irrevocable. The goal is to minimize both the number of centers\nand the $k$-means cost. Previous works in this setting assume that the input's\norder is random, or that the input's aspect ratio is bounded. It is known that\nif the order is arbitrary and there is no assumption on the input, then any\nalgorithm must take all points as centers. Moreover, assuming a bounded aspect\nratio is too restrictive -- it does not include natural input generated from\nmixture models.\n  We introduce a new complexity measure that quantifies the difficulty of\nclustering a dataset arriving in arbitrary order. We design a new random\nalgorithm and prove that if applied on data with complexity $d$, the algorithm\ntakes $O(d\\log(n) k\\log(k))$ centers and is an $O(k^3)$-approximation. We also\nprove that if the data is sampled from a ``natural\" distribution, such as a\nmixture of $k$ Gaussians, then the new complexity measure is equal to\n$O(k^2\\log(n))$. This implies that for data generated from those distributions,\nour new algorithm takes only $\\text{poly}(k\\log(n))$ centers and is a\n$\\text{poly}(k)$-approximation. In terms of negative results, we prove that the\nnumber of centers needed to achieve an $\\alpha$-approximation is at least\n$\\Omega\\left(\\frac{d}{k\\log(n\\alpha)}\\right)$.\n","authors":["Robi Bhattacharjee","Michal Moshkovitz"],"pdf_url":"https://arxiv.org/pdf/2012.14512v2.pdf","comment":"accepted to ALT 2021"},{"id":"http://arxiv.org/abs/2211.09800v2","updated":"2023-01-18T17:31:52Z","published":"2022-11-17T18:58:43Z","title":"InstructPix2Pix: Learning to Follow Image Editing Instructions","summary":"  We propose a method for editing images from human instructions: given an\ninput image and a written instruction that tells the model what to do, our\nmodel follows these instructions to edit the image. To obtain training data for\nthis problem, we combine the knowledge of two large pretrained models -- a\nlanguage model (GPT-3) and a text-to-image model (Stable Diffusion) -- to\ngenerate a large dataset of image editing examples. Our conditional diffusion\nmodel, InstructPix2Pix, is trained on our generated data, and generalizes to\nreal images and user-written instructions at inference time. Since it performs\nedits in the forward pass and does not require per example fine-tuning or\ninversion, our model edits images quickly, in a matter of seconds. We show\ncompelling editing results for a diverse collection of input images and written\ninstructions.\n","authors":["Tim Brooks","Aleksander Holynski","Alexei A. Efros"],"pdf_url":"https://arxiv.org/pdf/2211.09800v2.pdf","comment":"Project page with code:\n  https://www.timothybrooks.com/instruct-pix2pix"},{"id":"http://arxiv.org/abs/2301.07665v1","updated":"2023-01-18T17:19:04Z","published":"2023-01-18T17:19:04Z","title":"An investigation of the reconstruction capacity of stacked convolutional\n  autoencoders for log-mel-spectrograms","summary":"  In audio processing applications, the generation of expressive sounds based\non high-level representations demonstrates a high demand. These representations\ncan be used to manipulate the timbre and influence the synthesis of creative\ninstrumental notes. Modern algorithms, such as neural networks, have inspired\nthe development of expressive synthesizers based on musical instrument timbre\ncompression. Unsupervised deep learning methods can achieve audio compression\nby training the network to learn a mapping from waveforms or spectrograms to\nlow-dimensional representations. This study investigates the use of stacked\nconvolutional autoencoders for the compression of time-frequency audio\nrepresentations for a variety of instruments for a single pitch. Further\nexploration of hyper-parameters and regularization techniques is demonstrated\nto enhance the performance of the initial design. In an unsupervised manner,\nthe network is able to reconstruct a monophonic and harmonic sound based on\nlatent representations. In addition, we introduce an evaluation metric to\nmeasure the similarity between the original and reconstructed samples.\nEvaluating a deep generative model for the synthesis of sound is a challenging\ntask. Our approach is based on the accuracy of the generated frequencies as it\npresents a significant metric for the perception of harmonic sounds. This work\nis expected to accelerate future experiments on audio compression using neural\nautoencoders.\n","authors":["Anastasia Natsiou","Luca Longo","Sean O'Leary"],"pdf_url":"https://arxiv.org/pdf/2301.07665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00774v2","updated":"2023-01-18T17:13:49Z","published":"2023-01-02T17:48:56Z","title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot","summary":"  We show for the first time that large-scale generative pretrained transformer\n(GPT) family models can be pruned to at least 50% sparsity in one-shot, without\nany retraining, at minimal loss of accuracy. This is achieved via a new pruning\nmethod called SparseGPT, specifically designed to work efficiently and\naccurately on massive GPT-family models. When executing SparseGPT on the\nlargest available open-source models, OPT-175B and BLOOM-176B, we can reach 60%\nsparsity with negligible increase in perplexity: remarkably, more than 100\nbillion weights from these models can be ignored at inference time. SparseGPT\ngeneralizes to semi-structured (2:4 and 4:8) patterns, and is compatible with\nweight quantization approaches.\n","authors":["Elias Frantar","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2301.00774v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07656v1","updated":"2023-01-18T17:02:16Z","published":"2023-01-18T17:02:16Z","title":"Non-parametric identifiability and sensitivity analysis of synthetic\n  control models","summary":"  Quantifying cause and effect relationships is an important problem in many\ndomains. The gold standard solution is to conduct a randomised controlled\ntrial. However, in many situations such trials cannot be performed. In the\nabsence of such trials, many methods have been devised to quantify the causal\nimpact of an intervention from observational data given certain assumptions.\nOne widely used method are synthetic control models. While identifiability of\nthe causal estimand in such models has been obtained from a range of\nassumptions, it is widely and implicitly assumed that the underlying\nassumptions are satisfied for all time periods both pre- and post-intervention.\nThis is a strong assumption, as synthetic control models can only be learned in\npre-intervention period. In this paper we address this challenge, and prove\nidentifiability can be obtained without the need for this assumption, by\nshowing it follows from the principle of invariant causal mechanisms. Moreover,\nfor the first time, we formulate and study synthetic control models in Pearl's\nstructural causal model framework. Importantly, we provide a general framework\nfor sensitivity analysis of synthetic control causal inference to violations of\nthe assumptions underlying non-parametric identifiability. We end by providing\nan empirical demonstration of our sensitivity analysis framework on simulated\nand real data in the widely-used linear synthetic control framework.\n","authors":["Jakob Zeitler","Athanasios Vlontzos","Ciaran M. Gilligan-Lee"],"pdf_url":"https://arxiv.org/pdf/2301.07656v1.pdf","comment":"Accepted at Causal Learning and Reasoning Conference (CLeaR) 2023"},{"id":"http://arxiv.org/abs/2210.12874v3","updated":"2023-01-18T16:47:51Z","published":"2022-10-23T22:35:02Z","title":"Global Contrastive Batch Sampling via Optimization on Sample\n  Permutations","summary":"  Contrastive Learning has recently achieved state-of-the-art performance in a\nwide range of tasks. Many contrastive learning approaches use mined hard\nnegatives to make batches more informative during training but these approaches\nare inefficient as they increase epoch length proportional to the number of\nmined negatives and require frequent updates of nearest neighbor indices or\nmining from recent batches. In this work, we provide an alternative to hard\nnegative mining, Global Contrastive Batch Sampling (GCBS), an efficient\napproximation to the batch assignment problem that upper bounds the gap between\nthe global and training losses, $\\mathcal{L}^{Global} - \\mathcal{L}^{Train}$,\nin contrastive learning settings. Through experimentation we find GCBS improves\nstate-of-the-art performance in sentence embedding and code-search tasks.\nAdditionally, GCBS is easy to implement as it requires only a few additional\nlines of code, does not maintain external data structures such as nearest\nneighbor indices, is more computationally efficient than the most minimal hard\nnegative mining approaches, and makes no changes to the model being trained.\n","authors":["Vin Sachidananda","Ziyi Yang","Chenguang Zhu"],"pdf_url":"https://arxiv.org/pdf/2210.12874v3.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2209.03299v5","updated":"2023-01-18T16:30:16Z","published":"2022-09-07T16:59:03Z","title":"Multimodal learning with graphs","summary":"  Artificial intelligence for graphs has achieved remarkable success in\nmodeling complex systems, ranging from dynamic networks in biology to\ninteracting particle systems in physics. However, the increasingly\nheterogeneous graph datasets call for multimodal methods that can combine\ndifferent inductive biases: the set of assumptions that algorithms use to make\npredictions for inputs they have not encountered during training. Learning on\nmultimodal datasets presents fundamental challenges because the inductive\nbiases can vary by data modality and graphs might not be explicitly given in\nthe input. To address these challenges, multimodal graph AI methods combine\ndifferent modalities while leveraging cross-modal dependencies using graphs.\nDiverse datasets are combined using graphs and fed into sophisticated\nmultimodal architectures, specified as image-intensive, knowledge-grounded and\nlanguage-intensive models. Using this categorization, we introduce a blueprint\nfor multimodal graph learning, use it to study existing methods and provide\nguidelines to design new models.\n","authors":["Yasha Ektefaie","George Dasoulas","Ayush Noori","Maha Farhat","Marinka Zitnik"],"pdf_url":"https://arxiv.org/pdf/2209.03299v5.pdf","comment":"27 pages, 5 figures, 2 boxes"},{"id":"http://arxiv.org/abs/2301.07638v1","updated":"2023-01-18T16:26:57Z","published":"2023-01-18T16:26:57Z","title":"An Analysis of Loss Functions for Binary Classification and Regression","summary":"  This paper explores connections between margin-based loss functions and\nconsistency in binary classification and regression applications. It is shown\nthat a large class of margin-based loss functions for binary\nclassification/regression result in estimating scores equivalent to\nlog-likelihood scores weighted by an even function. A simple characterization\nfor conformable (consistent) loss functions is given, which allows for\nstraightforward comparison of different losses, including exponential loss,\nlogistic loss, and others. The characterization is used to construct a new\nHuber-type loss function for the logistic model. A simple relation between the\nmargin and standardized logistic regression residuals is derived, demonstrating\nthat all margin-based loss can be viewed as loss functions of squared\nstandardized logistic regression residuals. The relation provides new,\nstraightforward interpretations for exponential and logistic loss, and aids in\nunderstanding why exponential loss is sensitive to outliers. In particular, it\nis shown that minimizing empirical exponential loss is equivalent to minimizing\nthe sum of squared standardized logistic regression residuals. The relation\nalso provides new insight into the AdaBoost algorithm.\n","authors":["Jeffrey Buzas"],"pdf_url":"https://arxiv.org/pdf/2301.07638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07635v1","updated":"2023-01-18T16:25:10Z","published":"2023-01-18T16:25:10Z","title":"Local Learning with Neuron Groups","summary":"  Traditional deep network training methods optimize a monolithic objective\nfunction jointly for all the components. This can lead to various\ninefficiencies in terms of potential parallelization. Local learning is an\napproach to model-parallelism that removes the standard end-to-end learning\nsetup and utilizes local objective functions to permit parallel learning\namongst model components in a deep network. Recent works have demonstrated that\nvariants of local learning can lead to efficient training of modern deep\nnetworks. However, in terms of how much computation can be distributed, these\napproaches are typically limited by the number of layers in a network. In this\nwork we propose to study how local learning can be applied at the level of\nsplitting layers or modules into sub-components, adding a notion of width-wise\nmodularity to the existing depth-wise modularity associated with local\nlearning. We investigate local-learning penalties that permit such models to be\ntrained efficiently. Our experiments on the CIFAR-10, CIFAR-100, and Imagenet32\ndatasets demonstrate that introducing width-level modularity can lead to\ncomputational advantages over existing methods based on local learning and\nopens new opportunities for improved model-parallel distributed training. Code\nis available at: https://github.com/adeetyapatel12/GN-DGL.\n","authors":["Adeetya Patel","Michael Eickenberg","Eugene Belilovsky"],"pdf_url":"https://arxiv.org/pdf/2301.07635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07634v1","updated":"2023-01-18T16:22:40Z","published":"2023-01-18T16:22:40Z","title":"Training Semantic Segmentation on Heterogeneous Datasets","summary":"  We explore semantic segmentation beyond the conventional, single-dataset\nhomogeneous training and bring forward the problem of Heterogeneous Training of\nSemantic Segmentation (HTSS). HTSS involves simultaneous training on multiple\nheterogeneous datasets, i.e. datasets with conflicting label spaces and\ndifferent (weak) annotation types from the perspective of semantic\nsegmentation. The HTSS formulation exposes deep networks to a larger and\npreviously unexplored aggregation of information that can potentially enhance\nsemantic segmentation in three directions: i) performance: increased\nsegmentation metrics on seen datasets, ii) generalization: improved\nsegmentation metrics on unseen datasets, and iii) knowledgeability: increased\nnumber of recognizable semantic concepts. To research these benefits of HTSS,\nwe propose a unified framework, that incorporates heterogeneous datasets in a\nsingle-network training pipeline following the established FCN standard. Our\nframework first curates heterogeneous datasets to bring them into a common\nformat and then trains a single-backbone FCN on all of them simultaneously. To\nachieve this, it transforms weak annotations, which are incompatible with\nsemantic segmentation, to per-pixel labels, and hierarchizes their label spaces\ninto a universal taxonomy. The trained HTSS models demonstrate performance and\ngeneralization gains over a wide range of datasets and extend the inference\nlabel space entailing hundreds of semantic classes.\n","authors":["Panagiotis Meletis","Gijs Dubbelman"],"pdf_url":"https://arxiv.org/pdf/2301.07634v1.pdf","comment":"Submitted 2021 (under review)"},{"id":"http://arxiv.org/abs/2207.09442v3","updated":"2023-01-18T16:20:27Z","published":"2022-07-19T17:57:40Z","title":"Theseus: A Library for Differentiable Nonlinear Optimization","summary":"  We present Theseus, an efficient application-agnostic open source library for\ndifferentiable nonlinear least squares (DNLS) optimization built on PyTorch,\nproviding a common framework for end-to-end structured learning in robotics and\nvision. Existing DNLS implementations are application specific and do not\nalways incorporate many ingredients important for efficiency. Theseus is\napplication-agnostic, as we illustrate with several example applications that\nare built using the same underlying differentiable components, such as\nsecond-order optimizers, standard costs functions, and Lie groups. For\nefficiency, Theseus incorporates support for sparse solvers, automatic\nvectorization, batching, GPU acceleration, and gradient computation with\nimplicit differentiation and direct loss minimization. We do extensive\nperformance evaluation in a set of applications, demonstrating significant\nefficiency gains and better scalability when these features are incorporated.\nProject page: https://sites.google.com/view/theseus-ai\n","authors":["Luis Pineda","Taosha Fan","Maurizio Monge","Shobha Venkataraman","Paloma Sodhi","Ricky T. Q. Chen","Joseph Ortiz","Daniel DeTone","Austin Wang","Stuart Anderson","Jing Dong","Brandon Amos","Mustafa Mukadam"],"pdf_url":"https://arxiv.org/pdf/2207.09442v3.pdf","comment":"Advances in Neural Information Processing Systems (NeurIPS), 2022"},{"id":"http://arxiv.org/abs/2301.07628v1","updated":"2023-01-18T16:12:04Z","published":"2023-01-18T16:12:04Z","title":"Universal Neural-Cracking-Machines: Self-Configurable Password Models\n  from Auxiliary Data","summary":"  We develop the first universal password model -- a password model that, once\npre-trained, can automatically adapt to any password distribution. To achieve\nthis result, the model does not need to access any plaintext passwords from the\ntarget set. Instead, it exploits users' auxiliary information, such as email\naddresses, as a proxy signal to predict the underlying target password\ndistribution. The model uses deep learning to capture the correlation between\nthe auxiliary data of a group of users (e.g., users of a web application) and\ntheir passwords. It then exploits those patterns to create a tailored password\nmodel for the target community at inference time. No further training steps,\ntargeted data collection, or prior knowledge of the community's password\ndistribution is required. Besides defining a new state-of-the-art for password\nstrength estimation, our model enables any end-user (e.g., system\nadministrators) to autonomously generate tailored password models for their\nsystems without the often unworkable requirement of collecting suitable\ntraining data and fitting the underlying password model. Ultimately, our\nframework enables the democratization of well-calibrated password models to the\ncommunity, addressing a major challenge in the deployment of password security\nsolutions on a large scale.\n","authors":["Dario Pasquini","Giuseppe Ateniese","Carmela Troncoso"],"pdf_url":"https://arxiv.org/pdf/2301.07628v1.pdf","comment":"v0.01"},{"id":"http://arxiv.org/abs/2212.01351v2","updated":"2023-01-18T16:08:45Z","published":"2022-12-02T18:13:48Z","title":"A Bayesian Framework for Digital Twin-Based Control, Monitoring, and\n  Data Collection in Wireless Systems","summary":"  Commonly adopted in the manufacturing and aerospace sectors, digital twin\n(DT) platforms are increasingly seen as a promising paradigm to control,\nmonitor, and analyze software-based, \"open\", communication systems. Notably, DT\nplatforms provide a sandbox in which to test artificial intelligence (AI)\nsolutions for communication systems, potentially reducing the need to collect\ndata and test algorithms in the field, i.e., on the physical twin (PT). A key\nchallenge in the deployment of DT systems is to ensure that virtual control\noptimization, monitoring, and analysis at the DT are safe and reliable,\navoiding incorrect decisions caused by \"model exploitation\". To address this\nchallenge, this paper presents a general Bayesian framework with the aim of\nquantifying and accounting for model uncertainty at the DT that is caused by\nlimitations in the amount and quality of data available at the DT from the PT.\nIn the proposed framework, the DT builds a Bayesian model of the communication\nsystem, which is leveraged to enable core DT functionalities such as control\nvia multi-agent reinforcement learning (MARL), monitoring of the PT for anomaly\ndetection, prediction, data-collection optimization, and counterfactual\nanalysis. To exemplify the application of the proposed framework, we\nspecifically investigate a case-study system encompassing multiple sensing\ndevices that report to a common receiver. Experimental results validate the\neffectiveness of the proposed Bayesian framework as compared to standard\nfrequentist model-based solutions.\n","authors":["Clement Ruah","Osvaldo Simeone","Bashir Al-Hashimi"],"pdf_url":"https://arxiv.org/pdf/2212.01351v2.pdf","comment":"Extends and subsumes arXiv:2210.05582 Updates: - 18/01/2023: Updated\n  reference"},{"id":"http://arxiv.org/abs/2301.07624v1","updated":"2023-01-18T16:07:56Z","published":"2023-01-18T16:07:56Z","title":"Performance-Preserving Event Log Sampling for Predictive Monitoring","summary":"  Predictive process monitoring is a subfield of process mining that aims to\nestimate case or event features for running process instances. Such predictions\nare of significant interest to the process stakeholders. However, most of the\nstate-of-the-art methods for predictive monitoring require the training of\ncomplex machine learning models, which is often inefficient. Moreover, most of\nthese methods require a hyper-parameter optimization that requires several\nrepetitions of the training process which is not feasible in many real-life\napplications. In this paper, we propose an instance selection procedure that\nallows sampling training process instances for prediction models. We show that\nour instance selection procedure allows for a significant increase of training\nspeed for next activity and remaining time prediction methods while maintaining\nreliable levels of prediction accuracy.\n","authors":["Mohammadreza Fani Sani","Mozhgan Vazifehdoostirani","Gyunam Park","Marco Pegoraro","Sebastiaan J. van Zelst","Wil M. P. van der Aalst"],"pdf_url":"https://arxiv.org/pdf/2301.07624v1.pdf","comment":"25 pages, 1 figure, 13 tables, 47 references. arXiv admin note:\n  substantial text overlap with arXiv:2204.01470"},{"id":"http://arxiv.org/abs/2210.05582v2","updated":"2023-01-18T16:04:08Z","published":"2022-10-11T16:14:43Z","title":"Digital Twin-Based Multiple Access Optimization and Monitoring via\n  Model-Driven Bayesian Learning","summary":"  Commonly adopted in the manufacturing and aerospace sectors, digital twin\n(DT) platforms are increasingly seen as a promising paradigm to control and\nmonitor software-based, \"open\", communication systems, which play the role of\nthe physical twin (PT). In the general framework presented in this work, the DT\nbuilds a Bayesian model of the communication system, which is leveraged to\nenable core DT functionalities such as control via multi-agent reinforcement\nlearning (MARL) and monitoring of the PT for anomaly detection. We specifically\ninvestigate the application of the proposed framework to a simple case-study\nsystem encompassing multiple sensing devices that report to a common receiver.\nThe Bayesian model trained at the DT has the key advantage of capturing\nepistemic uncertainty regarding the communication system, e.g., regarding\ncurrent traffic conditions, which arise from limited PT-to-DT data transfer.\nExperimental results validate the effectiveness of the proposed Bayesian\nframework as compared to standard frequentist model-based solutions.\n","authors":["Clement Ruah","Osvaldo Simeone","Bashir Al-Hashimi"],"pdf_url":"https://arxiv.org/pdf/2210.05582v2.pdf","comment":"Submitted for conference publication Updates: - 18/01/2023: updated\n  reference"},{"id":"http://arxiv.org/abs/2211.04756v3","updated":"2023-01-18T15:58:27Z","published":"2022-11-09T09:19:15Z","title":"Spiking Neural Network Decision Feedback Equalization","summary":"  In the past years, artificial neural networks (ANNs) have become the de-facto\nstandard to solve tasks in communications engineering that are difficult to\nsolve with traditional methods. In parallel, the artificial intelligence\ncommunity drives its research to biology-inspired, brain-like spiking neural\nnetworks (SNNs), which promise extremely energy-efficient computing. In this\npaper, we investigate the use of SNNs in the context of channel equalization\nfor ultra-low complexity receivers. We propose an SNN-based equalizer with a\nfeedback structure akin to the decision feedback equalizer (DFE). For\nconversion of real-world data into spike signals we introduce a novel ternary\nencoding and compare it with traditional log-scale encoding. We show that our\napproach clearly outperforms conventional linear equalizers for three different\nexemplary channels. We highlight that mainly the conversion of the channel\noutput to spikes introduces a small performance penalty. The proposed SNN with\na decision feedback structure enables the path to competitive energy-efficient\ntransceivers.\n","authors":["Eike-Manuel Bansbach","Alexander von Bank","Laurent Schmalen"],"pdf_url":"https://arxiv.org/pdf/2211.04756v3.pdf","comment":"accepted for publication at SCC 2023"},{"id":"http://arxiv.org/abs/2301.07609v1","updated":"2023-01-18T15:40:19Z","published":"2023-01-18T15:40:19Z","title":"Physics-informed Information Field Theory for Modeling Physical Systems\n  with Uncertainty Quantification","summary":"  Data-driven approaches coupled with physical knowledge are powerful\ntechniques to model systems. The goal of such models is to efficiently solve\nfor the underlying field by combining measurements with known physical laws. As\nmany systems contain unknown elements, such as missing parameters, noisy data,\nor incomplete physical laws, this is widely approached as an uncertainty\nquantification problem. The common techniques to handle all the variables\ntypically depend on the numerical scheme used to approximate the posterior, and\nit is desirable to have a method which is independent of any such\ndiscretization. Information field theory (IFT) provides the tools necessary to\nperform statistics over fields that are not necessarily Gaussian. We extend IFT\nto physics-informed IFT (PIFT) by encoding the functional priors with\ninformation about the physical laws which describe the field. The posteriors\nderived from this PIFT remain independent of any numerical scheme and can\ncapture multiple modes, allowing for the solution of problems which are\nill-posed. We demonstrate our approach through an analytical example involving\nthe Klein-Gordon equation. We then develop a variant of stochastic gradient\nLangevin dynamics to draw samples from the joint posterior over the field and\nmodel parameters. We apply our method to numerical examples with various\ndegrees of model-form error and to inverse problems involving nonlinear\ndifferential equations. As an addendum, the method is equipped with a metric\nwhich allows the posterior to automatically quantify model-form uncertainty.\nBecause of this, our numerical experiments show that the method remains robust\nto even an incorrect representation of the physics given sufficient data. We\nnumerically demonstrate that the method correctly identifies when the physics\ncannot be trusted, in which case it automatically treats learning the field as\na regression problem.\n","authors":["Alex Alberts","Ilias Bilionis"],"pdf_url":"https://arxiv.org/pdf/2301.07609v1.pdf","comment":"31 pages, 8 figures"},{"id":"http://arxiv.org/abs/2301.07608v1","updated":"2023-01-18T15:39:21Z","published":"2023-01-18T15:39:21Z","title":"Human-Timescale Adaptation in an Open-Ended Task Space","summary":"  Foundation models have shown impressive adaptation and scalability in\nsupervised and self-supervised learning problems, but so far these successes\nhave not fully translated to reinforcement learning (RL). In this work, we\ndemonstrate that training an RL agent at scale leads to a general in-context\nlearning algorithm that can adapt to open-ended novel embodied 3D problems as\nquickly as humans. In a vast space of held-out environment dynamics, our\nadaptive agent (AdA) displays on-the-fly hypothesis-driven exploration,\nefficient exploitation of acquired knowledge, and can successfully be prompted\nwith first-person demonstrations. Adaptation emerges from three ingredients:\n(1) meta-reinforcement learning across a vast, smooth and diverse task\ndistribution, (2) a policy parameterised as a large-scale attention-based\nmemory architecture, and (3) an effective automated curriculum that prioritises\ntasks at the frontier of an agent's capabilities. We demonstrate characteristic\nscaling laws with respect to network size, memory length, and richness of the\ntraining task distribution. We believe our results lay the foundation for\nincreasingly general and adaptive RL agents that perform well across\never-larger open-ended domains.\n","authors":[" Adaptive Agent Team","Jakob Bauer","Kate Baumli","Satinder Baveja","Feryal Behbahani","Avishkar Bhoopchand","Nathalie Bradley-Schmieg","Michael Chang","Natalie Clay","Adrian Collister","Vibhavari Dasagi","Lucy Gonzalez","Karol Gregor","Edward Hughes","Sheleem Kashem","Maria Loks-Thompson","Hannah Openshaw","Jack Parker-Holder","Shreya Pathak","Nicolas Perez-Nieves","Nemanja Rakicevic","Tim Rocktäschel","Yannick Schroecker","Jakub Sygnowski","Karl Tuyls","Sarah York","Alexander Zacherl","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.07608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07605v1","updated":"2023-01-18T15:37:11Z","published":"2023-01-18T15:37:11Z","title":"Strong inductive biases provably prevent harmless interpolation","summary":"  Classical wisdom suggests that estimators should avoid fitting noise to\nachieve good generalization. In contrast, modern overparameterized models can\nyield small test error despite interpolating noise -- a phenomenon often called\n\"benign overfitting\" or \"harmless interpolation\". This paper argues that the\ndegree to which interpolation is harmless hinges upon the strength of an\nestimator's inductive bias, i.e., how heavily the estimator favors solutions\nwith a certain structure: while strong inductive biases prevent harmless\ninterpolation, weak inductive biases can even require fitting noise to\ngeneralize well. Our main theoretical result establishes tight non-asymptotic\nbounds for high-dimensional kernel regression that reflect this phenomenon for\nconvolutional kernels, where the filter size regulates the strength of the\ninductive bias. We further provide empirical evidence of the same behavior for\ndeep neural networks with varying filter sizes and rotational invariance.\n","authors":["Michael Aerni","Marco Milanta","Konstantin Donhauser","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.11932v3","updated":"2023-01-18T15:17:54Z","published":"2021-01-28T11:09:40Z","title":"Approximation Theory of Tree Tensor Networks: Tensorized Multivariate\n  Functions","summary":"  We study the approximation of multivariate functions with tensor networks\n(TNs). The main conclusion of this work is an answer to the following two\nquestions: \"What are the approximation capabilities of TNs?\" and \"What is an\nappropriate model class of functions that can be approximated with TNs?\" To\nanswer the former: we show that TNs can (near to) optimally replicate\n$h$-uniform and $h$-adaptive approximation, for any smoothness order of the\ntarget function. Tensor networks thus exhibit universal expressivity w.r.t.\nisotropic, anisotropic and mixed smoothness spaces that is comparable with more\ngeneral neural networks families such as deep rectified linear unit (ReLU)\nnetworks. Put differently, TNs have the capacity to (near to) optimally\napproximate many function classes -- without being adapted to the particular\nclass in question. To answer the latter: as a candidate model class we consider\napproximation classes of TNs and show that these are (quasi-)Banach spaces,\nthat many types of classical smoothness spaces are continuously embedded into\nsaid approximation classes and that TN approximation classes are themselves not\nembedded in any classical smoothness space.\n","authors":["Mazen Ali","Anthony Nouy"],"pdf_url":"https://arxiv.org/pdf/2101.11932v3.pdf","comment":"For part I see arXiv:2007.00118, for part II see arXiv:2007.00128"},{"id":"http://arxiv.org/abs/2007.00128v5","updated":"2023-01-18T15:16:30Z","published":"2020-06-30T21:57:42Z","title":"Approximation Theory of Tree Tensor Networks: Tensorized Univariate\n  Functions -- Part II","summary":"  We study the approximation by tensor networks (TNs) of functions from\nclassical smoothness classes. The considered approximation tool combines a\ntensorization of functions in $L^p([0,1))$, which allows to identify a\nunivariate function with a multivariate function (or tensor), and the use of\ntree tensor networks (the tensor train format) for exploiting low-rank\nstructures of multivariate functions. The resulting tool can be interpreted as\na feed-forward neural network, with first layers implementing the\ntensorization, interpreted as a particular featuring step, followed by a\nsum-product network with sparse architecture. In part I of this work, we\npresented several approximation classes associated with different measures of\ncomplexity of tensor networks and studied their properties. In this work (part\nII), we show how classical approximation tools, such as polynomials or splines\n(with fixed or free knots), can be encoded as a tensor network with controlled\ncomplexity. We use this to derive direct (Jackson) inequalities for the\napproximation spaces of tensor networks. This is then utilized to show that\nBesov spaces are continuously embedded into these approximation spaces. In\nother words, we show that arbitrary Besov functions can be approximated with\noptimal or near to optimal rate. We also show that an arbitrary function in the\napproximation class possesses no Besov smoothness, unless one limits the depth\nof the tensor network.\n","authors":["Mazen Ali","Anthony Nouy"],"pdf_url":"https://arxiv.org/pdf/2007.00128v5.pdf","comment":"For part I see arXiv:2007.00118, for part III see arXiv:2101.11932"},{"id":"http://arxiv.org/abs/2007.00118v5","updated":"2023-01-18T15:15:06Z","published":"2020-06-30T21:32:59Z","title":"Approximation Theory of Tree Tensor Networks: Tensorized Univariate\n  Functions -- Part I","summary":"  We study the approximation of functions by tensor networks (TNs). We show\nthat Lebesgue $L^p$-spaces in one dimension can be identified with tensor\nproduct spaces of arbitrary order through tensorization. We use this tensor\nproduct structure to define subsets of $L^p$ of rank-structured functions of\nfinite representation complexity. These subsets are then used to define\ndifferent approximation classes of tensor networks, associated with different\nmeasures of complexity. These approximation classes are shown to be\nquasi-normed linear spaces. We study some elementary properties and\nrelationships of said spaces. In part II of this work, we will show that\nclassical smoothness (Besov) spaces are continuously embedded into these\napproximation classes. We will also show that functions in these approximation\nclasses do not possess any Besov smoothness, unless one restricts the depth of\nthe tensor networks. The results of this work are both an analysis of the\napproximation spaces of TNs and a study of the expressivity of a particular\ntype of neural networks (NN) -- namely feed-forward sum-product networks with\nsparse architecture. The input variables of this network result from the\ntensorization step, interpreted as a particular featuring step which can also\nbe implemented with a neural network with a specific architecture. We point out\ninteresting parallels to recent results on the expressivity of rectified linear\nunit (ReLU) networks -- currently one of the most popular type of NNs.\n","authors":["Mazen Ali","Anthony Nouy"],"pdf_url":"https://arxiv.org/pdf/2007.00118v5.pdf","comment":"For part II see arXiv:2007.00128, for part III see arXiv:2101.11932"},{"id":"http://arxiv.org/abs/2301.07584v1","updated":"2023-01-18T15:02:07Z","published":"2023-01-18T15:02:07Z","title":"Joint Representation Learning for Text and 3D Point Cloud","summary":"  Recent advancements in vision-language pre-training (e.g. CLIP) have shown\nthat vision models can benefit from language supervision. While many models\nusing language modality have achieved great success on 2D vision tasks, the\njoint representation learning of 3D point cloud with text remains\nunder-explored due to the difficulty of 3D-Text data pair acquisition and the\nirregularity of 3D data structure. In this paper, we propose a novel Text4Point\nframework to construct language-guided 3D point cloud models. The key idea is\nutilizing 2D images as a bridge to connect the point cloud and the language\nmodalities. The proposed Text4Point follows the pre-training and fine-tuning\nparadigm. During the pre-training stage, we establish the correspondence of\nimages and point clouds based on the readily available RGB-D data and use\ncontrastive learning to align the image and point cloud representations.\nTogether with the well-aligned image and text features achieved by CLIP, the\npoint cloud features are implicitly aligned with the text embeddings. Further,\nwe propose a Text Querying Module to integrate language information into 3D\nrepresentation learning by querying text embeddings with point cloud features.\nFor fine-tuning, the model learns task-specific 3D representations under\ninformative language guidance from the label set without 2D images. Extensive\nexperiments demonstrate that our model shows consistent improvement on various\ndownstream tasks, such as point cloud semantic segmentation, instance\nsegmentation, and object detection. The code will be available here:\nhttps://github.com/LeapLabTHU/Text4Point\n","authors":["Rui Huang","Xuran Pan","Henry Zheng","Haojun Jiang","Zhifeng Xie","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2301.07584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07583v1","updated":"2023-01-18T15:01:36Z","published":"2023-01-18T15:01:36Z","title":"A Survey of Advanced Computer Vision Techniques for Sports","summary":"  Computer Vision developments are enabling significant advances in many\nfields, including sports. Many applications built on top of Computer Vision\ntechnologies, such as tracking data, are nowadays essential for every top-level\nanalyst, coach, and even player. In this paper, we survey Computer Vision\ntechniques that can help many sports-related studies gather vast amounts of\ndata, such as Object Detection and Pose Estimation. We provide a use case for\nsuch data: building a model for shot speed estimation with pose data obtained\nusing only Computer Vision models. Our model achieves a correlation of 67%. The\npossibility of estimating shot speeds enables much deeper studies about\nenabling the creation of new metrics and recommendation systems that will help\nathletes improve their performance, in any sport. The proposed methodology is\neasily replicable for many technical movements and is only limited by the\navailability of video data.\n","authors":["Tiago Mendes-Neves","Luís Meireles","João Mendes-Moreira"],"pdf_url":"https://arxiv.org/pdf/2301.07583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06582v2","updated":"2023-01-18T14:51:21Z","published":"2023-01-16T19:40:50Z","title":"Antenna Array Calibration Via Gaussian Process Models","summary":"  Antenna array calibration is necessary to maintain the high fidelity of beam\npatterns across a wide range of advanced antenna systems and to ensure channel\nreciprocity in time division duplexing schemes. Despite the continuous\ndevelopment in this area, most existing solutions are optimised for specific\nradio architectures, require standardised over-the-air data transmission, or\nserve as extensions of conventional methods. The diversity of communication\nprotocols and hardware creates a problematic case, since this diversity\nrequires to design or update the calibration procedures for each new advanced\nantenna system. In this study, we formulate antenna calibration in an\nalternative way, namely as a task of functional approximation, and address it\nvia Bayesian machine learning. Our contributions are three-fold. Firstly, we\ndefine a parameter space, based on near-field measurements, that captures the\nunderlying hardware impairments corresponding to each radiating element, their\npositional offsets, as well as the mutual coupling effects between antenna\nelements. Secondly, Gaussian process regression is used to form models from a\nsparse set of the aforementioned near-field data. Once deployed, the learned\nnon-parametric models effectively serve to continuously transform the\nbeamforming weights of the system, resulting in corrected beam patterns.\nLastly, we demonstrate the viability of the described methodology for both\ndigital and analog beamforming antenna arrays of different scales and discuss\nits further extension to support real-time operation with dynamic hardware\nimpairments.\n","authors":["Sergey S. Tambovskiy","Gábor Fodor","Hugo Tullberg"],"pdf_url":"https://arxiv.org/pdf/2301.06582v2.pdf","comment":"International ITG 26th Workshop on Smart Antennas and 13th Conference\n  on Systems, Communications, and Coding"},{"id":"http://arxiv.org/abs/2301.07573v1","updated":"2023-01-18T14:49:54Z","published":"2023-01-18T14:49:54Z","title":"Synthcity: facilitating innovative use cases of synthetic data in\n  different data modalities","summary":"  Synthcity is an open-source software package for innovative use cases of\nsynthetic data in ML fairness, privacy and augmentation across diverse tabular\ndata modalities, including static data, regular and irregular time series, data\nwith censoring, multi-source data, composite data, and more. Synthcity provides\nthe practitioners with a single access point to cutting edge research and tools\nin synthetic data. It also offers the community a playground for rapid\nexperimentation and prototyping, a one-stop-shop for SOTA benchmarks, and an\nopportunity for extending research impact. The library can be accessed on\nGitHub (https://github.com/vanderschaarlab/synthcity) and pip\n(https://pypi.org/project/synthcity/). We warmly invite the community to join\nthe development effort by providing feedback, reporting bugs, and contributing\ncode.\n","authors":["Zhaozhi Qian","Bogdan-Constantin Cebere","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2301.07573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07568v1","updated":"2023-01-18T14:39:34Z","published":"2023-01-18T14:39:34Z","title":"Beating the Best: Improving on AlphaFold2 at Protein Structure\n  Prediction","summary":"  The goal of Protein Structure Prediction (PSP) problem is to predict a\nprotein's 3D structure (confirmation) from its amino acid sequence. The problem\nhas been a 'holy grail' of science since the Noble prize-winning work of\nAnfinsen demonstrated that protein conformation was determined by sequence. A\nrecent and important step towards this goal was the development of AlphaFold2,\ncurrently the best PSP method. AlphaFold2 is probably the highest profile\napplication of AI to science. Both AlphaFold2 and RoseTTAFold (another\nimpressive PSP method) have been published and placed in the public domain\n(code & models). Stacking is a form of ensemble machine learning ML in which\nmultiple baseline models are first learnt, then a meta-model is learnt using\nthe outputs of the baseline level model to form a model that outperforms the\nbase models. Stacking has been successful in many applications. We developed\nthe ARStack PSP method by stacking AlphaFold2 and RoseTTAFold. ARStack\nsignificantly outperforms AlphaFold2. We rigorously demonstrate this using two\nsets of non-homologous proteins, and a test set of protein structures published\nafter that of AlphaFold2 and RoseTTAFold. As more high quality prediction\nmethods are published it is likely that ensemble methods will increasingly\noutperform any single method.\n","authors":["Abbi Abdel-Rehim","Oghenejokpeme Orhobor","Hang Lou","Hao Ni","Ross D. King"],"pdf_url":"https://arxiv.org/pdf/2301.07568v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2210.09784v4","updated":"2023-01-18T14:36:17Z","published":"2022-10-18T11:56:20Z","title":"Generalized Many-Body Dispersion Correction through Random-phase\n  Approximation for Chemically Accurate Density Functional Theory","summary":"  We extend our recently proposed Deep Learning-aided many-body dispersion\n(DNN-MBD) model to quadrupole polarizability (Q) terms using a generalized\nRandom Phase Approximation (RPA) formalism, thus enabling the inclusion of van\nder Waals contributions beyond dipole. The resulting DNN-MBDQ model only relies\non ab initio-derived quantities as the introduced quadrupole polarizabilities\nare recursively retrieved from dipole ones, in turn modelled via the\nTkatchenko-Scheffler method. A transferable and efficient deep-neuronal network\n(DNN) provides atom in molecule volumes, while a single range-separation\nparameter is used to couple the model to Density Functional Theory (DFT). Since\nit can be computed at a negligible cost, the DNN-MBDQ approach can be coupled\nwith DFT functionals such as PBE,PBE0 and B86bPBE (dispersionless). The\nDNN-MBQ-corrected functionals reach chemical accuracy while exhibiting lower\nerrors compared to their dipole-only counterparts.\n","authors":["Pier Paolo Poier","Louis Lagardère","Jean-Philip Piquemal"],"pdf_url":"https://arxiv.org/pdf/2210.09784v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07557v1","updated":"2023-01-18T14:21:38Z","published":"2023-01-18T14:21:38Z","title":"Targeted Image Reconstruction by Sampling Pre-trained Diffusion Model","summary":"  A trained neural network model contains information on the training data.\nGiven such a model, malicious parties can leverage the \"knowledge\" in this\nmodel and design ways to print out any usable information (known as model\ninversion attack). Therefore, it is valuable to explore the ways to conduct a\nsuch attack and demonstrate its severity. In this work, we proposed ways to\ngenerate a data point of the target class without prior knowledge of the exact\ntarget distribution by using a pre-trained diffusion model.\n","authors":["Jiageng Zheng"],"pdf_url":"https://arxiv.org/pdf/2301.07557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02450v2","updated":"2023-01-18T14:00:12Z","published":"2022-06-06T09:25:40Z","title":"Optimization-based Block Coordinate Gradient Coding for Mitigating\n  Partial Stragglers in Distributed Learning","summary":"  Gradient coding schemes effectively mitigate full stragglers in distributed\nlearning by introducing identical redundancy in coded local partial derivatives\ncorresponding to all model parameters. However, they are no longer effective\nfor partial stragglers as they cannot utilize incomplete computation results\nfrom partial stragglers. This paper aims to design a new gradient coding scheme\nfor mitigating partial stragglers in distributed learning. Specifically, we\nconsider a distributed system consisting of one master and N workers,\ncharacterized by a general partial straggler model and focuses on solving a\ngeneral large-scale machine learning problem with L model parameters using\ngradient coding. First, we propose a coordinate gradient coding scheme with L\ncoding parameters representing L possibly different diversities for the L\ncoordinates, which generates most gradient coding schemes. Then, we consider\nthe minimization of the expected overall runtime and the maximization of the\ncompletion probability with respect to the L coding parameters for coordinates,\nwhich are challenging discrete optimization problems. To reduce computational\ncomplexity, we first transform each to an equivalent but much simpler discrete\nproblem with N\\llL variables representing the partition of the L coordinates\ninto N blocks, each with identical redundancy. This indicates an equivalent but\nmore easily implemented block coordinate gradient coding scheme with N coding\nparameters for blocks. Then, we adopt continuous relaxation to further reduce\ncomputational complexity. For the resulting minimization of expected overall\nruntime, we develop an iterative algorithm of computational complexity O(N^2)\nto obtain an optimal solution and derive two closed-form approximate solutions\nboth with computational complexity O(N). For the resultant maximization of the\ncompletion probability, we develop an iterative algorithm of...\n","authors":["Qi Wang","Ying Cui","Chenglin Li","Junni Zou","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2206.02450v2.pdf","comment":"17 pages, 7 figures, submitted to IEEE Trans. Signal Process. arXiv\n  admin note: text overlap with arXiv:2109.08933"},{"id":"http://arxiv.org/abs/2301.07530v1","updated":"2023-01-18T13:48:20Z","published":"2023-01-18T13:48:20Z","title":"Optimistic Dynamic Regret Bounds","summary":"  Online Learning (OL) algorithms have originally been developed to guarantee\ngood performances when comparing their output to the best fixed strategy. The\nquestion of performance with respect to dynamic strategies remains an active\nresearch topic. We develop in this work dynamic adaptations of classical OL\nalgorithms based on the use of experts' advice and the notion of optimism. We\nalso propose a constructivist method to generate those advices and eventually\nprovide both theoretical and experimental guarantees for our procedures.\n","authors":["Maxime Haddouche","Benjamin Guedj","Olivier Wintenberger"],"pdf_url":"https://arxiv.org/pdf/2301.07530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00768v2","updated":"2023-01-18T13:32:00Z","published":"2022-09-02T00:38:44Z","title":"Non-IID Quantum Federated Learning with One-shot Communication\n  Complexity","summary":"  Federated learning refers to the task of machine learning based on\ndecentralized data from multiple clients with secured data privacy. Recent\nstudies show that quantum algorithms can be exploited to boost its performance.\nHowever, when the clients' data are not independent and identically distributed\n(IID), the performance of conventional federated algorithms is known to\ndeteriorate. In this work, we explore the non-IID issue in quantum federated\nlearning with both theoretical and numerical analysis. We further prove that a\nglobal quantum channel can be exactly decomposed into local channels trained by\neach client with the help of local density estimators. This observation leads\nto a general framework for quantum federated learning on non-IID data with\none-shot communication complexity. Numerical simulations show that the proposed\nalgorithm outperforms the conventional ones significantly under non-IID\nsettings.\n","authors":["Haimeng Zhao"],"pdf_url":"https://arxiv.org/pdf/2209.00768v2.pdf","comment":"7 pages excluding appendices and references. Code available at\n  https://github.com/JasonZHM/quantum-fed-infer"},{"id":"http://arxiv.org/abs/2212.14319v2","updated":"2023-01-18T13:30:30Z","published":"2022-12-29T14:28:32Z","title":"Gaussian Process Priors for Systems of Linear Partial Differential\n  Equations with Constant Coefficients","summary":"  Partial differential equations (PDEs) are important tools to model physical\nsystems, and including them into machine learning models is an important way of\nincorporating physical knowledge. Given any system of linear PDEs with constant\ncoefficients, we propose a family of Gaussian process (GP) priors, which we\ncall EPGP, such that all realizations are exact solutions of this system. We\napply the Ehrenpreis-Palamodov fundamental principle, which works like a\nnon-linear Fourier transform, to construct GP kernels mirroring standard\nspectral methods for GPs. Our approach can infer probable solutions of linear\nPDE systems from any data such as noisy measurements, or pointwise defined\ninitial and boundary conditions. Constructing EPGP-priors is algorithmic,\ngenerally applicable, and comes with a sparse version (S-EPGP) that learns the\nrelevant spectral frequencies and works better for big data sets. We\ndemonstrate our approach on three families of systems of PDE, the heat\nequation, wave equation, and Maxwell's equations, where we improve upon the\nstate of the art in computation time and precision, in some experiments by\nseveral orders of magnitude.\n","authors":["Marc Härkönen","Markus Lange-Hegermann","Bogdan Raiţă"],"pdf_url":"https://arxiv.org/pdf/2212.14319v2.pdf","comment":"26 pages, 8 figures; updated with expanded appendices and ancillary\n  files. Code available at https://github.com/haerski/EPGP. For animations, see\n  https://mathrepo.mis.mpg.de/EPGP/index.html"},{"id":"http://arxiv.org/abs/2208.14008v2","updated":"2023-01-18T13:25:09Z","published":"2022-08-30T06:24:38Z","title":"Prediction of Red Wine Quality Using One-dimensional Convolutional\n  Neural Networks","summary":"  As an alcoholic beverage, wine has remained prevalent for thousands of years,\nand the quality assessment of wines has been significant in wine production and\ntrade. Scholars have proposed various deep learning and machine learning\nalgorithms for wine quality prediction, such as Support vector machine (SVM),\nRandom Forest (RF), K-nearest neighbors (KNN), Deep neural network (DNN), and\nLogistic regression (LR). However, these methods ignore the inner relationship\nbetween the physical and chemical properties of the wine, for example, the\ncorrelations between pH values, fixed acidity, citric acid, and so on. To fill\nthe gap, this paper conducts the Pearson correlation analysis, PCA analysis,\nand Shapiro-Wilk test on those properties and incorporates 1D-CNN architecture\nto capture the correlations among neighboring features. In addition, it\nimplemented dropout and batch normalization techniques to improve the\nrobustness of the proposed model. Massive experiments have shown that our\nmethod can outperform baseline approaches in wine quality prediction. Moreover,\nablation experiments also demonstrate the effectiveness of incorporating the\n1-D CNN module, Dropout, and normalization techniques.\n","authors":["S. Di","Y. Yang"],"pdf_url":"https://arxiv.org/pdf/2208.14008v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.04170v3","updated":"2023-01-18T13:12:32Z","published":"2021-02-08T12:53:32Z","title":"Learning Task-Oriented Communication for Edge Inference: An Information\n  Bottleneck Approach","summary":"  This paper investigates task-oriented communication for edge inference, where\na low-end edge device transmits the extracted feature vector of a local data\nsample to a powerful edge server for processing. It is critical to encode the\ndata into an informative and compact representation for low-latency inference\ngiven the limited bandwidth. We propose a learning-based communication scheme\nthat jointly optimizes feature extraction, source coding, and channel coding in\na task-oriented manner, i.e., targeting the downstream inference task rather\nthan data reconstruction. Specifically, we leverage an information bottleneck\n(IB) framework to formalize a rate-distortion tradeoff between the\ninformativeness of the encoded feature and the inference performance. As the IB\noptimization is computationally prohibitive for the high-dimensional data, we\nadopt a variational approximation, namely the variational information\nbottleneck (VIB), to build a tractable upper bound. To reduce the communication\noverhead, we leverage a sparsity-inducing distribution as the variational prior\nfor the VIB framework to sparsify the encoded feature vector. Furthermore,\nconsidering dynamic channel conditions in practical communication systems, we\npropose a variable-length feature encoding scheme based on dynamic neural\nnetworks to adaptively adjust the activated dimensions of the encoded feature\nto different channel conditions. Extensive experiments evidence that the\nproposed task-oriented communication system achieves a better rate-distortion\ntradeoff than baseline methods and significantly reduces the feature\ntransmission latency in dynamic channel conditions.\n","authors":["Jiawei Shao","Yuyi Mao","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2102.04170v3.pdf","comment":"This paper was accepted to the IEEE JSAC Series on Machine Learning\n  for Communications and Networks and will be published in Jan 2022"},{"id":"http://arxiv.org/abs/2301.07482v1","updated":"2023-01-18T12:51:13Z","published":"2023-01-18T12:51:13Z","title":"ReFresh: Reducing Memory Access from Exploiting Stable Historical\n  Embeddings for Graph Neural Network Training","summary":"  A key performance bottleneck when training graph neural network (GNN) models\non large, real-world graphs is loading node features onto a GPU. Due to limited\nGPU memory, expensive data movement is necessary to facilitate the storage of\nthese features on alternative devices with slower access (e.g. CPU memory).\nMoreover, the irregularity of graph structures contributes to poor data\nlocality which further exacerbates the problem. Consequently, existing\nframeworks capable of efficiently training large GNN models usually incur a\nsignificant accuracy degradation because of the inevitable shortcuts involved.\nTo address these limitations, we instead propose ReFresh, a general-purpose GNN\nmini-batch training framework that leverages a historical cache for storing and\nreusing GNN node embeddings instead of re-computing them through fetching raw\nfeatures at every iteration. Critical to its success, the corresponding cache\npolicy is designed, using a combination of gradient-based and staleness\ncriteria, to selectively screen those embeddings which are relatively stable\nand can be cached, from those that need to be re-computed to reduce estimation\nerrors and subsequent downstream accuracy loss. When paired with complementary\nsystem enhancements to support this selective historical cache, ReFresh is able\nto accelerate the training speed on large graph datasets such as\nogbn-papers100M and MAG240M by 4.6x up to 23.6x and reduce the memory access by\n64.5% (85.7% higher than a raw feature cache), with less than 1% influence on\ntest accuracy.\n","authors":["Kezhao Huang","Haitian Jiang","Minjie Wang","Guangxuan Xiao","David Wipf","Xiang Song","Quan Gan","Zengfeng Huang","Jidong Zhai","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.07482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07475v1","updated":"2023-01-18T12:41:12Z","published":"2023-01-18T12:41:12Z","title":"Curvilinear object segmentation in medical images based on ODoS filter\n  and deep learning network","summary":"  Automatic segmentation of curvilinear objects in medical images plays an\nimportant role in the diagnosis and evaluation of human diseases, yet it is a\nchallenging uncertainty for the complex segmentation task due to different\nissues like various image appearance, low contrast between curvilinear objects\nand their surrounding backgrounds, thin and uneven curvilinear structures, and\nimproper background illumination. To overcome these challenges, we present a\nunique curvilinear structure segmentation framework based on oriented\nderivative of stick (ODoS) filter and deep learning network for curvilinear\nobject segmentation in medical images. Currently, a large number of deep\nlearning models emphasis on developing deep architectures and ignore capturing\nthe structural features of curvature objects, which may lead to unsatisfactory\nresults. In consequence, a new approach that incorporates the ODoS filter as\npart of a deep learning network is presented to improve the spatial attention\nof curvilinear objects. In which, the original image is considered as principal\npart to describe various image appearance and complex background illumination,\nthe multi-step strategy is used to enhance contrast between curvilinear objects\nand their surrounding backgrounds, and the vector field is applied to\ndiscriminate thin and uneven curvilinear structures. Subsequently, a deep\nlearning framework is employed to extract varvious structural features for\ncurvilinear object segmentation in medical images. The performance of the\ncomputational model was validated in experiments with publicly available DRIVE,\nSTARE and CHASEDB1 datasets. Experimental results indicate that the presented\nmodel has yielded surprising results compared with some state-of-the-art\nmethods.\n","authors":["Yuanyuan Peng","Lin Pan","Pengpeng Luan","Hongbin Tu","Xiong Li"],"pdf_url":"https://arxiv.org/pdf/2301.07475v1.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.07474v1","updated":"2023-01-18T12:32:51Z","published":"2023-01-18T12:32:51Z","title":"Threats, Vulnerabilities, and Controls of Machine Learning Based\n  Systems: A Survey and Taxonomy","summary":"  In this article, we propose the Artificial Intelligence Security Taxonomy to\nsystematize the knowledge of threats, vulnerabilities, and security controls of\nML-based systems. We first classify the damage caused by attacks against\nML-based systems, define ML-specific security, and discuss its characteristics.\nNext, we enumerate all relevant assets and stakeholders and provide a general\ntaxonomy for ML-specific threats. Then, we collect a wide range of security\ncontrols against ML-specific threats through an extensive review of recent\nliterature. Finally, we classify the vulnerabilities and controls of an\nML-based system in terms of each vulnerable asset in the system's entire\nlifecycle.\n","authors":["Yusuke Kawamoto","Kazumasa Miyake","Koich Konishi","Yutaka Oiwa"],"pdf_url":"https://arxiv.org/pdf/2301.07474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07473v1","updated":"2023-01-18T12:30:44Z","published":"2023-01-18T12:30:44Z","title":"Discrete Latent Structure in Neural Networks","summary":"  Many types of data from fields including natural language processing,\ncomputer vision, and bioinformatics, are well represented by discrete,\ncompositional structures such as trees, sequences, or matchings. Latent\nstructure models are a powerful tool for learning to extract such\nrepresentations, offering a way to incorporate structural bias, discover\ninsight about the data, and interpret decisions. However, effective training is\nchallenging, as neural networks are typically designed for continuous\ncomputation.\n  This text explores three broad strategies for learning with discrete latent\nstructure: continuous relaxation, surrogate gradients, and probabilistic\nestimation. Our presentation relies on consistent notations for a wide range of\nmodels. As such, we reveal many new connections between latent structure\nlearning strategies, showing how most consist of the same small set of\nfundamental building blocks, but use them differently, leading to substantially\ndifferent applicability and properties.\n","authors":["Vlad Niculae","Caio F. Corro","Nikita Nangia","Tsvetomila Mihaylova","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2301.07473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07464v1","updated":"2023-01-18T12:16:19Z","published":"2023-01-18T12:16:19Z","title":"CLIPTER: Looking at the Bigger Picture in Scene Text Recognition","summary":"  Understanding the scene is often essential for reading text in real-world\nscenarios. However, current scene text recognizers operate on cropped text\nimages, unaware of the bigger picture. In this work, we harness the\nrepresentative power of recent vision-language models, such as CLIP, to provide\nthe crop-based recognizer with scene, image-level information. Specifically, we\nobtain a rich representation of the entire image and fuse it with the\nrecognizer word-level features via cross-attention. Moreover, a gated mechanism\nis introduced that gradually shifts to the context-enriched representation,\nenabling simply fine-tuning a pretrained recognizer. We implement our\nmodel-agnostic framework, named CLIPTER - CLIP Text Recognition, on several\nleading text recognizers and demonstrate consistent performance gains,\nachieving state-of-the-art results over multiple benchmarks. Furthermore, an\nin-depth analysis reveals improved robustness to out-of-vocabulary words and\nenhanced generalization in low-data regimes.\n","authors":["Aviad Aberdam","David Bensaïd","Alona Golts","Roy Ganz","Oren Nuriel","Royee Tichauer","Shai Mazor","Ron Litman"],"pdf_url":"https://arxiv.org/pdf/2301.07464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07069v2","updated":"2023-01-18T11:30:05Z","published":"2023-01-17T18:32:06Z","title":"Prompting Large Language Model for Machine Translation: A Case Study","summary":"  Research on prompting has shown excellent performance with little or even no\nsupervised training across many tasks. However, prompting for machine\ntranslation is still under-explored in the literature. We fill this gap by\noffering a systematic study on prompting strategies for translation, examining\nvarious factors for prompt template and demonstration example selection. We\nfurther explore the use of monolingual data and the feasibility of\ncross-lingual, cross-domain, and sentence-to-document transfer learning in\nprompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the\ntestbed show that 1) the number and the quality of prompt examples matter,\nwhere using suboptimal examples degenerates translation; 2) several features of\nprompt examples, such as semantic similarity, show significant Spearman\ncorrelation with their prompting performance; yet, none of the correlations are\nstrong enough; 3) using pseudo parallel prompt examples constructed from\nmonolingual data via zero-shot prompting could improve translation; and 4)\nimproved performance is achievable by transferring knowledge from prompt\nexamples selected in other settings. We finally provide an analysis on the\nmodel outputs and discuss several problems that prompting still suffers from.\n","authors":["Biao Zhang","Barry Haddow","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2301.07069v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/1912.02143v5","updated":"2023-01-18T11:10:24Z","published":"2019-12-04T17:47:24Z","title":"Landscape Complexity for the Empirical Risk of Generalized Linear Models","summary":"  We present a method to obtain the average and the typical value of the number\nof critical points of the empirical risk landscape for generalized linear\nestimation problems and variants. This represents a substantial extension of\nprevious applications of the Kac-Rice method since it allows to analyze the\ncritical points of high dimensional non-Gaussian random functions. Under a\ntechnical hypothesis, we obtain a rigorous explicit variational formula for the\nannealed complexity, which is the logarithm of the average number of critical\npoints at fixed value of the empirical risk. This result is simplified, and\nextended, using the non-rigorous Kac-Rice replicated method from theoretical\nphysics. In this way we find an explicit variational formula for the quenched\ncomplexity, which is generally different from its annealed counterpart, and\nallows to obtain the number of critical points for typical instances up to\nexponential accuracy.\n","authors":["Antoine Maillard","Gérard Ben Arous","Giulio Biroli"],"pdf_url":"https://arxiv.org/pdf/1912.02143v5.pdf","comment":"18 pages and 18 pages appendix. Update to match the published version\n  (v2). Corrections of remaining small typos (v3). Simplification of a\n  technical argument in Appendix A (v4) and clarification of a technical\n  hypothesis (v5)"},{"id":"http://arxiv.org/abs/2301.07433v1","updated":"2023-01-18T11:02:06Z","published":"2023-01-18T11:02:06Z","title":"DDPEN: Trajectory Optimisation With Sub Goal Generation Model","summary":"  Differential dynamic programming (DDP) is a widely used and powerful\ntrajectory optimization technique, however, due to its internal structure, it\nis not exempt from local minima. In this paper, we present Differential Dynamic\nProgramming with Escape Network (DDPEN) - a novel approach to avoid DDP local\nminima by utilising an additional term used in the optimization criteria\npointing towards the direction where robot should move in order to escape local\nminima. In order to produce the aforementioned directions, we propose to\nutilize a deep model that takes as an input the map of the environment in the\nform of a costmap together with the desired goal position. The Model produces\npossible future directions that will lead to the goal, avoiding local minima\nwhich is possible to run in real time conditions. The model is trained on a\nsynthetic dataset and overall the system is evaluated at the Gazebo simulator.\nIn this work we show that our proposed method allows avoiding local minima of\ntrajectory optimization algorithm and successfully execute a trajectory 278 m\nlong with various convex and nonconvex obstacles.\n","authors":["Aleksander Gamayunov","Aleksey Postnikov","Gonzalo Ferrer"],"pdf_url":"https://arxiv.org/pdf/2301.07433v1.pdf","comment":"4 pages, 6 figures, IROS2022 Workshop: Artificial Intelligence for\n  Social Robots Interacting with Humans in the Real World [intellect4hri]"},{"id":"http://arxiv.org/abs/2301.07424v1","updated":"2023-01-18T10:47:43Z","published":"2023-01-18T10:47:43Z","title":"Autonomous Slalom Maneuver Based on Expert Drivers' Behavior Using\n  Convolutional Neural Network","summary":"  Lane changing and obstacle avoidance are one of the most important tasks in\nautomated cars. To date, many algorithms have been suggested that are generally\nbased on path trajectory or reinforcement learning approaches. Although these\nmethods have been efficient, they are not able to accurately imitate a smooth\npath traveled by an expert driver. In this paper, a method is presented to\nmimic drivers' behavior using a convolutional neural network (CNN). First,\nseven features are extracted from a dataset gathered from four expert drivers\nin a driving simulator. Then, these features are converted from 1D arrays to 2D\narrays and injected into a CNN. The CNN model computes the desired steering\nwheel angle and sends it to an adaptive PD controller. Finally, the control\nunit applies proper torque to the steering wheel. Results show that the CNN\nmodel can mimic the drivers' behavior with an R2-squared of 0.83. Also, the\nperformance of the presented method was evaluated in the driving simulator for\n17 trials, which avoided all traffic cones successfully. In some trials, the\npresented method performed a smoother maneuver compared to the expert drivers.\n","authors":["Shafagh A. Pashaki","Ali Nahvi","Ahmad Ahmadi","Sajad Tavakoli","Shahin Naeemi","Salar H. Shamchi"],"pdf_url":"https://arxiv.org/pdf/2301.07424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02478v2","updated":"2023-01-18T10:44:33Z","published":"2022-11-04T14:08:53Z","title":"Concentration inequalities for leave-one-out cross validation","summary":"  In this article we prove that estimator stability is enough to show that\nleave-one-out cross validation is a sound procedure, by providing concentration\nbounds in a general framework. In particular, we provide concentration bounds\nbeyond Lipschitz continuity assumptions on the loss or on the estimator. In\norder to obtain our results, we rely on random variables with distribution\nsatisfying the logarithmic Sobolev inequality, providing us a relatively rich\nclass of distributions. We illustrate our method by considering several\ninteresting examples, including linear regression, kernel density estimation,\nand stabilized / truncated estimators such as stabilized kernel regression.\n","authors":["Benny Avelin","Lauri Viitasaari"],"pdf_url":"https://arxiv.org/pdf/2211.02478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07421v1","updated":"2023-01-18T10:42:00Z","published":"2023-01-18T10:42:00Z","title":"DIRECT: Learning from Sparse and Shifting Rewards using Discriminative\n  Reward Co-Training","summary":"  We propose discriminative reward co-training (DIRECT) as an extension to deep\nreinforcement learning algorithms. Building upon the concept of self-imitation\nlearning (SIL), we introduce an imitation buffer to store beneficial\ntrajectories generated by the policy determined by their return. A\ndiscriminator network is trained concurrently to the policy to distinguish\nbetween trajectories generated by the current policy and beneficial\ntrajectories generated by previous policies. The discriminator's verdict is\nused to construct a reward signal for optimizing the policy. By interpolating\nprior experience, DIRECT is able to act as a surrogate, steering policy\noptimization towards more valuable regions of the reward landscape thus\nlearning an optimal policy. Our results show that DIRECT outperforms\nstate-of-the-art algorithms in sparse- and shifting-reward environments being\nable to provide a surrogate reward to the policy and direct the optimization\ntowards valuable areas.\n","authors":["Philipp Altmann","Thomy Phan","Fabian Ritz","Thomas Gabor","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2301.07421v1.pdf","comment":"9 pages, 10 figures, under review"},{"id":"http://arxiv.org/abs/2301.07420v1","updated":"2023-01-18T10:32:53Z","published":"2023-01-18T10:32:53Z","title":"Compression of GPS Trajectories using Autoencoders","summary":"  The ubiquitous availability of mobile devices capable of location tracking\nled to a significant rise in the collection of GPS data. Several compression\nmethods have been developed in order to reduce the amount of storage needed\nwhile keeping the important information. In this paper, we present an\nlstm-autoencoder based approach in order to compress and reconstruct GPS\ntrajectories, which is evaluated on both a gaming and real-world dataset. We\nconsider various compression ratios and trajectory lengths. The performance is\ncompared to other trajectory compression algorithms, i.e., Douglas-Peucker.\nOverall, the results indicate that our approach outperforms Douglas-Peucker\nsignificantly in terms of the discrete Fr\\'echet distance and dynamic time\nwarping. Furthermore, by reconstructing every point lossy, the proposed\nmethodology offers multiple advantages over traditional methods.\n","authors":["Michael Kölle","Steffen Illium","Carsten Hahn","Lorenz Schauer","Johannes Hutter","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2301.07420v1.pdf","comment":"Accepted at ICAART 2023"},{"id":"http://arxiv.org/abs/2103.04689v3","updated":"2023-01-18T09:57:38Z","published":"2021-03-08T11:52:51Z","title":"Reverse Differentiation via Predictive Coding","summary":"  Deep learning has redefined the field of artificial intelligence (AI) thanks\nto the rise of artificial neural networks, which are architectures inspired by\ntheir neurological counterpart in the brain. Through the years, this dualism\nbetween AI and neuroscience has brought immense benefits to both fields,\nallowing neural networks to be used in dozens of applications. These networks\nuse an efficient implementation of reverse differentiation, called\nbackpropagation (BP). This algorithm, however, is often criticized for its\nbiological implausibility (e.g., lack of local update rules for the\nparameters). Therefore, biologically plausible learning methods that rely on\npredictive coding (PC), a framework for describing information processing in\nthe brain, are increasingly studied. Recent works prove that these methods can\napproximate BP up to a certain margin on multilayer perceptrons (MLPs), and\nasymptotically on any other complex model, and that zero-divergence inference\nlearning (Z-IL), a variant of PC, is able to exactly implement BP on MLPs.\nHowever, the recent literature shows also that there is no biologically\nplausible method yet that can exactly replicate the weight update of BP on\ncomplex models. To fill this gap, in this paper, we generalize (PC and) Z-IL by\ndirectly defining them on computational graphs, and show that it can perform\nexact reverse differentiation. What results is the first biologically plausible\nalgorithm that is equivalent to BP in the way of updating parameters on any\nneural network, providing a bridge between the interdisciplinary research of\nneuroscience and deep learning.\n","authors":["Tommaso Salvatori","Yuhang Song","Thomas Lukasiewicz","Rafal Bogacz","Zhenghua Xu"],"pdf_url":"https://arxiv.org/pdf/2103.04689v3.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.07390v1","updated":"2023-01-18T09:37:05Z","published":"2023-01-18T09:37:05Z","title":"Relativistic Digital Twin: Bringing the IoT to the Future","summary":"  Complex IoT ecosystems often require the usage of Digital Twins (DTs) of\ntheir physical assets in order to perform predictive analytics and simulate\nwhat-if scenarios. DTs are able to replicate IoT devices and adapt over time to\ntheir behavioral changes. However, DTs in IoT are typically tailored to a\nspecific use case, without the possibility to seamlessly adapt to different\nscenarios. Further, the fragmentation of IoT poses additional challenges on how\nto deploy DTs in heterogeneous scenarios characterized by the usage of multiple\ndata formats and IoT network protocols. In this paper, we propose the\nRelativistic Digital Twin (RDT) framework, through which we automatically\ngenerate general purpose DTs of IoT entities and tune their behavioral models\nover time by constantly observing their real counterparts. The framework relies\non the object representation via the Web of Things (WoT), to offer a\nstandardized interface to each of the IoT devices as well as to their DTs. To\nthis purpose, we extended the W3C WoT standard in order to encompass the\nconcept of behavioral model and define it in the Thing Description (TD) through\na new vocabulary. Finally, we evaluated the RDT framework over two disjoint use\ncases to assess its correctness and learning performance, i.e. the DT of a\nsimulated smart home scenario with the capability of forecasting the indoor\ntemperature, and the DT of a real-world drone with the capability of\nforecasting its trajectory in an outdoor scenario.\n","authors":["Luca Sciullo","Alberto De Marchi","Angelo Trotta","Federico Montori","Luciano Bononi","Marco Di Felice"],"pdf_url":"https://arxiv.org/pdf/2301.07390v1.pdf","comment":"16 pages, 10 figures, 3 tables, 6 listings. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2301.07389v1","updated":"2023-01-18T09:36:41Z","published":"2023-01-18T09:36:41Z","title":"Towards Models that Can See and Read","summary":"  Visual Question Answering (VQA) and Image Captioning (CAP), which are among\nthe most popular vision-language tasks, have analogous scene-text versions that\nrequire reasoning from the text in the image. Despite the obvious resemblance\nbetween them, the two are treated independently, yielding task-specific methods\nthat can either see or read, but not both. In this work, we conduct an in-depth\nanalysis of this phenomenon and propose UniTNT, a Unified Text-Non-Text\napproach, which grants existing multimodal architectures scene-text\nunderstanding capabilities. Specifically, we treat scene-text information as an\nadditional modality, fusing it with any pretrained encoder-decoder-based\narchitecture via designated modules. Thorough experiments reveal that UniTNT\nleads to the first single model that successfully handles both task types.\nMoreover, we show that scene-text understanding capabilities can boost\nvision-language models' performance on VQA and CAP by up to 3.49% and 0.7\nCIDEr, respectively.\n","authors":["Roy Ganz","Oren Nuriel","Aviad Aberdam","Yair Kittenplon","Shai Mazor","Ron Litman"],"pdf_url":"https://arxiv.org/pdf/2301.07389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07388v1","updated":"2023-01-18T09:32:33Z","published":"2023-01-18T09:32:33Z","title":"Learning Deformation Trajectories of Boltzmann Densities","summary":"  We introduce a training objective for continuous normalizing flows that can\nbe used in the absence of samples but in the presence of an energy function.\nOur method relies on either a prescribed or a learnt interpolation $f_t$ of\nenergy functions between the target energy $f_1$ and the energy function of a\ngeneralized Gaussian $f_0(x) = (|x|/\\sigma)^p$. This then induces an\ninterpolation of Boltzmann densities $p_t \\propto e^{-f_t}$ and we aim to find\na time-dependent vector field $V_t$ that transports samples along this family\nof densities. Concretely, this condition can be translated to a PDE between\n$V_t$ and $f_t$ and we minimize the amount by which this PDE fails to hold. We\ncompare this objective to the reverse KL-divergence on Gaussian mixtures and on\nthe $\\phi^4$ lattice field theory on a circle.\n","authors":["Bálint Máté","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2301.07388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01519v3","updated":"2023-01-18T09:27:49Z","published":"2022-12-03T03:27:51Z","title":"Beyond ADMM: A Unified Client-variance-reduced Adaptive Federated\n  Learning Framework","summary":"  As a novel distributed learning paradigm, federated learning (FL) faces\nserious challenges in dealing with massive clients with heterogeneous data\ndistribution and computation and communication resources. Various\nclient-variance-reduction schemes and client sampling strategies have been\nrespectively introduced to improve the robustness of FL. Among others,\nprimal-dual algorithms such as the alternating direction of method multipliers\n(ADMM) have been found being resilient to data distribution and outperform most\nof the primal-only FL algorithms. However, the reason behind remains a mystery\nstill. In this paper, we firstly reveal the fact that the federated ADMM is\nessentially a client-variance-reduced algorithm. While this explains the\ninherent robustness of federated ADMM, the vanilla version of it lacks the\nability to be adaptive to the degree of client heterogeneity. Besides, the\nglobal model at the server under client sampling is biased which slows down the\npractical convergence. To go beyond ADMM, we propose a novel primal-dual FL\nalgorithm, termed FedVRA, that allows one to adaptively control the\nvariance-reduction level and biasness of the global model. In addition, FedVRA\nunifies several representative FL algorithms in the sense that they are either\nspecial instances of FedVRA or are close to it. Extensions of FedVRA to\nsemi/un-supervised learning are also presented. Experiments based on\n(semi-)supervised image classification tasks demonstrate superiority of FedVRA\nover the existing schemes in learning scenarios with massive heterogeneous\nclients and client sampling.\n","authors":["Shuai Wang","Yanqing Xu","Zhiguo Wang","Tsung-Hui Chang","Tony Q. S. Quek","Defeng Sun"],"pdf_url":"https://arxiv.org/pdf/2212.01519v3.pdf","comment":null},{"id":"http://arxiv.org/abs/1909.12488v2","updated":"2023-01-18T08:30:06Z","published":"2019-09-27T04:26:37Z","title":"Improving Federated Learning Personalization via Model Agnostic Meta\n  Learning","summary":"  Federated Learning (FL) refers to learning a high quality global model based\non decentralized data storage, without ever copying the raw data. A natural\nscenario arises with data created on mobile phones by the activity of their\nusers. Given the typical data heterogeneity in such situations, it is natural\nto ask how can the global model be personalized for every such device,\nindividually. In this work, we point out that the setting of Model Agnostic\nMeta Learning (MAML), where one optimizes for a fast, gradient-based, few-shot\nadaptation to a heterogeneous distribution of tasks, has a number of\nsimilarities with the objective of personalization for FL. We present FL as a\nnatural source of practical applications for MAML algorithms, and make the\nfollowing observations. 1) The popular FL algorithm, Federated Averaging, can\nbe interpreted as a meta learning algorithm. 2) Careful fine-tuning can yield a\nglobal model with higher accuracy, which is at the same time easier to\npersonalize. However, solely optimizing for the global model accuracy yields a\nweaker personalization result. 3) A model trained using a standard datacenter\noptimization method is much harder to personalize, compared to one trained\nusing Federated Averaging, supporting the first claim. These results raise new\nquestions for FL, MAML, and broader ML research.\n","authors":["Yihan Jiang","Jakub Konečný","Keith Rush","Sreeram Kannan"],"pdf_url":"https://arxiv.org/pdf/1909.12488v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07361v1","updated":"2023-01-18T08:10:49Z","published":"2023-01-18T08:10:49Z","title":"Dirichlet-Neumann learning algorithm for solving elliptic interface\n  problems","summary":"  Non-overlapping domain decomposition methods are natural for solving\ninterface problems arising from various disciplines, however, the numerical\nsimulation requires technical analysis and is often available only with the use\nof high-quality grids, thereby impeding their use in more complicated\nsituations. To remove the burden of mesh generation and to effectively tackle\nwith the interface jump conditions, a novel mesh-free scheme, i.e.,\nDirichlet-Neumann learning algorithm, is proposed in this work to solve the\nbenchmark elliptic interface problem with high-contrast coefficients as well as\nirregular interfaces. By resorting to the variational principle, we carry out a\nrigorous error analysis to evaluate the discrepancy caused by the boundary\npenalty treatment for each decomposed subproblem, which paves the way for\nrealizing the Dirichlet-Neumann algorithm using neural network extension\noperators. The effectiveness and robustness of our proposed methods are\ndemonstrated experimentally through a series of elliptic interface problems,\nachieving better performance over other alternatives especially in the presence\nof erroneous flux prediction at interface.\n","authors":["Qi Sun","Xuejun Xu","Haotian Yi"],"pdf_url":"https://arxiv.org/pdf/2301.07361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07901v2","updated":"2023-01-18T08:00:01Z","published":"2022-02-16T07:09:04Z","title":"Auxiliary Cross-Modal Representation Learning with Triplet Loss\n  Functions for Online Handwriting Recognition","summary":"  Cross-modal representation learning learns a shared embedding between two or\nmore modalities to improve performance in a given task compared to using only\none of the modalities. Cross-modal representation learning from different data\ntypes -- such as images and time-series data (e.g., audio or text data) --\nrequires a deep metric learning loss that minimizes the distance between the\nmodality embeddings. In this paper, we propose to use the triplet loss, which\nuses positive and negative identities to create sample pairs with different\nlabels, for cross-modal representation learning between image and time-series\nmodalities (CMR-IS). By adapting the triplet loss for cross-modal\nrepresentation learning, higher accuracy in the main (time-series\nclassification) task can be achieved by exploiting additional information of\nthe auxiliary (image classification) task. Our experiments on synthetic data\nand handwriting recognition data from sensor-enhanced pens show improved\nclassification accuracy, faster convergence, and better generalizability.\n","authors":["Felix Ott","David Rügamer","Lucas Heublein","Bernd Bischl","Christopher Mutschler"],"pdf_url":"https://arxiv.org/pdf/2202.07901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06418v2","updated":"2023-01-18T07:22:53Z","published":"2023-01-16T13:19:18Z","title":"- Modelling Difference Between Censored and Uncensored Electric Vehicle\n  Charging Demand","summary":"  Electric vehicle charging demand models, with charging records as input, will\ninherently be biased toward the supply of available chargers, as the data do\nnot include demand lost from occupied stations and competitors. This lost\ndemand implies that the records only observe a fraction of the total demand,\ni.e. the observations are censored, and actual demand is likely higher than\nwhat the data reflect. Machine learning models often neglect to account for\nthis censored demand when forecasting the charging demand, which limits models'\napplications for future expansions and supply management. We address this gap\nby modelling the charging demand with probabilistic censorship-aware graph\nneural networks, which learn the latent demand distribution in both the spatial\nand temporal dimensions. We use GPS trajectories from cars in Copenhagen,\nDenmark, to study how censoring occurs and much demand is lost due to occupied\ncharging and competing services. We find that censorship varies throughout the\ncity and over time, encouraging spatial and temporal modelling. We find that in\nsome regions of Copenhagen, censorship occurs 61% of the time. Our results show\ncensorship-aware models provide better prediction and uncertainty estimation in\nactual future demand than censorship-unaware models. Our results suggest that\nfuture models based on charging records should account for the censoring to\nexpand the application areas of machine learning models in this supply\nmanagement and infrastructure expansion.\n","authors":["Frederik Boe Hüttel","Filipe Rodrigues","Francisco Câmara Pereira"],"pdf_url":"https://arxiv.org/pdf/2301.06418v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12403v2","updated":"2023-01-18T07:21:51Z","published":"2022-01-28T20:26:55Z","title":"Planning and Learning with Adaptive Lookahead","summary":"  Some of the most powerful reinforcement learning frameworks use planning for\naction selection. Interestingly, their planning horizon is either fixed or\ndetermined arbitrarily by the state visitation history. Here, we expand beyond\nthe naive fixed horizon and propose a theoretically justified strategy for\nadaptive selection of the planning horizon as a function of the state-dependent\nvalue estimate. We propose two variants for lookahead selection and analyze the\ntrade-off between iteration count and computational complexity per iteration.\nWe then devise a corresponding deep Q-network algorithm with an adaptive tree\nsearch horizon. We separate the value estimation per depth to compensate for\nthe off-policy discrepancy between depths. Lastly, we demonstrate the efficacy\nof our adaptive lookahead method in a maze environment and Atari.\n","authors":["Aviv Rosenberg","Assaf Hallak","Shie Mannor","Gal Chechik","Gal Dalal"],"pdf_url":"https://arxiv.org/pdf/2201.12403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06701v2","updated":"2023-01-18T07:05:40Z","published":"2023-01-17T04:57:31Z","title":"Operator Learning Framework for Digital Twin and Complex Engineering\n  Systems","summary":"  With modern computational advancements and statistical analysis methods,\nmachine learning algorithms have become a vital part of engineering modeling.\nNeural Operator Networks (ONets) is an emerging machine learning algorithm as a\n\"faster surrogate\" for approximating solutions to partial differential\nequations (PDEs) due to their ability to approximate mathematical operators\nversus the direct approximation of Neural Networks (NN). ONets use the\nUniversal Approximation Theorem to map finite-dimensional inputs to\ninfinite-dimensional space using the branch-trunk architecture, which encodes\ndomain and feature information separately before using a dot product to combine\nthe information. ONets are expected to occupy a vital niche for surrogate\nmodeling in physical systems and Digital Twin (DT) development. Three test\ncases are evaluated using ONets for operator approximation, including a\n1-dimensional ordinary differential equations (ODE), general diffusion system,\nand convection-diffusion (Burger) system. Solutions for ODE and diffusion\nsystems yield accurate and reliable results (R2>0.95), while solutions for\nBurger systems need further refinement in the ONet algorithm.\n","authors":["Kazuma Kobayashi","James Daniell","Syed B. Alam"],"pdf_url":"https://arxiv.org/pdf/2301.06701v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09189v2","updated":"2023-01-18T07:03:18Z","published":"2022-08-19T07:28:31Z","title":"Cross-Domain Evaluation of a Deep Learning-Based Type Inference System","summary":"  Optional type annotations allow for enriching dynamic programming languages\nwith static typing features like better Integrated Development Environment\n(IDE) support, more precise program analysis, and early detection and\nprevention of type-related runtime errors. Machine learning-based type\ninference promises interesting results for automating this task. However, the\npractical usage of such systems depends on their ability to generalize across\ndifferent domains, as they are often applied outside their training domain. In\nthis work, we investigate Type4Py as a representative of state-of-the-art deep\nlearning-based type inference systems, by conducting extensive cross-domain\nexperiments. Thereby, we address the following problems: class imbalances,\nout-of-vocabulary words, dataset shifts, and unknown classes. To perform such\nexperiments, we use the datasets ManyTypes4Py and CrossDomainTypes4Py. The\nlatter we introduce in this paper. Our dataset enables the evaluation of type\ninference systems in different domains of software projects and has over\n1,000,000 type annotations mined on the platforms GitHub and Libraries. It\nconsists of data from the two domains web development and scientific\ncalculation. Through our experiments, we detect that the shifts in the dataset\nand the long-tailed distribution with many rare and unknown data types decrease\nthe performance of the deep learning-based type inference system drastically.\nIn this context, we test unsupervised domain adaptation methods and fine-tuning\nto overcome these issues. Moreover, we investigate the impact of\nout-of-vocabulary words.\n","authors":["Bernd Gruner","Tim Sonnekalb","Thomas S. Heinze","Clemens-Alexander Brust"],"pdf_url":"https://arxiv.org/pdf/2208.09189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05816v2","updated":"2023-01-18T05:54:07Z","published":"2023-01-14T04:21:25Z","title":"Understanding the Spectral Bias of Coordinate Based MLPs Via Training\n  Dynamics","summary":"  Recently, multi-layer perceptrons (MLPs) with ReLU activations have enabled\nnew photo-realistic rendering techniques by encoding scene properties using\ntheir weights. For these models, termed coordinate based MLPs, sinusoidal\nencodings are necessary in allowing for convergence to the high frequency\ncomponents of the signal due to their severe spectral bias. Previous work has\nexplained this phenomenon using Neural Tangent Kernel (NTK) and Fourier\nanalysis. However, the kernel regime does not expose the properties of the\nnetwork that induce this behavior, and the Fourier decomposition is global, not\nallowing for insight on the network's local dynamics. A new interpretation of\nspectral bias directly through ReLU network computations would expose their\nlimitations in dense settings, while providing a clearer explanation as to how\nthis behavior emerges during the learning process. In this paper, we provide\nthe first study of spectral bias in a coordinate based MLP through its\nactivation regions and gradient descent dynamics, specifically using gradient\nconfusion. We relate the confusion between inputs to the distinctiveness of\ntheir activation patterns, and find higher amounts of confusion when expressive\npower is limited. This leads to slower convergence to the high frequency\ncomponents of the signal, which is magnified by the density of coordinates.\nAdditionally, this method allows us to analyze the properties of the activation\nregions as spectral bias is reduced, in which we find distinct dynamics.\n","authors":["John Lazzari","Xiuwen Liu"],"pdf_url":"https://arxiv.org/pdf/2301.05816v2.pdf","comment":"8 pages, 10 figures, preprint"},{"id":"http://arxiv.org/abs/2301.07316v1","updated":"2023-01-18T05:36:06Z","published":"2023-01-18T05:36:06Z","title":"Adaptively Integrated Knowledge Distillation and Prediction Uncertainty\n  for Continual Learning","summary":"  Current deep learning models often suffer from catastrophic forgetting of old\nknowledge when continually learning new knowledge. Existing strategies to\nalleviate this issue often fix the trade-off between keeping old knowledge\n(stability) and learning new knowledge (plasticity). However, the\nstability-plasticity trade-off during continual learning may need to be\ndynamically changed for better model performance. In this paper, we propose two\nnovel ways to adaptively balance model stability and plasticity. The first one\nis to adaptively integrate multiple levels of old knowledge and transfer it to\neach block level in the new model. The second one uses prediction uncertainty\nof old knowledge to naturally tune the importance of learning new knowledge\nduring model training. To our best knowledge, this is the first time to connect\nmodel prediction uncertainty and knowledge distillation for continual learning.\nIn addition, this paper applies a modified CutMix particularly to augment the\ndata for old knowledge, further alleviating the catastrophic forgetting issue.\nExtensive evaluations on the CIFAR100 and the ImageNet datasets confirmed the\neffectiveness of the proposed method for continual learning.\n","authors":["Kanghao Chen","Sijia Liu","Ruixuan Wang","Wei-Shi Zheng"],"pdf_url":"https://arxiv.org/pdf/2301.07316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08708v2","updated":"2023-01-18T05:15:26Z","published":"2022-10-17T02:48:58Z","title":"Teacher Forcing Recovers Reward Functions for Text Generation","summary":"  Reinforcement learning (RL) has been widely used in text generation to\nalleviate the exposure bias issue or to utilize non-parallel datasets. The\nreward function plays an important role in making RL training successful.\nHowever, previous reward functions are typically task-specific and sparse,\nrestricting the use of RL. In our work, we propose a task-agnostic approach\nthat derives a step-wise reward function directly from a model trained with\nteacher forcing. We additionally propose a simple modification to stabilize the\nRL training on non-parallel datasets with our induced reward function.\nEmpirical results show that our method outperforms self-training and reward\nregression methods on several text generation tasks, confirming the\neffectiveness of our reward function.\n","authors":["Yongchang Hao","Yuxin Liu","Lili Mou"],"pdf_url":"https://arxiv.org/pdf/2210.08708v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.07306v1","updated":"2023-01-18T04:54:58Z","published":"2023-01-18T04:54:58Z","title":"Improve Noise Tolerance of Robust Loss via Noise-Awareness","summary":"  Robust loss minimization is an important strategy for handling robust\nlearning issue on noisy labels. Current robust losses, however, inevitably\ninvolve hyperparameters to be tuned for different datasets with noisy labels,\nmanually or heuristically through cross validation, which makes them fairly\nhard to be generally applied in practice. Existing robust loss methods usually\nassume that all training samples share common hyperparameters, which are\nindependent of instances. This limits the ability of these methods on\ndistinguishing individual noise properties of different samples, making them\nhardly adapt to different noise structures. To address above issues, we propose\nto assemble robust loss with instance-dependent hyperparameters to improve\ntheir noise-tolerance with theoretical guarantee. To achieve setting such\ninstance-dependent hyperparameters for robust loss, we propose a meta-learning\nmethod capable of adaptively learning a hyperparameter prediction function,\ncalled Noise-Aware-Robust-Loss-Adjuster (NARL-Adjuster). Specifically, through\nmutual amelioration between hyperparameter prediction function and classifier\nparameters in our method, both of them can be simultaneously finely ameliorated\nand coordinated to attain solutions with good generalization capability. Four\nkinds of SOTA robust losses are attempted to be integrated with our algorithm,\nand experiments substantiate the general availability and effectiveness of the\nproposed method in both its noise tolerance and generalization performance.\nMeanwhile, the explicit parameterized structure makes the meta-learned\nprediction function capable of being readily transferrable and plug-and-play to\nunseen datasets with noisy labels. Specifically, we transfer our meta-learned\nNARL-Adjuster to unseen tasks, including several real noisy datasets, and\nachieve better performance compared with conventional hyperparameter tuning\nstrategy.\n","authors":["Kehui Ding","Jun Shu","Deyu Meng","Zongben Xu"],"pdf_url":"https://arxiv.org/pdf/2301.07306v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2002.06482"},{"id":"http://arxiv.org/abs/2211.00802v2","updated":"2023-01-18T04:45:10Z","published":"2022-11-02T00:41:37Z","title":"Concrete Score Matching: Generalized Score Matching for Discrete Data","summary":"  Representing probability distributions by the gradient of their density\nfunctions has proven effective in modeling a wide range of continuous data\nmodalities. However, this representation is not applicable in discrete domains\nwhere the gradient is undefined. To this end, we propose an analogous score\nfunction called the \"Concrete score\", a generalization of the (Stein) score for\ndiscrete settings. Given a predefined neighborhood structure, the Concrete\nscore of any input is defined by the rate of change of the probabilities with\nrespect to local directional changes of the input. This formulation allows us\nto recover the (Stein) score in continuous domains when measuring such changes\nby the Euclidean distance, while using the Manhattan distance leads to our\nnovel score function in discrete domains. Finally, we introduce a new framework\nto learn such scores from samples called Concrete Score Matching (CSM), and\npropose an efficient training objective to scale our approach to high\ndimensions. Empirically, we demonstrate the efficacy of CSM on density\nestimation tasks on a mixture of synthetic, tabular, and high-dimensional image\ndatasets, and demonstrate that it performs favorably relative to existing\nbaselines for modeling discrete data.\n","authors":["Chenlin Meng","Kristy Choi","Jiaming Song","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2211.00802v2.pdf","comment":"NeurIPS 2022. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2301.07302v1","updated":"2023-01-18T04:40:50Z","published":"2023-01-18T04:40:50Z","title":"PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav","summary":"  We study ObjectGoal Navigation - where a virtual robot situated in a new\nenvironment is asked to navigate to an object. Prior work has shown that\nimitation learning (IL) on a dataset of human demonstrations achieves promising\nresults. However, this has limitations $-$ 1) IL policies generalize poorly to\nnew states, since the training mimics actions not their consequences, and 2)\ncollecting demonstrations is expensive. On the other hand, reinforcement\nlearning (RL) is trivially scalable, but requires careful reward engineering to\nachieve desirable behavior. We present a two-stage learning scheme for IL\npretraining on human demonstrations followed by RL-finetuning. This leads to a\nPIRLNav policy that advances the state-of-the-art on ObjectNav from $60.0\\%$\nsuccess rate to $65.0\\%$ ($+5.0\\%$ absolute). Using this IL$\\rightarrow$RL\ntraining recipe, we present a rigorous empirical analysis of design choices.\nFirst, we investigate whether human demonstrations can be replaced with `free'\n(automatically generated) sources of demonstrations, e.g. shortest paths (SP)\nor task-agnostic frontier exploration (FE) trajectories. We find that\nIL$\\rightarrow$RL on human demonstrations outperforms IL$\\rightarrow$RL on SP\nand FE trajectories, even when controlled for the same IL-pretraining success\non TRAIN, and even on a subset of VAL episodes where IL-pretraining success\nfavors the SP or FE policies. Next, we study how RL-finetuning performance\nscales with the size of the IL pretraining dataset. We find that as we increase\nthe size of the IL-pretraining dataset and get to high IL accuracies, the\nimprovements from RL-finetuning are smaller, and that $90\\%$ of the performance\nof our best IL$\\rightarrow$RL policy can be achieved with less than half the\nnumber of IL demonstrations. Finally, we analyze failure modes of our ObjectNav\npolicies, and present guidelines for further improving them.\n","authors":["Ram Ramrakhya","Dhruv Batra","Erik Wijmans","Abhishek Das"],"pdf_url":"https://arxiv.org/pdf/2301.07302v1.pdf","comment":"8 pages + supplement"},{"id":"http://arxiv.org/abs/2301.07301v1","updated":"2023-01-18T04:35:49Z","published":"2023-01-18T04:35:49Z","title":"PTA-Det: Point Transformer Associating Point cloud and Image for 3D\n  Object Detection","summary":"  In autonomous driving, 3D object detection based on multi-modal data has\nbecome an indispensable approach when facing complex environments around the\nvehicle. During multi-modal detection, LiDAR and camera are simultaneously\napplied for capturing and modeling. However, due to the intrinsic discrepancies\nbetween the LiDAR point and camera image, the fusion of the data for object\ndetection encounters a series of problems. Most multi-modal detection methods\nperform even worse than LiDAR-only methods. In this investigation, we propose a\nmethod named PTA-Det to improve the performance of multi-modal detection.\nAccompanied by PTA-Det, a Pseudo Point Cloud Generation Network is proposed,\nwhich can convert image information including texture and semantic features by\npseudo points. Thereafter, through a transformer-based Point Fusion Transition\n(PFT) module, the features of LiDAR points and pseudo points from image can be\ndeeply fused under a unified point-based representation. The combination of\nthese modules can conquer the major obstacle in feature fusion across\nmodalities and realizes a complementary and discriminative representation for\nproposal generation. Extensive experiments on the KITTI dataset show the\nPTA-Det achieves a competitive result and support its effectiveness.\n","authors":["Rui Wan","Tianyun Zhao","Wei Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.07301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.02359v3","updated":"2023-01-18T04:23:03Z","published":"2021-06-04T09:17:15Z","title":"How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social\n  Impact","summary":"  Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via the moral philosophy definition of social good, propose a\nframework to evaluate the direct and indirect real-world impact of NLP tasks,\nand adopt the methodology of global priorities research to identify priority\ncauses for NLP research. Finally, we use our theoretical framework to provide\nsome practical guidelines for future NLP research for social good. Our data and\ncode are available at http://github.com/zhijing-jin/nlp4sg_acl2021. In\naddition, we curate a list of papers and resources on NLP for social good at\nhttps://github.com/zhijing-jin/NLP4SocialGood_Papers.\n","authors":["Zhijing Jin","Geeticka Chauhan","Brian Tse","Mrinmaya Sachan","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2106.02359v3.pdf","comment":"Findings of ACL 2021; also accepted at the NLP for Positive Impact\n  workshop@ACL 2021"},{"id":"http://arxiv.org/abs/2006.14563v3","updated":"2023-01-18T04:17:47Z","published":"2020-06-25T17:06:47Z","title":"Dynamically Mitigating Data Discrepancy with Balanced Focal Loss for\n  Replay Attack Detection","summary":"  It becomes urgent to design effective anti-spoofing algorithms for vulnerable\nautomatic speaker verification systems due to the advancement of high-quality\nplayback devices. Current studies mainly treat anti-spoofing as a binary\nclassification problem between bonafide and spoofed utterances, while lack of\nindistinguishable samples makes it difficult to train a robust spoofing\ndetector. In this paper, we argue that for anti-spoofing, it needs more\nattention for indistinguishable samples over easily-classified ones in the\nmodeling process, to make correct discrimination a top priority. Therefore, to\nmitigate the data discrepancy between training and inference, we propose D3M,\nto leverage a balanced focal loss function as the training objective to\ndynamically scale the loss based on the traits of the sample itself. Besides,\nin the experiments, we select three kinds of features that contain both\nmagnitude-based and phase-based information to form complementary and\ninformative features. Experimental results on the ASVspoof2019 dataset\ndemonstrate the superiority of the proposed methods by comparison between our\nsystems and top-performing ones. Systems trained with the balanced focal loss\nperform significantly better than conventional cross-entropy loss. With\ncomplementary features, our fusion system with only three kinds of features\noutperforms other systems containing five or more complex single models by\n22.5% for min-tDCF and 7% for EER, achieving a min-tDCF and an EER of 0.0124\nand 0.55% respectively. Furthermore, we present and discuss the evaluation\nresults on real replay data apart from the simulated ASVspoof2019 data,\nindicating that research for anti-spoofing still has a long way to go. Source\ncode, analysis data, and other details are publicly available at\nhttps://github.com/asvspoof/D3M.\n","authors":["Yongqiang Dou","Haocheng Yang","Maolin Yang","Yanyan Xu","Dengfeng Ke"],"pdf_url":"https://arxiv.org/pdf/2006.14563v3.pdf","comment":"The 25th International Conference on Pattern Recognition (ICPR2020)"},{"id":"http://arxiv.org/abs/2301.07295v1","updated":"2023-01-18T03:57:53Z","published":"2023-01-18T03:57:53Z","title":"Adapting Multilingual Speech Representation Model for a New,\n  Underresourced Language through Multilingual Fine-tuning and Continued\n  Pretraining","summary":"  In recent years, neural models learned through self-supervised pretraining on\nlarge scale multilingual text or speech data have exhibited promising results\nfor underresourced languages, especially when a relatively large amount of data\nfrom related language(s) is available. While the technology has a potential for\nfacilitating tasks carried out in language documentation projects, such as\nspeech transcription, pretraining a multilingual model from scratch for every\nnew language would be highly impractical. We investigate the possibility for\nadapting an existing multilingual wav2vec 2.0 model for a new language,\nfocusing on actual fieldwork data from a critically endangered tongue: Ainu.\nSpecifically, we (i) examine the feasibility of leveraging data from similar\nlanguages also in fine-tuning; (ii) verify whether the model's performance can\nbe improved by further pretraining on target language data. Our results show\nthat continued pretraining is the most effective method to adapt a wav2vec 2.0\nmodel for a new language and leads to considerable reduction in error rates.\nFurthermore, we find that if a model pretrained on a related speech variety or\nan unrelated language with similar phonological characteristics is available,\nmultilingual fine-tuning using additional data from that language can have\npositive impact on speech recognition performance when there is very little\nlabeled data in the target language.\n","authors":["Karol Nowakowski","Michal Ptaszynski","Kyoko Murasaki","Jagna Nieuważny"],"pdf_url":"https://arxiv.org/pdf/2301.07295v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2301.07294v1","updated":"2023-01-18T03:56:17Z","published":"2023-01-18T03:56:17Z","title":"Enhancing Self-Training Methods","summary":"  Semi-supervised learning approaches train on small sets of labeled data along\nwith large sets of unlabeled data. Self-training is a semi-supervised\nteacher-student approach that often suffers from the problem of \"confirmation\nbias\" that occurs when the student model repeatedly overfits to incorrect\npseudo-labels given by the teacher model for the unlabeled data. This bias\nimpedes improvements in pseudo-label accuracy across self-training iterations,\nleading to unwanted saturation in model performance after just a few\niterations. In this work, we describe multiple enhancements to improve the\nself-training pipeline to mitigate the effect of confirmation bias. We evaluate\nour enhancements over multiple datasets showing performance gains over existing\nself-training design choices. Finally, we also study the extendability of our\nenhanced approach to Open Set unlabeled data (containing classes not seen in\nlabeled data).\n","authors":["Aswathnarayan Radhakrishnan","Jim Davis","Zachary Rabin","Benjamin Lewis","Matthew Scherreik","Roman Ilin"],"pdf_url":"https://arxiv.org/pdf/2301.07294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02494v2","updated":"2023-01-18T03:50:55Z","published":"2023-01-06T13:12:59Z","title":"Adaptive Pattern Extraction Multi-Task Learning for Multi-Step\n  Conversion Estimations","summary":"  Multi-task learning (MTL) has been successfully implemented in many\nreal-world applications, which aims to simultaneously solve multiple tasks with\na single model. The general idea of multi-task learning is designing kinds of\nglobal parameter sharing mechanism and task-specific feature extractor to\nimprove the performance of all tasks. However, sequential dependence between\ntasks are rarely studied but frequently encountered in e-commence online\nrecommendation, e.g. impression, click and conversion on displayed product.\nThere is few theoretical work on this problem and biased optimization object\nadopted in most MTL methods deteriorates online performance. Besides, challenge\nstill remains in balancing the trade-off between various tasks and effectively\nlearn common and specific representation. In this paper, we first analyze\nsequential dependence MTL from rigorous mathematical perspective and design a\ndependence task learning loss to provide an unbiased optimizing object. And we\npropose a Task Aware Feature Extraction (TAFE) framework for sequential\ndependence MTL, which enables to selectively reconstruct implicit shared\nrepresentations from a sample-wise view and extract explicit task-specific\ninformation in an more efficient way. Extensive experiments on offline datasets\nand online A/B implementation demonstrate the effectiveness of our proposed\nTAFE.\n","authors":["Xuewen Tao","Mingming Ha","Xiaobo Guo","Qiongxu Ma","Hongwei Cheng","Wenfang Lin"],"pdf_url":"https://arxiv.org/pdf/2301.02494v2.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.06080v2","updated":"2023-01-18T03:44:49Z","published":"2022-12-14T16:53:26Z","title":"Comprehensive Literature Survey on Deep Learning used in Image\n  Memorability Prediction and Modification","summary":"  As humans, we can remember certain visuals in great detail, and sometimes\neven after viewing them once. What is even more interesting is that humans tend\nto remember and forget the same things, suggesting that there might be some\ngeneral internal characteristics of an image to encode and discard similar\ntypes of information. Research suggests that some pictures tend to be memorized\nmore than others. The ability of an image to be remembered by different viewers\nis one of its intrinsic properties. In visualization and photography, creating\nmemorable images is a difficult task. Hence, to solve the problem, various\ntechniques predict visual memorability and manipulate images' memorability. We\npresent a comprehensive literature survey to assess the deep learning\ntechniques used to predict and modify memorability. In particular, we analyze\nthe use of Convolutional Neural Networks, Recurrent Neural Networks, and\nGenerative Adversarial Networks for image memorability prediction and\nmodification.\n","authors":["Ananya Sadana","Nikita Thakur","Nikita Poria","Astika Anand","Seeja K. R"],"pdf_url":"https://arxiv.org/pdf/2301.06080v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07286v1","updated":"2023-01-18T03:22:47Z","published":"2023-01-18T03:22:47Z","title":"Reslicing Ultrasound Images for Data Augmentation and Vessel\n  Reconstruction","summary":"  Robot-guided catheter insertion has the potential to deliver urgent medical\ncare in situations where medical personnel are unavailable. However, this\ntechnique requires accurate and reliable segmentation of anatomical landmarks\nin the body. For the ultrasound imaging modality, obtaining large amounts of\ntraining data for a segmentation model is time-consuming and expensive. This\npaper introduces RESUS (RESlicing of UltraSound Images), a weak supervision\ndata augmentation technique for ultrasound images based on slicing\nreconstructed 3D volumes from tracked 2D images. This technique allows us to\ngenerate views which cannot be easily obtained in vivo due to physical\nconstraints of ultrasound imaging, and use these augmented ultrasound images to\ntrain a semantic segmentation model. We demonstrate that RESUS achieves\nstatistically significant improvement over training with non-augmented images\nand highlight qualitative improvements through vessel reconstruction.\n","authors":["Cecilia Morales","Jason Yao","Tejas Rane","Robert Edman","Howie Choset","Artur Dubrawski"],"pdf_url":"https://arxiv.org/pdf/2301.07286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07285v1","updated":"2023-01-18T03:17:36Z","published":"2023-01-18T03:17:36Z","title":"A Novel, Scale-Invariant, Differentiable, Efficient, Scalable\n  Regularizer","summary":"  $L_{p}$-norm regularization schemes such as $L_{0}$, $L_{1}$, and\n$L_{2}$-norm regularization and $L_{p}$-norm-based regularization techniques\nsuch as weight decay and group LASSO compute a quantity which de pends on model\nweights considered in isolation from one another. This paper describes a novel\nregularizer which is not based on an $L_{p}$-norm. In contrast with\n$L_{p}$-norm-based regularization, this regularizer is concerned with the\nspatial arrangement of weights within a weight matrix. This regularizer is an\nadditive term for the loss function and is differentiable, simple and fast to\ncompute, scale-invariant, requires a trivial amount of additional memory, and\ncan easily be parallelized. Empirically this method yields approximately a one\norder-of-magnitude improvement in the number of nonzero model parameters at a\ngiven level of accuracy.\n","authors":["Hovig Tigran Bayandorian"],"pdf_url":"https://arxiv.org/pdf/2301.07285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07284v1","updated":"2023-01-18T03:17:24Z","published":"2023-01-18T03:17:24Z","title":"Label Inference Attack against Split Learning under Regression Setting","summary":"  As a crucial building block in vertical Federated Learning (vFL), Split\nLearning (SL) has demonstrated its practice in the two-party model training\ncollaboration, where one party holds the features of data samples and another\nparty holds the corresponding labels. Such method is claimed to be private\nconsidering the shared information is only the embedding vectors and gradients\ninstead of private raw data and labels. However, some recent works have shown\nthat the private labels could be leaked by the gradients. These existing attack\nonly works under the classification setting where the private labels are\ndiscrete. In this work, we step further to study the leakage in the scenario of\nthe regression model, where the private labels are continuous numbers (instead\nof discrete labels in classification). This makes previous attacks harder to\ninfer the continuous labels due to the unbounded output range. To address the\nlimitation, we propose a novel learning-based attack that integrates gradient\ninformation and extra learning regularization objectives in aspects of model\ntraining properties, which can infer the labels under regression settings\neffectively. The comprehensive experiments on various datasets and models have\ndemonstrated the effectiveness of our proposed attack. We hope our work can\npave the way for future analyses that make the vFL framework more secure.\n","authors":["Shangyu Xie","Xin Yang","Yuanshun Yao","Tianyi Liu","Taiqing Wang","Jiankai Sun"],"pdf_url":"https://arxiv.org/pdf/2301.07284v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2301.07281v1","updated":"2023-01-18T03:09:28Z","published":"2023-01-18T03:09:28Z","title":"Detecting and Ranking Causal Anomalies in End-to-End Complex System","summary":"  With the rapid development of technology, the automated monitoring systems of\nlarge-scale factories are becoming more and more important. By collecting a\nlarge amount of machine sensor data, we can have many ways to find anomalies.\nWe believe that the real core value of an automated monitoring system is to\nidentify and track the cause of the problem. The most famous method for finding\ncausal anomalies is RCA, but there are many problems that cannot be ignored.\nThey used the AutoRegressive eXogenous (ARX) model to create a time-invariant\ncorrelation network as a machine profile, and then use this profile to track\nthe causal anomalies by means of a method called fault propagation. There are\ntwo major problems in describing the behavior of a machine by using the\ncorrelation network established by ARX: (1) It does not take into account the\ndiversity of states (2) It does not separately consider the correlations with\ndifferent time-lag. Based on these problems, we propose a framework called\nRanking Causal Anomalies in End-to-End System (RCAE2E), which completely solves\nthe problems mentioned above. In the experimental part, we use synthetic data\nand real-world large-scale photoelectric factory data to verify the correctness\nand existence of our method hypothesis.\n","authors":["Ching Chang","Cheng-Han Yeh","Wen-Chih Peng"],"pdf_url":"https://arxiv.org/pdf/2301.07281v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2112.15530v2","updated":"2023-01-18T02:38:19Z","published":"2021-12-31T16:12:23Z","title":"Scalable Deep Graph Clustering with Random-walk based Self-supervised\n  Learning","summary":"  Web-based interactions can be frequently represented by an attributed graph,\nand node clustering in such graphs has received much attention lately. Multiple\nefforts have successfully applied Graph Convolutional Networks (GCN), though\nwith some limits on accuracy as GCNs have been shown to suffer from\nover-smoothing issues. Though other methods (particularly those based on\nLaplacian Smoothing) have reported better accuracy, a fundamental limitation of\nall the work is a lack of scalability. This paper addresses this open problem\nby relating the Laplacian smoothing to the Generalized PageRank and applying a\nrandom-walk based algorithm as a scalable graph filter. This forms the basis\nfor our scalable deep clustering algorithm, RwSL, where through a\nself-supervised mini-batch training mechanism, we simultaneously optimize a\ndeep neural network for sample-cluster assignment distribution and an\nautoencoder for a clustering-oriented embedding. Using 6 real-world datasets\nand 6 clustering metrics, we show that RwSL achieved improved results over\nseveral recent baselines. Most notably, we show that RwSL, unlike all other\ndeep clustering frameworks, can continue to scale beyond graphs with more than\none million nodes, i.e., handle web-scale. We also demonstrate how RwSL could\nperform node clustering on a graph with 1.8 billion edges using only a single\nGPU.\n","authors":["Xiang Li","Dong Li","Ruoming Jin","Gagan Agrawal","Rajiv Ramnath"],"pdf_url":"https://arxiv.org/pdf/2112.15530v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07272v1","updated":"2023-01-18T02:36:03Z","published":"2023-01-18T02:36:03Z","title":"A variational autoencoder-based nonnegative matrix factorisation model\n  for deep dictionary learning","summary":"  Construction of dictionaries using nonnegative matrix factorisation (NMF) has\nextensive applications in signal processing and machine learning. With the\nadvances in deep learning, training compact and robust dictionaries using deep\nneural networks, i.e., dictionaries of deep features, has been proposed. In\nthis study, we propose a probabilistic generative model which employs a\nvariational autoencoder (VAE) to perform nonnegative dictionary learning. In\ncontrast to the existing VAE models, we cast the model under a statistical\nframework with latent variables obeying a Gamma distribution and design a new\nloss function to guarantee the nonnegative dictionaries. We adopt an\nacceptance-rejection sampling reparameterization trick to update the latent\nvariables iteratively. We apply the dictionaries learned from VAE-NMF to two\nsignal processing tasks, i.e., enhancement of speech and extraction of muscle\nsynergies. Experimental results demonstrate that VAE-NMF performs better in\nlearning the latent nonnegative dictionaries in comparison with\nstate-of-the-art methods.\n","authors":["Hong-Bo Xie","Caoyuan Li","Shuliang Wang","Richard Yi Da Xu","Kerrie Mengersen"],"pdf_url":"https://arxiv.org/pdf/2301.07272v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2301.05599v2","updated":"2023-01-18T02:34:58Z","published":"2023-01-13T15:04:32Z","title":"Short-time SSVEP data extension by a novel generative adversarial\n  networks based framework","summary":"  Steady-state visual evoked potentials (SSVEPs) based brain-computer interface\n(BCI) has received considerable attention due to its high transfer rate and\navailable quantity of targets. However, the performance of frequency\nidentification methods heavily hinges on the amount of user calibration data\nand data length, which hinders the deployment in real-world applications.\nRecently, generative adversarial networks (GANs)-based data generation methods\nhave been widely adopted to create supplementary synthetic\nelectroencephalography (EEG) data, holds promise to address these issues. In\nthis paper, we proposed a GAN-based end-to-end signal transformation network\nfor data length window extension, termed as TEGAN. TEGAN transforms short-time\nSSVEP signals into long-time artificial SSVEP signals. By incorporating a novel\nU-Net generator architecture and auxiliary classifier into the network design,\nthe TEGAN could produce conditioned features in the synthetic data.\nAdditionally, to regularize the training process of GAN, we introduced a\ntwo-stage training strategy and the LeCam-divergence regularization term during\nthe network implementation. The proposed TEGAN was evaluated on two public\nSSVEP datasets. With the assistance of TEGAN, the performance of traditional\nfrequency recognition methods and deep learning-based methods have been\nsignificantly improved under limited calibration data. This study substantiates\nthe feasibility of the proposed method to extend the data length for short-time\nSSVEP signals to develop a high-performance BCI system. The proposed GAN-based\nmethods have the great potential of shortening the calibration time for various\nreal-world BCI-based applications, while the novelty of our augmentation\nstrategies shed some value light on understanding the subject-invariant\nproperties of SSVEPs.\n","authors":["Yudong Pan","Ning Li","Yangsong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.05599v2.pdf","comment":"10 pages, 8 figures, 2 tables, submitted to IEEE TBME"},{"id":"http://arxiv.org/abs/2209.02655v2","updated":"2023-01-18T02:21:26Z","published":"2022-09-06T17:12:30Z","title":"Concentration of polynomial random matrices via Efron-Stein inequalities","summary":"  Analyzing concentration of large random matrices is a common task in a wide\nvariety of fields. Given independent random variables, many tools are available\nto analyze random matrices whose entries are linear in the variables, e.g. the\nmatrix-Bernstein inequality. However, in many applications, we need to analyze\nrandom matrices whose entries are polynomials in the variables. These arise\nnaturally in the analysis of spectral algorithms, e.g., Hopkins et al. [STOC\n2016], Moitra-Wein [STOC 2019]; and in lower bounds for semidefinite programs\nbased on the Sum of Squares hierarchy, e.g. Barak et al. [FOCS 2016], Jones et\nal. [FOCS 2021]. In this work, we present a general framework to obtain such\nbounds, based on the matrix Efron-Stein inequalities developed by\nPaulin-Mackey-Tropp [Annals of Probability 2016]. The Efron-Stein inequality\nbounds the norm of a random matrix by the norm of another simpler (but still\nrandom) matrix, which we view as arising by \"differentiating\" the starting\nmatrix. By recursively differentiating, our framework reduces the main task to\nanalyzing far simpler matrices. For Rademacher variables, these simpler\nmatrices are in fact deterministic and hence, analyzing them is far easier. For\ngeneral non-Rademacher variables, the task reduces to scalar concentration,\nwhich is much easier. Moreover, in the setting of polynomial matrices, our\nresults generalize the work of Paulin-Mackey-Tropp. Using our basic framework,\nwe recover known bounds in the literature for simple \"tensor networks\" and\n\"dense graph matrices\". Using our general framework, we derive bounds for\n\"sparse graph matrices\", which were obtained only recently by Jones et al.\n[FOCS 2021] using a nontrivial application of the trace power method, and was a\ncore component in their work. We expect our framework to be helpful for other\napplications involving concentration phenomena for nonlinear random matrices.\n","authors":["Goutham Rajendran","Madhur Tulsiani"],"pdf_url":"https://arxiv.org/pdf/2209.02655v2.pdf","comment":"To appear at SODA 2023. 41 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.06267v2","updated":"2023-01-18T02:13:43Z","published":"2023-01-16T05:40:42Z","title":"Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with\n  Multimodal Models","summary":"  The ability to quickly learn a new task with minimal instruction - known as\nfew-shot learning - is a central aspect of intelligent agents. Classical\nfew-shot benchmarks make use of few-shot samples from a single modality, but\nsuch samples may not be sufficient to characterize an entire concept class. In\ncontrast, humans use cross-modal information to learn new concepts efficiently.\nIn this work, we demonstrate that one can indeed build a better ${\\bf visual}$\ndog classifier by ${\\bf read}$ing about dogs and ${\\bf listen}$ing to them\nbark. To do so, we exploit the fact that recent multimodal foundation models\nsuch as CLIP are inherently cross-modal, mapping different modalities to the\nsame representation space. Specifically, we propose a simple cross-modal\nadaptation approach that learns from few-shot examples spanning different\nmodalities. By repurposing class names as additional one-shot training samples,\nwe achieve SOTA results with an embarrassingly simple linear classifier for\nvision-language adaptation. Furthermore, we show that our approach can benefit\nexisting methods such as prefix tuning, adapters, and classifier ensembling.\nFinally, to explore other modalities beyond vision and language, we construct\nthe first (to our knowledge) audiovisual few-shot benchmark and use cross-modal\ntraining to improve the performance of both image and audio classification.\n","authors":["Zhiqiu Lin","Samuel Yu","Zhiyi Kuang","Deepak Pathak","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2301.06267v2.pdf","comment":"Project website: https://linzhiqiu.github.io/papers/cross_modal/"},{"id":"http://arxiv.org/abs/2206.14389v3","updated":"2023-01-18T01:25:50Z","published":"2022-06-29T03:46:16Z","title":"Data Redaction from Pre-trained GANs","summary":"  Large pre-trained generative models are known to occasionally output\nundesirable samples, which undermines their trustworthiness. The common way to\nmitigate this is to re-train them differently from scratch using different data\nor different regularization -- which uses a lot of computational resources and\ndoes not always fully address the problem.\n  In this work, we take a different, more compute-friendly approach and\ninvestigate how to post-edit a model after training so that it ''redacts'', or\nrefrains from outputting certain kinds of samples. We show that redaction is a\nfundamentally different task from data deletion, and data deletion may not\nalways lead to redaction. We then consider Generative Adversarial Networks\n(GANs), and provide three different algorithms for data redaction that differ\non how the samples to be redacted are described. Extensive evaluations on\nreal-world image datasets show that our algorithms out-perform data deletion\nbaselines, and are capable of redacting data while retaining high generation\nquality at a fraction of the cost of full re-training.\n","authors":["Zhifeng Kong","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2206.14389v3.pdf","comment":"SaTML 2023"},{"id":"http://arxiv.org/abs/2301.07247v1","updated":"2023-01-18T01:19:36Z","published":"2023-01-18T01:19:36Z","title":"Tailor: Altering Skip Connections for Resource-Efficient Inference","summary":"  Deep neural networks use skip connections to improve training convergence.\nHowever, these skip connections are costly in hardware, requiring extra buffers\nand increasing on- and off-chip memory utilization and bandwidth requirements.\nIn this paper, we show that skip connections can be optimized for hardware when\ntackled with a hardware-software codesign approach. We argue that while a\nnetwork's skip connections are needed for the network to learn, they can later\nbe removed or shortened to provide a more hardware efficient implementation\nwith minimal to no accuracy loss. We introduce Tailor, a codesign tool whose\nhardware-aware training algorithm gradually removes or shortens a fully trained\nnetwork's skip connections to lower their hardware cost. The optimized hardware\ndesigns improve resource utilization by up to 34% for BRAMs, 13% for FFs, and\n16% for LUTs.\n","authors":["Olivia Weng","Gabriel Marcano","Vladimir Loncar","Alireza Khodamoradi","Nojan Sheybani","Farinaz Koushanfar","Kristof Denolf","Javier Mauricio Duarte","Ryan Kastner"],"pdf_url":"https://arxiv.org/pdf/2301.07247v1.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2103.15990v7","updated":"2023-01-18T01:18:34Z","published":"2021-03-29T23:48:51Z","title":"An Overview of Human Activity Recognition Using Wearable Sensors:\n  Healthcare and Artificial Intelligence","summary":"  With the rapid development of the internet of things (IoT) and artificial\nintelligence (AI) technologies, human activity recognition (HAR) has been\napplied in a variety of domains such as security and surveillance, human-robot\ninteraction, and entertainment. Even though a number of surveys and review\npapers have been published, there is a lack of HAR overview papers focusing on\nhealthcare applications that use wearable sensors. Therefore, we fill in the\ngap by presenting this overview paper. In particular, we present our projects\nto illustrate the system design of HAR applications for healthcare. Our\nprojects include early mobility identification of human activities for\nintensive care unit (ICU) patients and gait analysis of Duchenne muscular\ndystrophy (DMD) patients. We cover essential components of designing HAR\nsystems including sensor factors (e.g., type, number, and placement location),\nAI model selection (e.g., classical machine learning models versus deep\nlearning models), and feature engineering. In addition, we highlight the\nchallenges of such healthcare-oriented HAR systems and propose several research\nopportunities for both the medical and the computer science community.\n","authors":["Rex Liu","Albara Ah Ramli","Huanle Zhang","Erik Henricson","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2103.15990v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07244v1","updated":"2023-01-18T01:04:03Z","published":"2023-01-18T01:04:03Z","title":"Efficient correlation-based discretization of continuous variables for\n  annealing machines","summary":"  Annealing machines specialized for combinatorial optimization problems have\nbeen developed, and some companies offer services to use those machines. Such\nspecialized machines can only handle binary variables, and their input format\nis the quadratic unconstrained binary optimization (QUBO) formulation.\nTherefore, discretization is necessary to solve problems with continuous\nvariables. However, there is a severe constraint on the number of binary\nvariables with such machines. Although the simple binary expansion in the\nprevious research requires many binary variables, we need to reduce the number\nof such variables in the QUBO formulation due to the constraint. We propose a\ndiscretization method that involves using correlations of continuous variables.\nWe numerically show that the proposed method reduces the number of necessary\nbinary variables in the QUBO formulation without a significant loss in\nprediction accuracy.\n","authors":["Yuki Furue","Makiko Konoshima","Hirotaka Tamura","Jun Ohkubo"],"pdf_url":"https://arxiv.org/pdf/2301.07244v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2301.07243v1","updated":"2023-01-18T00:53:46Z","published":"2023-01-18T00:53:46Z","title":"Complexity Analysis of a Countable-armed Bandit Problem","summary":"  We consider a stochastic multi-armed bandit (MAB) problem motivated by\n``large'' action spaces, and endowed with a population of arms containing\nexactly $K$ arm-types, each characterized by a distinct mean reward. The\ndecision maker is oblivious to the statistical properties of reward\ndistributions as well as the population-level distribution of different\narm-types, and is precluded also from observing the type of an arm after play.\nWe study the classical problem of minimizing the expected cumulative regret\nover a horizon of play $n$, and propose algorithms that achieve a rate-optimal\nfinite-time instance-dependent regret of $\\mathcal{O}\\left( \\log n \\right)$. We\nalso show that the instance-independent (minimax) regret is\n$\\tilde{\\mathcal{O}}\\left( \\sqrt{n} \\right)$ when $K=2$. While the order of\nregret and complexity of the problem suggests a great degree of similarity to\nthe classical MAB problem, properties of the performance bounds and salient\naspects of algorithm design are quite distinct from the latter, as are the key\nprimitives that determine complexity along with the analysis tools needed to\nstudy them.\n","authors":["Anand Kalvit","Assaf Zeevi"],"pdf_url":"https://arxiv.org/pdf/2301.07243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.06126v2","updated":"2023-01-18T00:43:34Z","published":"2021-12-08T22:49:39Z","title":"Neural Network Quantization for Efficient Inference: A Survey","summary":"  As neural networks have become more powerful, there has been a rising desire\nto deploy them in the real world; however, the power and accuracy of neural\nnetworks is largely due to their depth and complexity, making them difficult to\ndeploy, especially in resource-constrained devices. Neural network quantization\nhas recently arisen to meet this demand of reducing the size and complexity of\nneural networks by reducing the precision of a network. With smaller and\nsimpler networks, it becomes possible to run neural networks within the\nconstraints of their target hardware. This paper surveys the many neural\nnetwork quantization techniques that have been developed in the last decade.\nBased on this survey and comparison of neural network quantization techniques,\nwe propose future directions of research in the area.\n","authors":["Olivia Weng"],"pdf_url":"https://arxiv.org/pdf/2112.06126v2.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2202.08312v3","updated":"2023-01-18T00:08:02Z","published":"2022-02-16T19:39:58Z","title":"Improved Differential Privacy for SGD via Optimal Private Linear\n  Operators on Adaptive Streams","summary":"  Motivated by recent applications requiring differential privacy over adaptive\nstreams, we investigate the question of optimal instantiations of the matrix\nmechanism in this setting. We prove fundamental theoretical results on the\napplicability of matrix factorizations to adaptive streams, and provide a\nparameter-free fixed-point algorithm for computing optimal factorizations. We\ninstantiate this framework with respect to concrete matrices which arise\nnaturally in machine learning, and train user-level differentially private\nmodels with the resulting optimal mechanisms, yielding significant improvements\nin a notable problem in federated learning with user-level differential\nprivacy.\n","authors":["Sergey Denisov","Brendan McMahan","Keith Rush","Adam Smith","Abhradeep Guha Thakurta"],"pdf_url":"https://arxiv.org/pdf/2202.08312v3.pdf","comment":"33 pages, 6 figures. Associated code at\n  https://github.com/google-research/federated/tree/master/dp_matrix_factorization"},{"id":"http://arxiv.org/abs/2301.07824v1","updated":"2023-01-18T23:49:25Z","published":"2023-01-18T23:49:25Z","title":"Augmenting a Physics-Informed Neural Network for the 2D Burgers Equation\n  by Addition of Solution Data Points","summary":"  We implement a Physics-Informed Neural Network (PINN) for solving the\ntwo-dimensional Burgers equations. This type of model can be trained with no\nprevious knowledge of the solution; instead, it relies on evaluating the\ngoverning equations of the system in points of the physical domain. It is also\npossible to use points with a known solution during training. In this paper, we\ncompare PINNs trained with different amounts of governing equation evaluation\npoints and known solution points. Comparing models that were trained purely\nwith known solution points to those that have also used the governing\nequations, we observe an improvement in the overall observance of the\nunderlying physics in the latter. We also investigate how changing the number\nof each type of point affects the resulting models differently. Finally, we\nargue that the addition of the governing equations during training may provide\na way to improve the overall performance of the model without relying on\nadditional data, which is especially important for situations where the number\nof known solution points is limited.\n","authors":["Marlon Sproesser Mathias","Wesley Pereira de Almeida","Marcel Rodrigues de Barros","Jefferson Fialho Coelho","Lucas Palmiro de Freitas","Felipe Marino Moreno","Caio Fabricio Deberaldini Netto","Fabio Gagliardi Cozman","Anna Helena Reali Costa","Eduardo Aoun Tannuri","Edson Satoshi Gomi","Marcelo Dottori"],"pdf_url":"https://arxiv.org/pdf/2301.07824v1.pdf","comment":"This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in the Lecture Notes in Computer Science book series (LNAI,volume\n  13654), and is available online at\n  https://doi.org/10.1007/978-3-031-21689-3_28"},{"id":"http://arxiv.org/abs/2211.07844v2","updated":"2023-01-18T23:47:25Z","published":"2022-11-15T02:01:41Z","title":"Characterizing the Spectrum of the NTK via a Power Series Expansion","summary":"  Under mild conditions on the network initialization we derive a power series\nexpansion for the Neural Tangent Kernel (NTK) of arbitrarily deep feedforward\nnetworks in the infinite width limit. We provide expressions for the\ncoefficients of this power series which depend on both the Hermite coefficients\nof the activation function as well as the depth of the network. We observe\nfaster decay of the Hermite coefficients leads to faster decay in the NTK\ncoefficients and explore the role of depth. Using this series, first we relate\nthe effective rank of the NTK to the effective rank of the input-data Gram.\nSecond, for data drawn uniformly on the sphere we study the eigenvalues of the\nNTK, analyzing the impact of the choice of activation function. Finally, for\ngeneric data and activation functions with sufficiently fast Hermite\ncoefficient decay, we derive an asymptotic upper bound on the spectrum of the\nNTK.\n","authors":["Michael Murray","Hui Jin","Benjamin Bowman","Guido Montufar"],"pdf_url":"https://arxiv.org/pdf/2211.07844v2.pdf","comment":"55 pages, 3 Figures, 1 Table"},{"id":"http://arxiv.org/abs/2204.12490v2","updated":"2023-01-18T23:40:47Z","published":"2022-04-26T17:59:51Z","title":"From One Hand to Multiple Hands: Imitation Learning for Dexterous\n  Manipulation from Single-Camera Teleoperation","summary":"  We propose to perform imitation learning for dexterous manipulation with\nmulti-finger robot hand from human demonstrations, and transfer the policy to\nthe real robot hand. We introduce a novel single-camera teleoperation system to\ncollect the 3D demonstrations efficiently with only an iPad and a computer. One\nkey contribution of our system is that we construct a customized robot hand for\neach user in the physical simulator, which is a manipulator resembling the same\nkinematics structure and shape of the operator's hand. This provides an\nintuitive interface and avoid unstable human-robot hand retargeting for data\ncollection, leading to large-scale and high quality data. Once the data is\ncollected, the customized robot hand trajectories can be converted to different\nspecified robot hands (models that are manufactured) to generate training\ndemonstrations. With imitation learning using our data, we show large\nimprovement over baselines with multiple complex manipulation tasks.\nImportantly, we show our learned policy is significantly more robust when\ntransferring to the real robot. More videos can be found in the\nhttps://yzqin.github.io/dex-teleop-imitation .\n","authors":["Yuzhe Qin","Hao Su","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2204.12490v2.pdf","comment":"https://yzqin.github.io/dex-teleop-imitation/"},{"id":"http://arxiv.org/abs/2301.07820v1","updated":"2023-01-18T23:16:53Z","published":"2023-01-18T23:16:53Z","title":"Emergence of the SVD as an interpretable factorization in deep learning\n  for inverse problems","summary":"  We demonstrate the emergence of weight matrix singular value decomposition\n(SVD) in interpreting neural networks (NNs) for parameter estimation from noisy\nsignals. The SVD appears naturally as a consequence of initial application of a\ndescrambling transform - a recently-developed technique for addressing\ninterpretability in NNs \\cite{amey2021neural}. We find that within the class of\nnoisy parameter estimation problems, the SVD may be the means by which networks\nmemorize the signal model. We substantiate our theoretical findings with\nempirical evidence from both linear and non-linear settings. Our results also\nilluminate the connections between a mathematical theory of semantic\ndevelopment \\cite{saxe2019mathematical} and neural network interpretability.\n","authors":["Shashank Sule","Richard G. Spencer","Wojciech Czaja"],"pdf_url":"https://arxiv.org/pdf/2301.07820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11049v2","updated":"2023-01-18T22:59:29Z","published":"2022-07-22T12:41:53Z","title":"Context-aware controller inference for stabilizing dynamical systems\n  from scarce data","summary":"  This work introduces a data-driven control approach for stabilizing\nhigh-dimensional dynamical systems from scarce data. The proposed context-aware\ncontroller inference approach is based on the observation that controllers need\nto act locally only on the unstable dynamics to stabilize systems. This means\nit is sufficient to learn the unstable dynamics alone, which are typically\nconfined to much lower dimensional spaces than the high-dimensional state\nspaces of all system dynamics and thus few data samples are sufficient to\nidentify them. Numerical experiments demonstrate that context-aware controller\ninference learns stabilizing controllers from orders of magnitude fewer data\nsamples than traditional data-driven control techniques and variants of\nreinforcement learning. The experiments further show that the low data\nrequirements of context-aware controller inference are especially beneficial in\ndata-scarce engineering problems with complex physics, for which learning\ncomplete system dynamics is often intractable in terms of data and training\ncosts.\n","authors":["Steffen W. R. Werner","Benjamin Peherstorfer"],"pdf_url":"https://arxiv.org/pdf/2207.11049v2.pdf","comment":"27 pages, 10 figures"},{"id":"http://arxiv.org/abs/2210.13414v2","updated":"2023-01-18T22:58:27Z","published":"2022-10-24T17:30:08Z","title":"Thermodynamics-informed neural networks for physically realistic mixed\n  reality","summary":"  The imminent impact of immersive technologies in society urges for active\nresearch in real-time and interactive physics simulation for virtual worlds to\nbe realistic. In this context, realistic means to be compliant to the laws of\nphysics. In this paper we present a method for computing the dynamic response\nof (possibly non-linear and dissipative) deformable objects induced by\nreal-time user interactions in mixed reality using deep learning. The\ngraph-based architecture of the method ensures the thermodynamic consistency of\nthe predictions, whereas the visualization pipeline allows a natural and\nrealistic user experience. Two examples of virtual solids interacting with\nvirtual or physical solids in mixed reality scenarios are provided to prove the\nperformance of the method.\n","authors":["Quercus Hernández","Alberto Badías","Francisco Chinesta","Elías Cueto"],"pdf_url":"https://arxiv.org/pdf/2210.13414v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2104.10770v2","updated":"2023-01-18T22:31:29Z","published":"2021-04-21T21:25:02Z","title":"Skeleton Clustering: Dimension-Free Density-based Clustering","summary":"  We introduce a density-based clustering method called skeleton clustering\nthat can detect clusters in multivariate and even high-dimensional data with\nirregular shapes. To bypass the curse of dimensionality, we propose surrogate\ndensity measures that are less dependent on the dimension but have intuitive\ngeometric interpretations. The clustering framework constructs a concise\nrepresentation of the given data as an intermediate step and can be thought of\nas a combination of prototype methods, density-based clustering, and\nhierarchical clustering. We show by theoretical analysis and empirical studies\nthat the skeleton clustering leads to reliable clusters in multivariate and\nhigh-dimensional scenarios.\n","authors":["Zeyu Wei","Yen-Chi Chen"],"pdf_url":"https://arxiv.org/pdf/2104.10770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07806v1","updated":"2023-01-18T22:28:49Z","published":"2023-01-18T22:28:49Z","title":"Federated Automatic Differentiation","summary":"  Federated learning (FL) is a general framework for learning across\nheterogeneous clients while preserving data privacy, under the orchestration of\na central server. FL methods often compute gradients of loss functions purely\nlocally (ie. entirely at each client, or entirely at the server), typically\nusing automatic differentiation (AD) techniques. We propose a federated\nautomatic differentiation (FAD) framework that 1) enables computing derivatives\nof functions involving client and server computation as well as communication\nbetween them and 2) operates in a manner compatible with existing federated\ntechnology. In other words, FAD computes derivatives across communication\nboundaries. We show, in analogy with traditional AD, that FAD may be\nimplemented using various accumulation modes, which introduce distinct\ncomputation-communication trade-offs and systems requirements. Further, we show\nthat a broad class of federated computations is closed under these various\nmodes of FAD, implying in particular that if the original computation can be\nimplemented using privacy-preserving primitives, its derivative may be computed\nusing only these same primitives. We then show how FAD can be used to create\nalgorithms that dynamically learn components of the algorithm itself. In\nparticular, we show that FedAvg-style algorithms can exhibit significantly\nimproved performance by using FAD to adjust the server optimization step\nautomatically, or by using FAD to learn weighting schemes for computing\nweighted averages across clients.\n","authors":["Keith Rush","Zachary Charles","Zachary Garrett"],"pdf_url":"https://arxiv.org/pdf/2301.07806v1.pdf","comment":"36 pages, 13 figures"},{"id":"http://arxiv.org/abs/2301.07799v1","updated":"2023-01-18T21:58:54Z","published":"2023-01-18T21:58:54Z","title":"A Domain-Agnostic Approach for Characterization of Lifelong Learning\n  Systems","summary":"  Despite the advancement of machine learning techniques in recent years,\nstate-of-the-art systems lack robustness to \"real world\" events, where the\ninput distributions and tasks encountered by the deployed systems will not be\nlimited to the original training context, and systems will instead need to\nadapt to novel distributions and tasks while deployed. This critical gap may be\naddressed through the development of \"Lifelong Learning\" systems that are\ncapable of 1) Continuous Learning, 2) Transfer and Adaptation, and 3)\nScalability. Unfortunately, efforts to improve these capabilities are typically\ntreated as distinct areas of research that are assessed independently, without\nregard to the impact of each separate capability on other aspects of the\nsystem. We instead propose a holistic approach, using a suite of metrics and an\nevaluation framework to assess Lifelong Learning in a principled way that is\nagnostic to specific domains or system techniques. Through five case studies,\nwe show that this suite of metrics can inform the development of varied and\ncomplex Lifelong Learning systems. We highlight how the proposed suite of\nmetrics quantifies performance trade-offs present during Lifelong Learning\nsystem development - both the widely discussed Stability-Plasticity dilemma and\nthe newly proposed relationship between Sample Efficient and Robust Learning.\nFurther, we make recommendations for the formulation and use of metrics to\nguide the continuing development of Lifelong Learning systems and assess their\nprogress in the future.\n","authors":["Megan M. Baker","Alexander New","Mario Aguilar-Simon","Ziad Al-Halah","Sébastien M. R. Arnold","Ese Ben-Iwhiwhu","Andrew P. Brna","Ethan Brooks","Ryan C. Brown","Zachary Daniels","Anurag Daram","Fabien Delattre","Ryan Dellana","Eric Eaton","Haotian Fu","Kristen Grauman","Jesse Hostetler","Shariq Iqbal","Cassandra Kent","Nicholas Ketz","Soheil Kolouri","George Konidaris","Dhireesha Kudithipudi","Erik Learned-Miller","Seungwon Lee","Michael L. Littman","Sandeep Madireddy","Jorge A. Mendez","Eric Q. Nguyen","Christine D. Piatko","Praveen K. Pilly","Aswin Raghavan","Abrar Rahman","Santhosh Kumar Ramakrishnan","Neale Ratzlaff","Andrea Soltoggio","Peter Stone","Indranil Sur","Zhipeng Tang","Saket Tiwari","Kyle Vedder","Felix Wang","Zifan Xu","Angel Yanguas-Gil","Harel Yedidsion","Shangqun Yu","Gautam K. Vallabha"],"pdf_url":"https://arxiv.org/pdf/2301.07799v1.pdf","comment":"To appear in Neural Networks"},{"id":"http://arxiv.org/abs/2301.07794v1","updated":"2023-01-18T21:47:05Z","published":"2023-01-18T21:47:05Z","title":"HCE: Improving Performance and Efficiency with Heterogeneously\n  Compressed Neural Network Ensemble","summary":"  Ensemble learning has gain attention in resent deep learning research as a\nway to further boost the accuracy and generalizability of deep neural network\n(DNN) models. Recent ensemble training method explores different training\nalgorithms or settings on multiple sub-models with the same model architecture,\nwhich lead to significant burden on memory and computation cost of the ensemble\nmodel. Meanwhile, the heurtsically induced diversity may not lead to\nsignificant performance gain. We propose a new prespective on exploring the\nintrinsic diversity within a model architecture to build efficient DNN\nensemble. We make an intriguing observation that pruning and quantization,\nwhile both leading to efficient model architecture at the cost of small\naccuracy drop, leads to distinct behavior in the decision boundary. To this\nend, we propose Heterogeneously Compressed Ensemble (HCE), where we build an\nefficient ensemble with the pruned and quantized variants from a pretrained DNN\nmodel. An diversity-aware training objective is proposed to further boost the\nperformance of the HCE ensemble. Experiemnt result shows that HCE achieves\nsignificant improvement in the efficiency-accuracy tradeoff comparing to both\ntraditional DNN ensemble training methods and previous model compression\nmethods.\n","authors":["Jingchi Zhang","Huanrui Yang","Hai Li"],"pdf_url":"https://arxiv.org/pdf/2301.07794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.07785v2","updated":"2023-01-18T21:26:09Z","published":"2021-10-15T00:45:25Z","title":"Scalable Causal Structure Learning: Scoping Review of Traditional and\n  Deep Learning Algorithms and New Opportunities in Biomedicine","summary":"  Causal structure learning refers to a process of identifying causal\nstructures from observational data, and it can have multiple applications in\nbiomedicine and health care. This paper provides a practical review and\ntutorial on scalable causal structure learning models with examples of\nreal-world data to help health care audiences understand and apply them. We\nreviewed traditional (combinatorial and score-based methods) for causal\nstructure discovery and machine learning-based schemes. We also highlighted\nrecent developments in biomedicine where causal structure learning can be\napplied to discover structures such as gene networks, brain connectivity\nnetworks, and those in cancer epidemiology. We also compared the performance of\ntraditional and machine learning-based algorithms for causal discovery over\nsome benchmark data sets. Machine learning-based approaches, including deep\nlearning, have many advantages over traditional approaches, such as\nscalability, including a greater number of variables, and potentially being\napplied in a wide range of biomedical applications, such as genetics, if\nsufficient data are available. Furthermore, these models are more flexible than\ntraditional models and are poised to positively affect many applications in the\nfuture.\n","authors":["Pulakesh Upadhyaya","Kai Zhang","Can Li","Xiaoqian Jiang","Yejin Kim"],"pdf_url":"https://arxiv.org/pdf/2110.07785v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07784v1","updated":"2023-01-18T20:54:40Z","published":"2023-01-18T20:54:40Z","title":"Sample-Efficient Multi-Objective Learning via Generalized Policy\n  Improvement Prioritization","summary":"  Multi-objective reinforcement learning (MORL) algorithms tackle sequential\ndecision problems where agents may have different preferences over (possibly\nconflicting) reward functions. Such algorithms often learn a set of policies\n(each optimized for a particular agent preference) that can later be used to\nsolve problems with novel preferences. We introduce a novel algorithm that uses\nGeneralized Policy Improvement (GPI) to define principled, formally-derived\nprioritization schemes that improve sample-efficient learning. They implement\nactive-learning strategies by which the agent can (i) identify the most\npromising preferences/objectives to train on at each moment, to more rapidly\nsolve a given MORL problem; and (ii) identify which previous experiences are\nmost relevant when learning a policy for a particular agent preference, via a\nnovel Dyna-style MORL method. We prove our algorithm is guaranteed to always\nconverge to an optimal solution in a finite number of steps, or an\n$\\epsilon$-optimal solution (for a bounded $\\epsilon$) if the agent is limited\nand can only identify possibly sub-optimal policies. We also prove that our\nmethod monotonically improves the quality of its partial solutions while\nlearning. Finally, we introduce a bound that characterizes the maximum utility\nloss (with respect to the optimal solution) incurred by the partial solutions\ncomputed by our method throughout learning. We empirically show that our method\noutperforms state-of-the-art MORL algorithms in challenging multi-objective\ntasks, both with discrete and continuous state spaces.\n","authors":["Lucas N. Alegre","Ana L. C. Bazzan","Diederik M. Roijers","Ann Nowé","Bruno C. da Silva"],"pdf_url":"https://arxiv.org/pdf/2301.07784v1.pdf","comment":"Accepted to AAMAS 2023"},{"id":"http://arxiv.org/abs/2301.07768v1","updated":"2023-01-18T20:22:44Z","published":"2023-01-18T20:22:44Z","title":"Automated deep reinforcement learning for real-time scheduling strategy\n  of multi-energy system integrated with post-carbon and direct-air carbon\n  captured system","summary":"  The carbon-capturing process with the aid of CO2 removal technology (CDRT)\nhas been recognised as an alternative and a prominent approach to deep\ndecarbonisation. However, the main hindrance is the enormous energy demand and\nthe economic implication of CDRT if not effectively managed. Hence, a novel\ndeep reinforcement learning agent (DRL), integrated with an automated\nhyperparameter selection feature, is proposed in this study for the real-time\nscheduling of a multi-energy system coupled with CDRT. Post-carbon capture\nsystems (PCCS) and direct-air capture systems (DACS) are considered CDRT.\nVarious possible configurations are evaluated using real-time multi-energy data\nof a district in Arizona and CDRT parameters from manufacturers' catalogues and\npilot project documentation. The simulation results validate that an optimised\nsoft-actor critic (SAC) algorithm outperformed the TD3 algorithm due to its\nmaximum entropy feature. We then trained four (4) SAC agents, equivalent to the\nnumber of considered case studies, using optimised hyperparameter values and\ndeployed them in real time for evaluation. The results show that the proposed\nDRL agent can meet the prosumers' multi-energy demand and schedule the CDRT\nenergy demand economically without specified constraints violation. Also, the\nproposed DRL agent outperformed rule-based scheduling by 23.65%. However, the\nconfiguration with PCCS and solid-sorbent DACS is considered the most suitable\nconfiguration with a high CO2 captured-released ratio of 38.54, low CO2\nreleased indicator value of 2.53, and a 36.5% reduction in CDR cost due to\nwaste heat utilisation and high absorption capacity of the selected sorbent.\nHowever, the adoption of CDRT is not economically viable at the current carbon\nprice. Finally, we showed that CDRT would be attractive at a carbon price of\n400-450USD/ton with the provision of tax incentives by the policymakers.\n","authors":["Tobi Michael Alabi","Nathan P. Lawrence","Lin Lu","Zaiyue Yang","R. Bhushan Gopaluni"],"pdf_url":"https://arxiv.org/pdf/2301.07768v1.pdf","comment":"39 pages; postprint"},{"id":"http://arxiv.org/abs/2206.07756v2","updated":"2023-01-18T19:51:28Z","published":"2022-06-15T18:27:10Z","title":"Hybrid thermal modeling of additive manufacturing processes using\n  physics-informed neural networks for temperature prediction and parameter\n  identification","summary":"  Understanding the thermal behavior of additive manufacturing (AM) processes\nis crucial for enhancing the quality control and enabling customized process\ndesign. Most purely physics-based computational models suffer from intensive\ncomputational costs and the need of calibrating unknown parameters, thus not\nsuitable for online control and iterative design application. Data-driven\nmodels taking advantage of the latest developed computational tools can serve\nas a more efficient surrogate, but they are usually trained over a large amount\nof simulation data and often fail to effectively use small but high-quality\nexperimental data. In this work, we developed a hybrid physics-based\ndata-driven thermal modeling approach of AM processes using physics-informed\nneural networks. Specifically, partially observed temperature data measured\nfrom an infrared camera is combined with the physics laws to predict full-field\ntemperature history and to discover unknown material and process parameters. In\nthe numerical and experimental examples, the effectiveness of adding auxiliary\ntraining data and using the pretrained model on training efficiency and\nprediction accuracy, as well as the ability to identify unknown parameters with\npartially observed data, are demonstrated. The results show that the hybrid\nthermal model can effectively identify unknown parameters and capture the\nfull-field temperature accurately, and thus it has the potential to be used in\niterative process design and real-time process control of AM.\n","authors":["Shuheng Liao","Tianju Xue","Jihoon Jeong","Samantha Webster","Kornel Ehmann","Jian Cao"],"pdf_url":"https://arxiv.org/pdf/2206.07756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05804v2","updated":"2023-01-18T19:48:16Z","published":"2023-01-14T01:47:09Z","title":"Salient Sign Detection In Safe Autonomous Driving: AI Which Reasons Over\n  Full Visual Context","summary":"  Detecting road traffic signs and accurately determining how they can affect\nthe driver's future actions is a critical task for safe autonomous driving\nsystems. However, various traffic signs in a driving scene have an unequal\nimpact on the driver's decisions, making detecting the salient traffic signs a\nmore important task. Our research addresses this issue, constructing a traffic\nsign detection model which emphasizes performance on salient signs, or signs\nthat influence the decisions of a driver. We define a traffic sign salience\nproperty and use it to construct the LAVA Salient Signs Dataset, the first\ntraffic sign dataset that includes an annotated salience property. Next, we use\na custom salience loss function, Salience-Sensitive Focal Loss, to train a\nDeformable DETR object detection model in order to emphasize stronger\nperformance on salient signs. Results show that a model trained with\nSalience-Sensitive Focal Loss outperforms a model trained without, with regards\nto recall of both salient signs and all signs combined. Further, the\nperformance margin on salient signs compared to all signs is largest for the\nmodel trained with Salience-Sensitive Focal Loss.\n","authors":["Ross Greer","Akshay Gopalkrishnan","Nachiket Deo","Akshay Rangesh","Mohan Trivedi"],"pdf_url":"https://arxiv.org/pdf/2301.05804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11060v2","updated":"2023-01-18T19:28:44Z","published":"2022-11-20T19:22:44Z","title":"Simultaneously Learning Robust Audio Embeddings and balanced Hash codes\n  for Query-by-Example","summary":"  Audio fingerprinting systems must efficiently and robustly identify query\nsnippets in an extensive database. To this end, state-of-the-art systems use\ndeep learning to generate compact audio fingerprints. These systems deploy\nindexing methods, which quantize fingerprints to hash codes in an unsupervised\nmanner to expedite the search. However, these methods generate imbalanced hash\ncodes, leading to their suboptimal performance. Therefore, we propose a\nself-supervised learning framework to compute fingerprints and balanced hash\ncodes in an end-to-end manner to achieve both fast and accurate retrieval\nperformance. We model hash codes as a balanced clustering process, which we\nregard as an instance of the optimal transport problem. Experimental results\nindicate that the proposed approach improves retrieval efficiency while\npreserving high accuracy, particularly at high distortion levels, compared to\nthe competing methods. Moreover, our system is efficient and scalable in\ncomputational load and memory storage.\n","authors":["Anup Singh","Kris Demuynck","Vipul Arora"],"pdf_url":"https://arxiv.org/pdf/2211.11060v2.pdf","comment":"We need to rewrite the subsection 'Efficiency' section under section\n  4 to make it more easy to follow for the readers and appreciate our results"},{"id":"http://arxiv.org/abs/2301.07743v1","updated":"2023-01-18T19:19:27Z","published":"2023-01-18T19:19:27Z","title":"Using CycleGANs to Generate Realistic STEM Images for Machine Learning","summary":"  The rise of automation and machine learning (ML) in electron microscopy has\nthe potential to revolutionize materials research by enabling the autonomous\ncollection and processing of vast amounts of atomic resolution data. However, a\nmajor challenge is developing ML models that can reliably and rapidly\ngeneralize to large data sets with varying experimental conditions. To overcome\nthis challenge, we develop a cycle generative adversarial network (CycleGAN)\nthat introduces a novel reciprocal space discriminator to augment simulated\ndata with realistic, complex spatial frequency information learned from\nexperimental data. This enables the CycleGAN to generate nearly\nindistinguishable images from real experimental data, while also providing\nlabels for further ML applications. We demonstrate the effectiveness of this\napproach by training a fully convolutional network (FCN) to identify single\natom defects in a large data set of 4.5 million atoms, which we collected using\nautomated acquisition in an aberration-corrected scanning transmission electron\nmicroscope (STEM). Our approach yields highly adaptable FCNs that can adjust to\ndynamically changing experimental variables, such as lens aberrations, noise,\nand local contamination, with minimal manual intervention. This represents a\nsignificant step towards building fully autonomous approaches for harnessing\nmicroscopy big data.\n","authors":["Abid Khan","Chia-Hao Lee","Pinshane Y. Huang","Bryan K. Clark"],"pdf_url":"https://arxiv.org/pdf/2301.07743v1.pdf","comment":"29 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2301.07737v1","updated":"2023-01-18T19:03:48Z","published":"2023-01-18T19:03:48Z","title":"Catapult Dynamics and Phase Transitions in Quadratic Nets","summary":"  Neural networks trained with gradient descent can undergo non-trivial phase\ntransitions as a function of the learning rate. In (Lewkowycz et al., 2020) it\nwas discovered that wide neural nets can exhibit a catapult phase for\nsuper-critical learning rates, where the training loss grows exponentially\nquickly at early times before rapidly decreasing to a small value. During this\nphase the top eigenvalue of the neural tangent kernel (NTK) also undergoes\nsignificant evolution. In this work, we will prove that the catapult phase\nexists in a large class of models, including quadratic models and two-layer,\nhomogenous neural nets. To do this, we show that for a certain range of\nlearning rates the weight norm decreases whenever the loss becomes large. We\nalso empirically study learning rates beyond this theoretically derived range\nand show that the activation map of ReLU nets trained with super-critical\nlearning rates becomes increasingly sparse as we increase the learning rate.\n","authors":["David Meltzer","Junyu Liu"],"pdf_url":"https://arxiv.org/pdf/2301.07737v1.pdf","comment":"44 pages, 16 figures, 1 table"},{"id":"http://arxiv.org/abs/2301.07733v1","updated":"2023-01-18T19:00:50Z","published":"2023-01-18T19:00:50Z","title":"Learning-Rate-Free Learning by D-Adaptation","summary":"  The speed of gradient descent for convex Lipschitz functions is highly\ndependent on the choice of learning rate. Setting the learning rate to achieve\nthe optimal convergence rate requires knowing the distance D from the initial\npoint to the solution set. In this work, we describe a single-loop method, with\nno back-tracking or line searches, which does not require knowledge of $D$ yet\nasymptotically achieves the optimal rate of convergence for the complexity\nclass of convex Lipschitz functions. Our approach is the first parameter-free\nmethod for this class without additional multiplicative log factors in the\nconvergence rate. We present extensive experiments for SGD and Adam variants of\nour method, where the method automatically matches hand-tuned learning rates\nacross more than a dozen diverse machine learning problems, including\nlarge-scale vision and language problems. Our method is practical, efficient\nand requires no additional function value or gradient evaluations each step. An\nopen-source implementation is available\n(https://github.com/facebookresearch/dadaptation).\n","authors":["Aaron Defazio","Konstantin Mishchenko"],"pdf_url":"https://arxiv.org/pdf/2301.07733v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.07681v1","updated":"2023-01-18T18:00:29Z","published":"2023-01-18T18:00:29Z","title":"Reduced-Reference Quality Assessment of Point Clouds via\n  Content-Oriented Saliency Projection","summary":"  Many dense 3D point clouds have been exploited to represent visual objects\ninstead of traditional images or videos. To evaluate the perceptual quality of\nvarious point clouds, in this letter, we propose a novel and efficient\nReduced-Reference quality metric for point clouds, which is based on\nContent-oriented sAliency Projection (RR-CAP). Specifically, we make the first\nattempt to simplify reference and distorted point clouds into projected\nsaliency maps with a downsampling operation. Through this process, we tackle\nthe issue of transmitting large-volume original point clouds to user-ends for\nquality assessment. Then, motivated by the characteristics of the human visual\nsystem (HVS), the objective quality scores of distorted point clouds are\nproduced by combining content-oriented similarity and statistical correlation\nmeasurements. Finally, extensive experiments are conducted on SJTU-PCQA and WPC\ndatabases. The experimental results demonstrate that our proposed algorithm\noutperforms existing reduced-reference and no-reference quality metrics, and\nsignificantly reduces the performance gap between state-of-the-art\nfull-reference quality assessment methods. In addition, we show the performance\nvariation of each proposed technical component by ablation tests.\n","authors":["Wei Zhou","Guanghui Yue","Ruizeng Zhang","Yipeng Qin","Hantao Liu"],"pdf_url":"https://arxiv.org/pdf/2301.07681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07431v1","updated":"2023-01-18T11:00:45Z","published":"2023-01-18T11:00:45Z","title":"Sharp Eyes: A Salient Object Detector Working The Same Way as Human\n  Visual Characteristics","summary":"  Current methods aggregate multi-level features or introduce edge and skeleton\nto get more refined saliency maps. However, little attention is paid to how to\nobtain the complete salient object in cluttered background, where the targets\nare usually similar in color and texture to the background. To handle this\ncomplex scene, we propose a sharp eyes network (SENet) that first seperates the\nobject from scene, and then finely segments it, which is in line with human\nvisual characteristics, i.e., to look first and then focus. Different from\nprevious methods which directly integrate edge or skeleton to supplement the\ndefects of objects, the proposed method aims to utilize the expanded objects to\nguide the network obtain complete prediction. Specifically, SENet mainly\nconsists of target separation (TS) brach and object segmentation (OS) branch\ntrained by minimizing a new hierarchical difference aware (HDA) loss. In the TS\nbranch, we construct a fractal structure to produce saliency features with\nexpanded boundary via the supervision of expanded ground truth, which can\nenlarge the detail difference between foreground and background. In the OS\nbranch, we first aggregate multi-level features to adaptively select\ncomplementary components, and then feed the saliency features with expanded\nboundary into aggregated features to guide the network obtain complete\nprediction. Moreover, we propose the HDA loss to further improve the structural\nintegrity and local details of the salient objects, which assigns weight to\neach pixel according to its distance from the boundary hierarchically. Hard\npixels with similar appearance in border region will be given more attention\nhierarchically to emphasize their importance in completeness prediction.\nComprehensive experimental results on five datasets demonstrate that the\nproposed approach outperforms the state-of-the-art methods both quantitatively\nand qualitatively.\n","authors":["Ge Zhu","Jinbao Li","Yahong Guo"],"pdf_url":"https://arxiv.org/pdf/2301.07431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07740v1","updated":"2023-01-18T19:10:28Z","published":"2023-01-18T19:10:28Z","title":"The Metaverse from a Multimedia Communications Perspective","summary":"  eXtended reality (XR) technologies such as virtual reality and 360{\\deg}\nstereoscopic streaming enable the concept of the Metaverse, an immersive\nvirtual space for collaboration and interaction. To ensure high fidelity\ndisplay of immersive media, the bandwidth, latency and network traffic patterns\nwill need to be considered to ensure a user's Quality of Experience (QoE). In\nthis article, examples and calculations are explored to demonstrate the\nrequirements of the abovementioned parameters. Additionally, future methods\nsuch as network-awareness using reinforcement learning (RL) and XR content\nawareness using spatial or temporal difference in the frames could be explored\nfrom a multimedia communications perspective.\n","authors":["Haiwei Dong","Jeannie S. A. Lee"],"pdf_url":"https://arxiv.org/pdf/2301.07740v1.pdf","comment":null}]},"2023-01-19T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2212.06373v2","updated":"2023-01-19T17:56:49Z","published":"2022-12-13T05:12:40Z","title":"InferEM: Inferring the Speaker's Intention for Empathetic Dialogue\n  Generation","summary":"  Current approaches to empathetic response generation typically encode the\nentire dialogue history directly and put the output into a decoder to generate\nfriendly feedback. These methods focus on modelling contextual information but\nneglect capturing the direct intention of the speaker. We argue that the last\nutterance in the dialogue empirically conveys the intention of the speaker.\nConsequently, we propose a novel model named InferEM for empathetic response\ngeneration. We separately encode the last utterance and fuse it with the entire\ndialogue through the multi-head attention based intention fusion module to\ncapture the speaker's intention. Besides, we utilize previous utterances to\npredict the last utterance, which simulates human's psychology to guess what\nthe interlocutor may speak in advance. To balance the optimizing rates of the\nutterance prediction and response generation, a multi-task learning strategy is\ndesigned for InferEM. Experimental results demonstrate the plausibility and\nvalidity of InferEM in improving empathetic expression.\n","authors":["Guoqing Lv","Xiaoping Wang","Jiang Li","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2212.06373v2.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.08193v1","updated":"2023-01-19T17:41:46Z","published":"2023-01-19T17:41:46Z","title":"JCSE: Contrastive Learning of Japanese Sentence Embeddings and Its\n  Applications","summary":"  Contrastive learning is widely used for sentence representation learning.\nDespite this prevalence, most studies have focused exclusively on English and\nfew concern domain adaptation for domain-specific downstream tasks, especially\nfor low-resource languages like Japanese, which are characterized by\ninsufficient target domain data and the lack of a proper training strategy. To\novercome this, we propose a novel Japanese sentence representation framework,\nJCSE (derived from ``Contrastive learning of Sentence Embeddings for\nJapanese''), that creates training data by generating sentences and\nsynthesizing them with sentences available in a target domain. Specifically, a\npre-trained data generator is finetuned to a target domain using our collected\ncorpus. It is then used to generate contradictory sentence pairs that are used\nin contrastive learning for adapting a Japanese language model to a specific\ntask in the target domain.\n  Another problem of Japanese sentence representation learning is the\ndifficulty of evaluating existing embedding methods due to the lack of\nbenchmark datasets. Thus, we establish a comprehensive Japanese Semantic\nTextual Similarity (STS) benchmark on which various embedding models are\nevaluated. Based on this benchmark result, multiple embedding methods are\nchosen and compared with JCSE on two domain-specific tasks, STS in a clinical\ndomain and information retrieval in an educational domain. The results show\nthat JCSE achieves significant performance improvement surpassing direct\ntransfer and other training strategies. This empirically demonstrates JCSE's\neffectiveness and practicability for downstream tasks of a low-resource\nlanguage.\n","authors":["Zihao Chen","Hisashi Handa","Kimiaki Shirahama"],"pdf_url":"https://arxiv.org/pdf/2301.08193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08115v1","updated":"2023-01-19T15:09:59Z","published":"2023-01-19T15:09:59Z","title":"Language Embeddings Sometimes Contain Typological Generalizations","summary":"  To what extent can neural network models learn generalizations about language\nstructure, and how do we find out what they have learned? We explore these\nquestions by training neural models for a range of natural language processing\ntasks on a massively multilingual dataset of Bible translations in 1295\nlanguages. The learned language representations are then compared to existing\ntypological databases as well as to a novel set of quantitative syntactic and\nmorphological features obtained through annotation projection. We conclude that\nsome generalizations are surprisingly close to traditional features from\nlinguistic typology, but that most of our models, as well as those of previous\nwork, do not appear to have made linguistically meaningful generalizations.\nCareful attention to details in the evaluation turns out to be essential to\navoid false positives. Furthermore, to encourage continued work in this field,\nwe release several resources covering most or all of the languages in our data:\n(i) multiple sets of language representations, (ii) multilingual word\nembeddings, (iii) projected and predicted syntactic and morphological features,\n(iv) software to provide linguistically sound evaluations of language\nrepresentations.\n","authors":["Robert Östling","Murathan Kurfalı"],"pdf_url":"https://arxiv.org/pdf/2301.08115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08104v1","updated":"2023-01-19T14:50:36Z","published":"2023-01-19T14:50:36Z","title":"Author as Character and Narrator: Deconstructing Personal Narratives\n  from the r/AmITheAsshole Reddit Community","summary":"  In the r/AmITheAsshole subreddit, people anonymously share first person\nnarratives that contain some moral dilemma or conflict and ask the community to\njudge who is at fault (i.e., who is \"the asshole\"). In general, first person\nnarratives are a unique storytelling domain where the author is the narrator\n(the person telling the story) but can also be a character (the person living\nthe story) and, thus, the author has two distinct voices presented in the\nstory. In this study, we identify linguistic and narrative features associated\nwith the author as the character or as a narrator. We use these features to\nanswer the following questions: (1) what makes an asshole character and (2)\nwhat makes an asshole narrator? We extract both Author-as-Character features\n(e.g., demographics, narrative event chain, and emotional arc) and\nAuthor-as-Narrator features (i.e., the style and emotion of the story as a\nwhole) in order to identify which aspects of the narrative are correlated with\nthe final moral judgment. Our work shows that \"assholes\" as Characters frame\nthemselves as lacking agency with a more positive personal arc, while\n\"assholes\" as Narrators will tell emotional and opinionated stories.\n","authors":["Salvatore Giorgi","Ke Zhao","Alexander H. Feng","Lara J. Martin"],"pdf_url":"https://arxiv.org/pdf/2301.08104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12197v2","updated":"2023-01-19T12:09:23Z","published":"2022-10-21T18:54:17Z","title":"Life is a Circus and We are the Clowns: Automatically Finding Analogies\n  between Situations and Processes","summary":"  Analogy-making gives rise to reasoning, abstraction, flexible categorization\nand counterfactual inference -- abilities lacking in even the best AI systems\ntoday. Much research has suggested that analogies are key to non-brittle\nsystems that can adapt to new domains. Despite their importance, analogies\nreceived little attention in the NLP community, with most research focusing on\nsimple word analogies. Work that tackled more complex analogies relied heavily\non manually constructed, hard-to-scale input representations. In this work, we\nexplore a more realistic, challenging setup: our input is a pair of natural\nlanguage procedural texts, describing a situation or a process (e.g., how the\nheart works/how a pump works). Our goal is to automatically extract entities\nand their relations from the text and find a mapping between the different\ndomains based on relational similarity (e.g., blood is mapped to water). We\ndevelop an interpretable, scalable algorithm and demonstrate that it identifies\nthe correct mappings 87% of the time for procedural texts and 94% for stories\nfrom cognitive-psychology literature. We show it can extract analogies from a\nlarge dataset of procedural texts, achieving 79% precision (analogy prevalence\nin data: 3%). Lastly, we demonstrate that our algorithm is robust to\nparaphrasing the input texts.\n","authors":["Oren Sultan","Dafna Shahaf"],"pdf_url":"https://arxiv.org/pdf/2210.12197v2.pdf","comment":"Accepted to EMNLP 2022 main conference (long paper)"},{"id":"http://arxiv.org/abs/2301.08008v1","updated":"2023-01-19T11:27:56Z","published":"2023-01-19T11:27:56Z","title":"Improving Machine Translation with Phrase Pair Injection and Corpus\n  Filtering","summary":"  In this paper, we show that the combination of Phrase Pair Injection and\nCorpus Filtering boosts the performance of Neural Machine Translation (NMT)\nsystems. We extract parallel phrases and sentences from the pseudo-parallel\ncorpus and augment it with the parallel corpus to train the NMT models. With\nthe proposed approach, we observe an improvement in the Machine Translation\n(MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi,\nand English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on\nthe FLORES test data. These BLEU score improvements are over the models trained\nusing the whole pseudo-parallel corpus augmented with the parallel corpus.\n","authors":["Akshay Batheja","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2301.08008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08006v1","updated":"2023-01-19T11:13:04Z","published":"2023-01-19T11:13:04Z","title":"Keyword Embeddings for Query Suggestion","summary":"  Nowadays, search engine users commonly rely on query suggestions to improve\ntheir initial inputs. Current systems are very good at recommending lexical\nadaptations or spelling corrections to users' queries. However, they often\nstruggle to suggest semantically related keywords given a user's query. The\nconstruction of a detailed query is crucial in some tasks, such as legal\nretrieval or academic search. In these scenarios, keyword suggestion methods\nare critical to guide the user during the query formulation. This paper\nproposes two novel models for the keyword suggestion task trained on scientific\nliterature. Our techniques adapt the architecture of Word2Vec and FastText to\ngenerate keyword embeddings by leveraging documents' keyword co-occurrence.\nAlong with these models, we also present a specially tailored negative sampling\napproach that exploits how keywords appear in academic publications. We devise\na ranking-based evaluation methodology following both known-item and ad-hoc\nsearch scenarios. Finally, we evaluate our proposals against the\nstate-of-the-art word and sentence embedding models showing considerable\nimprovements over the baselines for the tasks.\n","authors":["Jorge Gabín","M. Eduardo Ares","Javier Parapar"],"pdf_url":"https://arxiv.org/pdf/2301.08006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07981v1","updated":"2023-01-19T10:16:56Z","published":"2023-01-19T10:16:56Z","title":"Continuously Reliable Detection of New-Normal Misinformation: Semantic\n  Masking and Contrastive Smoothing in High-Density Latent Regions","summary":"  Toxic misinformation campaigns have caused significant societal harm, e.g.,\naffecting elections and COVID-19 information awareness. Unfortunately, despite\nsuccesses of (gold standard) retrospective studies of misinformation that\nconfirmed their harmful effects after the fact, they arrive too late for timely\nintervention and reduction of such harm. By design, misinformation evades\nretrospective classifiers by exploiting two properties we call new-normal: (1)\nnever-seen-before novelty that cause inescapable generalization challenges for\nprevious classifiers, and (2) massive but short campaigns that end before they\ncan be manually annotated for new classifier training. To tackle these\nchallenges, we propose UFIT, which combines two techniques: semantic masking of\nstrong signal keywords to reduce overfitting, and intra-proxy smoothness\nregularization of high-density regions in the latent space to improve\nreliability and maintain accuracy. Evaluation of UFIT on public new-normal\nmisinformation data shows over 30% improvement over existing approaches on\nfuture (and unseen) campaigns. To the best of our knowledge, UFIT is the first\nsuccessful effort to achieve such high level of generalization on new-normal\nmisinformation data with minimal concession (1 to 5%) of accuracy compared to\noracles trained with full knowledge of all campaigns.\n","authors":["Abhijit Suprem","Joao Eduardo Ferreira","Calton Pu"],"pdf_url":"https://arxiv.org/pdf/2301.07981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02010v2","updated":"2023-01-19T08:10:09Z","published":"2022-01-06T11:00:52Z","title":"Self-Training Vision Language BERTs with a Unified Conditional Model","summary":"  Natural language BERTs are trained with language corpus in a self-supervised\nmanner. Unlike natural language BERTs, vision language BERTs need paired data\nto train, which restricts the scale of VL-BERT pretraining. We propose a\nself-training approach that allows training VL-BERTs from unlabeled image data.\nThe proposed method starts with our unified conditional model -- a vision\nlanguage BERT model that can perform zero-shot conditional generation. Given\ndifferent conditions, the unified conditional model can generate captions,\ndense captions, and even questions. We use the labeled image data to train a\nteacher model and use the trained model to generate pseudo captions on\nunlabeled image data. We then combine the labeled data and pseudo labeled data\nto train a student model. The process is iterated by putting the student model\nas a new teacher. By using the proposed self-training approach and only 300k\nunlabeled extra data, we are able to get competitive or even better\nperformances compared to the models of similar model size trained with 3\nmillion extra image data.\n","authors":["Xiaofeng Yang","Fengmao Lv","Fayao Liu","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2201.02010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07919v1","updated":"2023-01-19T07:04:32Z","published":"2023-01-19T07:04:32Z","title":"Semantic-aware Contrastive Learning for More Accurate Semantic Parsing","summary":"  Since the meaning representations are detailed and accurate annotations which\nexpress fine-grained sequence-level semtantics, it is usually hard to train\ndiscriminative semantic parsers via Maximum Likelihood Estimation (MLE) in an\nautoregressive fashion. In this paper, we propose a semantic-aware contrastive\nlearning algorithm, which can learn to distinguish fine-grained meaning\nrepresentations and take the overall sequence-level semantic into\nconsideration. Specifically, a multi-level online sampling algorithm is\nproposed to sample confusing and diverse instances. Three semantic-aware\nsimilarity functions are designed to accurately measure the distance between\nmeaning representations as a whole. And a ranked contrastive loss is proposed\nto pull the representations of the semantic-identical instances together and\npush negative instances away. Experiments on two standard datasets show that\nour approach achieves significant improvements over MLE baselines and gets\nstate-of-the-art performances by simply applying semantic-aware contrastive\nlearning on a vanilla Seq2Seq model.\n","authors":["Shan Wu","Chunlei Xin","Bo Chen","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2301.07919v1.pdf","comment":"Accepted by EMNLP 2022"},{"id":"http://arxiv.org/abs/2204.01235v2","updated":"2023-01-19T04:22:07Z","published":"2022-04-04T04:50:32Z","title":"An Analysis of Semantically-Aligned Speech-Text Embeddings","summary":"  Embeddings play an important role in end-to-end solutions for multi-modal\nlanguage processing problems. Although there has been some effort to understand\nthe properties of single-modality embedding spaces, particularly that of text,\ntheir cross-modal counterparts are less understood. In this work, we study some\nintrinsic properties of a joint speech-text embedding space, constructed by\nminimizing the distance between paired utterance and transcription inputs in a\nteacher-student model setup, that are informative for several prominent use\ncases. We found that incorporating automatic speech recognition through both\npretraining and multitask scenarios aid semantic alignment significantly,\nresulting in more tightly coupled embeddings. To analyse cross-modal embeddings\nwe utilise a quantitative retrieval accuracy metric for semantic alignment,\nzero-shot classification for generalisability, and probing of the encoders to\nobserve the extent of knowledge transfer from one modality to another.\n","authors":["Muhammad Huzaifah","Ivan Kukanov"],"pdf_url":"https://arxiv.org/pdf/2204.01235v2.pdf","comment":"This is the accepted version of the paper published at IEEE Spoken\n  Language Technology (SLT) Workshop 2022"},{"id":"http://arxiv.org/abs/2011.00136v2","updated":"2023-01-19T23:16:34Z","published":"2020-10-30T23:04:56Z","title":"Improving Dialogue Breakdown Detection with Semi-Supervised Learning","summary":"  Building user trust in dialogue agents requires smooth and consistent\ndialogue exchanges. However, agents can easily lose conversational context and\ngenerate irrelevant utterances. These situations are called dialogue breakdown,\nwhere agent utterances prevent users from continuing the conversation. Building\nsystems to detect dialogue breakdown allows agents to recover appropriately or\navoid breakdown entirely. In this paper we investigate the use of\nsemi-supervised learning methods to improve dialogue breakdown detection,\nincluding continued pre-training on the Reddit dataset and a manifold-based\ndata augmentation method. We demonstrate the effectiveness of these methods on\nthe Dialogue Breakdown Detection Challenge (DBDC) English shared task. Our\nsubmissions to the 2020 DBDC5 shared task place first, beating baselines and\nother submissions by over 12\\% accuracy. In ablations on DBDC4 data from 2019,\nour semi-supervised learning methods improve the performance of a baseline BERT\nmodel by 2\\% accuracy. These methods are applicable generally to any dialogue\ntask and provide a simple way to improve model performance.\n","authors":["Nathan Ng","Marzyeh Ghassemi","Narendran Thangarajan","Jiacheng Pan","Qi Guo"],"pdf_url":"https://arxiv.org/pdf/2011.00136v2.pdf","comment":"6 pages, 1 figure, accepted at the NeurIPS Workshop on Human in the\n  Loop Dialogue Systems"},{"id":"http://arxiv.org/abs/2301.08347v1","updated":"2023-01-19T22:43:59Z","published":"2023-01-19T22:43:59Z","title":"Sentiment Analysis for Measuring Hope and Fear from Reddit Posts During\n  the 2022 Russo-Ukrainian Conflict","summary":"  This paper proposes a novel lexicon-based unsupervised sentimental analysis\nmethod to measure the $``\\textit{hope}\"$ and $``\\textit{fear}\"$ for the 2022\nUkrainian-Russian Conflict. $\\textit{Reddit.com}$ is utilised as the main\nsource of human reactions to daily events during nearly the first three months\nof the conflict. The top 50 $``hot\"$ posts of six different subreddits about\nUkraine and news (Ukraine, worldnews, Ukraina, UkrainianConflict,\nUkraineWarVideoReport, UkraineWarReports) and their relative comments are\nscraped and a data set is created. On this corpus, multiple analyses such as\n(1) public interest, (2) hope/fear score, (3) stock price interaction are\nemployed. We promote using a dictionary approach, which scores the hopefulness\nof every submitted user post. The Latent Dirichlet Allocation (LDA) algorithm\nof topic modelling is also utilised to understand the main issues raised by\nusers and what are the key talking points. Experimental analysis shows that the\nhope strongly decreases after the symbolic and strategic losses of Azovstal\n(Mariupol) and Severodonetsk. Spikes in hope/fear, both positives and\nnegatives, are present after important battles, but also some non-military\nevents, such as Eurovision and football games.\n","authors":["Alessio Guerra","Oktay Karakuş"],"pdf_url":"https://arxiv.org/pdf/2301.08347v1.pdf","comment":"23 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2301.08718v1","updated":"2023-01-19T12:51:59Z","published":"2023-01-19T12:51:59Z","title":"Reversing The Twenty Questions Game","summary":"  Twenty questions is a widely popular verbal game. In recent years, many\ncomputerized versions of this game have been developed in which a user thinks\nof an entity and a computer attempts to guess this entity by asking a series of\nboolean-type (yes/no) questions. In this research, we aim to reverse this game\nby making the computer choose an entity at random. The human aims to guess this\nentity by quizzing the computer with natural language queries which the\ncomputer will then attempt to parse using a boolean question answering model.\nThe game ends when the human is successfully able to guess the entity of the\ncomputer's choice.\n","authors":["Parth Parikh","Anisha Gupta"],"pdf_url":"https://arxiv.org/pdf/2301.08718v1.pdf","comment":"14 pages, 9 figures, 2 tables, This paper is a graduate course\n  project for North Carolina State University, written for the Natural Language\n  Processing class in Fall 2021. The paper was submitted to and graded by Dr.\n  Munindar P. Singh"},{"id":"http://arxiv.org/abs/2301.08721v1","updated":"2023-01-19T02:29:23Z","published":"2023-01-19T02:29:23Z","title":"Batch Prompting: Efficient Inference with Large Language Model APIs","summary":"  Performing inference on hundreds of thousands of samples with large language\nmodels (LLMs) can be computationally and financially costly. We propose batch\nprompting, a simple alternative prompting approach that enables the LLM to run\ninference in batches, instead of one sample at a time. Our method reduces both\ntoken and time costs while retaining downstream performance. We theoretically\ndemonstrate that under a few-shot in-context learning setting, the inference\ncosts decrease almost inverse linearly with the number of samples in each\nbatch. We extensively validate the effectiveness of batch prompting on ten\ndatasets across commonsense QA, arithmetic reasoning, and NLI/NLU: batch\nprompting significantly~(up to $5\\times$ with six samples in batch) reduces the\nLLM (Codex) inference token and time costs while achieving better or comparable\nperformance. Our analysis shows that the number of samples in each batch and\nthe complexity of tasks affect its performance. Further, batch prompting can be\napplied across different LLMs and reasoning methods.\n","authors":["Zhoujun Cheng","Jungo Kasai","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2301.08721v1.pdf","comment":"18 pages, 9 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.08247v1","updated":"2023-01-19T18:59:52Z","published":"2023-01-19T18:59:52Z","title":"Multiview Compressive Coding for 3D Reconstruction","summary":"  A central goal of visual recognition is to understand objects and scenes from\na single image. 2D recognition has witnessed tremendous progress thanks to\nlarge-scale learning and general-purpose representations. Comparatively, 3D\nposes new challenges stemming from occlusions not depicted in the image. Prior\nworks try to overcome these by inferring from multiple views or rely on scarce\nCAD models and category-specific priors which hinder scaling to novel settings.\nIn this work, we explore single-view 3D reconstruction by learning\ngeneralizable representations inspired by advances in self-supervised learning.\nWe introduce a simple framework that operates on 3D points of single objects or\nwhole scenes coupled with category-agnostic large-scale training from diverse\nRGB-D videos. Our model, Multiview Compressive Coding (MCC), learns to compress\nthe input appearance and geometry to predict the 3D structure by querying a\n3D-aware decoder. MCC's generality and efficiency allow it to learn from\nlarge-scale and diverse data sources with strong generalization to novel\nobjects imagined by DALL$\\cdot$E 2 or captured in-the-wild with an iPhone.\n","authors":["Chao-Yuan Wu","Justin Johnson","Jitendra Malik","Christoph Feichtenhofer","Georgia Gkioxari"],"pdf_url":"https://arxiv.org/pdf/2301.08247v1.pdf","comment":"Project page: https://mcc3d.github.io/"},{"id":"http://arxiv.org/abs/2211.02578v2","updated":"2023-01-19T18:59:45Z","published":"2022-11-04T16:50:10Z","title":"Data Models for Dataset Drift Controls in Machine Learning With Images","summary":"  Camera images are ubiquitous in machine learning research. They also play a\ncentral role in the delivery of important services spanning medicine and\nenvironmental surveying. However, the application of machine learning models in\nthese domains has been limited because of robustness concerns. A primary\nfailure mode are performance drops due to differences between the training and\ndeployment data. While there are methods to prospectively validate the\nrobustness of machine learning models to such dataset drifts, existing\napproaches do not account for explicit models of the primary object of\ninterest: the data. This limits our ability to study and understand the\nrelationship between data generation and downstream machine learning model\nperformance in a physically accurate manner. In this study, we demonstrate how\nto overcome this limitation by pairing traditional machine learning with\nphysical optics to obtain explicit and differentiable data models. We\ndemonstrate how such data models can be constructed for image data and used to\ncontrol downstream machine learning model performance related to dataset drift.\nThe findings are distilled into three applications. First, drift synthesis\nenables the controlled generation of physically faithful drift test cases to\npower model selection and targeted generalization. Second, the gradient\nconnection between machine learning task model and data model allows advanced,\nprecise tolerancing of task model sensitivity to changes in the data\ngeneration. These drift forensics can be used to precisely specify the\nacceptable data environments in which a task model may be run. Third, drift\noptimization opens up the possibility to create drifts that can help the task\nmodel learn better faster, effectively optimizing the data generating process\nitself. A guide to access the open code and datasets is available at\nhttps://github.com/aiaudit-org/raw2logit.\n","authors":["Luis Oala","Marco Aversa","Gabriel Nobis","Kurt Willis","Yoan Neuenschwander","Michèle Buck","Christian Matek","Jerome Extermann","Enrico Pomarico","Wojciech Samek","Roderick Murray-Smith","Christoph Clausen","Bruno Sanguinetti"],"pdf_url":"https://arxiv.org/pdf/2211.02578v2.pdf","comment":"LO and MA contributed equally"},{"id":"http://arxiv.org/abs/2301.08245v1","updated":"2023-01-19T18:59:28Z","published":"2023-01-19T18:59:28Z","title":"Booster: a Benchmark for Depth from Images of Specular and Transparent\n  Surfaces","summary":"  Estimating depth from images nowadays yields outstanding results, both in\nterms of in-domain accuracy and generalization. However, we identify two main\nchallenges that remain open in this field: dealing with non-Lambertian\nmaterials and effectively processing high-resolution images. Purposely, we\npropose a novel dataset that includes accurate and dense ground-truth labels at\nhigh resolution, featuring scenes containing several specular and transparent\nsurfaces. Our acquisition pipeline leverages a novel deep space-time stereo\nframework, enabling easy and accurate labeling with sub-pixel precision. The\ndataset is composed of 606 samples collected in 85 different scenes, each\nsample includes both a high-resolution pair (12 Mpx) as well as an unbalanced\nstereo pair (Left: 12 Mpx, Right: 1.1 Mpx). Additionally, we provide manually\nannotated material segmentation masks and 15K unlabeled samples. We divide the\ndataset into a training set, and two testing sets, the latter devoted to the\nevaluation of stereo and monocular depth estimation networks respectively to\nhighlight the open challenges and future research directions in this field.\n","authors":["Pierluigi Zama Ramirez","Alex Costanzino","Fabio Tosi","Matteo Poggi","Samuele Salti","Stefano Mattoccia","Luigi Di Stefano"],"pdf_url":"https://arxiv.org/pdf/2301.08245v1.pdf","comment":"Extension of the paper \"Open Challenges in Deep Stereo: the Booster\n  Dataset\" that was presented at CVPR 2022"},{"id":"http://arxiv.org/abs/2301.08243v1","updated":"2023-01-19T18:59:01Z","published":"2023-01-19T18:59:01Z","title":"Self-Supervised Learning from Images with a Joint-Embedding Predictive\n  Architecture","summary":"  This paper demonstrates an approach for learning highly semantic image\nrepresentations without relying on hand-crafted data-augmentations. We\nintroduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a\nnon-generative approach for self-supervised learning from images. The idea\nbehind I-JEPA is simple: from a single context block, predict the\nrepresentations of various target blocks in the same image. A core design\nchoice to guide I-JEPA towards producing semantic representations is the\nmasking strategy; specifically, it is crucial to (a) predict several target\nblocks in the image, (b) sample target blocks with sufficiently large scale\n(occupying 15%-20% of the image), and (c) use a sufficiently informative\n(spatially distributed) context block. Empirically, when combined with Vision\nTransformers, we find I-JEPA to be highly scalable. For instance, we train a\nViT-Huge/16 on ImageNet using 32 A100 GPUs in under 38 hours to achieve strong\ndownstream performance across a wide range of tasks requiring various levels of\nabstraction, from linear classification to object counting and depth\nprediction.\n","authors":["Mahmoud Assran","Quentin Duval","Ishan Misra","Piotr Bojanowski","Pascal Vincent","Michael Rabbat","Yann LeCun","Nicolas Ballas"],"pdf_url":"https://arxiv.org/pdf/2301.08243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08237v1","updated":"2023-01-19T18:54:43Z","published":"2023-01-19T18:54:43Z","title":"LoCoNet: Long-Short Context Network for Active Speaker Detection","summary":"  Active Speaker Detection (ASD) aims to identify who is speaking in each frame\nof a video. ASD reasons from audio and visual information from two contexts:\nlong-term intra-speaker context and short-term inter-speaker context. Long-term\nintra-speaker context models the temporal dependencies of the same speaker,\nwhile short-term inter-speaker context models the interactions of speakers in\nthe same scene. These two contexts are complementary to each other and can help\ninfer the active speaker. Motivated by these observations, we propose LoCoNet,\na simple yet effective Long-Short Context Network that models the long-term\nintra-speaker context and short-term inter-speaker context. We use\nself-attention to model long-term intra-speaker context due to its\neffectiveness in modeling long-range dependencies, and convolutional blocks\nthat capture local patterns to model short-term inter-speaker context.\nExtensive experiments show that LoCoNet achieves state-of-the-art performance\non multiple datasets, achieving an mAP of 95.2%(+1.1%) on AVA-ActiveSpeaker,\n68.1%(+22%) on Columbia dataset, 97.2%(+2.8%) on Talkies dataset and\n59.7%(+8.0%) on Ego4D dataset. Moreover, in challenging cases where multiple\nspeakers are present, or face of active speaker is much smaller than other\nfaces in the same scene, LoCoNet outperforms previous state-of-the-art methods\nby 3.4% on the AVA-ActiveSpeaker dataset. The code will be released at\nhttps://github.com/SJTUwxz/LoCoNet_ASD.\n","authors":["Xizi Wang","Feng Cheng","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2301.08237v1.pdf","comment":"tech report"},{"id":"http://arxiv.org/abs/2301.08229v1","updated":"2023-01-19T18:38:04Z","published":"2023-01-19T18:38:04Z","title":"Estimating Remaining Lifespan from the Face","summary":"  The face is a rich source of information that can be utilized to infer a\nperson's biological age, sex, phenotype, genetic defects, and health status.\nAll of these factors are relevant for predicting an individual's remaining\nlifespan. In this study, we collected a dataset of over 24,000 images (from\nWikidata/Wikipedia) of individuals who died of natural causes, along with the\nnumber of years between when the image was taken and when the person passed\naway. We made this dataset publicly available. We fine-tuned multiple\nConvolutional Neural Network (CNN) models on this data, at best achieving a\nmean absolute error of 8.3 years in the validation data using VGGFace. However,\nthe model's performance diminishes when the person was younger at the time of\nthe image. To demonstrate the potential applications of our remaining lifespan\nmodel, we present examples of using it to estimate the average loss of life (in\nyears) due to the COVID-19 pandemic and to predict the increase in life\nexpectancy that might result from a health intervention such as weight loss.\nAdditionally, we discuss the ethical considerations associated with such\nmodels.\n","authors":["Amir Fekrazad"],"pdf_url":"https://arxiv.org/pdf/2301.08229v1.pdf","comment":"15 pages, 15 figures"},{"id":"http://arxiv.org/abs/2301.08189v1","updated":"2023-01-19T17:37:40Z","published":"2023-01-19T17:37:40Z","title":"Benchmarking YOLOv5 and YOLOv7 models with DeepSORT for droplet tracking\n  applications","summary":"  Tracking droplets in microfluidics is a challenging task. The difficulty\narises in choosing a tool to analyze general microfluidic videos to infer\nphysical quantities. The state-of-the-art object detector algorithm You Only\nLook Once (YOLO) and the object tracking algorithm Simple Online and Realtime\nTracking with a Deep Association Metric (DeepSORT) are customizable for droplet\nidentification and tracking. The customization includes training YOLO and\nDeepSORT networks to identify and track the objects of interest. We trained\nseveral YOLOv5 and YOLOv7 models and the DeepSORT network for droplet\nidentification and tracking from microfluidic experimental videos. We compare\nthe performance of the droplet tracking applications with YOLOv5 and YOLOv7 in\nterms of training time and time to analyze a given video across various\nhardware configurations. Despite the latest YOLOv7 being 10% faster, the\nreal-time tracking is only achieved by lighter YOLO models on RTX 3070 Ti GPU\nmachine due to additional significant droplet tracking costs arising from the\nDeepSORT algorithm. This work is a benchmark study for the YOLOv5 and YOLOv7\nnetworks with DeepSORT in terms of the training time and inference time for a\ncustom dataset of microfluidic droplets.\n","authors":["Mihir Durve","Sibilla Orsini","Adriano Tiribocchi","Andrea Montessori","Jean-Michel Tucny","Marco Lauricella","Andrea Camposeo","Dario Pisignano","Sauro Succi"],"pdf_url":"https://arxiv.org/pdf/2301.08189v1.pdf","comment":"13 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2301.08187v1","updated":"2023-01-19T17:33:48Z","published":"2023-01-19T17:33:48Z","title":"A Multi-Resolution Framework for U-Nets with Applications to\n  Hierarchical VAEs","summary":"  U-Net architectures are ubiquitous in state-of-the-art deep learning, however\ntheir regularisation properties and relationship to wavelets are understudied.\nIn this paper, we formulate a multi-resolution framework which identifies\nU-Nets as finite-dimensional truncations of models on an infinite-dimensional\nfunction space. We provide theoretical results which prove that average pooling\ncorresponds to projection within the space of square-integrable functions and\nshow that U-Nets with average pooling implicitly learn a Haar wavelet basis\nrepresentation of the data. We then leverage our framework to identify\nstate-of-the-art hierarchical VAEs (HVAEs), which have a U-Net architecture, as\na type of two-step forward Euler discretisation of multi-resolution diffusion\nprocesses which flow from a point mass, introducing sampling instabilities. We\nalso demonstrate that HVAEs learn a representation of time which allows for\nimproved parameter efficiency through weight-sharing. We use this observation\nto achieve state-of-the-art HVAE performance with half the number of parameters\nof existing models, exploiting the properties of our continuous-time\nformulation.\n","authors":["Fabian Falck","Christopher Williams","Dominic Danks","George Deligiannidis","Christopher Yau","Chris Holmes","Arnaud Doucet","Matthew Willetts"],"pdf_url":"https://arxiv.org/pdf/2301.08187v1.pdf","comment":"NeurIPS 2022 (selected as oral)"},{"id":"http://arxiv.org/abs/2301.08174v1","updated":"2023-01-19T17:05:07Z","published":"2023-01-19T17:05:07Z","title":"Collaborative Robotic Ultrasound Tissue Scanning for Surgical Resection\n  Guidance in Neurosurgery","summary":"  The aim of this paper is to introduce a robotic platform for autonomous iUS\ntissue scanning to optimise intraoperative diagnosis and improve surgical\nresection during robot-assisted operations. To guide anatomy specific robotic\nscanning and generate a representation of the robot task space, fast and\naccurate techniques for the recovery of 3D morphological structures of the\nsurgical cavity are developed. The prototypic DLR MIRO surgical robotic arm is\nused to control the applied force and the in-plane motion of the US transducer.\nA key application of the proposed platform is the scanning of brain tissue to\nguide tumour resection.\n","authors":["Alistair Weld","Michael Dyck","Julian Klodmann","Giulio Anichini","Luke Dixon","Sophie Camp","Alin Albu-Schäffer","Stamatia Giannarou"],"pdf_url":"https://arxiv.org/pdf/2301.08174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12684v2","updated":"2023-01-19T16:41:19Z","published":"2022-09-23T03:04:27Z","title":"Soft-labeling Strategies for Rapid Sub-Typing","summary":"  The challenge of labeling large example datasets for computer vision\ncontinues to limit the availability and scope of image repositories. This\nresearch provides a new method for automated data collection, curation,\nlabeling, and iterative training with minimal human intervention for the case\nof overhead satellite imagery and object detection. The new operational scale\neffectively scanned an entire city (68 square miles) in grid search and yielded\na prediction of car color from space observations. A partially trained yolov5\nmodel served as an initial inference seed to output further, more refined model\npredictions in iterative cycles. Soft labeling here refers to accepting label\nnoise as a potentially valuable augmentation to reduce overfitting and enhance\ngeneralized predictions to previously unseen test data. The approach takes\nadvantage of a real-world instance where a cropped image of a car can\nautomatically receive sub-type information as white or colorful from pixel\nvalues alone, thus completing an end-to-end pipeline without overdependence on\nhuman labor.\n","authors":["Grant Rosario","David Noever","Matt Ciolino"],"pdf_url":"https://arxiv.org/pdf/2209.12684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08160v1","updated":"2023-01-19T16:31:13Z","published":"2023-01-19T16:31:13Z","title":"FECANet: Boosting Few-Shot Semantic Segmentation with Feature-Enhanced\n  Context-Aware Network","summary":"  Few-shot semantic segmentation is the task of learning to locate each pixel\nof the novel class in the query image with only a few annotated support images.\nThe current correlation-based methods construct pair-wise feature correlations\nto establish the many-to-many matching because the typical prototype-based\napproaches cannot learn fine-grained correspondence relations. However, the\nexisting methods still suffer from the noise contained in naive correlations\nand the lack of context semantic information in correlations. To alleviate\nthese problems mentioned above, we propose a Feature-Enhanced Context-Aware\nNetwork (FECANet). Specifically, a feature enhancement module is proposed to\nsuppress the matching noise caused by inter-class local similarity and enhance\nthe intra-class relevance in the naive correlation. In addition, we propose a\nnovel correlation reconstruction module that encodes extra correspondence\nrelations between foreground and background and multi-scale context semantic\nfeatures, significantly boosting the encoder to capture a reliable matching\npattern. Experiments on PASCAL-$5^i$ and COCO-$20^i$ datasets demonstrate that\nour proposed FECANet leads to remarkable improvement compared to previous\nstate-of-the-arts, demonstrating its effectiveness.\n","authors":["Huafeng Liu","Pai Peng","Tao Chen","Qiong Wang","Yazhou Yao","Xian-Sheng Hua"],"pdf_url":"https://arxiv.org/pdf/2301.08160v1.pdf","comment":"accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2301.08157v1","updated":"2023-01-19T16:22:17Z","published":"2023-01-19T16:22:17Z","title":"SoftEnNet: Symbiotic Monocular Depth Estimation and Lumen Segmentation\n  for Colonoscopy Endorobots","summary":"  Colorectal cancer is the third most common cause of cancer death worldwide.\nOptical colonoscopy is the gold standard for detecting colorectal cancer;\nhowever, about 25 percent of polyps are missed during the procedure. A\nvision-based autonomous endorobot can improve colonoscopy procedures\nsignificantly through systematic, complete screening of the colonic mucosa. The\nreliable robot navigation needed requires a three-dimensional understanding of\nthe environment and lumen tracking to support autonomous tasks. We propose a\nnovel multi-task model that simultaneously predicts dense depth and lumen\nsegmentation with an ensemble of deep networks. The depth estimation\nsub-network is trained in a self-supervised fashion guided by view synthesis;\nthe lumen segmentation sub-network is supervised. The two sub-networks are\ninterconnected with pathways that enable information exchange and thereby\nmutual learning. As the lumen is in the image's deepest visual space, lumen\nsegmentation helps with the depth estimation at the farthest location. In turn,\nthe estimated depth guides the lumen segmentation network as the lumen location\ndefines the farthest scene location. Unlike other environments, view synthesis\noften fails in the colon because of the deformable wall, textureless surface,\nspecularities, and wide field of view image distortions, all challenges that\nour pipeline addresses. We conducted qualitative analysis on a synthetic\ndataset and quantitative analysis on a colon training model and real\ncolonoscopy videos. The experiments show that our model predicts accurate\nscale-invariant depth maps and lumen segmentation from colonoscopy images in\nnear real-time.\n","authors":["Alwyn Mathew","Ludovic Magerand","Emanuele Trucco","Luigi Manfredi"],"pdf_url":"https://arxiv.org/pdf/2301.08157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08153v1","updated":"2023-01-19T16:14:28Z","published":"2023-01-19T16:14:28Z","title":"SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character\n  on Arbitrary Avatar Engines","summary":"  The creation of a parameterized stylized character involves careful selection\nof numerous parameters, also known as the \"avatar vectors\" that can be\ninterpreted by the avatar engine. Existing unsupervised avatar vector\nestimation methods that auto-create avatars for users, however, often fail to\nwork because of the domain gap between realistic faces and stylized avatar\nimages. To this end, we propose SwiftAvatar, a novel avatar auto-creation\nframework that is evidently superior to previous works. SwiftAvatar introduces\ndual-domain generators to create pairs of realistic faces and avatar images\nusing shared latent codes. The latent codes can then be bridged with the avatar\nvectors as pairs, by performing GAN inversion on the avatar images rendered\nfrom the engine using avatar vectors. Through this way, we are able to\nsynthesize paired data in high-quality as many as possible, consisting of\navatar vectors and their corresponding realistic faces. We also propose\nsemantic augmentation to improve the diversity of synthesis. Finally, a\nlight-weight avatar vector estimator is trained on the synthetic pairs to\nimplement efficient auto-creation. Our experiments demonstrate the\neffectiveness and efficiency of SwiftAvatar on two different avatar engines.\nThe superiority and advantageous flexibility of SwiftAvatar are also verified\nin both subjective and objective evaluations.\n","authors":["Shizun Wang","Weihong Zeng","Xu Wang","Hao Yang","Li Chen","Chuang Zhang","Ming Wu","Yi Yuan","Yunzhao Zeng","Min Zheng"],"pdf_url":"https://arxiv.org/pdf/2301.08153v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11606v3","updated":"2023-01-19T16:08:46Z","published":"2022-05-23T20:01:32Z","title":"Discriminative Feature Learning through Feature Distance Loss","summary":"  Ensembles of Convolutional neural networks have shown remarkable results in\nlearning discriminative semantic features for image classification tasks.\nThough, the models in the ensemble often concentrate on similar regions in\nimages. This work proposes a novel method that forces a set of base models to\nlearn different features for a classification task. These models are combined\nin an ensemble to make a collective classification. The key finding is that by\nforcing the models to concentrate on different features, the classification\naccuracy is increased. To learn different feature concepts, a so-called feature\ndistance loss is implemented on the feature maps. The experiments on benchmark\nconvolutional neural networks (VGG16, ResNet, AlexNet), popular datasets\n(Cifar10, Cifar100, miniImageNet, NEU, BSD, TEX), and different training\nsamples (3, 5, 10, 20, 50, 100 per class) show the effectiveness of the\nproposed feature loss. The proposed method outperforms classical ensemble\nversions of the base models. The Class Activation Maps explicitly prove the\nability to learn different feature concepts. The code is available at:\nhttps://github.com/2Obe/Feature-Distance-Loss.git\n","authors":["Tobias Schlagenhauf","Yiwen Lin","Benjamin Noack"],"pdf_url":"https://arxiv.org/pdf/2205.11606v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08147v1","updated":"2023-01-19T15:59:10Z","published":"2023-01-19T15:59:10Z","title":"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods,\n  Datasets, and Evaluation","summary":"  Recently, various methods for 6D pose and shape estimation of objects at a\nper-category level have been proposed. This work provides an overview of the\nfield in terms of methods, datasets, and evaluation protocols. First, an\noverview of existing works and their commonalities and differences is provided.\nSecond, we take a critical look at the predominant evaluation protocol,\nincluding metrics and datasets. Based on the findings, we propose a new set of\nmetrics, contribute new annotations for the Redwood dataset, and evaluate\nstate-of-the-art methods in a fair comparison. The results indicate that\nexisting methods do not generalize well to unconstrained orientations and are\nactually heavily biased towards objects being upright. We provide an\neasy-to-use evaluation toolbox with well-defined metrics, methods, and dataset\ninterfaces, which allows evaluation and comparison with various\nstate-of-the-art approaches\n(https://github.com/roym899/pose_and_shape_evaluation).\n","authors":["Leonard Bruns","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2301.08147v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2202.10346"},{"id":"http://arxiv.org/abs/2301.08140v1","updated":"2023-01-19T15:54:52Z","published":"2023-01-19T15:54:52Z","title":"Regularizing disparity estimation via multi task learning with\n  structured light reconstruction","summary":"  3D reconstruction is a useful tool for surgical planning and guidance.\nHowever, the lack of available medical data stunts research and development in\nthis field, as supervised deep learning methods for accurate disparity\nestimation rely heavily on large datasets containing ground truth information.\nAlternative approaches to supervision have been explored, such as\nself-supervision, which can reduce or remove entirely the need for ground\ntruth. However, no proposed alternatives have demonstrated performance\ncapabilities close to what would be expected from a supervised setup. This work\naims to alleviate this issue. In this paper, we investigate the learning of\nstructured light projections to enhance the development of direct disparity\nestimation networks. We show for the first time that it is possible to\naccurately learn the projection of structured light on a scene, implicitly\nlearning disparity. Secondly, we \\textcolor{black}{explore the use of a multi\ntask learning (MTL) framework for the joint training of structured light and\ndisparity. We present results which show that MTL with structured light\nimproves disparity training; without increasing the number of model parameters.\nOur MTL setup outperformed the single task learning (STL) network in every\nvalidation test. Notably, in the medical generalisation test, the STL error was\n1.4 times worse than that of the best MTL performance. The benefit of using MTL\nis emphasised when the training data is limited.} A dataset containing\nstereoscopic images, disparity maps and structured light projections on medical\nphantoms and ex vivo tissue was created for evaluation together with virtual\nscenes. This dataset will be made publicly available in the future.\n","authors":["Alistair Weld","Joao Cartucho","Chi Xu","Joseph Davids","Stamatia Giannarou"],"pdf_url":"https://arxiv.org/pdf/2301.08140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06496v2","updated":"2023-01-19T15:44:27Z","published":"2023-01-16T16:10:52Z","title":"High-bandwidth Close-Range Information Transport through Light Pipes","summary":"  Image retrieval after propagation through multi-mode fibers is gaining\nattention due to their capacity to confine light and efficiently transport it\nover distances in a compact system. Here, we propose a generally applicable\ninformation-theoretic framework to transmit maximal-entropy (data) images and\nmaximize the information transmission over sub-meter distances, a crucial\ncapability that allows optical storage applications to scale and address\ndifferent parts of storage media. To this end, we use millimeter-sized square\noptical waveguides to image a megapixel 8-bit spatial-light modulator. Data is\nthus represented as a 2D array of 8-bit values (symbols). Transmitting 100000s\nof symbols requires innovation beyond transmission matrix approaches. Deep\nneural networks have been recently utilized to retrieve images, but have been\nlimited to small (thousands of symbols) and natural looking (low entropy)\nimages. We maximize information transmission by combining a bandwidth-optimized\nhomodyne detector with a differentiable hybrid neural-network consisting of a\ndigital twin of the experiment setup and a U-Net. For the digital twin, we\nimplement and compare a differentiable mode-based twin with a differentiable\nray-based twin. Importantly, the latter can adapt to manufacturing-related\nsetup imperfections during training which we show to be crucial. Our pipeline\nis trained end-to-end to recover digital input images while maximizing the\nachievable information page size based on a differentiable mutual-information\nestimator. We demonstrate retrieval of 66 kB at maximum with 1.7 bit per symbol\non average with a range of 0.3 - 3.4 bit.\n","authors":["Joowon Lim","Jannes Gladrow","Douglas Kelly","Greg O'Shea","Govert Verkes","Ioan Stefanovici","Sebastian Nowozin","Benn Thomsen"],"pdf_url":"https://arxiv.org/pdf/2301.06496v2.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.08125v1","updated":"2023-01-19T15:38:43Z","published":"2023-01-19T15:38:43Z","title":"Diagnose Like a Pathologist: Transformer-Enabled Hierarchical\n  Attention-Guided Multiple Instance Learning for Whole Slide Image\n  Classification","summary":"  Multiple Instance Learning (MIL) and transformers are increasingly popular in\nhistopathology Whole Slide Image (WSI) classification. However, unlike human\npathologists who selectively observe specific regions of histopathology tissues\nunder different magnifications, most methods do not incorporate multiple\nresolutions of the WSIs, hierarchically and attentively, thereby leading to a\nloss of focus on the WSIs and information from other resolutions. To resolve\nthis issue, we propose the Hierarchical Attention-Guided Multiple Instance\nLearning framework to fully exploit the WSIs, which can dynamically and\nattentively discover the discriminative regions across multiple resolutions of\nthe WSIs. Within this framework, to further enhance the performance of the\ntransformer and obtain a more holistic WSI (bag) representation, we propose an\nIntegrated Attention Transformer, consisting of multiple Integrated Attention\nModules, which is the combination of a transformer layer and an aggregation\nmodule that produces a bag representation based on every instance\nrepresentation in that bag. The results of the experiments show that our method\nachieved state-of-the-art performances on multiple datasets, including\nCamelyon16, TCGA-RCC, TCGA-NSCLC, and our in-house IMGC dataset.\n","authors":["Conghao Xiong","Hao Chen","Joseph Sung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2301.08125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06866v2","updated":"2023-01-19T15:33:02Z","published":"2023-01-17T13:20:21Z","title":"Building Scalable Video Understanding Benchmarks through Sports","summary":"  Existing benchmarks for evaluating long video understanding falls short on\nmultiple aspects, either lacking in scale or quality of annotations. These\nlimitations arise from the difficulty in collecting dense annotations for long\nvideos (e.g. actions, dialogues, etc.), which are often obtained by manually\nlabeling many frames per second. In this work, we introduce an automated\nAnnotation and Video Stream Alignment Pipeline (abbreviated ASAP). We\ndemonstrate the generality of ASAP by aligning unlabeled videos of four\ndifferent sports (Cricket, Football, Basketball, and American Football) with\ntheir corresponding dense annotations (i.e. commentary) freely available on the\nweb. Our human studies indicate that ASAP can align videos and annotations with\nhigh fidelity, precision, and speed. We then leverage ASAP scalability to\ncreate LCric, a large-scale long video understanding benchmark, with over 1000\nhours of densely annotated long Cricket videos (with an average sample length\nof 50 mins) collected at virtually zero annotation cost. We benchmark and\nanalyze state-of-the-art video understanding models on LCric through a large\nset of compositional multi-choice and regression queries. We establish a human\nbaseline that indicates significant room for new research to explore. The\ndataset along with the code for ASAP and baselines can be accessed here:\nhttps://asap-benchmark.github.io/.\n","authors":["Aniket Agarwal","Alex Zhang","Karthik Narasimhan","Igor Gilitschenski","Vishvak Murahari","Yash Kant"],"pdf_url":"https://arxiv.org/pdf/2301.06866v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.00770v3","updated":"2023-01-19T15:25:52Z","published":"2021-11-01T08:44:45Z","title":"Dense Prediction with Attentive Feature Aggregation","summary":"  Aggregating information from features across different layers is an essential\noperation for dense prediction models. Despite its limited expressiveness,\nfeature concatenation dominates the choice of aggregation operations. In this\npaper, we introduce Attentive Feature Aggregation (AFA) to fuse different\nnetwork layers with more expressive non-linear operations. AFA exploits both\nspatial and channel attention to compute weighted average of the layer\nactivations. Inspired by neural volume rendering, we extend AFA with\nScale-Space Rendering (SSR) to perform late fusion of multi-scale predictions.\nAFA is applicable to a wide range of existing network designs. Our experiments\nshow consistent and significant improvements on challenging semantic\nsegmentation benchmarks, including Cityscapes, BDD100K, and Mapillary Vistas,\nat negligible computational and parameter overhead. In particular, AFA improves\nthe performance of the Deep Layer Aggregation (DLA) model by nearly 6% mIoU on\nCityscapes. Our experimental analyses show that AFA learns to progressively\nrefine segmentation maps and to improve boundary details, leading to new\nstate-of-the-art results on boundary detection benchmarks on BSDS500 and\nNYUDv2. Code and video resources are available at http://vis.xyz/pub/dla-afa.\n","authors":["Yung-Hsu Yang","Thomas E. Huang","Min Sun","Samuel Rota Bulò","Peter Kontschieder","Fisher Yu"],"pdf_url":"https://arxiv.org/pdf/2111.00770v3.pdf","comment":"20 pages, 14 figures, WACV 2023"},{"id":"http://arxiv.org/abs/2301.08113v1","updated":"2023-01-19T15:05:13Z","published":"2023-01-19T15:05:13Z","title":"Soft Thresholding for Visual Image Enhancement","summary":"  Thresholding converts a greyscale image into a binary image, and is thus\noften a necessary segmentation step in image processing. For a human viewer\nhowever, thresholding usually has a negative impact on the legibility of\ndocument images. This report describes a simple method for \"smearing out\" the\nthreshold and transforming the greyscale image into a different greyscale\nimage. The method is similar to fuzzy thresholding, but is discussed here in\nthe simpler context of greyscale transformations and, unlike fuzzy\nthresholding, it is independent from the method for finding the threshold. A\nsimple formula is presented for automatically determining the width of the\nthreshold spread. The method can be used, e.g., for enhancing images for the\npresentation in online facsimile repositories.\n","authors":["Christoph Dalitz"],"pdf_url":"https://arxiv.org/pdf/2301.08113v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2301.08092v1","updated":"2023-01-19T14:22:44Z","published":"2023-01-19T14:22:44Z","title":"RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge\n  Distillation","summary":"  Deep Neural Networks are vulnerable to adversarial attacks. Neural\nArchitecture Search (NAS), one of the driving tools of deep neural networks,\ndemonstrates superior performance in prediction accuracy in various machine\nlearning applications. However, it is unclear how it performs against\nadversarial attacks. Given the presence of a robust teacher, it would be\ninteresting to investigate if NAS would produce robust neural architecture by\ninheriting robustness from the teacher. In this paper, we propose Robust Neural\nArchitecture Search by Cross-Layer Knowledge Distillation (RNAS-CL), a novel\nNAS algorithm that improves the robustness of NAS by learning from a robust\nteacher through cross-layer knowledge distillation. Unlike previous knowledge\ndistillation methods that encourage close student/teacher output only in the\nlast layer, RNAS-CL automatically searches for the best teacher layer to\nsupervise each student layer. Experimental result evidences the effectiveness\nof RNAS-CL and shows that RNAS-CL produces small and robust neural\narchitecture.\n","authors":["Utkarsh Nath","Yancheng Wang","Yingzhen Yang"],"pdf_url":"https://arxiv.org/pdf/2301.08092v1.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2210.11817v2","updated":"2023-01-19T14:11:52Z","published":"2022-10-21T08:42:00Z","title":"Motion Matters: A Novel Motion Modeling For Cross-View Gait Feature\n  Learning","summary":"  As a unique biometric that can be perceived at a distance, gait has broad\napplications in person authentication, social security, and so on. Existing\ngait recognition methods suffer from changes in viewpoint and clothing and\nbarely consider extracting diverse motion features, a fundamental\ncharacteristic in gaits, from gait sequences. This paper proposes a novel\nmotion modeling method to extract the discriminative and robust representation.\nSpecifically, we first extract the motion features from the encoded motion\nsequences in the shallow layer. Then we continuously enhance the motion feature\nin deep layers. This motion modeling approach is independent of mainstream work\nin building network architectures. As a result, one can apply this motion\nmodeling method to any backbone to improve gait recognition performance. In\nthis paper, we combine motion modeling with one commonly used backbone~(GaitGL)\nas GaitGL-M to illustrate motion modeling. Extensive experimental results on\ntwo commonly-used cross-view gait datasets demonstrate the superior performance\nof GaitGL-M over existing state-of-the-art methods.\n","authors":["Jingqi Li","Jiaqi Gao","Yuzhen Zhang","Hongming Shan","Junping Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.11817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08072v1","updated":"2023-01-19T13:37:19Z","published":"2023-01-19T13:37:19Z","title":"Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image\n  Fusion with Diffusion Models","summary":"  Color plays an important role in human visual perception, reflecting the\nspectrum of objects. However, the existing infrared and visible image fusion\nmethods rarely explore how to handle multi-spectral/channel data directly and\nachieve high color fidelity. This paper addresses the above issue by proposing\na novel method with diffusion models, termed as Dif-Fusion, to generate the\ndistribution of the multi-channel input data, which increases the ability of\nmulti-source information aggregation and the fidelity of colors. In specific,\ninstead of converting multi-channel images into single-channel data in existing\nfusion methods, we create the multi-channel data distribution with a denoising\nnetwork in a latent space with forward and reverse diffusion process. Then, we\nuse the the denoising network to extract the multi-channel diffusion features\nwith both visible and infrared information. Finally, we feed the multi-channel\ndiffusion features to the multi-channel fusion module to directly generate the\nthree-channel fused image. To retain the texture and intensity information, we\npropose multi-channel gradient loss and intensity loss. Along with the current\nevaluation metrics for measuring texture and intensity fidelity, we introduce a\nnew evaluation metric to quantify color fidelity. Extensive experiments\nindicate that our method is more effective than other state-of-the-art image\nfusion methods, especially in color fidelity.\n","authors":["Jun Yue","Leyuan Fang","Shaobo Xia","Yue Deng","Jiayi Ma"],"pdf_url":"https://arxiv.org/pdf/2301.08072v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2301.08067v1","updated":"2023-01-19T13:26:12Z","published":"2023-01-19T13:26:12Z","title":"Interpreting CNN Predictions using Conditional Generative Adversarial\n  Networks","summary":"  We propose a novel method that trains a conditional Generative Adversarial\nNetwork (GAN) to generate visual interpretations of a Convolutional Neural\nNetwork (CNN). To comprehend a CNN, the GAN is trained with information on how\nthe CNN processes an image when making predictions. Supplying that information\nhas two main challenges: how to represent this information in a form that is\nfeedable to the GANs and how to effectively feed the representation to the GAN.\nTo address these issues, we developed a suitable representation of CNN\narchitectures by cumulatively averaging intermediate interpretation maps. We\nalso propose two alternative approaches to feed the representations to the GAN\nand to choose an effective training strategy. Our approach learned the general\naspects of CNNs and was agnostic to datasets and CNN architectures. The study\nincludes both qualitative and quantitative evaluations and compares the\nproposed GANs with state-of-the-art approaches. We found that the initial\nlayers of CNNs and final layers are equally crucial for interpreting CNNs upon\ninterpreting the proposed GAN. We believe training a GAN to interpret CNNs\nwould open doors for improved interpretations by leveraging fast-paced deep\nlearning advancements. The code used for experimentation is publicly available\nat https://github.com/Akash-guna/Explain-CNN-With-GANS\n","authors":["Akash Guna R T","Raul Benitez","Sikha O K"],"pdf_url":"https://arxiv.org/pdf/2301.08067v1.pdf","comment":"Article submitted to JMLR. 19 Pages"},{"id":"http://arxiv.org/abs/2301.08064v1","updated":"2023-01-19T13:22:11Z","published":"2023-01-19T13:22:11Z","title":"Position Regression for Unsupervised Anomaly Detection","summary":"  In recent years, anomaly detection has become an essential field in medical\nimage analysis. Most current anomaly detection methods for medical images are\nbased on image reconstruction. In this work, we propose a novel anomaly\ndetection approach based on coordinate regression. Our method estimates the\nposition of patches within a volume, and is trained only on data of healthy\nsubjects. During inference, we can detect and localize anomalies by considering\nthe error of the position estimate of a given patch. We apply our method to 3D\nCT volumes and evaluate it on patients with intracranial haemorrhages and\ncranial fractures. The results show that our method performs well in detecting\nthese anomalies. Furthermore, we show that our method requires less memory than\ncomparable approaches that involve image reconstruction. This is highly\nrelevant for processing large 3D volumes, for instance, CT or MRI scans.\n","authors":["Florentin Bieder","Julia Wolleb","Robin Sandkühler","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2301.08064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08044v1","updated":"2023-01-19T12:39:08Z","published":"2023-01-19T12:39:08Z","title":"Reference Guided Image Inpainting using Facial Attributes","summary":"  Image inpainting is a technique of completing missing pixels such as occluded\nregion restoration, distracting objects removal, and facial completion. Among\nthese inpainting tasks, facial completion algorithm performs face inpainting\naccording to the user direction. Existing approaches require delicate and well\ncontrolled input by the user, thus it is difficult for an average user to\nprovide the guidance sufficiently accurate for the algorithm to generate\ndesired results. To overcome this limitation, we propose an alternative\nuser-guided inpainting architecture that manipulates facial attributes using a\nsingle reference image as the guide. Our end-to-end model consists of attribute\nextractors for accurate reference image attribute transfer and an inpainting\nmodel to map the attributes realistically and accurately to generated images.\nWe customize MS-SSIM loss and learnable bidirectional attention maps in which\nimportance structures remain intact even with irregular shaped masks. Based on\nour evaluation using the publicly available dataset CelebA-HQ, we demonstrate\nthat the proposed method delivers superior performance compared to some\nstate-of-the-art methods specialized in inpainting tasks.\n","authors":["Dongsik Yoon","Jeonggi Kwak","Yuanming Li","David Han","Youngsaeng Jin","Hanseok Ko"],"pdf_url":"https://arxiv.org/pdf/2301.08044v1.pdf","comment":"BMVC 2021"},{"id":"http://arxiv.org/abs/2108.06230v5","updated":"2023-01-19T11:58:47Z","published":"2021-08-13T13:29:27Z","title":"Generative Zero-Shot Learning for Semantic Segmentation of 3D Point\n  Clouds","summary":"  While there has been a number of studies on Zero-Shot Learning (ZSL) for 2D\nimages, its application to 3D data is still recent and scarce, with just a few\nmethods limited to classification. We present the first generative approach for\nboth ZSL and Generalized ZSL (GZSL) on 3D data, that can handle both\nclassification and, for the first time, semantic segmentation. We show that it\nreaches or outperforms the state of the art on ModelNet40 classification for\nboth inductive ZSL and inductive GZSL. For semantic segmentation, we created\nthree benchmarks for evaluating this new ZSL task, using S3DIS, ScanNet and\nSemanticKITTI. Our experiments show that our method outperforms strong\nbaselines, which we additionally propose for this task.\n","authors":["Björn Michele","Alexandre Boulch","Gilles Puy","Maxime Bucher","Renaud Marlet"],"pdf_url":"https://arxiv.org/pdf/2108.06230v5.pdf","comment":"For the published code, see https://github.com/valeoai/3DGenZ"},{"id":"http://arxiv.org/abs/2212.10957v2","updated":"2023-01-19T10:26:38Z","published":"2022-12-21T11:49:43Z","title":"TruFor: Leveraging all-round clues for trustworthy image forgery\n  detection and localization","summary":"  In this paper we present TruFor, a forensic framework that can be applied to\na large variety of image manipulation methods, from classic cheapfakes to more\nrecent manipulations based on deep learning. We rely on the extraction of both\nhigh-level and low-level traces through a transformer-based fusion architecture\nthat combines the RGB image and a learned noise-sensitive fingerprint. The\nlatter learns to embed the artifacts related to the camera internal and\nexternal processing by training only on real data in a self-supervised manner.\nForgeries are detected as deviations from the expected regular pattern that\ncharacterizes each pristine image. Looking for anomalies makes the approach\nable to robustly detect a variety of local manipulations, ensuring\ngeneralization. In addition to a pixel-level localization map and a whole-image\nintegrity score, our approach outputs a reliability map that highlights areas\nwhere localization predictions may be error-prone. This is particularly\nimportant in forensic applications in order to reduce false alarms and allow\nfor a large scale analysis. Extensive experiments on several datasets show that\nour method is able to reliably detect and localize both cheapfakes and\ndeepfakes manipulations outperforming state-of-the-art works. Code will be\npublicly available at https://grip-unina.github.io/TruFor/\n","authors":["Fabrizio Guillaro","Davide Cozzolino","Avneesh Sud","Nicholas Dufour","Luisa Verdoliva"],"pdf_url":"https://arxiv.org/pdf/2212.10957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07969v1","updated":"2023-01-19T09:48:07Z","published":"2023-01-19T09:48:07Z","title":"Fast Inference in Denoising Diffusion Models via MMD Finetuning","summary":"  Denoising Diffusion Models (DDMs) have become a popular tool for generating\nhigh-quality samples from complex data distributions. These models are able to\ncapture sophisticated patterns and structures in the data, and can generate\nsamples that are highly diverse and representative of the underlying\ndistribution. However, one of the main limitations of diffusion models is the\ncomplexity of sample generation, since a large number of inference timesteps is\nrequired to faithfully capture the data distribution. In this paper, we present\nMMD-DDM, a novel method for fast sampling of diffusion models. Our approach is\nbased on the idea of using the Maximum Mean Discrepancy (MMD) to finetune the\nlearned distribution with a given budget of timesteps. This allows the\nfinetuned model to significantly improve the speed-quality trade-off, by\nsubstantially increasing fidelity in inference regimes with few steps or,\nequivalently, by reducing the required number of steps to reach a target\nfidelity, thus paving the way for a more practical adoption of diffusion models\nin a wide range of applications. We evaluate our approach on unconditional\nimage generation with extensive experiments across the CIFAR-10, CelebA,\nImageNet and LSUN-Church datasets. Our findings show that the proposed method\nis able to produce high-quality samples in a fraction of the time required by\nwidely-used diffusion models, and outperforms state-of-the-art techniques for\naccelerated sampling. Code is available at:\nhttps://github.com/diegovalsesia/MMD-DDM.\n","authors":["Emanuele Aiello","Diego Valsesia","Enrico Magli"],"pdf_url":"https://arxiv.org/pdf/2301.07969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07958v1","updated":"2023-01-19T09:18:06Z","published":"2023-01-19T09:18:06Z","title":"RecolorNeRF: Layer Decomposed Radiance Field for Efficient Color Editing\n  of 3D Scenes","summary":"  Radiance fields have gradually become a main representation of media.\nAlthough its appearance editing has been studied, how to achieve\nview-consistent recoloring in an efficient manner is still under explored. We\npresent RecolorNeRF, a novel user-friendly color editing approach for the\nneural radiance field. Our key idea is to decompose the scene into a set of\npure-colored layers, forming a palette. Thus, color manipulation can be\nconducted by altering the color components of the palette directly. To support\nefficient palette-based editing, the color of each layer needs to be as\nrepresentative as possible. In the end, the problem is formulated as in an\noptimization formula, where the layers and their blending way are jointly\noptimized with the NeRF itself. Extensive experiments show that our\njointly-optimized layer decomposition can be used against multiple backbones\nand produce photo-realistic recolored novel-view renderings. We demonstrate\nthat RecolorNeRF outperforms baseline methods both quantitatively and\nqualitatively for color editing even in complex real-world scenes.\n","authors":["Bingchen Gong","Yuehao Wang","Xiaoguang Han","Qi Dou"],"pdf_url":"https://arxiv.org/pdf/2301.07958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07947v1","updated":"2023-01-19T08:47:31Z","published":"2023-01-19T08:47:31Z","title":"Point Cloud Data Simulation and Modelling with Aize Workspace","summary":"  This work takes a look at data models often used in digital twins and\npresents preliminary results specifically from surface reconstruction and\nsemantic segmentation models trained using simulated data. This work is\nexpected to serve as a ground work for future endeavours in data\ncontextualisation inside a digital twin.\n","authors":["Boris Mocialov","Eirik Eythorsson","Reza Parseh","Hoang Tran","Vegard Flovik"],"pdf_url":"https://arxiv.org/pdf/2301.07947v1.pdf","comment":"Extended abstract, Northern Lights Deep Learning Conference, 2023"},{"id":"http://arxiv.org/abs/2212.03504v2","updated":"2023-01-19T08:41:18Z","published":"2022-12-07T08:08:01Z","title":"LWSIS: LiDAR-guided Weakly Supervised Instance Segmentation for\n  Autonomous Driving","summary":"  Image instance segmentation is a fundamental research topic in autonomous\ndriving, which is crucial for scene understanding and road safety. Advanced\nlearning-based approaches often rely on the costly 2D mask annotations for\ntraining. In this paper, we present a more artful framework, LiDAR-guided\nWeakly Supervised Instance Segmentation (LWSIS), which leverages the\noff-the-shelf 3D data, i.e., Point Cloud, together with the 3D boxes, as\nnatural weak supervisions for training the 2D image instance segmentation\nmodels. Our LWSIS not only exploits the complementary information in multimodal\ndata during training, but also significantly reduces the annotation cost of the\ndense 2D masks. In detail, LWSIS consists of two crucial modules, Point Label\nAssignment (PLA) and Graph-based Consistency Regularization (GCR). The former\nmodule aims to automatically assign the 3D point cloud as 2D point-wise labels,\nwhile the latter further refines the predictions by enforcing geometry and\nappearance consistency of the multimodal data. Moreover, we conduct a secondary\ninstance segmentation annotation on the nuScenes, named nuInsSeg, to encourage\nfurther research on multimodal perception tasks. Extensive experiments on the\nnuInsSeg, as well as the large-scale Waymo, show that LWSIS can substantially\nimprove existing weakly supervised segmentation models by only involving 3D\ndata during training. Additionally, LWSIS can also be incorporated into 3D\nobject detectors like PointPainting to boost the 3D detection performance for\nfree. The code and dataset are available at https://github.com/Serenos/LWSIS.\n","authors":["Xiang Li","Junbo Yin","Botian Shi","Yikang Li","Ruigang Yang","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2212.03504v2.pdf","comment":"AAAI2023"},{"id":"http://arxiv.org/abs/2301.07944v1","updated":"2023-01-19T08:34:04Z","published":"2023-01-19T08:34:04Z","title":"Revisiting the Spatial and Temporal Modeling for Few-shot Action\n  Recognition","summary":"  Spatial and temporal modeling is one of the most core aspects of few-shot\naction recognition. Most previous works mainly focus on long-term temporal\nrelation modeling based on high-level spatial representations, without\nconsidering the crucial low-level spatial features and short-term temporal\nrelations. Actually, the former feature could bring rich local semantic\ninformation, and the latter feature could represent motion characteristics of\nadjacent frames, respectively. In this paper, we propose SloshNet, a new\nframework that revisits the spatial and temporal modeling for few-shot action\nrecognition in a finer manner. First, to exploit the low-level spatial\nfeatures, we design a feature fusion architecture search module to\nautomatically search for the best combination of the low-level and high-level\nspatial features. Next, inspired by the recent transformer, we introduce a\nlong-term temporal modeling module to model the global temporal relations based\non the extracted spatial appearance features. Meanwhile, we design another\nshort-term temporal modeling module to encode the motion characteristics\nbetween adjacent frame representations. After that, the final predictions can\nbe obtained by feeding the embedded rich spatial-temporal features to a common\nframe-level class prototype matcher. We extensively validate the proposed\nSloshNet on four few-shot action recognition datasets, including\nSomething-Something V2, Kinetics, UCF101, and HMDB51. It achieves favorable\nresults against state-of-the-art methods in all datasets.\n","authors":["Jiazheng Xing","Mengmeng Wang","Boyu Mu","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2301.07944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.06098v3","updated":"2023-01-19T08:21:44Z","published":"2021-08-13T07:16:40Z","title":"FedPara: Low-Rank Hadamard Product for Communication-Efficient Federated\n  Learning","summary":"  In this work, we propose a communication-efficient parameterization, FedPara,\nfor federated learning (FL) to overcome the burdens on frequent model uploads\nand downloads. Our method re-parameterizes weight parameters of layers using\nlow-rank weights followed by the Hadamard product. Compared to the conventional\nlow-rank parameterization, our FedPara method is not restricted to low-rank\nconstraints, and thereby it has a far larger capacity. This property enables to\nachieve comparable performance while requiring 3 to 10 times lower\ncommunication costs than the model with the original layers, which is not\nachievable by the traditional low-rank methods. The efficiency of our method\ncan be further improved by combining with other efficient FL optimizers. In\naddition, we extend our method to a personalized FL application, pFedPara,\nwhich separates parameters into global and local ones. We show that pFedPara\noutperforms competing personalized FL methods with more than three times fewer\nparameters.\n","authors":["Nam Hyeon-Woo","Moon Ye-Bin","Tae-Hyun Oh"],"pdf_url":"https://arxiv.org/pdf/2108.06098v3.pdf","comment":"Accepted at ICLR 2022"},{"id":"http://arxiv.org/abs/2201.02010v2","updated":"2023-01-19T08:10:09Z","published":"2022-01-06T11:00:52Z","title":"Self-Training Vision Language BERTs with a Unified Conditional Model","summary":"  Natural language BERTs are trained with language corpus in a self-supervised\nmanner. Unlike natural language BERTs, vision language BERTs need paired data\nto train, which restricts the scale of VL-BERT pretraining. We propose a\nself-training approach that allows training VL-BERTs from unlabeled image data.\nThe proposed method starts with our unified conditional model -- a vision\nlanguage BERT model that can perform zero-shot conditional generation. Given\ndifferent conditions, the unified conditional model can generate captions,\ndense captions, and even questions. We use the labeled image data to train a\nteacher model and use the trained model to generate pseudo captions on\nunlabeled image data. We then combine the labeled data and pseudo labeled data\nto train a student model. The process is iterated by putting the student model\nas a new teacher. By using the proposed self-training approach and only 300k\nunlabeled extra data, we are able to get competitive or even better\nperformances compared to the models of similar model size trained with 3\nmillion extra image data.\n","authors":["Xiaofeng Yang","Fengmao Lv","Fayao Liu","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2201.02010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06077v2","updated":"2023-01-19T07:32:33Z","published":"2023-01-15T11:56:32Z","title":"MN-Pair Contrastive Damage Representation and Clustering for Prognostic\n  Explanation","summary":"  It is essential for infrastructure managers to maintain a high standard to\nensure user satisfaction during daily operations. Surveillance cameras and\ndrone inspections have enabled progress toward automating the inspection of\ndamaged features and assessing the health condition of the deterioration. When\nwe prepare a pair of raw images and damage class labels, we can train\nsupervised learning toward the predefined damage grade, displacement. However,\nsuch a damage representation does not constantly match the predefined classes\nof damage grade, hence, there may be some detailed clusters from the unseen\ndamage space or more complex clusters from overlapped space between two damage\ngrades. The damage representation has fundamentally complex features,\nconsequently, all the damage classes could not be perfectly predefined. Our\nproposed MN-pair contrastive learning method enables us to explore the\nembedding damage representation beyond the predefined classes including more\ndetailed clusters. It maximizes the similarity of M-1 positive images close to\nthe anchor, and simultaneously maximize the dissimilarity of N-1 negative ones,\nusing both weighting loss functions. It has been learning faster than the\nN-pair algorithm, instead of using one positive image. We propose a pipeline to\nlearn damage representation and use density-based clustering on the 2-D\nreduction space to automate finer cluster discrimination. We also visualize the\nexplanation of the damage feature using Grad-CAM for MN-pair damage metric\nlearning. We demonstrate our method in three experimental studies: steel\nproduct defect, concrete crack of deck and pavement, and sewer pipe defect and\nmention its effectiveness and discuss potential future works.\n","authors":["Takato Yasuno","Masahiro Okano","Junichiro Fujii"],"pdf_url":"https://arxiv.org/pdf/2301.06077v2.pdf","comment":"8 pages, 14 figures, 3 tables"},{"id":"http://arxiv.org/abs/2301.07927v1","updated":"2023-01-19T07:32:23Z","published":"2023-01-19T07:32:23Z","title":"Exploiting Style Transfer-based Task Augmentation for Cross-Domain\n  Few-Shot Learning","summary":"  In cross-domain few-shot learning, the core issue is that the model trained\non source tasks from source domains can not generalize well to target tasks\nfrom the target domain, especially when the domain shift is very large.\nMotivated by the observation that the domain shift between training tasks and\ntarget tasks usually can reflect in their style variation, we propose Task\nAugmented Meta-Learning (TAML) to conduct style transfer-based task\naugmentation to improve the domain generalization ability. Firstly, Multi-task\nInterpolation (MTI) is introduced to perform feature fusion on tasks from\ndifferent tasks with different styles, which makes more diverse styles\navailable. Furthermore, a novel task-augmentation strategy called Multi-Task\nStyle Transfer (MTST) is put forward to perform style transfer on existing\ntasks to learn discriminative style-independent features. At last, we introduce\nFeature Modulation module (FM) to add random styles, which aims to improve the\ngeneralization of our model. The proposed TAML increases the diversity of\nstyles of training tasks, and contributes to training a model with better\ndomain generalization ability. The effectiveness is demonstrated via\ntheoretical analysis and thorough experiments on two popular cross-domain\nfew-shot benchmarks.\n","authors":["Shuzhen Rao","Jun Huang","Zengming Tang"],"pdf_url":"https://arxiv.org/pdf/2301.07927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07923v1","updated":"2023-01-19T07:26:33Z","published":"2023-01-19T07:26:33Z","title":"Human-Scene Network: A Novel Baseline with Self-rectifying Loss for\n  Weakly supervised Video Anomaly Detection","summary":"  Video anomaly detection in surveillance systems with only video-level labels\n(i.e. weakly-supervised) is challenging. This is due to, (i) the complex\nintegration of human and scene based anomalies comprising of subtle and sharp\nspatio-temporal cues in real-world scenarios, (ii) non-optimal optimization\nbetween normal and anomaly instances under weak supervision. In this paper, we\npropose a Human-Scene Network to learn discriminative representations by\ncapturing both subtle and strong cues in a dissociative manner. In addition, a\nself-rectifying loss is also proposed that dynamically computes the pseudo\ntemporal annotations from video-level labels for optimizing the Human-Scene\nNetwork effectively. The proposed Human-Scene Network optimized with\nself-rectifying loss is validated on three publicly available datasets i.e.\nUCF-Crime, ShanghaiTech and IITB-Corridor, outperforming recently reported\nstate-of-the-art approaches on five out of the six scenarios considered.\n","authors":["Snehashis Majhi","Rui Dai","Quan Kong","Lorenzo Garattoni","Gianpiero Francesca","Francois Bremond"],"pdf_url":"https://arxiv.org/pdf/2301.07923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07921v1","updated":"2023-01-19T07:06:35Z","published":"2023-01-19T07:06:35Z","title":"Spatio-Temporal Context Modeling for Road Obstacle Detection","summary":"  Road obstacle detection is an important problem for vehicle driving safety.\nIn this paper, we aim to obtain robust road obstacle detection based on\nspatio-temporal context modeling. Firstly, a data-driven spatial context model\nof the driving scene is constructed with the layouts of the training data.\nThen, obstacles in the input image are detected via the state-of-the-art object\ndetection algorithms, and the results are combined with the generated scene\nlayout. In addition, to further improve the performance and robustness,\ntemporal information in the image sequence is taken into consideration, and the\noptical flow is obtained in the vicinity of the detected objects to track the\nobstacles across neighboring frames. Qualitative and quantitative experiments\nwere conducted on the Small Obstacle Detection (SOD) dataset and the Lost and\nFound dataset. The results indicate that our method with spatio-temporal\ncontext modeling is superior to existing methods for road obstacle detection.\n","authors":["Xiuen Wu","Tao Wang","Lingyu Liang","Zuoyong Li","Fum Yew Ching"],"pdf_url":"https://arxiv.org/pdf/2301.07921v1.pdf","comment":"Paper accepted by the 4th International Conference on Machine\n  Learning for Cyber Security (ML4CS 2022), Guangzhou, China"},{"id":"http://arxiv.org/abs/2301.07895v1","updated":"2023-01-19T05:50:28Z","published":"2023-01-19T05:50:28Z","title":"Spatially Covariant Lesion Segmentation","summary":"  Compared to natural images, medical images usually show stronger visual\npatterns and therefore this adds flexibility and elasticity to resource-limited\nclinical applications by injecting proper priors into neural networks. In this\npaper, we propose spatially covariant pixel-aligned classifier (SCP) to improve\nthe computational efficiency and meantime maintain or increase accuracy for\nlesion segmentation. SCP relaxes the spatial invariance constraint imposed by\nconvolutional operations and optimizes an underlying implicit function that\nmaps image coordinates to network weights, the parameters of which are obtained\nalong with the backbone network training and later used for generating network\nweights to capture spatially covariant contextual information. We demonstrate\nthe effectiveness and efficiency of the proposed SCP using two lesion\nsegmentation tasks from different imaging modalities: white matter\nhyperintensity segmentation in magnetic resonance imaging and liver tumor\nsegmentation in contrast-enhanced abdominal computerized tomography. The\nnetwork using SCP has achieved 23.8%, 64.9% and 74.7% reduction in GPU memory\nusage, FLOPs, and network size with similar or better accuracy for lesion\nsegmentation.\n","authors":["Hang Zhang","Rongguang Wang","Jinwei Zhang","Dongdong Liu","Chao Li","Jiahao Li"],"pdf_url":"https://arxiv.org/pdf/2301.07895v1.pdf","comment":"9 pages, 7 figures, and 2 tables"},{"id":"http://arxiv.org/abs/2301.00114v2","updated":"2023-01-19T05:13:36Z","published":"2022-12-31T04:11:25Z","title":"Skeletal Video Anomaly Detection using Deep Learning: Survey, Challenges\n  and Future Directions","summary":"  The existing methods for video anomaly detection mostly utilize videos\ncontaining identifiable facial and appearance-based features. The use of videos\nwith identifiable faces raises privacy concerns, especially when used in a\nhospital or community-based setting. Appearance-based features can also be\nsensitive to pixel-based noise, straining the anomaly detection methods to\nmodel the changes in the background and making it difficult to focus on the\nactions of humans in the foreground. Structural information in the form of\nskeletons describing the human motion in the videos is privacy-protecting and\ncan overcome some of the problems posed by appearance-based features. In this\npaper, we present a survey of privacy-protecting deep learning anomaly\ndetection methods using skeletons extracted from videos. We present a novel\ntaxonomy of algorithms based on the various learning approaches. We conclude\nthat skeleton-based approaches for anomaly detection can be a plausible\nprivacy-protecting alternative for video anomaly detection. Lastly, we identify\nmajor open research questions and provide guidelines to address them.\n","authors":["Pratik K. Mishra","Alex Mihailidis","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2301.00114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07879v1","updated":"2023-01-19T05:02:55Z","published":"2023-01-19T05:02:55Z","title":"Unposed: Unsupervised Pose Estimation based Product Image\n  Recommendations","summary":"  Product images are the most impressing medium of customer interaction on the\nproduct detail pages of e-commerce websites. Millions of products are onboarded\non to webstore catalogues daily and maintaining a high quality bar for a\nproduct's set of images is a problem at scale. Grouping products by categories,\nclothing is a very high volume and high velocity category and thus deserves its\nown attention. Given the scale it is challenging to monitor the completeness of\nimage set, which adequately details the product for the consumers, which in\nturn often leads to a poor customer experience and thus customer drop off.\n  To supervise the quality and completeness of the images in the product pages\nfor these product types and suggest improvements, we propose a Human Pose\nDetection based unsupervised method to scan the image set of a product for the\nmissing ones. The unsupervised approach suggests a fair approach to sellers\nbased on product and category irrespective of any biases. We first create a\nreference image set of popular products with wholesome imageset. Then we create\nclusters of images to label most desirable poses to form the classes for the\nreference set from these ideal products set. Further, for all test products we\nscan the images for all desired pose classes w.r.t. reference set poses,\ndetermine the missing ones and sort them in the order of potential impact.\nThese missing poses can further be used by the sellers to add enriched product\nlisting image. We gathered data from popular online webstore and surveyed ~200\nproducts manually, a large fraction of which had at least 1 repeated image or\nmissing variant, and sampled 3K products(~20K images) of which a significant\nproportion had scope for adding many image variants as compared to high rated\nproducts which had more than double image variants, indicating that our model\ncan potentially be used on a large scale.\n","authors":["Saurabh Sharma","Faizan Ahemad"],"pdf_url":"https://arxiv.org/pdf/2301.07879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07870v1","updated":"2023-01-19T03:58:48Z","published":"2023-01-19T03:58:48Z","title":"Fast-BEV: Towards Real-time On-vehicle Bird's-Eye View Perception","summary":"  Recently, the pure camera-based Bird's-Eye-View (BEV) perception removes\nexpensive Lidar sensors, making it a feasible solution for economical\nautonomous driving. However, most existing BEV solutions either suffer from\nmodest performance or require considerable resources to execute on-vehicle\ninference. This paper proposes a simple yet effective framework, termed\nFast-BEV, which is capable of performing real-time BEV perception on the\non-vehicle chips. Towards this goal, we first empirically find that the BEV\nrepresentation can be sufficiently powerful without expensive view\ntransformation or depth representation. Starting from M2BEV baseline, we\nfurther introduce (1) a strong data augmentation strategy for both image and\nBEV space to avoid over-fitting (2) a multi-frame feature fusion mechanism to\nleverage the temporal information (3) an optimized deployment-friendly view\ntransformation to speed up the inference. Through experiments, we show Fast-BEV\nmodel family achieves considerable accuracy and efficiency on edge. In\nparticular, our M1 model (R18@256x704) can run over 50FPS on the Tesla T4\nplatform, with 47.0% NDS on the nuScenes validation set. Our largest model\n(R101@900x1600) establishes a new state-of-the-art 53.5% NDS on the nuScenes\nvalidation set. The code is released at: https://github.com/Sense-GVT/Fast-BEV.\n","authors":["Bin Huang","Yangguang Li","Enze Xie","Feng Liang","Luya Wang","Mingzhu Shen","Fenggang Liu","Tianqi Wang","Ping Luo","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2301.07870v1.pdf","comment":"Accepted by NeurIPS2022_ML4AD on October 22, 2022"},{"id":"http://arxiv.org/abs/2301.07868v1","updated":"2023-01-19T03:42:56Z","published":"2023-01-19T03:42:56Z","title":"Multimodal Video Adapter for Parameter Efficient Video Text Retrieval","summary":"  State-of-the-art video-text retrieval (VTR) methods usually fully fine-tune\nthe pre-trained model (e.g. CLIP) on specific datasets, which may suffer from\nsubstantial storage costs in practical applications since a separate model per\ntask needs to be stored. To overcome this issue, we present the premier work on\nperforming parameter-efficient VTR from the pre-trained model, i.e., only a\nsmall number of parameters are tunable while freezing the backbone. Towards\nthis goal, we propose a new method dubbed Multimodal Video Adapter (MV-Adapter)\nfor efficiently transferring the knowledge in the pre-trained CLIP from\nimage-text to video-text. Specifically, MV-Adapter adopts bottleneck structures\nin both video and text branches and introduces two novel components. The first\nis a Temporal Adaptation Module employed in the video branch to inject global\nand local temporal contexts. We also learn weights calibrations to adapt to the\ndynamic variations across frames. The second is a Cross-Modal Interaction\nModule that generates weights for video/text branches through a shared\nparameter space, for better aligning between modalities. Thanks to above\ninnovations, MV-Adapter can achieve on-par or better performance than standard\nfine-tuning with negligible parameters overhead. Notably, on five widely used\nVTR benchmarks (MSR-VTT, MSVD, LSMDC, DiDemo, and ActivityNet), MV-Adapter\nconsistently outperforms various competing methods in V2T/T2V tasks with large\nmargins. Codes will be released.\n","authors":["Bowen Zhang","Xiaojie Jin","Weibo Gong","Kai Xu","Zhao Zhang","Peng Wang","Xiaohui Shen","Jiashi Feng"],"pdf_url":"https://arxiv.org/pdf/2301.07868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01439v2","updated":"2023-01-19T03:26:18Z","published":"2022-10-04T07:54:40Z","title":"Boosting Few-shot Fine-grained Recognition with Background Suppression\n  and Foreground Alignment","summary":"  Few-shot fine-grained recognition (FS-FGR) aims to recognize novel\nfine-grained categories with the help of limited available samples.\nUndoubtedly, this task inherits the main challenges from both few-shot learning\nand fine-grained recognition. First, the lack of labeled samples makes the\nlearned model easy to overfit. Second, it also suffers from high intra-class\nvariance and low inter-class differences in the datasets. To address this\nchallenging task, we propose a two-stage background suppression and foreground\nalignment framework, which is composed of a background activation suppression\n(BAS) module, a foreground object alignment (FOA) module, and a local-to-local\n(L2L) similarity metric. Specifically, the BAS is introduced to generate a\nforeground mask for localization to weaken background disturbance and enhance\ndominative foreground objects. The FOA then reconstructs the feature map of\neach support sample according to its correction to the query ones, which\naddresses the problem of misalignment between support-query image pairs. To\nenable the proposed method to have the ability to capture subtle differences in\nconfused samples, we present a novel L2L similarity metric to further measure\nthe local similarity between a pair of aligned spatial features in the\nembedding space. What's more, considering that background interference brings\npoor robustness, we infer the pairwise similarity of feature maps using both\nthe raw image and the refined image. Extensive experiments conducted on\nmultiple popular fine-grained benchmarks demonstrate that our method\noutperforms the existing state of the art by a large margin. The source codes\nare available at: https://github.com/CSer-Tang-hao/BSFA-FSFG.\n","authors":["Zican Zha","Hao Tang","Yunlian Sun","Jinhui Tang"],"pdf_url":"https://arxiv.org/pdf/2210.01439v2.pdf","comment":"Accepted to IEEE Transactions on Circuits and Systems for Video\n  Technology (TCSVT) 2023"},{"id":"http://arxiv.org/abs/2301.07861v1","updated":"2023-01-19T03:12:05Z","published":"2023-01-19T03:12:05Z","title":"Improving Food Detection For Images From a Wearable Egocentric Camera","summary":"  Diet is an important aspect of our health. Good dietary habits can contribute\nto the prevention of many diseases and improve the overall quality of life. To\nbetter understand the relationship between diet and health, image-based dietary\nassessment systems have been developed to collect dietary information. We\nintroduce the Automatic Ingestion Monitor (AIM), a device that can be attached\nto one's eye glasses. It provides an automated hands-free approach to capture\neating scene images. While AIM has several advantages, images captured by the\nAIM are sometimes blurry. Blurry images can significantly degrade the\nperformance of food image analysis such as food detection. In this paper, we\npropose an approach to pre-process images collected by the AIM imaging sensor\nby rejecting extremely blurry images to improve the performance of food\ndetection.\n","authors":["Yue Han","Sri Kalyan Yarlagadda","Tonmoy Ghosh","Fengqing Zhu","Edward Sazonov","Edward J. Delp"],"pdf_url":"https://arxiv.org/pdf/2301.07861v1.pdf","comment":"6 pages, 6 figures, Conference Paper for Imaging and Multimedia\n  Analytics in a Web and Mobile World Conference, IS&T Electronic Imaging\n  Symposium, Burlingame, CA (Virtual), January, 2021"},{"id":"http://arxiv.org/abs/2112.10572v5","updated":"2023-01-19T03:02:35Z","published":"2021-12-20T14:47:32Z","title":"General Greedy De-bias Learning","summary":"  Neural networks often make predictions relying on the spurious correlations\nfrom the datasets rather than the intrinsic properties of the task of interest,\nfacing sharp degradation on out-of-distribution (OOD) test data. Existing\nde-bias learning frameworks try to capture specific dataset bias by annotations\nbut they fail to handle complicated OOD scenarios. Others implicitly identify\nthe dataset bias by special design low capability biased models or losses, but\nthey degrade when the training and testing data are from the same distribution.\nIn this paper, we propose a General Greedy De-bias learning framework (GGD),\nwhich greedily trains the biased models and the base model. The base model is\nencouraged to focus on examples that are hard to solve with biased models, thus\nremaining robust against spurious correlations in the test stage. GGD largely\nimproves models' OOD generalization ability on various tasks, but sometimes\nover-estimates the bias level and degrades on the in-distribution test. We\nfurther re-analyze the ensemble process of GGD and introduce the Curriculum\nRegularization inspired by curriculum learning, which achieves a good trade-off\nbetween in-distribution and out-of-distribution performance. Extensive\nexperiments on image classification, adversarial question answering, and visual\nquestion answering demonstrate the effectiveness of our method. GGD can learn a\nmore robust base model under the settings of both task-specific biased models\nwith prior knowledge and self-ensemble biased model without prior knowledge.\n","authors":["Xinzhe Han","Shuhui Wang","Chi Su","Qingming Huang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2112.10572v5.pdf","comment":"This work has been accepted by IEEE T-PAMI. Copyright is transferred\n  without notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2301.07845v1","updated":"2023-01-19T01:51:37Z","published":"2023-01-19T01:51:37Z","title":"Foresee What You Will Learn: Data Augmentation for Domain Generalization\n  in Non-Stationary Environments","summary":"  Existing domain generalization aims to learn a generalizable model to perform\nwell even on unseen domains. For many real-world machine learning applications,\nthe data distribution often shifts gradually along domain indices. For example,\na self-driving car with a vision system drives from dawn to dusk, with the sky\ndarkening gradually. Therefore, the system must be able to adapt to changes in\nambient illumination and continue to drive safely on the road. In this paper,\nwe formulate such problems as Evolving Domain Generalization, where a model\naims to generalize well on a target domain by discovering and leveraging the\nevolving pattern of the environment. We then propose Directional Domain\nAugmentation (DDA), which simulates the unseen target features by mapping\nsource data as augmentations through a domain transformer. Specifically, we\nformulate DDA as a bi-level optimization problem and solve it through a novel\nmeta-learning approach in the representation space. We evaluate the proposed\nmethod on both synthetic datasets and realworld datasets, and empirical results\nshow that our approach can outperform other existing methods.\n","authors":["Qiuhao Zeng","Wei Wang","Fan Zhou","Charles Ling","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07845v1.pdf","comment":"12 pages, 6 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2208.13930v3","updated":"2023-01-19T01:21:43Z","published":"2022-08-29T23:57:55Z","title":"SAFE: Sensitivity-Aware Features for Out-of-Distribution Object\n  Detection","summary":"  Feature-based out-of-distribution (OOD) detectors have received significant\nattention under the image classification setting lately. However, the\npracticality of these works in the object detection setting is limited due to\nthe current lack of understanding of the characteristics of the feature space\nin this setting. Our approach, SAFE (Sensitivity-Aware FEatures), leverages the\ninnate sensitivity of residual networks to detect OOD samples. Key to our\nmethod, we build on foundational theory from image classification to identify\nthat shortcut convolutional layers followed immediately by batch normalisation\nare uniquely powerful at detecting OOD samples. SAFE circumvents the need for\nrealistic OOD training data, expensive generative models and retraining of the\nbase object detector by training a 3-layer multilayer perceptron (MLP) on the\nsurrogate task of distinguishing noise-perturbed and clean in-distribution\nobject detections, using only the concatenated features from the identified\nmost sensitive layers. We show that this MLP can identify OOD object detections\nmore reliably than previous approaches, achieving a new state-of-the-art on\nmultiple benchmarks, e.g. reducing the FPR95 by an absolute 30% from 48.3% to\n18.4% on the OpenImages dataset. We provide empirical evidence for our claims\nthrough our ablations, demonstrating that the identified critical subset of\nlayers is disproportionately powerful at detecting OOD samples in comparison to\nthe rest of the network.\n","authors":["Samuel Wilson","Tobias Fischer","Feras Dayoub","Dimity Miller","Niko Sünderhauf"],"pdf_url":"https://arxiv.org/pdf/2208.13930v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13213v4","updated":"2023-01-19T01:12:54Z","published":"2022-05-26T08:16:14Z","title":"Fast Vision Transformers with HiLo Attention","summary":"  Vision Transformers (ViTs) have triggered the most recent and significant\nbreakthroughs in computer vision. Their efficient designs are mostly guided by\nthe indirect metric of computational complexity, i.e., FLOPs, which however has\na clear gap with the direct metric such as throughput. Thus, we propose to use\nthe direct speed evaluation on the target platform as the design principle for\nefficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT\nwhich performs favourably against the existing state-of-the-art methods across\na spectrum of different model sizes with faster speed. At the core of LITv2 is\na novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the\ninsight that high frequencies in an image capture local fine details and low\nfrequencies focus on global structures, whereas a multi-head self-attention\nlayer neglects the characteristic of different frequencies. Therefore, we\npropose to disentangle the high/low frequency patterns in an attention layer by\nseparating the heads into two groups, where one group encodes high frequencies\nvia self-attention within each local window, and another group encodes low\nfrequencies by performing global attention between the average-pooled\nlow-frequency keys and values from each window and each query position in the\ninput feature map. Benefiting from the efficient design for both groups, we\nshow that HiLo is superior to the existing attention mechanisms by\ncomprehensively benchmarking FLOPs, speed and memory consumption on GPUs and\nCPUs. For example, HiLo is 1.4x faster than spatial reduction attention and\n1.6x faster than local window attention on CPUs. Powered by HiLo, LITv2 serves\nas a strong backbone for mainstream vision tasks including image\nclassification, dense detection and segmentation. Code is available at\nhttps://github.com/ziplab/LITv2.\n","authors":["Zizheng Pan","Jianfei Cai","Bohan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2205.13213v4.pdf","comment":"NeurIPS 2022 camera ready"},{"id":"http://arxiv.org/abs/2301.07836v1","updated":"2023-01-19T01:05:18Z","published":"2023-01-19T01:05:18Z","title":"Self Supervision Does Not Help Natural Language Supervision at Scale","summary":"  Self supervision and natural language supervision have emerged as two\nexciting ways to train general purpose image encoders which excel at a variety\nof downstream tasks. Recent works such as M3AE and SLIP have suggested that\nthese approaches can be effectively combined, but most notably their results\nuse small pre-training datasets (<50M samples) and don't effectively reflect\nthe large-scale regime (>100M examples) that is commonly used for these\napproaches. Here we investigate whether a similar approach can be effective\nwhen trained with a much larger amount of data. We find that a combination of\ntwo state of the art approaches: masked auto-encoders, MAE and contrastive\nlanguage image pre-training, CLIP provides a benefit over CLIP when trained on\na corpus of 11.3M image-text pairs, but little to no benefit (as evaluated on a\nsuite of common vision tasks) over CLIP when trained on a large corpus of 1.4B\nimages. Our work provides some much needed clarity into the effectiveness (or\nlack thereof) of self supervision for large-scale image-text training.\n","authors":["Floris Weers","Vaishaal Shankar","Angelos Katharopoulos","Yinfei Yang","Tom Gunter"],"pdf_url":"https://arxiv.org/pdf/2301.07836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11042v3","updated":"2023-01-19T00:26:26Z","published":"2022-12-21T14:31:33Z","title":"Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from\n  Sparse Image Ensemble","summary":"  Automatically estimating 3D skeleton, shape, camera viewpoints, and part\narticulation from sparse in-the-wild image ensembles is a severely\nunder-constrained and challenging problem. Most prior methods rely on\nlarge-scale image datasets, dense temporal correspondence, or human annotations\nlike camera pose, 2D keypoints, and shape templates. We propose Hi-LASSIE,\nwhich performs 3D articulated reconstruction from only 20-30 online images in\nthe wild without any user-defined shape or skeleton templates. We follow the\nrecent work of LASSIE that tackles a similar problem setting and make two\nsignificant advances. First, instead of relying on a manually annotated 3D\nskeleton, we automatically estimate a class-specific skeleton from the selected\nreference image. Second, we improve the shape reconstructions with novel\ninstance-specific optimization strategies that allow reconstructions to\nfaithful fit on each instance while preserving the class-specific priors\nlearned across all images. Experiments on in-the-wild image ensembles show that\nHi-LASSIE obtains higher fidelity state-of-the-art 3D reconstructions despite\nrequiring minimum user input.\n","authors":["Chun-Han Yao","Wei-Chih Hung","Yuanzhen Li","Michael Rubinstein","Ming-Hsuan Yang","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2212.11042v3.pdf","comment":"Project page: https://chhankyao.github.io/hi-lassie/"},{"id":"http://arxiv.org/abs/2205.14375v3","updated":"2023-01-19T00:05:12Z","published":"2022-05-28T09:08:50Z","title":"WaveMix: A Resource-efficient Neural Network for Image Analysis","summary":"  To allow image analysis in resource-constrained scenarios without\ncompromising generalizability, we introduce WaveMix -- a novel and flexible\nneural framework that reduces the GPU RAM (memory) and compute (latency)\ncompared to CNNs and transformers. In addition to using convolutional layers\nthat exploit shift-invariant image statistics, the proposed framework uses\nmulti-level two-dimensional discrete wavelet transform (2D-DWT) modules to\nexploit scale-invariance and edge sparseness, which gives it the following\nadvantages. Firstly, the fixed weights of wavelet modules do not add to the\nparameter count while reorganizing information based on these image priors.\nSecondly, the wavelet modules scale the spatial extents of feature maps by\nintegral powers of $\\frac{1}{2}\\times\\frac{1}{2}$, which reduces the memory and\nlatency required for forward and backward passes. Finally, a multi-level 2D-DWT\nleads to a quicker expansion of the receptive field per layer than pooling\n(which we do not use) and it is a more effective spatial token mixer. WaveMix\nalso generalizes better than other token mixing models, such as ConvMixer,\nMLP-Mixer, PoolFormer, random filters, and Fourier basis, because the wavelet\ntransform is much better suited for image decomposition and spatial token\nmixing. WaveMix is a flexible model that can perform well on multiple image\ntasks without needing architectural modifications. WaveMix achieves a semantic\nsegmentation mIoU of 83% on the Cityscapes validation set outperforming\ntransformer and CNN-based architectures. We also demonstrate the advantages of\nWaveMix for classification on multiple datasets and show that WaveMix\nestablishes new state-of-the-results in Places-365, EMNIST, and iNAT-mini\ndatasets.\n","authors":["Pranav Jeevan","Kavitha Viswanathan","Anandu A S","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2205.14375v3.pdf","comment":"18 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2203.03689"},{"id":"http://arxiv.org/abs/2110.05668v6","updated":"2023-01-19T23:17:16Z","published":"2021-10-12T01:13:18Z","title":"NAS-Bench-360: Benchmarking Neural Architecture Search on Diverse Tasks","summary":"  Most existing neural architecture search (NAS) benchmarks and algorithms\nprioritize well-studied tasks, e.g. image classification on CIFAR or ImageNet.\nThis makes the performance of NAS approaches in more diverse areas poorly\nunderstood. In this paper, we present NAS-Bench-360, a benchmark suite to\nevaluate methods on domains beyond those traditionally studied in architecture\nsearch, and use it to address the following question: do state-of-the-art NAS\nmethods perform well on diverse tasks? To construct the benchmark, we curate\nten tasks spanning a diverse array of application domains, dataset sizes,\nproblem dimensionalities, and learning objectives. Each task is carefully\nchosen to interoperate with modern CNN-based search methods while possibly\nbeing far-afield from its original development domain. To speed up and reduce\nthe cost of NAS research, for two of the tasks we release the precomputed\nperformance of 15,625 architectures comprising a standard CNN search space.\nExperimentally, we show the need for more robust NAS evaluation of the kind\nNAS-Bench-360 enables by showing that several modern NAS procedures perform\ninconsistently across the ten tasks, with many catastrophically poor results.\nWe also demonstrate how NAS-Bench-360 and its associated precomputed results\nwill enable future scientific discoveries by testing whether several recent\nhypotheses promoted in the NAS literature hold on diverse tasks. NAS-Bench-360\nis hosted at https://nb360.ml.cmu.edu.\n","authors":["Renbo Tu","Nicholas Roberts","Mikhail Khodak","Junhong Shen","Frederic Sala","Ameet Talwalkar"],"pdf_url":"https://arxiv.org/pdf/2110.05668v6.pdf","comment":"NeurIPS 2022 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2007.12140v5","updated":"2023-01-19T23:15:04Z","published":"2020-07-23T17:11:48Z","title":"HITNet: Hierarchical Iterative Tile Refinement Network for Real-time\n  Stereo Matching","summary":"  This paper presents HITNet, a novel neural network architecture for real-time\nstereo matching. Contrary to many recent neural network approaches that operate\non a full cost volume and rely on 3D convolutions, our approach does not\nexplicitly build a volume and instead relies on a fast multi-resolution\ninitialization step, differentiable 2D geometric propagation and warping\nmechanisms to infer disparity hypotheses. To achieve a high level of accuracy,\nour network not only geometrically reasons about disparities but also infers\nslanted plane hypotheses allowing to more accurately perform geometric warping\nand upsampling operations. Our architecture is inherently multi-resolution\nallowing the propagation of information across different levels. Multiple\nexperiments prove the effectiveness of the proposed approach at a fraction of\nthe computation required by state-of-the-art methods. At the time of writing,\nHITNet ranks 1st-3rd on all the metrics published on the ETH3D website for two\nview stereo, ranks 1st on most of the metrics among all the end-to-end learning\napproaches on Middlebury-v3, ranks 1st on the popular KITTI 2012 and 2015\nbenchmarks among the published methods faster than 100ms.\n","authors":["Vladimir Tankovich","Christian Häne","Yinda Zhang","Adarsh Kowdle","Sean Fanello","Sofien Bouaziz"],"pdf_url":"https://arxiv.org/pdf/2007.12140v5.pdf","comment":"The pretrained models used for submission to benchmarks and sample\n  evaluation scripts can be found at\n  https://github.com/google-research/google-research/tree/master/hitnet"},{"id":"http://arxiv.org/abs/2301.03045v2","updated":"2023-01-19T22:29:35Z","published":"2023-01-08T14:07:01Z","title":"Seamless Multimodal Biometrics for Continuous Personalised Wellbeing\n  Monitoring","summary":"  Artificially intelligent perception is increasingly present in the lives of\nevery one of us. Vehicles are no exception, (...) In the near future, pattern\nrecognition will have an even stronger role in vehicles, as self-driving cars\nwill require automated ways to understand what is happening around (and within)\nthem and act accordingly. (...) This doctoral work focused on advancing\nin-vehicle sensing through the research of novel computer vision and pattern\nrecognition methodologies for both biometrics and wellbeing monitoring. The\nmain focus has been on electrocardiogram (ECG) biometrics, a trait well-known\nfor its potential for seamless driver monitoring. Major efforts were devoted to\nachieving improved performance in identification and identity verification in\noff-the-person scenarios, well-known for increased noise and variability. Here,\nend-to-end deep learning ECG biometric solutions were proposed and important\ntopics were addressed such as cross-database and long-term performance,\nwaveform relevance through explainability, and interlead conversion. Face\nbiometrics, a natural complement to the ECG in seamless unconstrained\nscenarios, was also studied in this work. The open challenges of masked face\nrecognition and interpretability in biometrics were tackled in an effort to\nevolve towards algorithms that are more transparent, trustworthy, and robust to\nsignificant occlusions. Within the topic of wellbeing monitoring, improved\nsolutions to multimodal emotion recognition in groups of people and\nactivity/violence recognition in in-vehicle scenarios were proposed. At last,\nwe also proposed a novel way to learn template security within end-to-end\nmodels, dismissing additional separate encryption processes, and a\nself-supervised learning approach tailored to sequential data, in order to\nensure data security and optimal performance. (...)\n","authors":["João Ribeiro Pinto"],"pdf_url":"https://arxiv.org/pdf/2301.03045v2.pdf","comment":"Doctoral thesis presented and approved on the 21st of December 2022\n  to the University of Porto"},{"id":"http://arxiv.org/abs/2208.09198v2","updated":"2023-01-19T22:14:54Z","published":"2022-08-19T07:50:04Z","title":"TTT-UCDR: Test-time Training for Universal Cross-Domain Retrieval","summary":"  Image retrieval under generalized test scenarios has gained significant\nmomentum in literature, and the recently proposed protocol of Universal\nCross-domain Retrieval is a pioneer in this direction. A common practice in any\nsuch generalized classification or retrieval algorithm is to exploit samples\nfrom multiple domains during training to learn a domain-invariant\nrepresentation of data. Such criterion is often restrictive, and thus in this\nwork, for the first time, we explore the challenges associated with generalized\nretrieval problems under a low-data regime, which is quite relevant in many\nreal-world scenarios. We attempt to make any retrieval model trained on a small\ncross-domain dataset (containing just two training domains) more generalizable\ntowards any unknown query domain or category by quickly adapting it to the test\ndata during inference. This form of test-time training or adaptation of the\nretrieval model is explored by means of a number of self-supervision-based loss\nfunctions, for example, Rotnet, Jigsaw-puzzle, Barlow twins, etc., in this\nwork. Extensive experiments on multiple large-scale datasets demonstrate the\neffectiveness of the proposed approach.\n","authors":["Soumava Paul","Titir Dutta","Aheli Saha","Abhishek Samanta","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2208.09198v2.pdf","comment":"9 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2301.08330v1","updated":"2023-01-19T21:39:38Z","published":"2023-01-19T21:39:38Z","title":"The role of noise in denoising models for anomaly detection in medical\n  images","summary":"  Pathological brain lesions exhibit diverse appearance in brain images, in\nterms of intensity, texture, shape, size, and location. Comprehensive sets of\ndata and annotations are difficult to acquire. Therefore, unsupervised anomaly\ndetection approaches have been proposed using only normal data for training,\nwith the aim of detecting outlier anomalous voxels at test time. Denoising\nmethods, for instance classical denoising autoencoders (DAEs) and more recently\nemerging diffusion models, are a promising approach, however naive application\nof pixelwise noise leads to poor anomaly detection performance. We show that\noptimization of the spatial resolution and magnitude of the noise improves the\nperformance of different model training regimes, with similar noise parameter\nadjustments giving good performance for both DAEs and diffusion models. Visual\ninspection of the reconstructions suggests that the training noise influences\nthe trade-off between the extent of the detail that is reconstructed and the\nextent of erasure of anomalies, both of which contribute to better anomaly\ndetection performance. We validate our findings on two real-world datasets\n(tumor detection in brain MRI and hemorrhage/ischemia/tumor detection in brain\nCT), showing good detection on diverse anomaly appearances. Overall, we find\nthat a DAE trained with coarse noise is a fast and simple method that gives\nstate-of-the-art accuracy. Diffusion models applied to anomaly detection are as\nyet in their infancy and provide a promising avenue for further research.\n","authors":["Antanas Kascenas","Pedro Sanchez","Patrick Schrempf","Chaoyang Wang","William Clackett","Shadia S. Mikhael","Jeremy P. Voisey","Keith Goatman","Alexander Weir","Nicolas Pugeault","Sotirios A. Tsaftaris","Alison Q. O'Neil"],"pdf_url":"https://arxiv.org/pdf/2301.08330v1.pdf","comment":"Submitted to Medical Image Analysis special issue for MIDL 2022"},{"id":"http://arxiv.org/abs/2301.08317v1","updated":"2023-01-19T21:16:36Z","published":"2023-01-19T21:16:36Z","title":"Learning ultrasound plane pose regression: assessing generalized pose\n  coordinates in the fetal brain","summary":"  In obstetric ultrasound (US) scanning, the learner's ability to mentally\nbuild a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US\nimage represents a significant challenge in skill acquisition. We aim to build\na US plane localization system for 3D visualization, training, and guidance\nwithout integrating additional sensors. This work builds on top of our previous\nwork, which predicts the six-dimensional (6D) pose of arbitrarily-oriented US\nplanes slicing the fetal brain with respect to a normalized reference frame\nusing a convolutional neural network (CNN) regression network. Here, we analyze\nin detail the assumptions of the normalized fetal brain reference frame and\nquantify its accuracy with respect to the acquisition of transventricular (TV)\nstandard plane (SP) for fetal biometry. We investigate the impact of\nregistration quality in the training and testing data and its subsequent effect\non trained models. Finally, we introduce data augmentations and larger training\nsets that improve the results of our previous work, achieving median errors of\n3.53 mm and 6.42 degrees for translation and rotation, respectively.\n","authors":["Chiara Di Vece","Maela Le Lous","Brian Dromey","Francisco Vasconcelos","Anna L David","Donald Peebles","Danail Stoyanov"],"pdf_url":"https://arxiv.org/pdf/2301.08317v1.pdf","comment":"12 pages, 9 figures, 2 tables. This work has been submitted to the\n  IEEE for possible publication (IEEE TMRB). Copyright may be transferred\n  without notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2301.08252v1","updated":"2023-01-19T11:37:20Z","published":"2023-01-19T11:37:20Z","title":"Evaluation of the potential of Near Infrared Hyperspectral Imaging for\n  monitoring the invasive brown marmorated stink bug","summary":"  The brown marmorated stink bug (BMSB), Halyomorpha halys, is an invasive\ninsect pest of global importance that damages several crops, compromising\nagri-food production. Field monitoring procedures are fundamental to perform\nrisk assessment operations, in order to promptly face crop infestations and\navoid economical losses. To improve pest management, spectral cameras mounted\non Unmanned Aerial Vehicles (UAVs) and other Internet of Things (IoT) devices,\nsuch as smart traps or unmanned ground vehicles, could be used as an innovative\ntechnology allowing fast, efficient and real-time monitoring of insect\ninfestations. The present study consists in a preliminary evaluation at the\nlaboratory level of Near Infrared Hyperspectral Imaging (NIR-HSI) as a possible\ntechnology to detect BMSB specimens on different vegetal backgrounds,\novercoming the problem of BMSB mimicry. Hyperspectral images of BMSB were\nacquired in the 980-1660 nm range, considering different vegetal backgrounds\nselected to mimic a real field application scene. Classification models were\nobtained following two different chemometric approaches. The first approach was\nfocused on modelling spectral information and selecting relevant spectral\nregions for discrimination by means of sparse-based variable selection coupled\nwith Soft Partial Least Squares Discriminant Analysis (s-Soft PLS-DA)\nclassification algorithm. The second approach was based on modelling spatial\nand spectral features contained in the hyperspectral images using Convolutional\nNeural Networks (CNN). Finally, to further improve BMSB detection ability, the\ntwo strategies were merged, considering only the spectral regions selected by\ns-Soft PLS-DA for CNN modelling.\n","authors":["Veronica Ferrari","Rosalba Calvini","Bas Boom","Camilla Menozzi","Aravind Krishnaswamy Rangarajan","Lara Maistrello","Peter Offermans","Alessandro Ulrici"],"pdf_url":"https://arxiv.org/pdf/2301.08252v1.pdf","comment":"Accepted manuscript"},{"id":"http://arxiv.org/abs/2301.08555v1","updated":"2023-01-19T11:02:44Z","published":"2023-01-19T11:02:44Z","title":"Hybrid Open-set Segmentation with Synthetic Negative Data","summary":"  Open-set segmentation is often conceived by complementing closed-set\nclassification with anomaly detection. Existing dense anomaly detectors operate\neither through generative modelling of regular training data or by\ndiscriminating with respect to negative training data. These two approaches\noptimize different objectives and therefore exhibit different failure modes.\nConsequently, we propose the first dense hybrid anomaly score that fuses\ngenerative and discriminative cues. The proposed score can be efficiently\nimplemented by upgrading any semantic segmentation model with\ntranslation-equivariant estimates of data likelihood and dataset posterior. Our\ndesign is a remarkably good fit for efficient inference on large images due to\nnegligible computational overhead over the closed-set baseline. The resulting\ndense hybrid open-set models require negative training images that can be\nsampled either from an auxiliary negative dataset or from a jointly trained\ngenerative model. We evaluate our contributions on benchmarks for dense anomaly\ndetection and open-set segmentation of traffic scenes. The experiments reveal\nstrong open-set performance in spite of negligible computational overhead.\n","authors":["Matej Grcić","Siniša Šegvić"],"pdf_url":"https://arxiv.org/pdf/2301.08555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00986v2","updated":"2023-01-19T11:02:33Z","published":"2023-01-03T07:40:28Z","title":"Look, Listen, and Attack: Backdoor Attacks Against Video Action\n  Recognition","summary":"  Deep neural networks (DNNs) are vulnerable to a class of attacks called\n\"backdoor attacks\", which create an association between a backdoor trigger and\na target label the attacker is interested in exploiting. A backdoored DNN\nperforms well on clean test images, yet persistently predicts an\nattacker-defined label for any sample in the presence of the backdoor trigger.\nAlthough backdoor attacks have been extensively studied in the image domain,\nthere are very few works that explore such attacks in the video domain, and\nthey tend to conclude that image backdoor attacks are less effective in the\nvideo domain. In this work, we revisit the traditional backdoor threat model\nand incorporate additional video-related aspects to that model. We show that\npoisoned-label image backdoor attacks could be extended temporally in two ways,\nstatically and dynamically, leading to highly effective attacks in the video\ndomain. In addition, we explore natural video backdoors to highlight the\nseriousness of this vulnerability in the video domain. And, for the first time,\nwe study multi-modal (audiovisual) backdoor attacks against video action\nrecognition models, where we show that attacking a single modality is enough\nfor achieving a high attack success rate.\n","authors":["Hasan Abed Al Kader Hammoud","Shuming Liu","Mohammed Alkhrashi","Fahad AlBalawi","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2301.00986v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.11080v2","updated":"2023-01-19T14:11:06Z","published":"2022-12-21T15:27:52Z","title":"Is it worth it? Comparing six deep and classical methods for\n  unsupervised anomaly detection in time series","summary":"  Detecting anomalies in time series data is important in a variety of fields,\nincluding system monitoring, healthcare, and cybersecurity. While the abundance\nof available methods makes it difficult to choose the most appropriate method\nfor a given application, each method has its strengths in detecting certain\ntypes of anomalies. In this study, we compare six unsupervised anomaly\ndetection methods of varying complexity to determine whether more complex\nmethods generally perform better and if certain methods are better suited to\ncertain types of anomalies. We evaluated the methods using the UCR anomaly\narchive, a recent benchmark dataset for anomaly detection. We analyzed the\nresults on a dataset and anomaly type level after adjusting the necessary\nhyperparameters for each method. Additionally, we assessed the ability of each\nmethod to incorporate prior knowledge about anomalies and examined the\ndifferences between point-wise and sequence-wise features. Our experiments show\nthat classical machine learning methods generally outperform deep learning\nmethods across a range of anomaly types.\n","authors":["Ferdinand Rewicki","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2212.11080v2.pdf","comment":"17 Pages, The repository to reproduce the results is available at\n  https://gitlab.com/dlr-dw/is-it-worth-it-benchmark"},{"id":"http://arxiv.org/abs/2301.08062v1","updated":"2023-01-19T13:21:36Z","published":"2023-01-19T13:21:36Z","title":"New Metrics to Encourage Innovation and Diversity in Information\n  Retrieval Approaches","summary":"  In evaluation campaigns, participants often explore variations of popular,\nstate-of-the-art baselines as a low-risk strategy to achieve competitive\nresults. While effective, this can lead to local \"hill climbing\" rather than\nmore radical and innovative departure from standard methods. Moreover, if many\nparticipants build on similar baselines, the overall diversity of approaches\nconsidered may be limited. In this work, we propose a new class of IR\nevaluation metrics intended to promote greater diversity of approaches in\nevaluation campaigns. Whereas traditional IR metrics focus on user experience,\nour two \"innovation\" metrics instead reward exploration of more divergent,\nhigher-risk strategies finding relevant documents missed by other systems.\nExperiments on four TREC collections show that our metrics do change system\nrankings by rewarding systems that find such rare, relevant documents. This\nresult is further supported by a controlled, synthetic data experiment, and a\nqualitative analysis. In addition, we show that our metrics achieve higher\nevaluation stability and discriminative power than the standard metrics we\nmodify. To support reproducibility, we share our source code.\n","authors":["Mehmet Deniz Türkmen","Matthew Lease","Mucahid Kutlu"],"pdf_url":"https://arxiv.org/pdf/2301.08062v1.pdf","comment":"13 pages + references, 6 figures, to be published in ECIR 2023"},{"id":"http://arxiv.org/abs/2301.08042v1","updated":"2023-01-19T12:37:07Z","published":"2023-01-19T12:37:07Z","title":"From 10 Blue Links Pages to Feature-Full Search Engine Results Pages --\n  Analysis of the Temporal Evolution of SERP Features","summary":"  Web Search Engine Results Pages (SERP) are one of the most well-known and\nused web pages. These pages have started as simple ``10 blue links'' pages, but\nthe information in SERP currently goes way beyond these links. Several features\nhave been included in these pages to complement organic and sponsored results\nand attempt to provide answers to the query instead of just pointing to\nwebsites that might deliver that information. In this work, we analyze the\nappearance and evolution of SERP features in the two leading web search\nengines, Google Search and Microsoft Bing. Using a sample of SERP from the\nInternet Archive, we analyzed the appearance and evolution of these features.\nWe found that SERP are becoming more diverse in terms of elements, aggregating\ncontent from different verticals and including more features that provide\ndirect answers.\n","authors":["B. Oliveira","C. T. Lopes"],"pdf_url":"https://arxiv.org/pdf/2301.08042v1.pdf","comment":"8 pages, CHIIR 2023 Conference Short Paper"},{"id":"http://arxiv.org/abs/2102.05571v6","updated":"2023-01-19T12:08:15Z","published":"2021-02-10T17:08:09Z","title":"TINKER: A framework for Open source Cyberthreat Intelligence","summary":"  Threat intelligence on malware attacks and campaigns is increasingly being\nshared with other security experts for a cost or for free. Other security\nanalysts use this intelligence to inform them of indicators of compromise,\nattack techniques, and preventative actions. Security analysts prepare threat\nanalysis reports after investigating an attack, an emerging cyber threat, or a\nrecently discovered vulnerability. Collectively known as cyber threat\nintelligence (CTI), the reports are typically in an unstructured format and,\ntherefore, challenging to integrate seamlessly into existing intrusion\ndetection systems. This paper proposes a framework that uses the aggregated CTI\nfor analysis and defense at scale. The information is extracted and stored in a\nstructured format using knowledge graphs such that the semantics of the threat\nintelligence can be preserved and shared at scale with other security analysts.\nSpecifically, we propose the first semi-supervised open-source knowledge\ngraph-based framework, TINKER, to capture cyber threat information and its\ncontext. Following TINKER, we generate a Cyberthreat Intelligence Knowledge\nGraph (CTI-KG) and demonstrate the usage using different use cases.\n","authors":["Nidhi Rastogi","Sharmishtha Dutta","Mohammed J. Zaki","Alex Gittens","Charu Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2102.05571v6.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2301.08006v1","updated":"2023-01-19T11:13:04Z","published":"2023-01-19T11:13:04Z","title":"Keyword Embeddings for Query Suggestion","summary":"  Nowadays, search engine users commonly rely on query suggestions to improve\ntheir initial inputs. Current systems are very good at recommending lexical\nadaptations or spelling corrections to users' queries. However, they often\nstruggle to suggest semantically related keywords given a user's query. The\nconstruction of a detailed query is crucial in some tasks, such as legal\nretrieval or academic search. In these scenarios, keyword suggestion methods\nare critical to guide the user during the query formulation. This paper\nproposes two novel models for the keyword suggestion task trained on scientific\nliterature. Our techniques adapt the architecture of Word2Vec and FastText to\ngenerate keyword embeddings by leveraging documents' keyword co-occurrence.\nAlong with these models, we also present a specially tailored negative sampling\napproach that exploits how keywords appear in academic publications. We devise\na ranking-based evaluation methodology following both known-item and ad-hoc\nsearch scenarios. Finally, we evaluate our proposals against the\nstate-of-the-art word and sentence embedding models showing considerable\nimprovements over the baselines for the tasks.\n","authors":["Jorge Gabín","M. Eduardo Ares","Javier Parapar"],"pdf_url":"https://arxiv.org/pdf/2301.08006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07946v1","updated":"2023-01-19T08:46:59Z","published":"2023-01-19T08:46:59Z","title":"Job recommendations: benchmarking of collaborative filtering methods for\n  classifieds","summary":"  Classifieds provide many challenges for recommendation methods, due to the\nlimited information regarding users and items. In this paper, we explore\nrecommendation methods for classifieds using the example of OLX Jobs.\n  The goal of the paper is to benchmark different recommendation methods for\njobs classifieds in order to improve advertisements' conversion rate and user\nsatisfaction.\n  In our research, we implemented methods that are scalable and represent\ndifferent approaches to recommendation, namely ALS, LightFM, Prod2Vec, RP3beta,\nand SLIM. We performed a laboratory comparison of methods with regard to\naccuracy, diversity, and scalability (memory and time consumption during\ntraining and in prediction). Online A/B tests were also carried out by sending\nmillions of messages with recommendations to evaluate models in a real-world\nsetting.\n  In addition, we have published the dataset that we created for the needs of\nour research. To the best of our knowledge, this is the first dataset of this\nkind. The dataset contains 65,502,201 events performed on OLX Jobs by 3,295,942\nusers, who interacted with (displayed, replied to, or bookmarked) 185,395 job\nads in two weeks of 2020.\n  We demonstrate that RP3beta, SLIM, and ALS perform significantly better than\nProd2Vec and LightFM when tested in a laboratory setting. Online A/B tests also\ndemonstrated that sending messages with recommendations generated by the ALS\nand RP3beta models increases the number of users contacting advertisers.\nAdditionally, RP3beta had a 20% greater impact on this metric than ALS.\n","authors":["Robert Kwieciński","Agata Filipowska","Tomasz Górecki","Viacheslav Dubrov"],"pdf_url":"https://arxiv.org/pdf/2301.07946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07854v1","updated":"2023-01-19T02:51:47Z","published":"2023-01-19T02:51:47Z","title":"FE-TCM: Filter-Enhanced Transformer Click Model for Web Search","summary":"  Constructing click models and extracting implicit relevance feedback\ninformation from the interaction between users and search engines are very\nimportant to improve the ranking of search results. Using neural network to\nmodel users' click behaviors has become one of the effective methods to\nconstruct click models. In this paper, We use Transformer as the backbone\nnetwork of feature extraction, add filter layer innovatively, and propose a new\nFilter-Enhanced Transformer Click Model (FE-TCM) for web search. Firstly, in\norder to reduce the influence of noise on user behavior data, we use the\nlearnable filters to filter log noise. Secondly, following the examination\nhypothesis, we model the attraction estimator and examination predictor\nrespectively to output the attractiveness scores and examination probabilities.\nA novel transformer model is used to learn the deeper representation among\ndifferent features. Finally, we apply the combination functions to integrate\nattractiveness scores and examination probabilities into the click prediction.\nFrom our experiments on two real-world session datasets, it is proved that\nFE-TCM outperforms the existing click models for the click prediction.\n","authors":["Yingfei Wang","Jianping Liu","Meng Wang","Xintao Chu"],"pdf_url":"https://arxiv.org/pdf/2301.07854v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2211.02578v2","updated":"2023-01-19T18:59:45Z","published":"2022-11-04T16:50:10Z","title":"Data Models for Dataset Drift Controls in Machine Learning With Images","summary":"  Camera images are ubiquitous in machine learning research. They also play a\ncentral role in the delivery of important services spanning medicine and\nenvironmental surveying. However, the application of machine learning models in\nthese domains has been limited because of robustness concerns. A primary\nfailure mode are performance drops due to differences between the training and\ndeployment data. While there are methods to prospectively validate the\nrobustness of machine learning models to such dataset drifts, existing\napproaches do not account for explicit models of the primary object of\ninterest: the data. This limits our ability to study and understand the\nrelationship between data generation and downstream machine learning model\nperformance in a physically accurate manner. In this study, we demonstrate how\nto overcome this limitation by pairing traditional machine learning with\nphysical optics to obtain explicit and differentiable data models. We\ndemonstrate how such data models can be constructed for image data and used to\ncontrol downstream machine learning model performance related to dataset drift.\nThe findings are distilled into three applications. First, drift synthesis\nenables the controlled generation of physically faithful drift test cases to\npower model selection and targeted generalization. Second, the gradient\nconnection between machine learning task model and data model allows advanced,\nprecise tolerancing of task model sensitivity to changes in the data\ngeneration. These drift forensics can be used to precisely specify the\nacceptable data environments in which a task model may be run. Third, drift\noptimization opens up the possibility to create drifts that can help the task\nmodel learn better faster, effectively optimizing the data generating process\nitself. A guide to access the open code and datasets is available at\nhttps://github.com/aiaudit-org/raw2logit.\n","authors":["Luis Oala","Marco Aversa","Gabriel Nobis","Kurt Willis","Yoan Neuenschwander","Michèle Buck","Christian Matek","Jerome Extermann","Enrico Pomarico","Wojciech Samek","Roderick Murray-Smith","Christoph Clausen","Bruno Sanguinetti"],"pdf_url":"https://arxiv.org/pdf/2211.02578v2.pdf","comment":"LO and MA contributed equally"},{"id":"http://arxiv.org/abs/2301.08243v1","updated":"2023-01-19T18:59:01Z","published":"2023-01-19T18:59:01Z","title":"Self-Supervised Learning from Images with a Joint-Embedding Predictive\n  Architecture","summary":"  This paper demonstrates an approach for learning highly semantic image\nrepresentations without relying on hand-crafted data-augmentations. We\nintroduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a\nnon-generative approach for self-supervised learning from images. The idea\nbehind I-JEPA is simple: from a single context block, predict the\nrepresentations of various target blocks in the same image. A core design\nchoice to guide I-JEPA towards producing semantic representations is the\nmasking strategy; specifically, it is crucial to (a) predict several target\nblocks in the image, (b) sample target blocks with sufficiently large scale\n(occupying 15%-20% of the image), and (c) use a sufficiently informative\n(spatially distributed) context block. Empirically, when combined with Vision\nTransformers, we find I-JEPA to be highly scalable. For instance, we train a\nViT-Huge/16 on ImageNet using 32 A100 GPUs in under 38 hours to achieve strong\ndownstream performance across a wide range of tasks requiring various levels of\nabstraction, from linear classification to object counting and depth\nprediction.\n","authors":["Mahmoud Assran","Quentin Duval","Ishan Misra","Piotr Bojanowski","Pascal Vincent","Michael Rabbat","Yann LeCun","Nicolas Ballas"],"pdf_url":"https://arxiv.org/pdf/2301.08243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08232v1","updated":"2023-01-19T18:41:02Z","published":"2023-01-19T18:41:02Z","title":"Efficient Pricing and Hedging of High Dimensional American Options Using\n  Recurrent Networks","summary":"  We propose a deep Recurrent neural network (RNN) framework for computing\nprices and deltas of American options in high dimensions. Our proposed\nframework uses two deep RNNs, where one network learns the price and the other\nlearns the delta of the option for each timestep. Our proposed framework yields\nprices and deltas for the entire spacetime, not only at a given point (e.g. t =\n0). The computational cost of the proposed approach is linear in time, which\nimproves on the quadratic time seen for feedforward networks that price\nAmerican options. The computational memory cost of our method is constant in\nmemory, which is an improvement over the linear memory costs seen in\nfeedforward networks. Our numerical simulations demonstrate these\ncontributions, and show that the proposed deep RNN framework is computationally\nmore efficient than traditional feedforward neural network frameworks in time\nand memory.\n","authors":["Andrew Na","Justin Wan"],"pdf_url":"https://arxiv.org/pdf/2301.08232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08230v1","updated":"2023-01-19T18:39:48Z","published":"2023-01-19T18:39:48Z","title":"Score-based Causal Representation Learning with Interventions","summary":"  This paper studies causal representation learning problem when the latent\ncausal variables are observed indirectly through an unknown linear\ntransformation. The objectives are: (i) recovering the unknown linear\ntransformation (up to scaling and ordering), and (ii) determining the directed\nacyclic graph (DAG) underlying the latent variables. Since identifiable\nrepresentation learning is impossible based on only observational data, this\npaper uses both observational and interventional data. The interventional data\nis generated under distinct single-node randomized hard and soft interventions.\nThese interventions are assumed to cover all nodes in the latent space. It is\nestablished that the latent DAG structure can be recovered under soft\nrandomized interventions via the following two steps. First, a set of\ntransformation candidates is formed by including all inverting transformations\ncorresponding to which the \\emph{score} function of the transformed variables\nhas the minimal number of coordinates that change between an interventional and\nthe observational environment summed over all pairs. Subsequently, this set is\ndistilled using a simple constraint to recover the latent DAG structure. For\nthe special case of hard randomized interventions, with an additional\nhypothesis testing step, one can also uniquely recover the linear\ntransformation, up to scaling and a valid causal ordering. These results\ngeneralize the recent results that either assume deterministic hard\ninterventions or linear causal relationships in the latent space.\n","authors":["Burak Varici","Emre Acarturk","Karthikeyan Shanmugam","Abhishek Kumar","Ali Tajer"],"pdf_url":"https://arxiv.org/pdf/2301.08230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08227v1","updated":"2023-01-19T18:36:48Z","published":"2023-01-19T18:36:48Z","title":"Diffusion-based Conditional ECG Generation with Structured State Space\n  Models","summary":"  Synthetic data generation is a promising solution to address privacy issues\nwith the distribution of sensitive health data. Recently, diffusion models have\nset new standards for generative models for different data modalities. Also\nvery recently, structured state space models emerged as a powerful modeling\nparadigm to capture long-term dependencies in time series. We put forward\nSSSD-ECG, as the combination of these two technologies, for the generation of\nsynthetic 12-lead electrocardiograms conditioned on more than 70 ECG\nstatements. Due to a lack of reliable baselines, we also propose conditional\nvariants of two state-of-the-art unconditional generative models. We thoroughly\nevaluate the quality of the generated samples, by evaluating pretrained\nclassifiers on the generated data and by evaluating the performance of a\nclassifier trained only on synthetic data, where SSSD-ECG clearly outperforms\nits GAN-based competitors. We demonstrate the soundness of our approach through\nfurther experiments, including conditional class interpolation and a clinical\nTuring test demonstrating the high quality of the SSSD-ECG samples across a\nwide range of conditions.\n","authors":["Juan Miguel Lopez Alcaraz","Nils Strodthoff"],"pdf_url":"https://arxiv.org/pdf/2301.08227v1.pdf","comment":"12 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.08215v1","updated":"2023-01-19T18:24:08Z","published":"2023-01-19T18:24:08Z","title":"Tight Guarantees for Interactive Decision Making with the\n  Decision-Estimation Coefficient","summary":"  A foundational problem in reinforcement learning and interactive decision\nmaking is to understand what modeling assumptions lead to sample-efficient\nlearning guarantees, and what algorithm design principles achieve optimal\nsample complexity. Recently, Foster et al. (2021) introduced the\nDecision-Estimation Coefficient (DEC), a measure of statistical complexity\nwhich leads to upper and lower bounds on the optimal sample complexity for a\ngeneral class of problems encompassing bandits and reinforcement learning with\nfunction approximation. In this paper, we introduce a new variant of the DEC,\nthe Constrained Decision-Estimation Coefficient, and use it to derive new lower\nbounds that improve upon prior work on three fronts:\n  - They hold in expectation, with no restrictions on the class of algorithms\nunder consideration.\n  - They hold globally, and do not rely on the notion of localization used by\nFoster et al. (2021).\n  - Most interestingly, they allow the reference model with respect to which\nthe DEC is defined to be improper, establishing that improper reference models\nplay a fundamental role.\n  We provide upper bounds on regret that scale with the same quantity, thereby\nclosing all but one of the gaps between upper and lower bounds in Foster et al.\n(2021). Our results apply to both the regret framework and PAC framework, and\nmake use of several new analysis and algorithm design techniques that we\nanticipate will find broader use.\n","authors":["Dylan J. Foster","Noah Golowich","Yanjun Han"],"pdf_url":"https://arxiv.org/pdf/2301.08215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08210v1","updated":"2023-01-19T18:09:43Z","published":"2023-01-19T18:09:43Z","title":"Everything is Connected: Graph Neural Networks","summary":"  In many ways, graphs are the main modality of data we receive from nature.\nThis is due to the fact that most of the patterns we see, both in natural and\nartificial systems, are elegantly representable using the language of graph\nstructures. Prominent examples include molecules (represented as graphs of\natoms and bonds), social networks and transportation networks. This potential\nhas already been seen by key scientific and industrial groups, with\nalready-impacted application areas including traffic forecasting, drug\ndiscovery, social network analysis and recommender systems. Further, some of\nthe most successful domains of application for machine learning in previous\nyears -- images, text and speech processing -- can be seen as special cases of\ngraph representation learning, and consequently there has been significant\nexchange of information between these areas. The main aim of this short survey\nis to enable the reader to assimilate the key concepts in the area, and\nposition graph representation learning in a proper context with related fields.\n","authors":["Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2301.08210v1.pdf","comment":"To appear in Current Opinion in Structural Biology. 14 pages, 1\n  figure"},{"id":"http://arxiv.org/abs/2301.08209v1","updated":"2023-01-19T18:00:51Z","published":"2023-01-19T18:00:51Z","title":"GIPA++: A General Information Propagation Algorithm for Graph Learning","summary":"  Graph neural networks (GNNs) have been widely used in graph-structured data\ncomputation, showing promising performance in various applications such as node\nclassification, link prediction, and network recommendation. Existing works\nmainly focus on node-wise correlation when doing weighted aggregation of\nneighboring nodes based on attention, such as dot product by the dense vectors\nof two nodes. This may cause conflicting noise in nodes to be propagated when\ndoing information propagation. To solve this problem, we propose a General\nInformation Propagation Algorithm (GIPA in short), which exploits more\nfine-grained information fusion including bit-wise and feature-wise\ncorrelations based on edge features in their propagation. Specifically, the\nbit-wise correlation calculates the element-wise attention weight through a\nmulti-layer perceptron (MLP) based on the dense representations of two nodes\nand their edge; The feature-wise correlation is based on the one-hot\nrepresentations of node attribute features for feature selection. We evaluate\nthe performance of GIPA on the Open Graph Benchmark proteins (OGBN-proteins for\nshort) dataset and the Alipay dataset of Alibaba. Experimental results reveal\nthat GIPA outperforms the state-of-the-art models in terms of prediction\naccuracy, e.g., GIPA achieves an average ROC-AUC of $0.8901\\pm 0.0011$, which\nis better than that of all the existing methods listed in the OGBN-proteins\nleaderboard.\n","authors":["Houyi Li","Zhihong Chen","Zhao Li","Qinkai Zheng","Peng Zhang","Shuigeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.08209v1.pdf","comment":"Accepted by DASFAA2023. arXiv admin note: substantial text overlap\n  with arXiv:2105.06035"},{"id":"http://arxiv.org/abs/2301.08203v1","updated":"2023-01-19T17:54:50Z","published":"2023-01-19T17:54:50Z","title":"An SDE for Modeling SAM: Theory and Insights","summary":"  We study the SAM (Sharpness-Aware Minimization) optimizer which has recently\nattracted a lot of interest due to its increased performance over more\nclassical variants of stochastic gradient descent. Our main contribution is the\nderivation of continuous-time models (in the form of SDEs) for SAM and its\nunnormalized variant USAM, both for the full-batch and mini-batch settings. We\ndemonstrate that these SDEs are rigorous approximations of the real\ndiscrete-time algorithms (in a weak sense, scaling linearly with the step\nsize). Using these models, we then offer an explanation of why SAM prefers flat\nminima over sharp ones - by showing that it minimizes an implicitly regularized\nloss with a Hessian-dependent noise structure. Finally, we prove that perhaps\nunexpectedly SAM is attracted to saddle points under some realistic conditions.\nOur theoretical results are supported by detailed experiments.\n","authors":["Enea Monzio Compagnoni","Antonio Orvieto","Luca Biggio","Hans Kersting","Frank Norbert Proske","Aurelien Lucchi"],"pdf_url":"https://arxiv.org/pdf/2301.08203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08202v1","updated":"2023-01-19T17:53:53Z","published":"2023-01-19T17:53:53Z","title":"Differentially Private Online Bayesian Estimation With Adaptive\n  Truncation","summary":"  We propose a novel online and adaptive truncation method for differentially\nprivate Bayesian online estimation of a static parameter regarding a\npopulation. We assume that sensitive information from individuals is collected\nsequentially and the inferential aim is to estimate, on-the-fly, a static\nparameter regarding the population to which those individuals belong. We\npropose sequential Monte Carlo to perform online Bayesian estimation. When\nindividuals provide sensitive information in response to a query, it is\nnecessary to perturb it with privacy-preserving noise to ensure the privacy of\nthose individuals. The amount of perturbation is proportional to the\nsensitivity of the query, which is determined usually by the range of the\nqueried information. The truncation technique we propose adapts to the\npreviously collected observations to adjust the query range for the next\nindividual. The idea is that, based on previous observations, we can carefully\narrange the interval into which the next individual's information is to be\ntruncated before being perturbed with privacy-preserving noise. In this way, we\naim to design predictive queries with small sensitivity, hence small\nprivacy-preserving noise, enabling more accurate estimation while maintaining\nthe same level of privacy. To decide on the location and the width of the\ninterval, we use an exploration-exploitation approach a la Thompson sampling\nwith an objective function based on the Fisher information of the generated\nobservation. We show the merits of our methodology with numerical examples.\n","authors":["Sinan Yıldırım"],"pdf_url":"https://arxiv.org/pdf/2301.08202v1.pdf","comment":"17 pages, 3 figures, Code available"},{"id":"http://arxiv.org/abs/2209.04933v3","updated":"2023-01-19T17:52:31Z","published":"2022-09-07T21:09:38Z","title":"Dimensionality Reduction using Elastic Measures","summary":"  With the recent surge in big data analytics for hyper-dimensional data there\nis a renewed interest in dimensionality reduction techniques for machine\nlearning applications. In order for these methods to improve performance gains\nand understanding of the underlying data, a proper metric needs to be\nidentified. This step is often overlooked and metrics are typically chosen\nwithout consideration of the underlying geometry of the data. In this paper, we\npresent a method for incorporating elastic metrics into the t-distributed\nStochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation and\nProjection (UMAP). We apply our method to functional data, which is uniquely\ncharacterized by rotations, parameterization, and scale. If these properties\nare ignored, they can lead to incorrect analysis and poor classification\nperformance. Through our method we demonstrate improved performance on shape\nidentification tasks for three benchmark data sets (MPEG-7, Car data set, and\nPlane data set of Thankoor), where we achieve 0.77, 0.95, and 1.00 F1 score,\nrespectively.\n","authors":["J. Derek Tucker","Matthew T. Martinez","Jose M. Laborde"],"pdf_url":"https://arxiv.org/pdf/2209.04933v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08190v1","updated":"2023-01-19T17:37:48Z","published":"2023-01-19T17:37:48Z","title":"Building Concise Logical Patterns by Constraining Tsetlin Machine Clause\n  Size","summary":"  Tsetlin machine (TM) is a logic-based machine learning approach with the\ncrucial advantages of being transparent and hardware-friendly. While TMs match\nor surpass deep learning accuracy for an increasing number of applications,\nlarge clause pools tend to produce clauses with many literals (long clauses).\nAs such, they become less interpretable. Further, longer clauses increase the\nswitching activity of the clause logic in hardware, consuming more power. This\npaper introduces a novel variant of TM learning - Clause Size Constrained TMs\n(CSC-TMs) - where one can set a soft constraint on the clause size. As soon as\na clause includes more literals than the constraint allows, it starts expelling\nliterals. Accordingly, oversized clauses only appear transiently. To evaluate\nCSC-TM, we conduct classification, clustering, and regression experiments on\ntabular data, natural language text, images, and board games. Our results show\nthat CSC-TM maintains accuracy with up to 80 times fewer literals. Indeed, the\naccuracy increases with shorter clauses for TREC, IMDb, and BBC Sports. After\nthe accuracy peaks, it drops gracefully as the clause size approaches a single\nliteral. We finally analyze CSC-TM power consumption and derive new convergence\nproperties.\n","authors":["K. Darshana Abeyrathna","Ahmed Abdulrahem Othman Abouzeid","Bimal Bhattarai","Charul Giri","Sondre Glimsdal","Ole-Christoffer Granmo","Lei Jiao","Rupsa Saha","Jivitesh Sharma","Svein Anders Tunheim","Xuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08190v1.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2210.07487v2","updated":"2023-01-19T17:35:36Z","published":"2022-10-14T03:33:53Z","title":"A Scalable Finite Difference Method for Deep Reinforcement Learning","summary":"  Several low-bandwidth distributable black-box optimization algorithms in the\nfamily of finite differences such as Evolution Strategies have recently been\nshown to perform nearly as well as tailored Reinforcement Learning methods in\nsome Reinforcement Learning domains. One shortcoming of these black-box methods\nis that they must collect information about the structure of the return\nfunction at every update, and can often employ only information drawn from a\ndistribution centered around the current parameters. As a result, when these\nalgorithms are distributed across many machines, a significant portion of total\nruntime may be spent with many machines idle, waiting for a final return and\nthen for an update to be calculated. In this work we introduce a novel method\nto use older data in finite difference algorithms, which produces a scalable\nalgorithm that avoids significant idle time or wasted computation.\n","authors":["Matthew Allen","John Raisbeck","Hakho Lee"],"pdf_url":"https://arxiv.org/pdf/2210.07487v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08187v1","updated":"2023-01-19T17:33:48Z","published":"2023-01-19T17:33:48Z","title":"A Multi-Resolution Framework for U-Nets with Applications to\n  Hierarchical VAEs","summary":"  U-Net architectures are ubiquitous in state-of-the-art deep learning, however\ntheir regularisation properties and relationship to wavelets are understudied.\nIn this paper, we formulate a multi-resolution framework which identifies\nU-Nets as finite-dimensional truncations of models on an infinite-dimensional\nfunction space. We provide theoretical results which prove that average pooling\ncorresponds to projection within the space of square-integrable functions and\nshow that U-Nets with average pooling implicitly learn a Haar wavelet basis\nrepresentation of the data. We then leverage our framework to identify\nstate-of-the-art hierarchical VAEs (HVAEs), which have a U-Net architecture, as\na type of two-step forward Euler discretisation of multi-resolution diffusion\nprocesses which flow from a point mass, introducing sampling instabilities. We\nalso demonstrate that HVAEs learn a representation of time which allows for\nimproved parameter efficiency through weight-sharing. We use this observation\nto achieve state-of-the-art HVAE performance with half the number of parameters\nof existing models, exploiting the properties of our continuous-time\nformulation.\n","authors":["Fabian Falck","Christopher Williams","Dominic Danks","George Deligiannidis","Christopher Yau","Chris Holmes","Arnaud Doucet","Matthew Willetts"],"pdf_url":"https://arxiv.org/pdf/2301.08187v1.pdf","comment":"NeurIPS 2022 (selected as oral)"},{"id":"http://arxiv.org/abs/2206.11489v2","updated":"2023-01-19T17:25:20Z","published":"2022-06-23T06:04:21Z","title":"Nearly Minimax Optimal Reinforcement Learning with Linear Function\n  Approximation","summary":"  We study reinforcement learning with linear function approximation where the\ntransition probability and reward functions are linear with respect to a\nfeature mapping $\\boldsymbol{\\phi}(s,a)$. Specifically, we consider the\nepisodic inhomogeneous linear Markov Decision Process (MDP), and propose a\nnovel computation-efficient algorithm, LSVI-UCB$^+$, which achieves an\n$\\widetilde{O}(Hd\\sqrt{T})$ regret bound where $H$ is the episode length, $d$\nis the feature dimension, and $T$ is the number of steps. LSVI-UCB$^+$ builds\non weighted ridge regression and upper confidence value iteration with a\nBernstein-type exploration bonus. Our statistical results are obtained with\nnovel analytical tools, including a new Bernstein self-normalized bound with\nconservatism on elliptical potentials, and refined analysis of the correction\nterm. To the best of our knowledge, this is the first minimax optimal algorithm\nfor linear MDPs up to logarithmic factors, which closes the $\\sqrt{Hd}$ gap\nbetween the best known upper bound of $\\widetilde{O}(\\sqrt{H^3d^3T})$ in\n\\cite{jin2020provably} and lower bound of $\\Omega(Hd\\sqrt{T})$ for linear MDPs.\n","authors":["Pihe Hu","Yu Chen","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2206.11489v2.pdf","comment":"This is an updated version of our last version (accepted by ICML\n  2022) by fixing the issue in building the over-optimistic value function"},{"id":"http://arxiv.org/abs/2202.08070v3","updated":"2023-01-19T17:12:39Z","published":"2022-02-16T13:52:25Z","title":"On Measuring Excess Capacity in Neural Networks","summary":"  We study the excess capacity of deep networks in the context of supervised\nclassification. That is, given a capacity measure of the underlying hypothesis\nclass - in our case, empirical Rademacher complexity - to what extent can we (a\npriori) constrain this class while retaining an empirical error on a par with\nthe unconstrained regime? To assess excess capacity in modern architectures\n(such as residual networks), we extend and unify prior Rademacher complexity\nbounds to accommodate function composition and addition, as well as the\nstructure of convolutions. The capacity-driving terms in our bounds are the\nLipschitz constants of the layers and an (2, 1) group norm distance to the\ninitializations of the convolution weights. Experiments on benchmark datasets\nof varying task difficulty indicate that (1) there is a substantial amount of\nexcess capacity per task, and (2) capacity can be kept at a surprisingly\nsimilar level across tasks. Overall, this suggests a notion of compressibility\nwith respect to weight norms, complementary to classic compression via weight\npruning. Source code is available at https://github.com/rkwitt/excess_capacity.\n","authors":["Florian Graf","Sebastian Zeng","Bastian Rieck","Marc Niethammer","Roland Kwitt"],"pdf_url":"https://arxiv.org/pdf/2202.08070v3.pdf","comment":"Updated to Neurips 2022 camera-ready version"},{"id":"http://arxiv.org/abs/2301.08173v1","updated":"2023-01-19T17:04:59Z","published":"2023-01-19T17:04:59Z","title":"Time-Warping Invariant Quantum Recurrent Neural Networks via\n  Quantum-Classical Adaptive Gating","summary":"  Adaptive gating plays a key role in temporal data processing via classical\nrecurrent neural networks (RNN), as it facilitates retention of past\ninformation necessary to predict the future, providing a mechanism that\npreserves invariance to time warping transformations. This paper builds on\nquantum recurrent neural networks (QRNNs), a dynamic model with quantum memory,\nto introduce a novel class of temporal data processing quantum models that\npreserve invariance to time-warping transformations of the (classical)\ninput-output sequences. The model, referred to as time warping-invariant QRNN\n(TWI-QRNN), augments a QRNN with a quantum-classical adaptive gating mechanism\nthat chooses whether to apply a parameterized unitary transformation at each\ntime step as a function of the past samples of the input sequence via a\nclassical recurrent model. The TWI-QRNN model class is derived from first\nprinciples, and its capacity to successfully implement time-warping\ntransformations is experimentally demonstrated on examples with classical or\nquantum dynamics.\n","authors":["Ivana Nikoloska","Osvaldo Simeone","Leonardo Banchi","Petar Velićković"],"pdf_url":"https://arxiv.org/pdf/2301.08173v1.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2301.08170v1","updated":"2023-01-19T17:02:02Z","published":"2023-01-19T17:02:02Z","title":"On the Vulnerability of Backdoor Defenses for Federated Learning","summary":"  Federated Learning (FL) is a popular distributed machine learning paradigm\nthat enables jointly training a global model without sharing clients' data.\nHowever, its repetitive server-client communication gives room for backdoor\nattacks with aim to mislead the global model into a targeted misprediction when\na specific trigger pattern is presented. In response to such backdoor threats\non federated learning, various defense measures have been proposed. In this\npaper, we study whether the current defense mechanisms truly neutralize the\nbackdoor threats from federated learning in a practical setting by proposing a\nnew federated backdoor attack method for possible countermeasures. Different\nfrom traditional training (on triggered data) and rescaling (the malicious\nclient model) based backdoor injection, the proposed backdoor attack framework\n(1) directly modifies (a small proportion of) local model weights to inject the\nbackdoor trigger via sign flips; (2) jointly optimize the trigger pattern with\nthe client model, thus is more persistent and stealthy for circumventing\nexisting defenses. In a case study, we examine the strength and weaknesses of\nrecent federated backdoor defenses from three major categories and provide\nsuggestions to the practitioners when training federated models in practice.\n","authors":["Pei Fang","Jinghui Chen"],"pdf_url":"https://arxiv.org/pdf/2301.08170v1.pdf","comment":"Accepted by AAAI 2023 (15 pages, 12 figures, 7 tables)"},{"id":"http://arxiv.org/abs/2301.08167v1","updated":"2023-01-19T16:58:39Z","published":"2023-01-19T16:58:39Z","title":"Learning Quantum Processes with Memory -- Quantum Recurrent Neural\n  Networks","summary":"  Recurrent neural networks play an important role in both research and\nindustry. With the advent of quantum machine learning, the quantisation of\nrecurrent neural networks has become recently relevant. We propose fully\nquantum recurrent neural networks, based on dissipative quantum neural\nnetworks, capable of learning general causal quantum automata. A quantum\ntraining algorithm is proposed and classical simulations for the case of\nproduct outputs with the fidelity as cost function are carried out. We thereby\ndemonstrate the potential of these algorithms to learn complex quantum\nprocesses with memory in terms of the exemplary delay channel, the time\nevolution of quantum states governed by a time-dependent Hamiltonian, and high-\nand low-frequency noise mitigation. Numerical simulations indicate that our\nquantum recurrent neural networks exhibit a striking ability to generalise from\nsmall training sets.\n","authors":["Dmytro Bondarenko","Robert Salzmann","Viktoria-S. Schmiesing"],"pdf_url":"https://arxiv.org/pdf/2301.08167v1.pdf","comment":"5 pages + 37 pages appendices, 2 + 12 figures"},{"id":"http://arxiv.org/abs/2301.08164v1","updated":"2023-01-19T16:56:21Z","published":"2023-01-19T16:56:21Z","title":"DiME: Maximizing Mutual Information by a Difference of Matrix-Based\n  Entropies","summary":"  We introduce an information-theoretic quantity with similar properties to\nmutual information that can be estimated from data without making explicit\nassumptions on the underlying distribution. This quantity is based on a\nrecently proposed matrix-based entropy that uses the eigenvalues of a\nnormalized Gram matrix to compute an estimate of the eigenvalues of an\nuncentered covariance operator in a reproducing kernel Hilbert space. We show\nthat a difference of matrix-based entropies (DiME) is well suited for problems\ninvolving maximization of mutual information between random variables. While\nmany methods for such tasks can lead to trivial solutions, DiME naturally\npenalizes such outcomes. We provide several examples of use cases for the\nproposed quantity including a multi-view representation learning problem where\nDiME is used to encourage learning a shared representation among views with\nhigh mutual information. We also show the versatility of DiME by using it as\nobjective function for a variety of tasks.\n","authors":["Oscar Skean","Jhoan Keider Hoyos Osorio","Austin J. Brockmeier","Luis Gonzalo Sanchez Giraldo"],"pdf_url":"https://arxiv.org/pdf/2301.08164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12684v2","updated":"2023-01-19T16:41:19Z","published":"2022-09-23T03:04:27Z","title":"Soft-labeling Strategies for Rapid Sub-Typing","summary":"  The challenge of labeling large example datasets for computer vision\ncontinues to limit the availability and scope of image repositories. This\nresearch provides a new method for automated data collection, curation,\nlabeling, and iterative training with minimal human intervention for the case\nof overhead satellite imagery and object detection. The new operational scale\neffectively scanned an entire city (68 square miles) in grid search and yielded\na prediction of car color from space observations. A partially trained yolov5\nmodel served as an initial inference seed to output further, more refined model\npredictions in iterative cycles. Soft labeling here refers to accepting label\nnoise as a potentially valuable augmentation to reduce overfitting and enhance\ngeneralized predictions to previously unseen test data. The approach takes\nadvantage of a real-world instance where a cropped image of a car can\nautomatically receive sub-type information as white or colorful from pixel\nvalues alone, thus completing an end-to-end pipeline without overdependence on\nhuman labor.\n","authors":["Grant Rosario","David Noever","Matt Ciolino"],"pdf_url":"https://arxiv.org/pdf/2209.12684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.12087v4","updated":"2023-01-19T16:32:06Z","published":"2020-11-24T13:45:17Z","title":"A Convenient Infinite Dimensional Framework for Generative Adversarial\n  Learning","summary":"  In recent years, generative adversarial networks (GANs) have demonstrated\nimpressive experimental results while there are only a few works that foster\nstatistical learning theory for GANs. In this work, we propose an infinite\ndimensional theoretical framework for generative adversarial learning. We\nassume that the probability density functions of the underlying measure are\nuniformly bounded, $k$-times $\\alpha$-H\\\"{o}lder differentiable\n($C^{k,\\alpha}$) and uniformly bounded away from zero. Under these assumptions,\nwe show that the Rosenblatt transformation induces an optimal generator, which\nis realizable in the hypothesis space of $C^{k,\\alpha}$-generators. With a\nconsistent definition of the hypothesis space of discriminators, we further\nshow that the Jensen-Shannon divergence between the distribution induced by the\ngenerator from the adversarial learning procedure and the data generating\ndistribution converges to zero. Under certain regularity assumptions on the\ndensity of the data generating process, we also provide rates of convergence\nbased on chaining and concentration.\n","authors":["Hayk Asatryan","Hanno Gottschalk","Marieke Lippert","Matthias Rottmann"],"pdf_url":"https://arxiv.org/pdf/2011.12087v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08151v1","updated":"2023-01-19T16:13:28Z","published":"2023-01-19T16:13:28Z","title":"Global mapping of fragmented rocks on the Moon with a neural network:\n  Implications for the failure mode of rocks on airless surfaces","summary":"  It has been recently recognized that the surface of sub-km asteroids in\ncontact with the space environment is not fine-grained regolith but consists of\ncentimeter to meter-scale rocks. Here we aim to understand how the rocky\nmorphology of minor bodies react to the well known space erosion agents on the\nMoon. We deploy a neural network and map a total of ~130,000 fragmented\nboulders scattered across the lunar surface and visually identify a dozen\ndifferent desintegration morphologies corresponding to different failure modes.\nWe find that several fragmented boulder morphologies are equivalent to\nmorphologies observed on asteroid Bennu, suggesting that these morphologies on\nthe Moon and on asteroids are likely not diagnostic of their formation\nmechanism. Our findings suggest that the boulder fragmentation process is\ncharacterized by an internal weakening period with limited morphological signs\nof damage at rock scale until a sudden highly efficient impact shattering event\noccurs. In addition, we identify new morphologies such as breccia boulders with\nan advection-like erosion style. We publicly release the produced fractured\nboulder catalog along with this paper.\n","authors":["O. Ruesch","V. T. Bickel"],"pdf_url":"https://arxiv.org/pdf/2301.08151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.02732v2","updated":"2023-01-19T16:12:10Z","published":"2021-06-04T21:46:37Z","title":"BO-DBA: Query-Efficient Decision-Based Adversarial Attacks via Bayesian\n  Optimization","summary":"  Decision-based attacks (DBA), wherein attackers perturb inputs to spoof\nlearning algorithms by observing solely the output labels, are a type of severe\nadversarial attacks against Deep Neural Networks (DNNs) requiring minimal\nknowledge of attackers. State-of-the-art DBA attacks relying on zeroth-order\ngradient estimation require an excessive number of queries. Recently, Bayesian\noptimization (BO) has shown promising in reducing the number of queries in\nscore-based attacks (SBA), in which attackers need to observe real-valued\nprobability scores as outputs. However, extending BO to the setting of DBA is\nnontrivial because in DBA only output labels instead of real-valued scores, as\nneeded by BO, are available to attackers. In this paper, we close this gap by\nproposing an efficient DBA attack, namely BO-DBA. Different from existing\napproaches, BO-DBA generates adversarial examples by searching so-called\n\\emph{directions of perturbations}. It then formulates the problem as a BO\nproblem that minimizes the real-valued distortion of perturbations. With the\noptimized perturbation generation process, BO-DBA converges much faster than\nthe state-of-the-art DBA techniques. Experimental results on pre-trained\nImageNet classifiers show that BO-DBA converges within 200 queries while the\nstate-of-the-art DBA techniques need over 15,000 queries to achieve the same\nlevel of perturbation distortion. BO-DBA also shows similar attack success\nrates even as compared to BO-based SBA attacks but with less distortion.\n","authors":["Zhuosheng Zhang","Shucheng Yu"],"pdf_url":"https://arxiv.org/pdf/2106.02732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07210v2","updated":"2023-01-19T15:53:43Z","published":"2023-01-17T22:18:53Z","title":"Causal Falsification of Digital Twins","summary":"  Digital twins hold substantial promise in many applications, but rigorous\nprocedures for assessing their accuracy are essential for their widespread\ndeployment in safety-critical settings. By formulating this task within the\nframework of causal inference, we show it is not possible to certify that a\ntwin is \"correct\" using real-world observational data unless potentially\ntenuous assumptions are made about the data-generating process. To avoid these\nassumptions, we propose an assessment strategy that instead aims to find cases\nwhere the twin is not correct, and present a general-purpose statistical\nprocedure for doing so that may be used across a wide variety of applications\nand twin models. Our approach yields reliable and actionable information about\nthe twin under only the assumption of an i.i.d. dataset of real-world\nobservations, and in particular remains sound even in the presence of arbitrary\nunmeasured confounding. We demonstrate the effectiveness of our methodology via\na large-scale case study involving sepsis modelling within the Pulse Physiology\nEngine, which we assess using the MIMIC-III dataset of ICU patients.\n","authors":["Rob Cornish","Muhammad Faaiz Taufiq","Arnaud Doucet","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2301.07210v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07686v2","updated":"2023-01-19T15:27:33Z","published":"2022-10-14T10:23:23Z","title":"Learning Generalizable Models for Vehicle Routing Problems via Knowledge\n  Distillation","summary":"  Recent neural methods for vehicle routing problems always train and test the\ndeep models on the same instance distribution (i.e., uniform). To tackle the\nconsequent cross-distribution generalization concerns, we bring the knowledge\ndistillation to this field and propose an Adaptive Multi-Distribution Knowledge\nDistillation (AMDKD) scheme for learning more generalizable deep models.\nParticularly, our AMDKD leverages various knowledge from multiple teachers\ntrained on exemplar distributions to yield a light-weight yet generalist\nstudent model. Meanwhile, we equip AMDKD with an adaptive strategy that allows\nthe student to concentrate on difficult distributions, so as to absorb\nhard-to-master knowledge more effectively. Extensive experimental results show\nthat, compared with the baseline neural methods, our AMDKD is able to achieve\ncompetitive results on both unseen in-distribution and out-of-distribution\ninstances, which are either randomly synthesized or adopted from benchmark\ndatasets (i.e., TSPLIB and CVRPLIB). Notably, our AMDKD is generic, and\nconsumes less computational resources for inference.\n","authors":["Jieyi Bi","Yining Ma","Jiahai Wang","Zhiguang Cao","Jinbiao Chen","Yuan Sun","Yeow Meng Chee"],"pdf_url":"https://arxiv.org/pdf/2210.07686v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.08117v1","updated":"2023-01-19T15:18:23Z","published":"2023-01-19T15:18:23Z","title":"Convergence beyond the over-parameterized regime using Rayleigh\n  quotients","summary":"  In this paper, we present a new strategy to prove the convergence of deep\nlearning architectures to a zero training (or even testing) loss by gradient\nflow. Our analysis is centered on the notion of Rayleigh quotients in order to\nprove Kurdyka-{\\L}ojasiewicz inequalities for a broader set of neural network\narchitectures and loss functions. We show that Rayleigh quotients provide a\nunified view for several convergence analysis techniques in the literature. Our\nstrategy produces a proof of convergence for various examples of parametric\nlearning. In particular, our analysis does not require the number of parameters\nto tend to infinity, nor the number of samples to be finite, thus extending to\ntest loss minimization and beyond the over-parameterized regime.\n","authors":["David A. R. Robin","Kevin Scaman","Marc Lelarge"],"pdf_url":"https://arxiv.org/pdf/2301.08117v1.pdf","comment":"Published at the 36th conference on Neural Information Processing\n  Systems (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2301.08114v1","updated":"2023-01-19T15:06:32Z","published":"2023-01-19T15:06:32Z","title":"Enhancing Deep Learning with Scenario-Based Override Rules: a Case Study","summary":"  Deep neural networks (DNNs) have become a crucial instrument in the software\ndevelopment toolkit, due to their ability to efficiently solve complex\nproblems. Nevertheless, DNNs are highly opaque, and can behave in an unexpected\nmanner when they encounter unfamiliar input. One promising approach for\naddressing this challenge is by extending DNN-based systems with hand-crafted\noverride rules, which override the DNN's output when certain conditions are\nmet. Here, we advocate crafting such override rules using the well-studied\nscenario-based modeling paradigm, which produces rules that are simple,\nextensible, and powerful enough to ensure the safety of the DNN, while also\nrendering the system more translucent. We report on two extensive case studies,\nwhich demonstrate the feasibility of the approach; and through them, propose an\nextension to scenario-based modeling, which facilitates its integration with\nDNN components. We regard this work as a step towards creating safer and more\nreliable DNN-based systems and models.\n","authors":["Adiel Ashrov","Guy Katz"],"pdf_url":"https://arxiv.org/pdf/2301.08114v1.pdf","comment":"A preprint of a paper with the same title, to appear at MODELSWARD\n  2023"},{"id":"http://arxiv.org/abs/2301.08110v1","updated":"2023-01-19T15:01:00Z","published":"2023-01-19T15:01:00Z","title":"AtMan: Understanding Transformer Predictions Through Memory Efficient\n  Attention Manipulation","summary":"  Generative transformer models have become increasingly complex, with large\nnumbers of parameters and the ability to process multiple input modalities.\nCurrent methods for explaining their predictions are resource-intensive. Most\ncrucially, they require prohibitively large amounts of extra memory, since they\nrely on backpropagation which allocates almost twice as much GPU memory as the\nforward pass. This makes it difficult, if not impossible, to use them in\nproduction. We present AtMan that provides explanations of generative\ntransformer models at almost no extra cost. Specifically, AtMan is a\nmodality-agnostic perturbation method that manipulates the attention mechanisms\nof transformers to produce relevance maps for the input with respect to the\noutput prediction. Instead of using backpropagation, AtMan applies a\nparallelizable token-based search method based on cosine similarity\nneighborhood in the embedding space. Our exhaustive experiments on text and\nimage-text benchmarks demonstrate that AtMan outperforms current\nstate-of-the-art gradient-based methods on several metrics while being\ncomputationally efficient. As such, AtMan is suitable for use in large model\ninference deployments.\n","authors":["Mayukh Deb","Björn Deiseroth","Samuel Weinbach","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2301.08110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08102v1","updated":"2023-01-19T14:45:03Z","published":"2023-01-19T14:45:03Z","title":"Geometric path augmentation for inference of sparsely observed\n  stochastic nonlinear systems","summary":"  Stochastic evolution equations describing the dynamics of systems under the\ninfluence of both deterministic and stochastic forces are prevalent in all\nfields of science. Yet, identifying these systems from sparse-in-time\nobservations remains still a challenging endeavour. Existing approaches focus\neither on the temporal structure of the observations by relying on conditional\nexpectations, discarding thereby information ingrained in the geometry of the\nsystem's invariant density; or employ geometric approximations of the invariant\ndensity, which are nevertheless restricted to systems with conservative forces.\nHere we propose a method that reconciles these two paradigms. We introduce a\nnew data-driven path augmentation scheme that takes the local observation\ngeometry into account. By employing non-parametric inference on the augmented\npaths, we can efficiently identify the deterministic driving forces of the\nunderlying system for systems observed at low sampling rates.\n","authors":["Dimitra Maoutsa"],"pdf_url":"https://arxiv.org/pdf/2301.08102v1.pdf","comment":"12+9 pages; 3 figures; Presented at NeurIPS 2022 - Machine Learning\n  and the Physical Sciences workshop; parts of text are reproduced from\n  author's Ph.D. thesis"},{"id":"http://arxiv.org/abs/2301.08092v1","updated":"2023-01-19T14:22:44Z","published":"2023-01-19T14:22:44Z","title":"RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge\n  Distillation","summary":"  Deep Neural Networks are vulnerable to adversarial attacks. Neural\nArchitecture Search (NAS), one of the driving tools of deep neural networks,\ndemonstrates superior performance in prediction accuracy in various machine\nlearning applications. However, it is unclear how it performs against\nadversarial attacks. Given the presence of a robust teacher, it would be\ninteresting to investigate if NAS would produce robust neural architecture by\ninheriting robustness from the teacher. In this paper, we propose Robust Neural\nArchitecture Search by Cross-Layer Knowledge Distillation (RNAS-CL), a novel\nNAS algorithm that improves the robustness of NAS by learning from a robust\nteacher through cross-layer knowledge distillation. Unlike previous knowledge\ndistillation methods that encourage close student/teacher output only in the\nlast layer, RNAS-CL automatically searches for the best teacher layer to\nsupervise each student layer. Experimental result evidences the effectiveness\nof RNAS-CL and shows that RNAS-CL produces small and robust neural\narchitecture.\n","authors":["Utkarsh Nath","Yancheng Wang","Yingzhen Yang"],"pdf_url":"https://arxiv.org/pdf/2301.08092v1.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.11080v2","updated":"2023-01-19T14:11:06Z","published":"2022-12-21T15:27:52Z","title":"Is it worth it? Comparing six deep and classical methods for\n  unsupervised anomaly detection in time series","summary":"  Detecting anomalies in time series data is important in a variety of fields,\nincluding system monitoring, healthcare, and cybersecurity. While the abundance\nof available methods makes it difficult to choose the most appropriate method\nfor a given application, each method has its strengths in detecting certain\ntypes of anomalies. In this study, we compare six unsupervised anomaly\ndetection methods of varying complexity to determine whether more complex\nmethods generally perform better and if certain methods are better suited to\ncertain types of anomalies. We evaluated the methods using the UCR anomaly\narchive, a recent benchmark dataset for anomaly detection. We analyzed the\nresults on a dataset and anomaly type level after adjusting the necessary\nhyperparameters for each method. Additionally, we assessed the ability of each\nmethod to incorporate prior knowledge about anomalies and examined the\ndifferences between point-wise and sequence-wise features. Our experiments show\nthat classical machine learning methods generally outperform deep learning\nmethods across a range of anomaly types.\n","authors":["Ferdinand Rewicki","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2212.11080v2.pdf","comment":"17 Pages, The repository to reproduce the results is available at\n  https://gitlab.com/dlr-dw/is-it-worth-it-benchmark"},{"id":"http://arxiv.org/abs/2301.05567v2","updated":"2023-01-19T14:10:52Z","published":"2023-01-13T14:19:17Z","title":"Neural network with optimal neuron activation functions based on\n  additive Gaussian process regression","summary":"  Feed-forward neural networks (NN) are a staple machine learning method widely\nused in many areas of science and technology. While even a single-hidden layer\nNN is a universal approximator, its expressive power is limited by the use of\nsimple neuron activation functions (such as sigmoid functions) that are\ntypically the same for all neurons. More flexible neuron activation functions\nwould allow using fewer neurons and layers and thereby save computational cost\nand improve expressive power. We show that additive Gaussian process regression\n(GPR) can be used to construct optimal neuron activation functions that are\nindividual to each neuron. An approach is also introduced that avoids\nnon-linear fitting of neural network parameters. The resulting method combines\nthe advantage of robustness of a linear regression with the higher expressive\npower of a NN. We demonstrate the approach by fitting the potential energy\nsurfaces of the water molecule and formaldehyde. Without requiring any\nnon-linear optimization, the additive GPR based approach outperforms a\nconventional NN in the high accuracy regime, where a conventional NN suffers\nmore from overfitting.\n","authors":["Sergei Manzhos","Manabu Ihara"],"pdf_url":"https://arxiv.org/pdf/2301.05567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08086v1","updated":"2023-01-19T14:07:08Z","published":"2023-01-19T14:07:08Z","title":"Shapley Values with Uncertain Value Functions","summary":"  We propose a novel definition of Shapley values with uncertain value\nfunctions based on first principles using probability theory. Such uncertain\nvalue functions can arise in the context of explainable machine learning as a\nresult of non-deterministic algorithms. We show that random effects can in fact\nbe absorbed into a Shapley value with a noiseless but shifted value function.\nHence, Shapley values with uncertain value functions can be used in analogy to\nregular Shapley values. However, their reliable evaluation typically requires\nmore computational effort.\n","authors":["Raoul Heese","Sascha Mücke","Matthias Jakobs","Thore Gerlach","Nico Piatkowski"],"pdf_url":"https://arxiv.org/pdf/2301.08086v1.pdf","comment":"12 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2301.08085v1","updated":"2023-01-19T14:05:33Z","published":"2023-01-19T14:05:33Z","title":"On backpropagating Hessians through ODEs","summary":"  We discuss the problem of numerically backpropagating Hessians through\nordinary differential equations (ODEs) in various contexts and elucidate how\ndifferent approaches may be favourable in specific situations. We discuss both\ntheoretical and pragmatic aspects such as, respectively, bounds on\ncomputational effort and typical impact of framework overhead.\n  Focusing on the approach of hand-implemented ODE-backpropagation, we develop\nthe computation for the Hessian of orbit-nonclosure for a mechanical system. We\nalso clarify the mathematical framework for extending the\nbackward-ODE-evolution of the costate-equation to Hessians, in its most generic\nform. Some calculations, such as that of the Hessian for orbit non-closure, are\nperformed in a language, defined in terms of a formal grammar, that we\nintroduce to facilitate the tracking of intermediate quantities.\n  As pedagogical examples, we discuss the Hessian of orbit-nonclosure for the\nhigher dimensional harmonic oscillator and conceptually related problems in\nNewtonian gravitational theory. In particular, applying our approach to the\nfigure-8 three-body orbit, we readily rediscover a distorted-figure-8 solution\noriginally described by Sim\\'o.\n  Possible applications may include: improvements to training of `neural ODE'-\ntype deep learning with second-order methods, numerical analysis of quantum\ncorrections around classical paths, and, more broadly, studying options for\nadjusting an ODE's initial configuration such that the impact on some given\nobjective function is small.\n","authors":["Axel Ciceri","Thomas Fischbacher"],"pdf_url":"https://arxiv.org/pdf/2301.08085v1.pdf","comment":"32 pages, 3 figures, 1500 lines of code in ancillary files (including\n  tests)"},{"id":"http://arxiv.org/abs/2210.16316v2","updated":"2023-01-19T13:59:42Z","published":"2022-10-28T09:07:08Z","title":"The secret role of undesired physical effects in accurate shape sensing\n  with eccentric FBGs","summary":"  Fiber optic shape sensors have enabled unique advances in various navigation\ntasks, from medical tool tracking to industrial applications. Eccentric fiber\nBragg gratings (FBG) are cheap and easy-to-fabricate shape sensors that are\noften interrogated with simple setups. However, using low-cost interrogation\nsystems for such intensity-based quasi-distributed sensors introduces further\ncomplications to the sensor's signal. Therefore, eccentric FBGs have not been\nable to accurately estimate complex multi-bend shapes. Here, we present a novel\ntechnique to overcome these limitations and provide accurate and precise shape\nestimation in eccentric FBG sensors. We investigate the most important\nbending-induced effects in curved optical fibers that are usually eliminated in\nintensity-based fiber sensors. These effects contain shape deformation\ninformation with a higher spatial resolution that we are now able to extract\nusing deep learning techniques. We design a deep learning model based on a\nconvolutional neural network that is trained to predict shapes given the\nsensor's spectra. We also provide a visual explanation, highlighting wavelength\nelements whose intensities are more relevant in making shape predictions. These\nfindings imply that deep learning techniques benefit from the bending-induced\neffects that impact the desired signal in a complex manner. This is the first\nstep toward cheap yet accurate fiber shape sensing solutions.\n","authors":["Samaneh Manavi Roodsari","Sara Freund","Martin Angelmahr","Georg Rauter","Wolfgang Schade","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2210.16316v2.pdf","comment":"18 pages, 5 figures, preprint"},{"id":"http://arxiv.org/abs/2301.08064v1","updated":"2023-01-19T13:22:11Z","published":"2023-01-19T13:22:11Z","title":"Position Regression for Unsupervised Anomaly Detection","summary":"  In recent years, anomaly detection has become an essential field in medical\nimage analysis. Most current anomaly detection methods for medical images are\nbased on image reconstruction. In this work, we propose a novel anomaly\ndetection approach based on coordinate regression. Our method estimates the\nposition of patches within a volume, and is trained only on data of healthy\nsubjects. During inference, we can detect and localize anomalies by considering\nthe error of the position estimate of a given patch. We apply our method to 3D\nCT volumes and evaluate it on patients with intracranial haemorrhages and\ncranial fractures. The results show that our method performs well in detecting\nthese anomalies. Furthermore, we show that our method requires less memory than\ncomparable approaches that involve image reconstruction. This is highly\nrelevant for processing large 3D volumes, for instance, CT or MRI scans.\n","authors":["Florentin Bieder","Julia Wolleb","Robin Sandkühler","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2301.08064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15617v2","updated":"2023-01-19T13:02:09Z","published":"2022-05-31T09:01:15Z","title":"Optimizing Intermediate Representations of Generative Models for Phase\n  Retrieval","summary":"  Phase retrieval is the problem of reconstructing images from magnitude-only\nmeasurements. In many real-world applications the problem is underdetermined.\nWhen training data is available, generative models allow optimization in a\nlower-dimensional latent space, hereby constraining the solution set to those\nimages that can be synthesized by the generative model. However, not all\npossible solutions are within the range of the generator. Instead, they are\nrepresented with some error. To reduce this representation error in the context\nof phase retrieval, we first leverage a novel variation of intermediate layer\noptimization (ILO) to extend the range of the generator while still producing\nimages consistent with the training data. Second, we introduce new\ninitialization schemes that further improve the quality of the reconstruction.\nWith extensive experiments on the Fourier phase retrieval problem and thorough\nablation studies, we can show the benefits of our modified ILO and the new\ninitialization schemes. Additionally, we analyze the performance of our\napproach on the Gaussian phase retrieval problem.\n","authors":["Tobias Uelwer","Sebastian Konietzny","Stefan Harmeling"],"pdf_url":"https://arxiv.org/pdf/2205.15617v2.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR). First\n  two authors contributed equally"},{"id":"http://arxiv.org/abs/2106.10147v2","updated":"2023-01-19T12:54:38Z","published":"2021-06-18T14:23:55Z","title":"Evaluating the Robustness of Trigger Set-Based Watermarks Embedded in\n  Deep Neural Networks","summary":"  Trigger set-based watermarking schemes have gained emerging attention as they\nprovide a means to prove ownership for deep neural network model owners. In\nthis paper, we argue that state-of-the-art trigger set-based watermarking\nalgorithms do not achieve their designed goal of proving ownership. We posit\nthat this impaired capability stems from two common experimental flaws that the\nexisting research practice has committed when evaluating the robustness of\nwatermarking algorithms: (1) incomplete adversarial evaluation and (2)\noverlooked adaptive attacks. We conduct a comprehensive adversarial evaluation\nof 11 representative watermarking schemes against six of the existing attacks\nand demonstrate that each of these watermarking schemes lacks robustness\nagainst at least two non-adaptive attacks. We also propose novel adaptive\nattacks that harness the adversary's knowledge of the underlying watermarking\nalgorithm of a target model. We demonstrate that the proposed attacks\neffectively break all of the 11 watermarking schemes, consequently allowing\nadversaries to obscure the ownership of any watermarked model. We encourage\nfollow-up studies to consider our guidelines when evaluating the robustness of\ntheir watermarking schemes via conducting comprehensive adversarial evaluation\nthat includes our adaptive attacks to demonstrate a meaningful upper bound of\nwatermark robustness.\n","authors":["Suyoung Lee","Wonho Song","Suman Jana","Meeyoung Cha","Sooel Son"],"pdf_url":"https://arxiv.org/pdf/2106.10147v2.pdf","comment":"15 pages, accepted at IEEE TDSC"},{"id":"http://arxiv.org/abs/2301.08039v1","updated":"2023-01-19T12:32:41Z","published":"2023-01-19T12:32:41Z","title":"Kinetic Langevin MCMC Sampling Without Gradient Lipschitz Continuity --\n  the Strongly Convex Case","summary":"  In this article we consider sampling from log concave distributions in\nHamiltonian setting, without assuming that the objective gradient is globally\nLipschitz. We propose two algorithms based on monotone polygonal (tamed) Euler\nschemes, to sample from a target measure, and provide non-asymptotic\n2-Wasserstein distance bounds between the law of the process of each algorithm\nand the target measure. Finally, we apply these results to bound the excess\nrisk optimization error of the associated optimization problem.\n","authors":["Tim Johnston","Iosif Lytras","Sotirios Sabanis"],"pdf_url":"https://arxiv.org/pdf/2301.08039v1.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2102.05571v6","updated":"2023-01-19T12:08:15Z","published":"2021-02-10T17:08:09Z","title":"TINKER: A framework for Open source Cyberthreat Intelligence","summary":"  Threat intelligence on malware attacks and campaigns is increasingly being\nshared with other security experts for a cost or for free. Other security\nanalysts use this intelligence to inform them of indicators of compromise,\nattack techniques, and preventative actions. Security analysts prepare threat\nanalysis reports after investigating an attack, an emerging cyber threat, or a\nrecently discovered vulnerability. Collectively known as cyber threat\nintelligence (CTI), the reports are typically in an unstructured format and,\ntherefore, challenging to integrate seamlessly into existing intrusion\ndetection systems. This paper proposes a framework that uses the aggregated CTI\nfor analysis and defense at scale. The information is extracted and stored in a\nstructured format using knowledge graphs such that the semantics of the threat\nintelligence can be preserved and shared at scale with other security analysts.\nSpecifically, we propose the first semi-supervised open-source knowledge\ngraph-based framework, TINKER, to capture cyber threat information and its\ncontext. Following TINKER, we generate a Cyberthreat Intelligence Knowledge\nGraph (CTI-KG) and demonstrate the usage using different use cases.\n","authors":["Nidhi Rastogi","Sharmishtha Dutta","Mohammed J. Zaki","Alex Gittens","Charu Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2102.05571v6.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2301.08030v1","updated":"2023-01-19T12:04:03Z","published":"2023-01-19T12:04:03Z","title":"Multi-Agent Interplay in a Competitive Survival Environment","summary":"  Solving hard-exploration environments in an important challenge in\nReinforcement Learning. Several approaches have been proposed and studied, such\nas Intrinsic Motivation, co-evolution of agents and tasks, and multi-agent\ncompetition. In particular, the interplay between multiple agents has proven to\nbe capable of generating human-relevant emergent behaviour that would be\ndifficult or impossible to learn in single-agent settings. In this work, an\nextensible competitive environment for multi-agent interplay was developed,\nwhich features realistic physics and human-relevant semantics. Moreover,\nseveral experiments on different variants of this environment were performed,\nresulting in some simple emergent strategies and concrete directions for future\nimprovement. The content presented here is part of the author's thesis\n\"Multi-Agent Interplay in a Competitive Survival Environment\" for the Master's\nDegree in Artificial Intelligence and Robotics at Sapienza University of Rome,\n2022.\n","authors":["Andrea Fanti"],"pdf_url":"https://arxiv.org/pdf/2301.08030v1.pdf","comment":"21 pages, 11 figures, part of a Master's thesis, Sapienza University\n  of Rome, 2022"},{"id":"http://arxiv.org/abs/2301.08028v1","updated":"2023-01-19T12:01:41Z","published":"2023-01-19T12:01:41Z","title":"A Survey of Meta-Reinforcement Learning","summary":"  While deep reinforcement learning (RL) has fueled multiple high-profile\nsuccesses in machine learning, it is held back from more widespread adoption by\nits often poor data efficiency and the limited generality of the policies it\nproduces. A promising approach for alleviating these limitations is to cast the\ndevelopment of better RL algorithms as a machine learning problem itself in a\nprocess called meta-RL. Meta-RL is most commonly studied in a problem setting\nwhere, given a distribution of tasks, the goal is to learn a policy that is\ncapable of adapting to any new task from the task distribution with as little\ndata as possible. In this survey, we describe the meta-RL problem setting in\ndetail as well as its major variations. We discuss how, at a high level,\nmeta-RL research can be clustered based on the presence of a task distribution\nand the learning budget available for each individual task. Using these\nclusters, we then survey meta-RL algorithms and applications. We conclude by\npresenting the open problems on the path to making meta-RL part of the standard\ntoolbox for a deep RL practitioner.\n","authors":["Jacob Beck","Risto Vuorio","Evan Zheran Liu","Zheng Xiong","Luisa Zintgraf","Chelsea Finn","Shimon Whiteson"],"pdf_url":"https://arxiv.org/pdf/2301.08028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08019v1","updated":"2023-01-19T11:42:09Z","published":"2023-01-19T11:42:09Z","title":"Identification, explanation and clinical evaluation of hospital patient\n  subtypes","summary":"  We present a pipeline in which unsupervised machine learning techniques are\nused to automatically identify subtypes of hospital patients admitted between\n2017 and 2021 in a large UK teaching hospital. With the use of state-of-the-art\nexplainability techniques, the identified subtypes are interpreted and assigned\nclinical meaning. In parallel, clinicians assessed intra-cluster similarities\nand inter-cluster differences of the identified patient subtypes within the\ncontext of their clinical knowledge. By confronting the outputs of both\nautomatic and clinician-based explanations, we aim to highlight the mutual\nbenefit of combining machine learning techniques with clinical expertise.\n","authors":["Enrico Werner","Jeffrey N. Clark","Ranjeet S. Bhamber","Michael Ambler","Christopher P. Bourdeaux","Alexander Hepburn","Christopher J. McWilliams","Raul Santos-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2301.08019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08015v1","updated":"2023-01-19T11:36:50Z","published":"2023-01-19T11:36:50Z","title":"Global Nash Equilibrium in Non-convex Multi-player Game: Theory and\n  Algorithms","summary":"  Wide machine learning tasks can be formulated as non-convex multi-player\ngames, where Nash equilibrium (NE) is an acceptable solution to all players,\nsince no one can benefit from changing its strategy unilaterally. Attributed to\nthe non-convexity, obtaining the existence condition of global NE is\nchallenging, let alone designing theoretically guaranteed realization\nalgorithms. This paper takes conjugate transformation to the formulation of\nnon-convex multi-player games, and casts the complementary problem into a\nvariational inequality (VI) problem with a continuous pseudo-gradient mapping.\nWe then prove the existence condition of global NE: the solution to the VI\nproblem satisfies a duality relation. Based on this VI formulation, we design a\nconjugate-based ordinary differential equation (ODE) to approach global NE,\nwhich is proved to have an exponential convergence rate. To make the dynamics\nmore implementable, we further derive a discretized algorithm. We apply our\nalgorithm to two typical scenarios: multi-player generalized monotone game and\nmulti-player potential game. In the two settings, we prove that the step-size\nsetting is required to be $\\mathcal{O}(1/k)$ and $\\mathcal{O}(1/\\sqrt k)$ to\nyield the convergence rates of $\\mathcal{O}(1/ k)$ and $\\mathcal{O}(1/\\sqrt\nk)$, respectively. Extensive experiments in robust neural network training and\nsensor localization are in full agreement with our theory.\n","authors":["Guanpu Chen","Gehui Xu","Fengxiang He","Yiguang Hong","Leszek Rutkowski","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2301.08015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08008v1","updated":"2023-01-19T11:27:56Z","published":"2023-01-19T11:27:56Z","title":"Improving Machine Translation with Phrase Pair Injection and Corpus\n  Filtering","summary":"  In this paper, we show that the combination of Phrase Pair Injection and\nCorpus Filtering boosts the performance of Neural Machine Translation (NMT)\nsystems. We extract parallel phrases and sentences from the pseudo-parallel\ncorpus and augment it with the parallel corpus to train the NMT models. With\nthe proposed approach, we observe an improvement in the Machine Translation\n(MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi,\nand English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on\nthe FLORES test data. These BLEU score improvements are over the models trained\nusing the whole pseudo-parallel corpus augmented with the parallel corpus.\n","authors":["Akshay Batheja","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2301.08008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01614v2","updated":"2023-01-19T10:42:11Z","published":"2022-06-01T10:07:37Z","title":"Learning programs by combining programs","summary":"  The goal of inductive logic programming is to induce a logic program (a set\nof logical rules) that generalises training examples. Inducing programs with\nmany rules and literals is a major challenge. To tackle this challenge, we\nintroduce an approach where we learn small non-separable programs and combine\nthem. We implement our approach in a constraint-driven ILP system. Our approach\ncan learn optimal and recursive programs and perform predicate invention. Our\nexperiments on multiple domains, including game playing and program synthesis,\nshow that our approach can drastically outperform existing approaches in terms\nof predictive accuracies and learning times, sometimes reducing learning times\nfrom over an hour to a few seconds.\n","authors":["Andrew Cropper","Céline Hocquette"],"pdf_url":"https://arxiv.org/pdf/2206.01614v2.pdf","comment":"under review. arXiv admin note: text overlap with arXiv:2109.07818"},{"id":"http://arxiv.org/abs/2111.09794v6","updated":"2023-01-19T10:32:33Z","published":"2021-11-18T16:53:02Z","title":"A Survey of Zero-shot Generalisation in Deep Reinforcement Learning","summary":"  The study of zero-shot generalisation (ZSG) in deep Reinforcement Learning\n(RL) aims to produce RL algorithms whose policies generalise well to novel\nunseen situations at deployment time, avoiding overfitting to their training\nenvironments. Tackling this is vital if we are to deploy reinforcement learning\nalgorithms in real world scenarios, where the environment will be diverse,\ndynamic and unpredictable. This survey is an overview of this nascent field. We\nrely on a unifying formalism and terminology for discussing different ZSG\nproblems, building upon previous works. We go on to categorise existing\nbenchmarks for ZSG, as well as current methods for tackling these problems.\nFinally, we provide a critical discussion of the current state of the field,\nincluding recommendations for future work. Among other conclusions, we argue\nthat taking a purely procedural content generation approach to benchmark design\nis not conducive to progress in ZSG, we suggest fast online adaptation and\ntackling RL-specific problems as some areas for future work on methods for ZSG,\nand we recommend building benchmarks in underexplored problem settings such as\noffline RL ZSG and reward-function variation.\n","authors":["Robert Kirk","Amy Zhang","Edward Grefenstette","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2111.09794v6.pdf","comment":"JAIR version. Added formal definitions of ZSPT and related concepts,\n  JAIR formatting, other small rewrites;\n  https://www.jair.org/index.php/jair/article/view/14174"},{"id":"http://arxiv.org/abs/2301.07981v1","updated":"2023-01-19T10:16:56Z","published":"2023-01-19T10:16:56Z","title":"Continuously Reliable Detection of New-Normal Misinformation: Semantic\n  Masking and Contrastive Smoothing in High-Density Latent Regions","summary":"  Toxic misinformation campaigns have caused significant societal harm, e.g.,\naffecting elections and COVID-19 information awareness. Unfortunately, despite\nsuccesses of (gold standard) retrospective studies of misinformation that\nconfirmed their harmful effects after the fact, they arrive too late for timely\nintervention and reduction of such harm. By design, misinformation evades\nretrospective classifiers by exploiting two properties we call new-normal: (1)\nnever-seen-before novelty that cause inescapable generalization challenges for\nprevious classifiers, and (2) massive but short campaigns that end before they\ncan be manually annotated for new classifier training. To tackle these\nchallenges, we propose UFIT, which combines two techniques: semantic masking of\nstrong signal keywords to reduce overfitting, and intra-proxy smoothness\nregularization of high-density regions in the latent space to improve\nreliability and maintain accuracy. Evaluation of UFIT on public new-normal\nmisinformation data shows over 30% improvement over existing approaches on\nfuture (and unseen) campaigns. To the best of our knowledge, UFIT is the first\nsuccessful effort to achieve such high level of generalization on new-normal\nmisinformation data with minimal concession (1 to 5%) of accuracy compared to\noracles trained with full knowledge of all campaigns.\n","authors":["Abhijit Suprem","Joao Eduardo Ferreira","Calton Pu"],"pdf_url":"https://arxiv.org/pdf/2301.07981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07978v1","updated":"2023-01-19T10:13:52Z","published":"2023-01-19T10:13:52Z","title":"SpotHitPy: A Study For ML-Based Song Hit Prediction Using Spotify","summary":"  In this study, we approached the Hit Song Prediction problem, which aims to\npredict which songs will become Billboard hits. We gathered a dataset of nearly\n18500 hit and non-hit songs and extracted their audio features using the\nSpotify Web API. We test four machine-learning models on our dataset. We were\nable to predict the Billboard success of a song with approximately 86\\%\naccuracy. The most succesful algorithms were Random Forest and Support Vector\nMachine.\n","authors":["Ioannis Dimolitsas","Spyridon Kantarelis","Afroditi Fouka"],"pdf_url":"https://arxiv.org/pdf/2301.07978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07926v2","updated":"2023-01-19T10:05:06Z","published":"2022-09-16T13:39:10Z","title":"Explainability in subgraphs-enhanced Graph Neural Networks","summary":"  Recently, subgraphs-enhanced Graph Neural Networks (SGNNs) have been\nintroduced to enhance the expressive power of Graph Neural Networks (GNNs),\nwhich was proved to be not higher than the 1-dimensional Weisfeiler-Leman\nisomorphism test. The new paradigm suggests using subgraphs extracted from the\ninput graph to improve the model's expressiveness, but the additional\ncomplexity exacerbates an already challenging problem in GNNs: explaining their\npredictions. In this work, we adapt PGExplainer, one of the most recent\nexplainers for GNNs, to SGNNs. The proposed explainer accounts for the\ncontribution of all the different subgraphs and can produce a meaningful\nexplanation that humans can interpret. The experiments that we performed both\non real and synthetic datasets show that our framework is successful in\nexplaining the decision process of an SGNN on graph classification tasks.\n","authors":["Michele Guerra","Indro Spinelli","Simone Scardapane","Filippo Maria Bianchi"],"pdf_url":"https://arxiv.org/pdf/2209.07926v2.pdf","comment":"The source code implementing our workflow is publicly available\n  online at https://github.com/MicheleUIT/Explaining_SGNN"},{"id":"http://arxiv.org/abs/2301.07966v1","updated":"2023-01-19T09:41:35Z","published":"2023-01-19T09:41:35Z","title":"Getting Away with More Network Pruning: From Sparsity to Geometry and\n  Linear Regions","summary":"  One surprising trait of neural networks is the extent to which their\nconnections can be pruned with little to no effect on accuracy. But when we\ncross a critical level of parameter sparsity, pruning any further leads to a\nsudden drop in accuracy. This drop plausibly reflects a loss in model\ncomplexity, which we aim to avoid. In this work, we explore how sparsity also\naffects the geometry of the linear regions defined by a neural network, and\nconsequently reduces the expected maximum number of linear regions based on the\narchitecture. We observe that pruning affects accuracy similarly to how\nsparsity affects the number of linear regions and our proposed bound for the\nmaximum number. Conversely, we find out that selecting the sparsity across\nlayers to maximize our bound very often improves accuracy in comparison to\npruning as much with the same sparsity in all layers, thereby providing us\nguidance on where to prune.\n","authors":["Junyang Cai","Khai-Nguyen Nguyen","Nishant Shrestha","Aidan Good","Ruisen Tu","Xin Yu","Shandian Zhe","Thiago Serra"],"pdf_url":"https://arxiv.org/pdf/2301.07966v1.pdf","comment":"(Under review)"},{"id":"http://arxiv.org/abs/2301.07946v1","updated":"2023-01-19T08:46:59Z","published":"2023-01-19T08:46:59Z","title":"Job recommendations: benchmarking of collaborative filtering methods for\n  classifieds","summary":"  Classifieds provide many challenges for recommendation methods, due to the\nlimited information regarding users and items. In this paper, we explore\nrecommendation methods for classifieds using the example of OLX Jobs.\n  The goal of the paper is to benchmark different recommendation methods for\njobs classifieds in order to improve advertisements' conversion rate and user\nsatisfaction.\n  In our research, we implemented methods that are scalable and represent\ndifferent approaches to recommendation, namely ALS, LightFM, Prod2Vec, RP3beta,\nand SLIM. We performed a laboratory comparison of methods with regard to\naccuracy, diversity, and scalability (memory and time consumption during\ntraining and in prediction). Online A/B tests were also carried out by sending\nmillions of messages with recommendations to evaluate models in a real-world\nsetting.\n  In addition, we have published the dataset that we created for the needs of\nour research. To the best of our knowledge, this is the first dataset of this\nkind. The dataset contains 65,502,201 events performed on OLX Jobs by 3,295,942\nusers, who interacted with (displayed, replied to, or bookmarked) 185,395 job\nads in two weeks of 2020.\n  We demonstrate that RP3beta, SLIM, and ALS perform significantly better than\nProd2Vec and LightFM when tested in a laboratory setting. Online A/B tests also\ndemonstrated that sending messages with recommendations generated by the ALS\nand RP3beta models increases the number of users contacting advertisers.\nAdditionally, RP3beta had a 20% greater impact on this metric than ALS.\n","authors":["Robert Kwieciński","Agata Filipowska","Tomasz Górecki","Viacheslav Dubrov"],"pdf_url":"https://arxiv.org/pdf/2301.07946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07945v1","updated":"2023-01-19T08:42:40Z","published":"2023-01-19T08:42:40Z","title":"PDFormer: Propagation Delay-aware Dynamic Long-range Transformer for\n  Traffic Flow Prediction","summary":"  As a core technology of Intelligent Transportation System, traffic flow\nprediction has a wide range of applications. The fundamental challenge in\ntraffic flow prediction is to effectively model the complex spatial-temporal\ndependencies in traffic data. Spatial-temporal Graph Neural Network (GNN)\nmodels have emerged as one of the most promising methods to solve this problem.\nHowever, GNN-based models have three major limitations for traffic prediction:\ni) Most methods model spatial dependencies in a static manner, which limits the\nability to learn dynamic urban traffic patterns; ii) Most methods only consider\nshort-range spatial information and are unable to capture long-range spatial\ndependencies; iii) These methods ignore the fact that the propagation of\ntraffic conditions between locations has a time delay in traffic systems. To\nthis end, we propose a novel Propagation Delay-aware dynamic long-range\ntransFormer, namely PDFormer, for accurate traffic flow prediction.\nSpecifically, we design a spatial self-attention module to capture the dynamic\nspatial dependencies. Then, two graph masking matrices are introduced to\nhighlight spatial dependencies from short- and long-range views. Moreover, a\ntraffic delay-aware feature transformation module is proposed to empower\nPDFormer with the capability of explicitly modeling the time delay of spatial\ninformation propagation. Extensive experimental results on six real-world\npublic traffic datasets show that our method can not only achieve\nstate-of-the-art performance but also exhibit competitive computational\nefficiency. Moreover, we visualize the learned spatial-temporal attention map\nto make our model highly interpretable.\n","authors":["Jiawei Jiang","Chengkai Han","Wayne Xin Zhao","Jingyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07945v1.pdf","comment":"9 pages, 5 figures, Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2301.07941v1","updated":"2023-01-19T08:23:34Z","published":"2023-01-19T08:23:34Z","title":"CEnt: An Entropy-based Model-agnostic Explainability Framework to\n  Contrast Classifiers' Decisions","summary":"  Current interpretability methods focus on explaining a particular model's\ndecision through present input features. Such methods do not inform the user of\nthe sufficient conditions that alter these decisions when they are not\ndesirable. Contrastive explanations circumvent this problem by providing\nexplanations of the form \"If the feature $X>x$, the output $Y$ would be\ndifferent''. While different approaches are developed to find contrasts; these\nmethods do not all deal with mutability and attainability constraints.\n  In this work, we present a novel approach to locally contrast the prediction\nof any classifier. Our Contrastive Entropy-based explanation method, CEnt,\napproximates a model locally by a decision tree to compute entropy information\nof different feature splits. A graph, G, is then built where contrast nodes are\nfound through a one-to-many shortest path search. Contrastive examples are\ngenerated from the shortest path to reflect feature splits that alter model\ndecisions while maintaining lower entropy. We perform local sampling on\nmanifold-like distances computed by variational auto-encoders to reflect data\ndensity. CEnt is the first non-gradient-based contrastive method generating\ndiverse counterfactuals that do not necessarily exist in the training data\nwhile satisfying immutability (ex. race) and semi-immutability (ex. age can\nonly change in an increasing direction). Empirical evaluation on four\nreal-world numerical datasets demonstrates the ability of CEnt in generating\ncounterfactuals that achieve better proximity rates than existing methods\nwithout compromising latency, feasibility, and attainability. We further extend\nCEnt to imagery data to derive visually appealing and useful contrasts between\nclass labels on MNIST and Fashion MNIST datasets. Finally, we show how CEnt can\nserve as a tool to detect vulnerabilities of textual classifiers.\n","authors":["Julia El Zini","Mohammad Mansour","Mariette Awad"],"pdf_url":"https://arxiv.org/pdf/2301.07941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.06098v3","updated":"2023-01-19T08:21:44Z","published":"2021-08-13T07:16:40Z","title":"FedPara: Low-Rank Hadamard Product for Communication-Efficient Federated\n  Learning","summary":"  In this work, we propose a communication-efficient parameterization, FedPara,\nfor federated learning (FL) to overcome the burdens on frequent model uploads\nand downloads. Our method re-parameterizes weight parameters of layers using\nlow-rank weights followed by the Hadamard product. Compared to the conventional\nlow-rank parameterization, our FedPara method is not restricted to low-rank\nconstraints, and thereby it has a far larger capacity. This property enables to\nachieve comparable performance while requiring 3 to 10 times lower\ncommunication costs than the model with the original layers, which is not\nachievable by the traditional low-rank methods. The efficiency of our method\ncan be further improved by combining with other efficient FL optimizers. In\naddition, we extend our method to a personalized FL application, pFedPara,\nwhich separates parameters into global and local ones. We show that pFedPara\noutperforms competing personalized FL methods with more than three times fewer\nparameters.\n","authors":["Nam Hyeon-Woo","Moon Ye-Bin","Tae-Hyun Oh"],"pdf_url":"https://arxiv.org/pdf/2108.06098v3.pdf","comment":"Accepted at ICLR 2022"},{"id":"http://arxiv.org/abs/2211.09510v3","updated":"2023-01-19T07:56:28Z","published":"2022-11-17T13:14:47Z","title":"Self-supervised Trajectory Representation Learning with Temporal\n  Regularities and Travel Semantics","summary":"  Trajectory Representation Learning (TRL) is a powerful tool for\nspatial-temporal data analysis and management. TRL aims to convert complicated\nraw trajectories into low-dimensional representation vectors, which can be\napplied to various downstream tasks, such as trajectory classification,\nclustering, and similarity computation. Existing TRL works usually treat\ntrajectories as ordinary sequence data, while some important spatial-temporal\ncharacteristics, such as temporal regularities and travel semantics, are not\nfully exploited. To fill this gap, we propose a novel Self-supervised\ntrajectory representation learning framework with TemporAl Regularities and\nTravel semantics, namely START. The proposed method consists of two stages. The\nfirst stage is a Trajectory Pattern-Enhanced Graph Attention Network (TPE-GAT),\nwhich converts the road network features and travel semantics into\nrepresentation vectors of road segments. The second stage is a Time-Aware\nTrajectory Encoder (TAT-Enc), which encodes representation vectors of road\nsegments in the same trajectory as a trajectory representation vector,\nmeanwhile incorporating temporal regularities with the trajectory\nrepresentation. Moreover, we also design two self-supervised tasks, i.e.,\nspan-masked trajectory recovery and trajectory contrastive learning, to\nintroduce spatial-temporal characteristics of trajectories into the training\nprocess of our START framework. The effectiveness of the proposed method is\nverified by extensive experiments on two large-scale real-world datasets for\nthree downstream tasks. The experiments also demonstrate that our method can be\ntransferred across different cities to adapt heterogeneous trajectory datasets.\n","authors":["Jiawei Jiang","Dayan Pan","Houxing Ren","Xiaohan Jiang","Chao Li","Jingyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2211.09510v3.pdf","comment":"13 pages, 10 figures, Accepted by ICDE 2023"},{"id":"http://arxiv.org/abs/2301.07928v1","updated":"2023-01-19T07:34:57Z","published":"2023-01-19T07:34:57Z","title":"Hamiltonian Neural Networks with Automatic Symmetry Detection","summary":"  Recently, Hamiltonian neural networks (HNN) have been introduced to\nincorporate prior physical knowledge when learning the dynamical equations of\nHamiltonian systems. Hereby, the symplectic system structure is preserved\ndespite the data-driven modeling approach. However, preserving symmetries\nrequires additional attention. In this research, we enhance the HNN with a Lie\nalgebra framework to detect and embed symmetries in the neural network. This\napproach allows to simultaneously learn the symmetry group action and the total\nenergy of the system. As illustrating examples, a pendulum on a cart and a\ntwo-body problem from astrodynamics are considered.\n","authors":["Eva Dierkes","Christian Offen","Sina Ober-Blöbaum","Kathrin Flaßkamp"],"pdf_url":"https://arxiv.org/pdf/2301.07928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.07914v2","updated":"2023-01-19T07:11:25Z","published":"2022-08-16T19:23:02Z","title":"PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning\n  Algorithm","summary":"  Multi-objective reinforcement learning (MORL) approaches have emerged to\ntackle many real-world problems with multiple conflicting objectives by\nmaximizing a joint objective function weighted by a preference vector. These\napproaches find fixed customized policies corresponding to preference vectors\nspecified during training. However, the design constraints and objectives\ntypically change dynamically in real-life scenarios. Furthermore, storing a\npolicy for each potential preference is not scalable. Hence, obtaining a set of\nPareto front solutions for the entire preference space in a given domain with a\nsingle training is critical. To this end, we propose a novel MORL algorithm\nthat trains a single universal network to cover the entire preference space\nscalable to continuous robotic tasks. The proposed approach, Preference-Driven\nMORL (PD-MORL), utilizes the preferences as guidance to update the network\nparameters. It also employs a novel parallelization approach to increase sample\nefficiency. We show that PD-MORL achieves up to 25% larger hypervolume for\nchallenging continuous control tasks and uses an order of magnitude fewer\ntrainable parameters compared to prior approaches.\n","authors":["Toygun Basaklar","Suat Gumussoy","Umit Y. Ogras"],"pdf_url":"https://arxiv.org/pdf/2208.07914v2.pdf","comment":"24 pages, 8 Figures, 9 Tables"},{"id":"http://arxiv.org/abs/2301.07912v1","updated":"2023-01-19T06:46:36Z","published":"2023-01-19T06:46:36Z","title":"Interval Reachability of Nonlinear Dynamical Systems with Neural Network\n  Controllers","summary":"  This paper proposes a computationally efficient framework, based on interval\nanalysis, for rigorous verification of nonlinear continuous-time dynamical\nsystems with neural network controllers. Given a neural network, we use an\nexisting verification algorithm to construct inclusion functions for its\ninput-output behavior. Inspired by mixed monotone theory, we embed the\nclosed-loop dynamics into a larger system using an inclusion function of the\nneural network and a decomposition function of the open-loop system. This\nembedding provides a scalable approach for safety analysis of the neural\ncontrol loop while preserving the nonlinear structure of the system.\n  We show that one can efficiently compute hyper-rectangular\nover-approximations of the reachable sets using a single trajectory of the\nembedding system. We design an algorithm to leverage this computational\nadvantage through partitioning strategies, improving our reachable set\nestimates while balancing its runtime with tunable parameters. We demonstrate\nthe performance of this algorithm through two case studies. First, we\ndemonstrate this method's strength in complex nonlinear environments. Then, we\nshow that our approach matches the performance of the state-of-the art\nverification algorithm for linear discretized systems.\n","authors":["Saber Jafarpour","Akash Harapanahalli","Samuel Coogan"],"pdf_url":"https://arxiv.org/pdf/2301.07912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07902v1","updated":"2023-01-19T06:08:01Z","published":"2023-01-19T06:08:01Z","title":"A Nonstochastic Control Approach to Optimization","summary":"  Tuning optimizer hyperparameters, notably the learning rate to a particular\noptimization instance, is an important but nonconvex problem. Therefore\niterative optimization methods such as hypergradient descent lack global\noptimality guarantees in general.\n  We propose an online nonstochastic control methodology for mathematical\noptimization. The choice of hyperparameters for gradient based methods,\nincluding the learning rate, momentum parameter and preconditioner, is\ndescribed as feedback control. The optimal solution to this control problem is\nshown to encompass preconditioned adaptive gradient methods with varying\nacceleration and momentum parameters. Although the optimal control problem by\nitself is nonconvex, we show how recent methods from online nonstochastic\ncontrol based on convex relaxation can be applied to compete with the best\noffline solution. This guarantees that in episodic optimization, we converge to\nthe best optimization method in hindsight.\n","authors":["Xinyi Chen","Elad Hazan"],"pdf_url":"https://arxiv.org/pdf/2301.07902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07882v1","updated":"2023-01-19T05:13:03Z","published":"2023-01-19T05:13:03Z","title":"Understanding the diffusion models by conditional expectations","summary":"  This paper provide several mathematical analyses of the diffusion model in\nmachine learning. The drift term of the backwards sampling process is\nrepresented as a conditional expectation involving the data distribution and\nthe forward diffusion. The training process aims to find such a drift function\nby minimizing the mean-squared residue related to the conditional expectation.\nUsing small-time approximations of the Green's function of the forward\ndiffusion, we show that the analytical mean drift function in DDPM and the\nscore function in SGM asymptotically blow up in the final stages of the\nsampling process for singular data distributions such as those concentrated on\nlower-dimensional manifolds, and is therefore difficult to approximate by a\nnetwork. To overcome this difficulty, we derive a new target function and\nassociated loss, which remains bounded even for singular data distributions. We\nillustrate the theoretical findings with several numerical examples.\n","authors":["Yibin Lu","Zhongjian Wang","Guillaume Bal"],"pdf_url":"https://arxiv.org/pdf/2301.07882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.06491v4","updated":"2023-01-19T04:44:41Z","published":"2022-05-13T07:46:43Z","title":"Tighter Regret Analysis and Optimization of Online Federated Learning","summary":"  In federated learning (FL), it is commonly assumed that all data are placed\nat clients in the beginning of machine learning (ML) optimization (i.e.,\noffline learning). However, in many real-world applications, it is expected to\nproceed in an online fashion. To this end, online FL (OFL) has been introduced,\nwhich aims at learning a sequence of global models from decentralized streaming\ndata such that the so-called cumulative regret is minimized. Combining online\ngradient descent and model averaging, in this framework, FedOGD is constructed\nas the counterpart of FedSGD in FL. While it can enjoy an optimal sublinear\nregret, FedOGD suffers from heavy communication costs. In this paper, we\npresent a communication-efficient method (named OFedIQ) by means of\nintermittent transmission (enabled by client subsampling and periodic\ntransmission) and quantization. For the first time, we derive the regret bound\nthat captures the impact of data-heterogeneity and the communication-efficient\ntechniques. Through this, we efficiently optimize the parameters of OFedIQ such\nas sampling rate, transmission period, and quantization levels. Also, it is\nproved that the optimized OFedIQ can asymptotically achieve the performance of\nFedOGD while reducing the communication costs by 99%. Via experiments with real\ndatasets, we demonstrate the effectiveness of the optimized OFedIQ.\n","authors":["Dohyeok Kwon","Jonghwan Park","Songnam Hong"],"pdf_url":"https://arxiv.org/pdf/2205.06491v4.pdf","comment":"v3. Compared to the previous version, tighter regret analysis and\n  parameter optimization have been included. v4. Add comments"},{"id":"http://arxiv.org/abs/2301.04844v2","updated":"2023-01-19T04:37:38Z","published":"2023-01-12T07:14:47Z","title":"SACDNet: Towards Early Type 2 Diabetes Prediction with Uncertainty for\n  Electronic Health Records","summary":"  Type 2 diabetes mellitus (T2DM) is one of the most common diseases and a\nleading cause of death. The problem of early diagnosis of T2DM is challenging\nand necessary to prevent serious complications. This study proposes a novel\nneural network architecture for early T2DM prediction using multi-headed\nself-attention and dense layers to extract features from historic diagnoses,\npatient vitals, and demographics. The proposed technique is called the\nSelf-Attention for Comorbid Disease Net (SACDNet), achieving an accuracy of\n89.3% and an F1-Score of 89.1%, having a 1.6% increased accuracy and 1.3%\nincreased f1-score compared to the baseline techniques. Monte Carlo (MC)\nDropout is applied to the SACDNet to get a bayesian approximation. A T2DM\nprediction framework based on the MC Dropout SACDNet is proposed to quantize\nthe uncertainty associated with the predictions. A T2DM prediction dataset is\nalso built as part of this study which is based on real-world routine\nElectronic Health Record (EHR) data comprising 4,124 diabetic and 181,767\nnon-diabetic examples, collected from 295 different EHR systems running in\ndifferent parts of the United States of America. This dataset is further used\nto evaluate 7 different machine learning and 3 deep learning-based models.\nFinally, a detailed analysis of the fairness of every technique against\ndifferent patient demographic groups is performed to validate the unbiased\ngeneralization of the techniques and the diversity of the data.\n","authors":["Tayyab Nasir","Muhammad Kamran Malik"],"pdf_url":"https://arxiv.org/pdf/2301.04844v2.pdf","comment":"Misspelled SACEDNet changed to SACDNet in Abstract. Related Work\n  corrected tehcniques to techniques. Dataset rh replaced with Rh. Methodology,\n  mod replaced with models, andrepresentation with representations. Removed\n  bold formatting from Table 3 in Methodology. Results replaced Hence the with\n  Hence, this"},{"id":"http://arxiv.org/abs/2301.07876v1","updated":"2023-01-19T04:33:19Z","published":"2023-01-19T04:33:19Z","title":"Suboptimality analysis of receding horizon quadratic control with\n  unknown linear systems and its applications in learning-based control","summary":"  For a receding-horizon controller with a known system and with an approximate\nterminal value function, it is well-known that increasing the prediction\nhorizon can improve its control performance. However, when the prediction model\nis inexact, a larger prediction horizon also causes propagation and\naccumulation of the prediction error. In this work, we aim to analyze the\neffect of the above trade-off between the modeling error, the terminal value\nfunction error, and the prediction horizon on the performance of a nominal\nreceding-horizon linear quadratic (LQ) controller. By developing a novel\nperturbation result of the Riccati difference equation, a performance upper\nbound is obtained and suggests that for many cases, the prediction horizon\nshould be either 1 or infinity to improve the control performance, depending on\nthe relative difference between the modeling error and the terminal value\nfunction error. The obtained suboptimality performance bound is also applied to\nprovide end-to-end performance guarantees, e.g., regret bounds, for nominal\nreceding-horizon LQ controllers in a learning-based setting.\n","authors":["Shengling Shi","Anastasios Tsiamis","Bart De Schutter"],"pdf_url":"https://arxiv.org/pdf/2301.07876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.01235v2","updated":"2023-01-19T04:22:07Z","published":"2022-04-04T04:50:32Z","title":"An Analysis of Semantically-Aligned Speech-Text Embeddings","summary":"  Embeddings play an important role in end-to-end solutions for multi-modal\nlanguage processing problems. Although there has been some effort to understand\nthe properties of single-modality embedding spaces, particularly that of text,\ntheir cross-modal counterparts are less understood. In this work, we study some\nintrinsic properties of a joint speech-text embedding space, constructed by\nminimizing the distance between paired utterance and transcription inputs in a\nteacher-student model setup, that are informative for several prominent use\ncases. We found that incorporating automatic speech recognition through both\npretraining and multitask scenarios aid semantic alignment significantly,\nresulting in more tightly coupled embeddings. To analyse cross-modal embeddings\nwe utilise a quantitative retrieval accuracy metric for semantic alignment,\nzero-shot classification for generalisability, and probing of the encoders to\nobserve the extent of knowledge transfer from one modality to another.\n","authors":["Muhammad Huzaifah","Ivan Kukanov"],"pdf_url":"https://arxiv.org/pdf/2204.01235v2.pdf","comment":"This is the accepted version of the paper published at IEEE Spoken\n  Language Technology (SLT) Workshop 2022"},{"id":"http://arxiv.org/abs/2211.07447v4","updated":"2023-01-19T03:49:12Z","published":"2022-11-14T15:22:20Z","title":"Neural Regression For Scale-Varying Targets","summary":"  In this work, we demonstrate that a major limitation of regression using a\nmean-squared error loss is its sensitivity to the scale of its targets. This\nmakes learning settings consisting of target's whose values take on varying\nscales challenging. A recently-proposed alternative loss function, known as\nhistogram loss, avoids this issue. However, its computational cost grows\nlinearly with the number of buckets in the histogram, which renders prediction\nwith real-valued targets intractable. To address this issue, we propose a novel\napproach to training deep learning models on real-valued regression targets,\nautoregressive regression, which learns a high-fidelity distribution by\nutilizing an autoregressive target decomposition. We demonstrate that this\ntraining objective allows us to solve regression tasks involving targets with\ndifferent scales.\n","authors":["Adam Khakhar","Jacob Buckman"],"pdf_url":"https://arxiv.org/pdf/2211.07447v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07482v2","updated":"2023-01-19T03:42:13Z","published":"2023-01-18T12:51:13Z","title":"ReFresh: Reducing Memory Access from Exploiting Stable Historical\n  Embeddings for Graph Neural Network Training","summary":"  A key performance bottleneck when training graph neural network (GNN) models\non large, real-world graphs is loading node features onto a GPU. Due to limited\nGPU memory, expensive data movement is necessary to facilitate the storage of\nthese features on alternative devices with slower access (e.g. CPU memory).\nMoreover, the irregularity of graph structures contributes to poor data\nlocality which further exacerbates the problem. Consequently, existing\nframeworks capable of efficiently training large GNN models usually incur a\nsignificant accuracy degradation because of the inevitable shortcuts involved.\nTo address these limitations, we instead propose ReFresh, a general-purpose GNN\nmini-batch training framework that leverages a historical cache for storing and\nreusing GNN node embeddings instead of re-computing them through fetching raw\nfeatures at every iteration. Critical to its success, the corresponding cache\npolicy is designed, using a combination of gradient-based and staleness\ncriteria, to selectively screen those embeddings which are relatively stable\nand can be cached, from those that need to be re-computed to reduce estimation\nerrors and subsequent downstream accuracy loss. When paired with complementary\nsystem enhancements to support this selective historical cache, ReFresh is able\nto accelerate the training speed on large graph datasets such as\nogbn-papers100M and MAG240M by 4.6x up to 23.6x and reduce the memory access by\n64.5% (85.7% higher than a raw feature cache), with less than 1% influence on\ntest accuracy.\n","authors":["Kezhao Huang","Haitian Jiang","Minjie Wang","Guangxuan Xiao","David Wipf","Xiang Song","Quan Gan","Zengfeng Huang","Jidong Zhai","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.07482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12532v2","updated":"2023-01-19T03:31:41Z","published":"2022-06-25T02:15:22Z","title":"Learning to Rank by Causal Effects Without Data to Accurately Estimate\n  Causal Effects","summary":"  Decision makers often want to identify the individuals for whom some\nintervention or treatment will be most effective in order to decide who to\ntreat. In such cases, decision makers would ideally like to rank potential\nrecipients of the treatment according to their individual causal effects.\nHowever, the available data may be completely inadequate to estimate causal\neffects accurately. We formalize a new assumption -- the rank preservation\nassumption (RPA) -- that defines when data are suitable to learn how to rank\nindividuals according to their causal effects, even if the effects themselves\ncannot be accurately estimated. The RPA holds when there is data to estimate a\nscoring variable that induces the same ranking of individuals as the causal\neffect of interest. Some of the scoring variables we consider are confounded\nestimates, proxy causal effects, and non-causal quantities. We show that such\nscoring variables can work well for treatment assignment if the RPA is met, and\npotentially even better than using causal effects as scores. We also show that\nthe RPA holds under conditions that are more general and weaker than the\ntypical assumptions made in observational studies. Finally, we showcase how\npractitioners can apply and evaluate alternative scoring models (including\nnon-causal models) to maximize the causal impact of their targeting decisions.\n","authors":["Carlos Fernández-Loría","Jorge Loría"],"pdf_url":"https://arxiv.org/pdf/2206.12532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05739v2","updated":"2023-01-19T03:21:34Z","published":"2023-01-13T19:34:18Z","title":"Eco-PiNN: A Physics-informed Neural Network for Eco-toll Estimation","summary":"  The eco-toll estimation problem quantifies the expected environmental cost\n(e.g., energy consumption, exhaust emissions) for a vehicle to travel along a\npath. This problem is important for societal applications such as eco-routing,\nwhich aims to find paths with the lowest exhaust emissions or energy need. The\nchallenges of this problem are three-fold: (1) the dependence of a vehicle's\neco-toll on its physical parameters; (2) the lack of access to data with\neco-toll information; and (3) the influence of contextual information (i.e. the\nconnections of adjacent segments in the path) on the eco-toll of road segments.\nPrior work on eco-toll estimation has mostly relied on pure data-driven\napproaches and has high estimation errors given the limited training data. To\naddress these limitations, we propose a novel Eco-toll estimation\nPhysics-informed Neural Network framework (Eco-PiNN) using three novel ideas,\nnamely, (1) a physics-informed decoder that integrates the physical laws of the\nvehicle engine into the network, (2) an attention-based contextual information\nencoder, and (3) a physics-informed regularization to reduce overfitting.\nExperiments on real-world heavy-duty truck data show that the proposed method\ncan greatly improve the accuracy of eco-toll estimation compared with\nstate-of-the-art methods.\n","authors":["Yan Li","Mingzhou Yang","Matthew Eagon","Majid Farhadloo","Yiqun Xie","William F. Northrop","Shashi Shekhar"],"pdf_url":"https://arxiv.org/pdf/2301.05739v2.pdf","comment":"Full version of the paper accepted for the SDM23 conference; Yan Li\n  and Mingzhou Yang contributed equally to this paper"},{"id":"http://arxiv.org/abs/2301.07863v1","updated":"2023-01-19T03:18:54Z","published":"2023-01-19T03:18:54Z","title":"Discover governing differential equations from evolving systems","summary":"  Discovering the governing equations of evolving systems from available\nobservations is essential and challenging. However, current methods does not\ncapture the situation that underlying system dynamics can be changed.Evolving\nsystems are changing over time, which invariably changes with system status.\nThus, finding the exact change points is critical. We propose an online\nmodeling method capable of handling samples one by one sequentially by modeling\nstreaming data instead of processing the entire dataset. The proposed method\nperforms well in discovering ordinary differential equations, partial\ndifferential equations (PDEs), and high-dimensional PDEs from streaming data.\nThe measurement generated from a changed system is distributed dissimilarly to\nbefore; hence, the difference can be identified by the proposed method. Our\nproposal performs well in identifying the change points and discovering\ngoverning differential equations in two evolving systems.\n","authors":["Yuanyuan Li","Kai Wu","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2301.07863v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2112.10572v5","updated":"2023-01-19T03:02:35Z","published":"2021-12-20T14:47:32Z","title":"General Greedy De-bias Learning","summary":"  Neural networks often make predictions relying on the spurious correlations\nfrom the datasets rather than the intrinsic properties of the task of interest,\nfacing sharp degradation on out-of-distribution (OOD) test data. Existing\nde-bias learning frameworks try to capture specific dataset bias by annotations\nbut they fail to handle complicated OOD scenarios. Others implicitly identify\nthe dataset bias by special design low capability biased models or losses, but\nthey degrade when the training and testing data are from the same distribution.\nIn this paper, we propose a General Greedy De-bias learning framework (GGD),\nwhich greedily trains the biased models and the base model. The base model is\nencouraged to focus on examples that are hard to solve with biased models, thus\nremaining robust against spurious correlations in the test stage. GGD largely\nimproves models' OOD generalization ability on various tasks, but sometimes\nover-estimates the bias level and degrades on the in-distribution test. We\nfurther re-analyze the ensemble process of GGD and introduce the Curriculum\nRegularization inspired by curriculum learning, which achieves a good trade-off\nbetween in-distribution and out-of-distribution performance. Extensive\nexperiments on image classification, adversarial question answering, and visual\nquestion answering demonstrate the effectiveness of our method. GGD can learn a\nmore robust base model under the settings of both task-specific biased models\nwith prior knowledge and self-ensemble biased model without prior knowledge.\n","authors":["Xinzhe Han","Shuhui Wang","Chi Su","Qingming Huang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2112.10572v5.pdf","comment":"This work has been accepted by IEEE T-PAMI. Copyright is transferred\n  without notice, after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2203.11572v3","updated":"2023-01-19T02:58:15Z","published":"2022-03-22T09:51:24Z","title":"Fast Multi-view Clustering via Ensembles: Towards Scalability,\n  Superiority, and Simplicity","summary":"  Despite significant progress, there remain three limitations to the previous\nmulti-view clustering algorithms. First, they often suffer from high\ncomputational complexity, restricting their feasibility for large-scale\ndatasets. Second, they typically fuse multi-view information via one-stage\nfusion, neglecting the possibilities in multi-stage fusions. Third,\ndataset-specific hyperparameter-tuning is frequently required, further\nundermining their practicability. In light of this, we propose a fast\nmulti-view clustering via ensembles (FastMICE) approach. Particularly, the\nconcept of random view groups is presented to capture the versatile view-wise\nrelationships, through which the hybrid early-late fusion strategy is designed\nto enable efficient multi-stage fusions. With multiple views extended to many\nview groups, three levels of diversity (w.r.t. features, anchors, and\nneighbors, respectively) are jointly leveraged for constructing the\nview-sharing bipartite graphs in the early-stage fusion. Then, a set of\ndiversified base clusterings for different view groups are obtained via fast\ngraph partitioning, which are further formulated into a unified bipartite graph\nfor final clustering in the late-stage fusion. Notably, FastMICE has almost\nlinear time and space complexity, and is free of dataset-specific tuning.\nExperiments on 22 multi-view datasets demonstrate its advantages in scalability\n(for extremely large datasets), superiority (in clustering performance), and\nsimplicity (to be applied) over the state-of-the-art. Code available:\nhttps://github.com/huangdonghere/FastMICE.\n","authors":["Dong Huang","Chang-Dong Wang","Jian-Huang Lai"],"pdf_url":"https://arxiv.org/pdf/2203.11572v3.pdf","comment":"To appear in IEEE Transactions on Knowledge and Data Engineering"},{"id":"http://arxiv.org/abs/2301.07854v1","updated":"2023-01-19T02:51:47Z","published":"2023-01-19T02:51:47Z","title":"FE-TCM: Filter-Enhanced Transformer Click Model for Web Search","summary":"  Constructing click models and extracting implicit relevance feedback\ninformation from the interaction between users and search engines are very\nimportant to improve the ranking of search results. Using neural network to\nmodel users' click behaviors has become one of the effective methods to\nconstruct click models. In this paper, We use Transformer as the backbone\nnetwork of feature extraction, add filter layer innovatively, and propose a new\nFilter-Enhanced Transformer Click Model (FE-TCM) for web search. Firstly, in\norder to reduce the influence of noise on user behavior data, we use the\nlearnable filters to filter log noise. Secondly, following the examination\nhypothesis, we model the attraction estimator and examination predictor\nrespectively to output the attractiveness scores and examination probabilities.\nA novel transformer model is used to learn the deeper representation among\ndifferent features. Finally, we apply the combination functions to integrate\nattractiveness scores and examination probabilities into the click prediction.\nFrom our experiments on two real-world session datasets, it is proved that\nFE-TCM outperforms the existing click models for the click prediction.\n","authors":["Yingfei Wang","Jianping Liu","Meng Wang","Xintao Chu"],"pdf_url":"https://arxiv.org/pdf/2301.07854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07474v2","updated":"2023-01-19T02:43:05Z","published":"2023-01-18T12:32:51Z","title":"Threats, Vulnerabilities, and Controls of Machine Learning Based\n  Systems: A Survey and Taxonomy","summary":"  In this article, we propose the Artificial Intelligence Security Taxonomy to\nsystematize the knowledge of threats, vulnerabilities, and security controls of\nmachine-learning-based (ML-based) systems. We first classify the damage caused\nby attacks against ML-based systems, define ML-specific security, and discuss\nits characteristics. Next, we enumerate all relevant assets and stakeholders\nand provide a general taxonomy for ML-specific threats. Then, we collect a wide\nrange of security controls against ML-specific threats through an extensive\nreview of recent literature. Finally, we classify the vulnerabilities and\ncontrols of an ML-based system in terms of each vulnerable asset in the\nsystem's entire lifecycle.\n","authors":["Yusuke Kawamoto","Kazumasa Miyake","Koichi Konishi","Yutaka Oiwa"],"pdf_url":"https://arxiv.org/pdf/2301.07474v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07851v1","updated":"2023-01-19T02:37:56Z","published":"2023-01-19T02:37:56Z","title":"From English to More Languages: Parameter-Efficient Model Reprogramming\n  for Cross-Lingual Speech Recognition","summary":"  In this work, we propose a new parameter-efficient learning framework based\non neural model reprogramming for cross-lingual speech recognition, which can\n\\textbf{re-purpose} well-trained English automatic speech recognition (ASR)\nmodels to recognize the other languages. We design different auxiliary neural\narchitectures focusing on learnable pre-trained feature enhancement that, for\nthe first time, empowers model reprogramming on ASR. Specifically, we\ninvestigate how to select trainable components (i.e., encoder) of a\nconformer-based RNN-Transducer, as a frozen pre-trained backbone. Experiments\non a seven-language multilingual LibriSpeech speech (MLS) task show that model\nreprogramming only requires 4.2% (11M out of 270M) to 6.8% (45M out of 660M) of\nits original trainable parameters from a full ASR model to perform competitive\nresults in a range of 11.9% to 8.1% WER averaged across different languages. In\naddition, we discover different setups to make large-scale pre-trained ASR\nsucceed in both monolingual and multilingual speech recognition. Our methods\noutperform existing ASR tuning architectures and their extension with\nself-supervised losses (e.g., w2v-bert) in terms of lower WER and better\ntraining efficiency.\n","authors":["Chao-Han Huck Yang","Bo Li","Yu Zhang","Nanxin Chen","Rohit Prabhavalkar","Tara N. Sainath","Trevor Strohman"],"pdf_url":"https://arxiv.org/pdf/2301.07851v1.pdf","comment":"Submitted to ICASSP 2023. The project was initiated in May 2022\n  during a research internship at Google Research"},{"id":"http://arxiv.org/abs/2301.07850v1","updated":"2023-01-19T02:33:58Z","published":"2023-01-19T02:33:58Z","title":"Concept Discovery for Fast Adapatation","summary":"  The advances in deep learning have enabled machine learning methods to\noutperform human beings in various areas, but it remains a great challenge for\na well-trained model to quickly adapt to a new task. One promising solution to\nrealize this goal is through meta-learning, also known as learning to learn,\nwhich has achieved promising results in few-shot learning. However, current\napproaches are still enormously different from human beings' learning process,\nespecially in the ability to extract structural and transferable knowledge.\nThis drawback makes current meta-learning frameworks non-interpretable and hard\nto extend to more complex tasks. We tackle this problem by introducing concept\ndiscovery to the few-shot learning problem, where we achieve more effective\nadaptation by meta-learning the structure among the data features, leading to a\ncomposite representation of the data. Our proposed method Concept-Based\nModel-Agnostic Meta-Learning (COMAML) has been shown to achieve consistent\nimprovements in the structured data for both synthesized datasets and\nreal-world datasets.\n","authors":["Shengyu Feng","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2301.07850v1.pdf","comment":"SDM23"},{"id":"http://arxiv.org/abs/2301.07846v1","updated":"2023-01-19T01:54:48Z","published":"2023-01-19T01:54:48Z","title":"ClusterLog: Clustering Logs for Effective Log-based Anomaly Detection","summary":"  With the increasing prevalence of scalable file systems in the context of\nHigh Performance Computing (HPC), the importance of accurate anomaly detection\non runtime logs is increasing. But as it currently stands, many\nstate-of-the-art methods for log-based anomaly detection, such as DeepLog, have\nencountered numerous challenges when applied to logs from many parallel file\nsystems (PFSes), often due to their irregularity and ambiguity in time-based\nlog sequences. To circumvent these problems, this study proposes ClusterLog, a\nlog pre-processing method that clusters the temporal sequence of log keys based\non their semantic similarity. By grouping semantically and sentimentally\nsimilar logs, this approach aims to represent log sequences with the smallest\namount of unique log keys, intending to improve the ability of a downstream\nsequence-based model to effectively learn the log patterns. The preliminary\nresults of ClusterLog indicate not only its effectiveness in reducing the\ngranularity of log sequences without the loss of important sequence information\nbut also its generalizability to different file systems' logs.\n","authors":["Chris Egersdoerfer","Dong Dai","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.07846v1.pdf","comment":"Accepted in 12th Workshop on Fault-Tolerance for HPC at Extreme Scale\n  at SC22"},{"id":"http://arxiv.org/abs/2301.07843v1","updated":"2023-01-19T01:39:21Z","published":"2023-01-19T01:39:21Z","title":"Spatio-temporal neural structural causal models for bike flow prediction","summary":"  As a representative of public transportation, the fundamental issue of\nmanaging bike-sharing systems is bike flow prediction. Recent methods\noveremphasize the spatio-temporal correlations in the data, ignoring the\neffects of contextual conditions on the transportation system and the\ninter-regional timevarying causality. In addition, due to the disturbance of\nincomplete observations in the data, random contextual conditions lead to\nspurious correlations between data and features, making the prediction of the\nmodel ineffective in special scenarios. To overcome this issue, we propose a\nSpatio-temporal Neural Structure Causal Model(STNSCM) from the perspective of\ncausality. First, we build a causal graph to describe the traffic prediction,\nand further analyze the causal relationship between the input data, contextual\nconditions, spatiotemporal states, and prediction results. Second, we propose\nto apply the frontdoor criterion to eliminate confounding biases in the feature\nextraction process. Finally, we propose a counterfactual representation\nreasoning module to extrapolate the spatio-temporal state under the factual\nscenario to future counterfactual scenarios to improve the prediction\nperformance. Experiments on real-world datasets demonstrate the superior\nperformance of our model, especially its resistance to fluctuations caused by\nthe external environment. The source code and data will be released.\n","authors":["Pan Deng","Yu Zhao","Junting Liu","Xiaofeng Jia","Mulan Wang"],"pdf_url":"https://arxiv.org/pdf/2301.07843v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2202.08871v2","updated":"2023-01-19T01:26:16Z","published":"2022-02-17T19:14:17Z","title":"Graph Data Augmentation for Graph Machine Learning: A Survey","summary":"  Data augmentation has recently seen increased interest in graph machine\nlearning given its demonstrated ability to improve model performance and\ngeneralization by added training data. Despite this recent surge, the area is\nstill relatively under-explored, due to the challenges brought by complex,\nnon-Euclidean structure of graph data, which limits the direct analogizing of\ntraditional augmentation operations on other types of image, video or text\ndata. Our work aims to give a necessary and timely overview of existing graph\ndata augmentation methods; notably, we present a comprehensive and systematic\nsurvey of graph data augmentation approaches, summarizing the literature in a\nstructured manner. We first introduce three different taxonomies for\ncategorizing graph data augmentation methods from the data, task, and learning\nperspectives, respectively. Next, we introduce recent advances in graph data\naugmentation, differentiated by their methodologies and applications. We\nconclude by outlining currently unsolved challenges and directions for future\nresearch. Overall, our work aims to clarify the landscape of existing\nliterature in graph data augmentation and motivates additional work in this\narea, providing a helpful resource for researchers and practitioners in the\nbroader graph machine learning domain. Additionally, we provide a continuously\nupdated reading list at\nhttps://github.com/zhao-tong/graph-data-augmentation-papers.\n","authors":["Tong Zhao","Wei Jin","Yozen Liu","Yingheng Wang","Gang Liu","Stephan Günnemann","Neil Shah","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2202.08871v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13213v4","updated":"2023-01-19T01:12:54Z","published":"2022-05-26T08:16:14Z","title":"Fast Vision Transformers with HiLo Attention","summary":"  Vision Transformers (ViTs) have triggered the most recent and significant\nbreakthroughs in computer vision. Their efficient designs are mostly guided by\nthe indirect metric of computational complexity, i.e., FLOPs, which however has\na clear gap with the direct metric such as throughput. Thus, we propose to use\nthe direct speed evaluation on the target platform as the design principle for\nefficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT\nwhich performs favourably against the existing state-of-the-art methods across\na spectrum of different model sizes with faster speed. At the core of LITv2 is\na novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the\ninsight that high frequencies in an image capture local fine details and low\nfrequencies focus on global structures, whereas a multi-head self-attention\nlayer neglects the characteristic of different frequencies. Therefore, we\npropose to disentangle the high/low frequency patterns in an attention layer by\nseparating the heads into two groups, where one group encodes high frequencies\nvia self-attention within each local window, and another group encodes low\nfrequencies by performing global attention between the average-pooled\nlow-frequency keys and values from each window and each query position in the\ninput feature map. Benefiting from the efficient design for both groups, we\nshow that HiLo is superior to the existing attention mechanisms by\ncomprehensively benchmarking FLOPs, speed and memory consumption on GPUs and\nCPUs. For example, HiLo is 1.4x faster than spatial reduction attention and\n1.6x faster than local window attention on CPUs. Powered by HiLo, LITv2 serves\nas a strong backbone for mainstream vision tasks including image\nclassification, dense detection and segmentation. Code is available at\nhttps://github.com/ziplab/LITv2.\n","authors":["Zizheng Pan","Jianfei Cai","Bohan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2205.13213v4.pdf","comment":"NeurIPS 2022 camera ready"},{"id":"http://arxiv.org/abs/2211.03627v3","updated":"2023-01-19T00:23:56Z","published":"2022-11-07T15:34:07Z","title":"A Deep Double Ritz Method (D$^2$RM) for solving Partial Differential\n  Equations using Neural Networks","summary":"  Residual minimization is a widely used technique for solving Partial\nDifferential Equations in variational form. It minimizes the dual norm of the\nresidual, which naturally yields a saddle-point (min-max) problem over the\nso-called trial and test spaces. In the context of neural networks, we can\naddress this min-max approach by employing one network to seek the trial\nminimum, while another network seeks the test maximizers. However, the\nresulting method is numerically unstable as we approach the trial solution. To\novercome this, we reformulate the residual minimization as an equivalent\nminimization of a Ritz functional fed by optimal test functions computed from\nanother Ritz functional minimization. We call the resulting scheme the Deep\nDouble Ritz Method (D$^2$RM), which combines two neural networks for\napproximating trial functions and optimal test functions along a nested double\nRitz minimization strategy. Numerical results on different diffusion and\nconvection problems support the robustness of our method, up to the\napproximation properties of the networks and the training capacity of the\noptimizers.\n","authors":["Carlos Uriarte","David Pardo","Ignacio Muga","Judit Muñoz-Matute"],"pdf_url":"https://arxiv.org/pdf/2211.03627v3.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2205.14375v3","updated":"2023-01-19T00:05:12Z","published":"2022-05-28T09:08:50Z","title":"WaveMix: A Resource-efficient Neural Network for Image Analysis","summary":"  To allow image analysis in resource-constrained scenarios without\ncompromising generalizability, we introduce WaveMix -- a novel and flexible\nneural framework that reduces the GPU RAM (memory) and compute (latency)\ncompared to CNNs and transformers. In addition to using convolutional layers\nthat exploit shift-invariant image statistics, the proposed framework uses\nmulti-level two-dimensional discrete wavelet transform (2D-DWT) modules to\nexploit scale-invariance and edge sparseness, which gives it the following\nadvantages. Firstly, the fixed weights of wavelet modules do not add to the\nparameter count while reorganizing information based on these image priors.\nSecondly, the wavelet modules scale the spatial extents of feature maps by\nintegral powers of $\\frac{1}{2}\\times\\frac{1}{2}$, which reduces the memory and\nlatency required for forward and backward passes. Finally, a multi-level 2D-DWT\nleads to a quicker expansion of the receptive field per layer than pooling\n(which we do not use) and it is a more effective spatial token mixer. WaveMix\nalso generalizes better than other token mixing models, such as ConvMixer,\nMLP-Mixer, PoolFormer, random filters, and Fourier basis, because the wavelet\ntransform is much better suited for image decomposition and spatial token\nmixing. WaveMix is a flexible model that can perform well on multiple image\ntasks without needing architectural modifications. WaveMix achieves a semantic\nsegmentation mIoU of 83% on the Cityscapes validation set outperforming\ntransformer and CNN-based architectures. We also demonstrate the advantages of\nWaveMix for classification on multiple datasets and show that WaveMix\nestablishes new state-of-the-results in Places-365, EMNIST, and iNAT-mini\ndatasets.\n","authors":["Pranav Jeevan","Kavitha Viswanathan","Anandu A S","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2205.14375v3.pdf","comment":"18 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2203.03689"},{"id":"http://arxiv.org/abs/2301.08360v1","updated":"2023-01-19T23:36:23Z","published":"2023-01-19T23:36:23Z","title":"Deep Reinforcement Learning for Power Trading","summary":"  The Dutch power market includes a day-ahead market and an auction-like\nintraday balancing market. The varying supply and demand of power and its\nuncertainty induces an imbalance, which causes differing power prices in these\ntwo markets and creates an opportunity for arbitrage. In this paper, we present\ncollaborative dual-agent reinforcement learning (RL) for bi-level simulation\nand optimization of European power arbitrage trading. Moreover, we propose two\nnovel practical implementations specifically addressing the electricity power\nmarket. Leveraging the concept of imitation learning, the RL agent's reward is\nreformed by taking into account prior domain knowledge results in better\nconvergence during training and, moreover, improves and generalizes\nperformance. In addition, tranching of orders improves the bidding success rate\nand significantly raises the P&L. We show that each method contributes\nsignificantly to the overall performance uplifting, and the integrated\nmethodology achieves about three-fold improvement in cumulative P&L over the\noriginal agent, as well as outperforms the highest benchmark policy by around\n50% while exhibits efficient computational performance.\n","authors":["Yuanrong Wang","Vignesh Raja Swaminathan","Nikita P. Granger","Carlos Ros Perez","Christian Michler"],"pdf_url":"https://arxiv.org/pdf/2301.08360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.05668v6","updated":"2023-01-19T23:17:16Z","published":"2021-10-12T01:13:18Z","title":"NAS-Bench-360: Benchmarking Neural Architecture Search on Diverse Tasks","summary":"  Most existing neural architecture search (NAS) benchmarks and algorithms\nprioritize well-studied tasks, e.g. image classification on CIFAR or ImageNet.\nThis makes the performance of NAS approaches in more diverse areas poorly\nunderstood. In this paper, we present NAS-Bench-360, a benchmark suite to\nevaluate methods on domains beyond those traditionally studied in architecture\nsearch, and use it to address the following question: do state-of-the-art NAS\nmethods perform well on diverse tasks? To construct the benchmark, we curate\nten tasks spanning a diverse array of application domains, dataset sizes,\nproblem dimensionalities, and learning objectives. Each task is carefully\nchosen to interoperate with modern CNN-based search methods while possibly\nbeing far-afield from its original development domain. To speed up and reduce\nthe cost of NAS research, for two of the tasks we release the precomputed\nperformance of 15,625 architectures comprising a standard CNN search space.\nExperimentally, we show the need for more robust NAS evaluation of the kind\nNAS-Bench-360 enables by showing that several modern NAS procedures perform\ninconsistently across the ten tasks, with many catastrophically poor results.\nWe also demonstrate how NAS-Bench-360 and its associated precomputed results\nwill enable future scientific discoveries by testing whether several recent\nhypotheses promoted in the NAS literature hold on diverse tasks. NAS-Bench-360\nis hosted at https://nb360.ml.cmu.edu.\n","authors":["Renbo Tu","Nicholas Roberts","Mikhail Khodak","Junhong Shen","Frederic Sala","Ameet Talwalkar"],"pdf_url":"https://arxiv.org/pdf/2110.05668v6.pdf","comment":"NeurIPS 2022 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2011.00136v2","updated":"2023-01-19T23:16:34Z","published":"2020-10-30T23:04:56Z","title":"Improving Dialogue Breakdown Detection with Semi-Supervised Learning","summary":"  Building user trust in dialogue agents requires smooth and consistent\ndialogue exchanges. However, agents can easily lose conversational context and\ngenerate irrelevant utterances. These situations are called dialogue breakdown,\nwhere agent utterances prevent users from continuing the conversation. Building\nsystems to detect dialogue breakdown allows agents to recover appropriately or\navoid breakdown entirely. In this paper we investigate the use of\nsemi-supervised learning methods to improve dialogue breakdown detection,\nincluding continued pre-training on the Reddit dataset and a manifold-based\ndata augmentation method. We demonstrate the effectiveness of these methods on\nthe Dialogue Breakdown Detection Challenge (DBDC) English shared task. Our\nsubmissions to the 2020 DBDC5 shared task place first, beating baselines and\nother submissions by over 12\\% accuracy. In ablations on DBDC4 data from 2019,\nour semi-supervised learning methods improve the performance of a baseline BERT\nmodel by 2\\% accuracy. These methods are applicable generally to any dialogue\ntask and provide a simple way to improve model performance.\n","authors":["Nathan Ng","Marzyeh Ghassemi","Narendran Thangarajan","Jiacheng Pan","Qi Guo"],"pdf_url":"https://arxiv.org/pdf/2011.00136v2.pdf","comment":"6 pages, 1 figure, accepted at the NeurIPS Workshop on Human in the\n  Loop Dialogue Systems"},{"id":"http://arxiv.org/abs/2212.02376v4","updated":"2023-01-19T22:46:09Z","published":"2022-12-05T15:58:00Z","title":"DIAMOND: Taming Sample and Communication Complexities in Decentralized\n  Bilevel Optimization","summary":"  Decentralized bilevel optimization has received increasing attention recently\ndue to its foundational role in many emerging multi-agent learning paradigms\n(e.g., multi-agent meta-learning and multi-agent reinforcement learning) over\npeer-to-peer edge networks. However, to work with the limited computation and\ncommunication capabilities of edge networks, a major challenge in developing\ndecentralized bilevel optimization techniques is to lower sample and\ncommunication complexities. This motivates us to develop a new decentralized\nbilevel optimization called DIAMOND (decentralized single-timescale stochastic\napproximation with momentum and gradient-tracking). The contributions of this\npaper are as follows: i) our DIAMOND algorithm adopts a single-loop structure\nrather than following the natural double-loop structure of bilevel\noptimization, which offers low computation and implementation complexity; ii)\ncompared to existing approaches, the DIAMOND algorithm does not require any\nfull gradient evaluations, which further reduces both sample and computational\ncomplexities; iii) through a careful integration of momentum information and\ngradient tracking techniques, we show that the DIAMOND algorithm enjoys\n$\\mathcal{O}(\\epsilon^{-3/2})$ in sample and communication complexities for\nachieving an $\\epsilon$-stationary solution, both of which are independent of\nthe dataset sizes and significantly outperform existing works. Extensive\nexperiments also verify our theoretical findings.\n","authors":["Peiwen Qiu","Yining Li","Zhuqing Liu","Prashant Khanduri","Jia Liu","Ness B. Shroff","Elizabeth Serena Bentley","Kurt Turck"],"pdf_url":"https://arxiv.org/pdf/2212.02376v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.13361v2","updated":"2023-01-19T22:20:49Z","published":"2021-10-26T02:29:10Z","title":"A Metalearning Approach for Physics-Informed Neural Networks (PINNs):\n  Application to Parameterized PDEs","summary":"  Physics-informed neural networks (PINNs) as a means of discretizing partial\ndifferential equations (PDEs) are garnering much attention in the Computational\nScience and Engineering (CS&E) world. At least two challenges exist for PINNs\nat present: an understanding of accuracy and convergence characteristics with\nrespect to tunable parameters and identification of optimization strategies\nthat make PINNs as efficient as other computational science tools. The cost of\nPINNs training remains a major challenge of Physics-informed Machine Learning\n(PiML) - and, in fact, machine learning (ML) in general. This paper is meant to\nmove towards addressing the latter through the study of PINNs on new tasks, for\nwhich parameterized PDEs provides a good testbed application as tasks can be\neasily defined in this context. Following the ML world, we introduce\nmetalearning of PINNs with application to parameterized PDEs. By introducing\nmetalearning and transfer learning concepts, we can greatly accelerate the\nPINNs optimization process. We present a survey of model-agnostic metalearning,\nand then discuss our model-aware metalearning applied to PINNs as well as\nimplementation considerations and algorithmic complexity. We then test our\napproach on various canonical forward parameterized PDEs that have been\npresented in the emerging PINNs literature.\n","authors":["Michael Penwarden","Shandian Zhe","Akil Narayan","Robert M. Kirby"],"pdf_url":"https://arxiv.org/pdf/2110.13361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08325v1","updated":"2023-01-19T21:31:23Z","published":"2023-01-19T21:31:23Z","title":"Advanced Scaling Methods for VNF deployment with Reinforcement Learning","summary":"  Network function virtualization (NFV) and software-defined network (SDN) have\nbecome emerging network paradigms, allowing virtualized network function (VNF)\ndeployment at a low cost. Even though VNF deployment can be flexible, it is\nstill challenging to optimize VNF deployment due to its high complexity.\nSeveral studies have approached the task as dynamic programming, e.g., integer\nlinear programming (ILP). However, optimizing VNF deployment for highly complex\nnetworks remains a challenge. Alternatively, reinforcement learning (RL) based\napproaches have been proposed to optimize this task, especially to employ a\nscaling action-based method which can deploy VNFs within less computational\ntime. However, the model architecture can be improved further to generalize to\nthe different networking settings. In this paper, we propose an enhanced model\nwhich can be adapted to more general network settings. We adopt the improved\nGNN architecture and a few techniques to obtain a better node representation\nfor the VNF deployment task. Furthermore, we apply a recently proposed RL\nmethod, phasic policy gradient (PPG), to leverage the shared representation of\nthe service function chain (SFC) generation model from the value function. We\nevaluate the proposed method in various scenarios, achieving a better QoS with\nminimum resource utilization compared to the previous methods. Finally, as a\nqualitative evaluation, we analyze our proposed encoder's representation for\nthe nodes, which shows a more disentangled representation.\n","authors":["Namjin Seo","DongNyeong Heo","Heeyoul Choi"],"pdf_url":"https://arxiv.org/pdf/2301.08325v1.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2208.02194v2","updated":"2023-01-19T21:11:10Z","published":"2022-08-03T16:27:29Z","title":"Interpretable bilinear attention network with domain adaptation improves\n  drug-target prediction","summary":"  Predicting drug-target interaction is key for drug discovery. Recent deep\nlearning-based methods show promising performance but two challenges remain:\n(i) how to explicitly model and learn local interactions between drugs and\ntargets for better prediction and interpretation; (ii) how to generalize\nprediction performance on novel drug-target pairs from different distribution.\nIn this work, we propose DrugBAN, a deep bilinear attention network (BAN)\nframework with domain adaptation to explicitly learn pair-wise local\ninteractions between drugs and targets, and adapt on out-of-distribution data.\nDrugBAN works on drug molecular graphs and target protein sequences to perform\nprediction, with conditional domain adversarial learning to align learned\ninteraction representations across different distributions for better\ngeneralization on novel drug-target pairs. Experiments on three benchmark\ndatasets under both in-domain and cross-domain settings show that DrugBAN\nachieves the best overall performance against five state-of-the-art baselines.\nMoreover, visualizing the learned bilinear attention map provides interpretable\ninsights from prediction results.\n","authors":["Peizhen Bai","Filip Miljković","Bino John","Haiping Lu"],"pdf_url":"https://arxiv.org/pdf/2208.02194v2.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2301.07187v2","updated":"2023-01-19T21:08:49Z","published":"2023-01-17T20:52:48Z","title":"Artificial Neuronal Ensembles with Learned Context Dependent Gating","summary":"  Biological neural networks are capable of recruiting different sets of\nneurons to encode different memories. However, when training artificial neural\nnetworks on a set of tasks, typically, no mechanism is employed for selectively\nproducing anything analogous to these neuronal ensembles. Further, artificial\nneural networks suffer from catastrophic forgetting, where the network's\nperformance rapidly deteriorates as tasks are learned sequentially. By\ncontrast, sequential learning is possible for a range of biological organisms.\nWe introduce Learned Context Dependent Gating (LXDG), a method to flexibly\nallocate and recall `artificial neuronal ensembles', using a particular network\nstructure and a new set of regularization terms. Activities in the hidden\nlayers of the network are modulated by gates, which are dynamically produced\nduring training. The gates are outputs of networks themselves, trained with a\nsigmoid output activation. The regularization terms we have introduced\ncorrespond to properties exhibited by biological neuronal ensembles. The first\nterm penalizes low gate sparsity, ensuring that only a specified fraction of\nthe network is used. The second term ensures that previously learned gates are\nrecalled when the network is presented with input from previously learned\ntasks. Finally, there is a regularization term responsible for ensuring that\nnew tasks are encoded in gates that are as orthogonal as possible from\npreviously used ones. We demonstrate the ability of this method to alleviate\ncatastrophic forgetting on continual learning benchmarks. When the new\nregularization terms are included in the model along with Elastic Weight\nConsolidation (EWC) it achieves better performance on the benchmark `permuted\nMNIST' than with EWC alone. The benchmark `rotated MNIST' demonstrates how\nsimilar tasks recruit similar neurons to the artificial neuronal ensemble.\n","authors":["Matthew J. Tilley","Michelle Miller","David J. Freedman"],"pdf_url":"https://arxiv.org/pdf/2301.07187v2.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/1910.05534v4","updated":"2023-01-19T20:59:02Z","published":"2019-10-12T09:13:26Z","title":"Spectral embedding of weighted graphs","summary":"  When analyzing weighted networks using spectral embedding, a judicious\ntransformation of the edge weights may produce better results. To formalize\nthis idea, we consider the asymptotic behavior of spectral embedding for\ndifferent edge-weight representations, under a generic low rank model. We\nmeasure the quality of different embeddings -- which can be on entirely\ndifferent scales -- by how easy it is to distinguish communities, in an\ninformation-theoretic sense. For common types of weighted graphs, such as count\nnetworks or p-value networks, we find that transformations such as tempering or\nthresholding can be highly beneficial, both in theory and in practice.\n","authors":["Ian Gallagher","Andrew Jones","Anna Bertiger","Carey Priebe","Patrick Rubin-Delanchy"],"pdf_url":"https://arxiv.org/pdf/1910.05534v4.pdf","comment":"27 pages, 5 figures"},{"id":"http://arxiv.org/abs/2105.15186v3","updated":"2023-01-19T20:26:26Z","published":"2021-05-31T17:51:15Z","title":"Fast Policy Extragradient Methods for Competitive Games with Entropy\n  Regularization","summary":"  This paper investigates the problem of computing the equilibrium of\ncompetitive games, which is often modeled as a constrained saddle-point\noptimization problem with probability simplex constraints. Despite recent\nefforts in understanding the last-iterate convergence of extragradient methods\nin the unconstrained setting, the theoretical underpinnings of these methods in\nthe constrained settings, especially those using multiplicative updates, remain\nhighly inadequate, even when the objective function is bilinear. Motivated by\nthe algorithmic role of entropy regularization in single-agent reinforcement\nlearning and game theory, we develop provably efficient extragradient methods\nto find the quantal response equilibrium (QRE) -- which are solutions to\nzero-sum two-player matrix games with entropy regularization -- at a linear\nrate. The proposed algorithms can be implemented in a decentralized manner,\nwhere each player executes symmetric and multiplicative updates iteratively\nusing its own payoff without observing the opponent's actions directly. In\naddition, by controlling the knob of entropy regularization, the proposed\nalgorithms can locate an approximate Nash equilibrium of the unregularized\nmatrix game at a sublinear rate without assuming the Nash equilibrium to be\nunique. Our methods also lead to efficient policy extragradient algorithms for\nsolving (entropy-regularized) zero-sum Markov games at similar rates. All of\nour convergence rates are nearly dimension-free, which are independent of the\nsize of the state and action spaces up to logarithm factors, highlighting the\npositive role of entropy regularization for accelerating convergence.\n","authors":["Shicong Cen","Yuting Wei","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2105.15186v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08292v1","updated":"2023-01-19T20:06:48Z","published":"2023-01-19T20:06:48Z","title":"Quantum HyperNetworks: Training Binary Neural Networks in Quantum\n  Superposition","summary":"  Binary neural networks, i.e., neural networks whose parameters and\nactivations are constrained to only two possible values, offer a compelling\navenue for the deployment of deep learning models on energy- and memory-limited\ndevices. However, their training, architectural design, and hyperparameter\ntuning remain challenging as these involve multiple computationally expensive\ncombinatorial optimization problems. Here we introduce quantum hypernetworks as\na mechanism to train binary neural networks on quantum computers, which unify\nthe search over parameters, hyperparameters, and architectures in a single\noptimization loop. Through classical simulations, we demonstrate that of our\napproach effectively finds optimal parameters, hyperparameters and\narchitectural choices with high probability on classification problems\nincluding a two-dimensional Gaussian dataset and a scaled-down version of the\nMNIST handwritten digits. We represent our quantum hypernetworks as variational\nquantum circuits, and find that an optimal circuit depth maximizes the\nprobability of finding performant binary neural networks. Our unified approach\nprovides an immense scope for other applications in the field of machine\nlearning.\n","authors":["Juan Carrasquilla","Mohamed Hibat-Allah","Estelle Inack","Alireza Makhzani","Kirill Neklyudov","Graham W. Taylor","Giacomo Torlai"],"pdf_url":"https://arxiv.org/pdf/2301.08292v1.pdf","comment":"10 pages, 6 figures. Minimal implementation:\n  https://github.com/carrasqu/binncode"},{"id":"http://arxiv.org/abs/2301.08290v1","updated":"2023-01-19T20:04:36Z","published":"2023-01-19T20:04:36Z","title":"Forecasting subcritical cylinder wakes with Fourier Neural Operators","summary":"  We apply Fourier neural operators (FNOs), a state-of-the-art operator\nlearning technique, to forecast the temporal evolution of experimentally\nmeasured velocity fields. FNOs are a recently developed machine learning method\ncapable of approximating solution operators to systems of partial differential\nequations through data alone. The learned FNO solution operator can be\nevaluated in milliseconds, potentially enabling faster-than-real-time modeling\nfor predictive flow control in physical systems. Here we use FNOs to predict\nhow physical fluid flows evolve in time, training with particle image\nvelocimetry measurements depicting cylinder wakes in the subcritical vortex\nshedding regime. We train separate FNOs at Reynolds numbers ranging from Re =\n240 to Re = 3060 and study how increasingly turbulent flow phenomena impact\nprediction accuracy. We focus here on a short prediction horizon of ten\nnon-dimensionalized time-steps, as would be relevant for problems of predictive\nflow control. We find that FNOs are capable of accurately predicting the\nevolution of experimental velocity fields throughout the range of Reynolds\nnumbers tested (L2 norm error < 0.1) despite being provided with limited and\nimperfect flow observations. Given these results, we conclude that this method\nholds significant potential for real-time predictive flow control of physical\nsystems.\n","authors":["Peter I Renn","Cong Wang","Sahin Lale","Zongyi Li","Anima Anandkumar","Morteza Gharib"],"pdf_url":"https://arxiv.org/pdf/2301.08290v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2203.15925v2","updated":"2023-01-19T19:49:47Z","published":"2022-03-29T22:02:28Z","title":"Asynchronous, Option-Based Multi-Agent Policy Gradient: A Conditional\n  Reasoning Approach","summary":"  Multi-agent policy gradient methods have demonstrated success in games and\nrobotics but are often limited to problems with low-level action space.\nHowever, when agents take higher-level, temporally-extended actions (i.e.\noptions), when and how to derive a centralized control policy, its gradient as\nwell as sampling options for all agents while not interrupting current option\nexecutions, becomes a challenge. This is mostly because agents may choose and\nterminate their options \\textit{asynchronously}. In this work, we propose a\nconditional reasoning approach to address this problem, and empirically\nvalidate its effectiveness on representative option-based multi-agent\ncooperative tasks.\n","authors":["Xubo Lyu","Amin Banitalebi-Dehkordi","Mo Chen","Yong Zhang"],"pdf_url":"https://arxiv.org/pdf/2203.15925v2.pdf","comment":"Submitted to ICRA2023"},{"id":"http://arxiv.org/abs/2301.08278v1","updated":"2023-01-19T19:33:54Z","published":"2023-01-19T19:33:54Z","title":"Investigating the Impact of Direct Punishment on the Emergence of\n  Cooperation in Multi-Agent Reinforcement Learning Systems","summary":"  The problem of cooperation is of fundamental importance for human societies,\nwith examples ranging from navigating road junctions to negotiating climate\ntreaties. As the use of AI becomes more pervasive within society, the need for\nsocially intelligent agents that are able to navigate these complex dilemmas is\nbecoming increasingly evident. Direct punishment is an ubiquitous social\nmechanism that has been shown to benefit the emergence of cooperation within\nthe natural world, however no prior work has investigated its impact on\npopulations of learning agents. Moreover, although the use of all forms of\npunishment in the natural world is strongly coupled with partner selection and\nreputation, no existing work has provided a holistic analysis of their\ncombination within multi-agent systems. In this paper, we present a\ncomprehensive analysis of the behaviors and learning dynamics associated with\ndirect punishment in multi-agent reinforcement learning systems and how this\ncompares to third-party punishment, when both forms of punishment are combined\nwith other social mechanisms such as partner selection and reputation. We\nprovide an extensive and systematic evaluation of the impact of these key\nmechanisms on the emergence of cooperation. Finally, we discuss the\nimplications of the use of these mechanisms in the design of cooperative AI\nsystems.\n","authors":["Nayana Dasgupta","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2301.08278v1.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2301.08559v1","updated":"2023-01-19T13:16:31Z","published":"2023-01-19T13:16:31Z","title":"The Lost Art of Mathematical Modelling","summary":"  We provide a critique of mathematical biology in light of rapid developments\nin modern machine learning. We argue that out of the three modelling activities\n-- (1) formulating models; (2) analysing models; and (3) fitting or comparing\nmodels to data -- inherent to mathematical biology, researchers currently focus\ntoo much on activity (2) at the cost of (1). This trend, we propose, can be\nreversed by realising that any given biological phenomena can be modelled in an\ninfinite number of different ways, through the adoption of an open/pluralistic\napproach. We explain the open approach using fish locomotion as a case study\nand illustrate some of the pitfalls -- universalism, creating models of models,\netc. -- that hinder mathematical biology. We then ask how we might rediscover a\nlost art: that of creative mathematical modelling.\n  This article is dedicated to the memory of Edmund Crampin.\n","authors":["Linnéa Gyllingberg","Abeba Birhane","David J. T. Sumpter"],"pdf_url":"https://arxiv.org/pdf/2301.08559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08252v1","updated":"2023-01-19T11:37:20Z","published":"2023-01-19T11:37:20Z","title":"Evaluation of the potential of Near Infrared Hyperspectral Imaging for\n  monitoring the invasive brown marmorated stink bug","summary":"  The brown marmorated stink bug (BMSB), Halyomorpha halys, is an invasive\ninsect pest of global importance that damages several crops, compromising\nagri-food production. Field monitoring procedures are fundamental to perform\nrisk assessment operations, in order to promptly face crop infestations and\navoid economical losses. To improve pest management, spectral cameras mounted\non Unmanned Aerial Vehicles (UAVs) and other Internet of Things (IoT) devices,\nsuch as smart traps or unmanned ground vehicles, could be used as an innovative\ntechnology allowing fast, efficient and real-time monitoring of insect\ninfestations. The present study consists in a preliminary evaluation at the\nlaboratory level of Near Infrared Hyperspectral Imaging (NIR-HSI) as a possible\ntechnology to detect BMSB specimens on different vegetal backgrounds,\novercoming the problem of BMSB mimicry. Hyperspectral images of BMSB were\nacquired in the 980-1660 nm range, considering different vegetal backgrounds\nselected to mimic a real field application scene. Classification models were\nobtained following two different chemometric approaches. The first approach was\nfocused on modelling spectral information and selecting relevant spectral\nregions for discrimination by means of sparse-based variable selection coupled\nwith Soft Partial Least Squares Discriminant Analysis (s-Soft PLS-DA)\nclassification algorithm. The second approach was based on modelling spatial\nand spectral features contained in the hyperspectral images using Convolutional\nNeural Networks (CNN). Finally, to further improve BMSB detection ability, the\ntwo strategies were merged, considering only the spectral regions selected by\ns-Soft PLS-DA for CNN modelling.\n","authors":["Veronica Ferrari","Rosalba Calvini","Bas Boom","Camilla Menozzi","Aravind Krishnaswamy Rangarajan","Lara Maistrello","Peter Offermans","Alessandro Ulrici"],"pdf_url":"https://arxiv.org/pdf/2301.08252v1.pdf","comment":"Accepted manuscript"},{"id":"http://arxiv.org/abs/2301.00986v2","updated":"2023-01-19T11:02:33Z","published":"2023-01-03T07:40:28Z","title":"Look, Listen, and Attack: Backdoor Attacks Against Video Action\n  Recognition","summary":"  Deep neural networks (DNNs) are vulnerable to a class of attacks called\n\"backdoor attacks\", which create an association between a backdoor trigger and\na target label the attacker is interested in exploiting. A backdoored DNN\nperforms well on clean test images, yet persistently predicts an\nattacker-defined label for any sample in the presence of the backdoor trigger.\nAlthough backdoor attacks have been extensively studied in the image domain,\nthere are very few works that explore such attacks in the video domain, and\nthey tend to conclude that image backdoor attacks are less effective in the\nvideo domain. In this work, we revisit the traditional backdoor threat model\nand incorporate additional video-related aspects to that model. We show that\npoisoned-label image backdoor attacks could be extended temporally in two ways,\nstatically and dynamically, leading to highly effective attacks in the video\ndomain. In addition, we explore natural video backdoors to highlight the\nseriousness of this vulnerability in the video domain. And, for the first time,\nwe study multi-modal (audiovisual) backdoor attacks against video action\nrecognition models, where we show that attacking a single modality is enough\nfor achieving a high attack success rate.\n","authors":["Hasan Abed Al Kader Hammoud","Shuming Liu","Mohammed Alkhrashi","Fahad AlBalawi","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2301.00986v2.pdf","comment":null}]},"2023-01-20T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.08731v1","updated":"2023-01-20T18:50:38Z","published":"2023-01-20T18:50:38Z","title":"Can Peanuts Fall in Love with Distributional Semantics?","summary":"  The context in which a sentence appears can drastically alter our\nexpectations about upcoming words - for example, following a short story\ninvolving an anthropomorphic peanut, experimental participants are more likely\nto expect the sentence 'the peanut was in love' than 'the peanut was salted',\nas indexed by N400 amplitude (Nieuwland & van Berkum, 2006). This rapid and\ndynamic updating of comprehenders' expectations about the kind of events that a\npeanut may take part in based on context has been explained using the construct\nof Situation Models - updated mental representations of key elements of an\nevent under discussion, in this case, the peanut protagonist. However, recent\nwork showing that N400 amplitude can be predicted based on distributional\ninformation alone raises the question whether situation models are in fact\nnecessary for the kinds of contextual effects observed in previous work. To\ninvestigate this question, we attempt to model the results of Nieuwland and van\nBerkum (2006) using six computational language models and three sets of word\nvectors, none of which have explicit situation models or semantic grounding. We\nfind that the effect found by Nieuwland and van Berkum (2006) can be fully\nmodeled by two language models and two sets of word vectors, with others\nshowing a reduced effect. Thus, at least some processing effects normally\nexplained through situation models may not in fact require explicit situation\nmodels.\n","authors":["James A. Michaelov","Seana Coulson","Benjamin K. Bergen"],"pdf_url":"https://arxiv.org/pdf/2301.08731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01282v2","updated":"2023-01-20T15:53:49Z","published":"2022-12-01T08:50:12Z","title":"CHAPTER: Exploiting Convolutional Neural Network Adapters for\n  Self-supervised Speech Models","summary":"  Self-supervised learning (SSL) is a powerful technique for learning\nrepresentations from unlabeled data. Transformer based models such as HuBERT,\nwhich consist a feature extractor and transformer layers, are leading the field\nin the speech domain. SSL models are fine-tuned on a wide range of downstream\ntasks, which involves re-training the majority of the model for each task.\nPrevious studies have introduced applying adapters, which are small lightweight\nmodules commonly used in Natural Language Processing (NLP) to adapt pre-trained\nmodels to new tasks. However, such efficient tuning techniques only provide\nadaptation at the transformer layer, but failed to perform adaptation at the\nfeature extractor. In this paper, we propose CHAPTER, an efficient tuning\nmethod specifically designed for SSL speech model, by applying CNN adapters at\nthe feature extractor. Using this method, we can only fine-tune fewer than 5%\nof parameters per task compared to fully fine-tuning and achieve better and\nmore stable performance. We empirically found that adding CNN adapters to the\nfeature extractor can help the adaptation on emotion and speaker tasks. For\ninstance, the accuracy of SID is improved from 87.71 to 91.56, and the accuracy\nof ER is improved by 5%.\n","authors":["Zih-Ching Chen","Yu-Shun Sung","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2212.01282v2.pdf","comment":"Submitted to ICASSP 2023. Under review"},{"id":"http://arxiv.org/abs/2301.08606v1","updated":"2023-01-20T14:36:22Z","published":"2023-01-20T14:36:22Z","title":"Data Augmentation for Modeling Human Personality: The Dexter Machine","summary":"  Modeling human personality is important for several AI challenges, from the\nengineering of artificial psychotherapists to the design of persona bots.\nHowever, the field of computational personality analysis heavily relies on\nlabeled data, which may be expensive, difficult or impossible to get. This\nproblem is amplified when dealing with rare personality types or disorders\n(e.g., the anti-social psychopathic personality disorder). In this context, we\ndeveloped a text-based data augmentation approach for human personality\n(PEDANT). PEDANT doesn't rely on the common type of labeled data but on the\ngenerative pre-trained model (GPT) combined with domain expertise. Testing the\nmethodology on three different datasets, provides results that support the\nquality of the generated data.\n","authors":["Yair Neuman","Vladyslav Kozhukhov","Dan Vilenchik"],"pdf_url":"https://arxiv.org/pdf/2301.08606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.07793v2","updated":"2023-01-20T13:54:48Z","published":"2021-11-15T14:28:21Z","title":"Analysis of Data Augmentation Methods for Low-Resource Maltese ASR","summary":"  Recent years have seen an increased interest in the computational speech\nprocessing of Maltese, but resources remain sparse. In this paper, we consider\ndata augmentation techniques for improving speech recognition for low-resource\nlanguages, focusing on Maltese as a test case. We consider three different\ntypes of data augmentation: unsupervised training, multilingual training and\nthe use of synthesized speech as training data. The goal is to determine which\nof these techniques, or combination of them, is the most effective to improve\nspeech recognition for languages where the starting point is a small corpus of\napproximately 7 hours of transcribed speech. Our results show that combining\nthe data augmentation techniques studied here lead us to an absolute WER\nimprovement of 15% without the use of a language model.\n","authors":["Andrea DeMarco","Carlos Mena","Albert Gatt","Claudia Borg","Aiden Williams","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2111.07793v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2301.08571v1","updated":"2023-01-20T13:38:24Z","published":"2023-01-20T13:38:24Z","title":"Visual Writing Prompts: Character-Grounded Story Generation with Curated\n  Image Sequences","summary":"  Current work on image-based story generation suffers from the fact that the\nexisting image sequence collections do not have coherent plots behind them. We\nimprove visual story generation by producing a new image-grounded dataset,\nVisual Writing Prompts (VWP). VWP contains almost 2K selected sequences of\nmovie shots, each including 5-10 images. The image sequences are aligned with a\ntotal of 12K stories which were collected via crowdsourcing given the image\nsequences and a set of grounded characters from the corresponding image\nsequence. Our new image sequence collection and filtering process has allowed\nus to obtain stories that are more coherent and have more narrativity compared\nto previous work. We also propose a character-based story generation model\ndriven by coherence as a strong baseline. Evaluations show that our generated\nstories are more coherent, visually grounded, and have more narrativity than\nstories generated with the current state-of-the-art model.\n","authors":["Xudong Hong","Asad Sayeed","Khushboo Mehra","Vera Demberg","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2301.08571v1.pdf","comment":"Paper accepted by Transactions of the Association for Computational\n  Linguistics (TACL). This is a pre-MIT Press publication version. 15 pages, 6\n  figures"},{"id":"http://arxiv.org/abs/2301.08549v1","updated":"2023-01-20T13:12:35Z","published":"2023-01-20T13:12:35Z","title":"Transforming Unstructured Text into Data with Context Rule Assisted\n  Machine Learning (CRAML)","summary":"  We describe a method and new no-code software tools enabling domain experts\nto build custom structured, labeled datasets from the unstructured text of\ndocuments and build niche machine learning text classification models traceable\nto expert-written rules. The Context Rule Assisted Machine Learning (CRAML)\nmethod allows accurate and reproducible labeling of massive volumes of\nunstructured text. CRAML enables domain experts to access uncommon constructs\nburied within a document corpus, and avoids limitations of current\ncomputational approaches that often lack context, transparency, and\ninterpetability. In this research methods paper, we present three use cases for\nCRAML: we analyze recent management literature that draws from text data,\ndescribe and release new machine learning models from an analysis of\nproprietary job advertisement text, and present findings of social and economic\ninterest from a public corpus of franchise documents. CRAML produces\ndocument-level coded tabular datasets that can be used for quantitative\nacademic research, and allows qualitative researchers to scale niche\nclassification schemes over massive text data. CRAML is a low-resource,\nflexible, and scalable methodology for building training data for supervised\nML. We make available as open-source resources: the software, job advertisement\ntext classifiers, a novel corpus of franchise documents, and a fully replicable\nstart-to-finish trained example in the context of no poach clauses.\n","authors":["Stephen Meisenbacher","Peter Norlander"],"pdf_url":"https://arxiv.org/pdf/2301.08549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08241v3","updated":"2023-01-20T10:38:03Z","published":"2022-08-17T11:41:43Z","title":"ILLUME: Rationalizing Vision-Language Models through Human Interactions","summary":"  Bootstrapping from pre-trained language models has been proven to be an\nefficient approach for building vision-language models (VLM) for tasks such as\nimage captioning or visual question answering. However, outputs of these models\nrarely align with user's rationales for specific answers. In order to improve\nthis alignment and reinforce commonsense reasons, we propose a tuning paradigm\nbased on human interactions with machine generated data. Our ILLUME executes\nthe following loop: Given an image-question-answer prompt, the VLM samples\nmultiple candidate rationales, and a human critic provides minimal feedback via\npreference selection, used for fine-tuning. This loop increases the training\ndata and gradually carves out the VLM's rationalization capabilities that are\naligned with human intend. Our exhaustive experiments demonstrate that ILLUME\nis competitive with standard supervised fine-tuning while using significantly\nfewer training data and only requiring minimal feedback.\n","authors":["Manuel Brack","Patrick Schramowski","Björn Deiseroth","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2208.08241v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08506v1","updated":"2023-01-20T10:33:03Z","published":"2023-01-20T10:33:03Z","title":"Language Agnostic Data-Driven Inverse Text Normalization","summary":"  With the emergence of automatic speech recognition (ASR) models, converting\nthe spoken form text (from ASR) to the written form is in urgent need. This\ninverse text normalization (ITN) problem attracts the attention of researchers\nfrom various fields. Recently, several works show that data-driven ITN methods\ncan output high-quality written form text. Due to the scarcity of labeled\nspoken-written datasets, the studies on non-English data-driven ITN are quite\nlimited. In this work, we propose a language-agnostic data-driven ITN framework\nto fill this gap. Specifically, we leverage the data augmentation in\nconjunction with neural machine translated data for low resource languages.\nMoreover, we design an evaluation method for language agnostic ITN model when\nonly English data is available. Our empirical evaluation shows this language\nagnostic modeling approach is effective for low resource languages while\npreserving the performance for high resource languages.\n","authors":["Szu-Jui Chen","Debjyoti Paul","Yutong Pang","Peng Su","Xuedong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10247v2","updated":"2023-01-20T06:13:46Z","published":"2022-11-18T14:07:29Z","title":"GoSum: Extractive Summarization of Long Documents by Reinforcement\n  Learning and Graph Organized discourse state","summary":"  Extracting summaries from long documents can be regarded as sentence\nclassification using the structural information of the documents. How to use\nsuch structural information to summarize a document is challenging. In this\npaper, we propose GoSum, a novel graph and reinforcement learning based\nextractive model for long-paper summarization. In particular, GoSum encodes\nsentence states in reinforcement learning by building a heterogeneous graph for\neach input document at different discourse levels. An edge in the graph\nreflects the discourse hierarchy of a document for restraining the semantic\ndrifts across section boundaries. We evaluate GoSum on two datasets of\nscientific articles summarization: PubMed and arXiv. The experimental results\nhave demonstrated that GoSum achieve state-of-the-art results compared with\nstrong baselines of both extractive and abstractive models. The ablation\nstudies further validate that the performance of our GoSum benefits from the\nuse of discourse information.\n","authors":["Junyi Bian","Xiaodi Huang","Hong Zhou","Shanfeng Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.10247v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08427v1","updated":"2023-01-20T05:39:26Z","published":"2023-01-20T05:39:26Z","title":"Which Features are Learned by CodeBert: An Empirical Study of the\n  BERT-based Source Code Representation Learning","summary":"  The Bidirectional Encoder Representations from Transformers (BERT) were\nproposed in the natural language process (NLP) and shows promising results.\nRecently researchers applied the BERT to source-code representation learning\nand reported some good news on several downstream tasks. However, in this\npaper, we illustrated that current methods cannot effectively understand the\nlogic of source codes. The representation of source code heavily relies on the\nprogrammer-defined variable and function names. We design and implement a set\nof experiments to demonstrate our conjecture and provide some insights for\nfuture works.\n","authors":["Lan Zhang","Chen Cao","Zhilong Wang","Peng Liu"],"pdf_url":"https://arxiv.org/pdf/2301.08427v1.pdf","comment":"1 table, 2 figures"},{"id":"http://arxiv.org/abs/2211.11703v2","updated":"2023-01-20T04:57:08Z","published":"2022-11-21T18:24:34Z","title":"Towards continually learning new languages","summary":"  Multilingual speech recognition with neural networks is often implemented\nwith batch-learning, when all of the languages are available before training.\nAn ability to add new languages after the prior training sessions can be\neconomically beneficial, but the main challenge is catastrophic forgetting. In\nthis work, we combine the qualities of weight factorization and elastic weight\nconsolidation in order to counter catastrophic forgetting and facilitate\nlearning new languages quickly. Such combination allowed us to eliminate\ncatastrophic forgetting while still achieving performance for the new languages\ncomparable with having all languages at once, in experiments of learning from\nan initial 10 languages to achieve 26 languages without catastrophic forgetting\nand a reasonable performance compared to training all languages from scratch.\n","authors":["Ngoc-Quan Pham","Jan Niehues","Alexander Waibel"],"pdf_url":"https://arxiv.org/pdf/2211.11703v2.pdf","comment":"Submitted to ICCASP 2023 - Revision 1.0"},{"id":"http://arxiv.org/abs/2301.08416v1","updated":"2023-01-20T04:11:38Z","published":"2023-01-20T04:11:38Z","title":"Machine Translation for Accessible Multi-Language Text Analysis","summary":"  English is the international standard of social research, but scholars are\nincreasingly conscious of their responsibility to meet the need for scholarly\ninsight into communication processes globally. This tension is as true in\ncomputational methods as any other area, with revolutionary advances in the\ntools for English language texts leaving most other languages far behind. In\nthis paper, we aim to leverage those very advances to demonstrate that\nmulti-language analysis is currently accessible to all computational scholars.\nWe show that English-trained measures computed after translation to English\nhave adequate-to-excellent accuracy compared to source-language measures\ncomputed on original texts. We show this for three major analytics -- sentiment\nanalysis, topic analysis, and word embeddings -- over 16 languages, including\nSpanish, Chinese, Hindi, and Arabic. We validate this claim by comparing\npredictions on original language tweets and their backtranslations: double\ntranslations from their source language to English and back to the source\nlanguage. Overall, our results suggest that Google Translate, a simple and\nwidely accessible tool, is effective in preserving semantic content across\nlanguages and methods. Modern machine translation can thus help computational\nscholars make more inclusive and general claims about human communication.\n","authors":["Edward W. Chew","William D. Weisman","Jingying Huang","Seth Frey"],"pdf_url":"https://arxiv.org/pdf/2301.08416v1.pdf","comment":"5000 words, 6 figures"},{"id":"http://arxiv.org/abs/2206.10128v2","updated":"2023-01-20T00:55:24Z","published":"2022-06-21T06:21:23Z","title":"Bridging the Gap Between Indexing and Retrieval for Differentiable\n  Search Index with Query Generation","summary":"  The Differentiable Search Index (DSI) is an emerging paradigm for information\nretrieval. Unlike traditional retrieval architectures where index and retrieval\nare two different and separate components, DSI uses a single transformer model\nto perform both indexing and retrieval.\n  In this paper, we identify and tackle an important issue of current DSI\nmodels: the data distribution mismatch that occurs between the DSI indexing and\nretrieval processes. Specifically, we argue that, at indexing, current DSI\nmethods learn to build connections between the text of long documents and the\nidentifier of the documents, but then retrieval of document identifiers is\nbased on queries that are commonly much shorter than the indexed documents.\nThis problem is further exacerbated when using DSI for cross-lingual retrieval,\nwhere document text and query text are in different languages.\n  To address this fundamental problem of current DSI models, we propose a\nsimple yet effective indexing framework for DSI, called DSI-QG. When indexing,\nDSI-QG represents documents with a number of potentially relevant queries\ngenerated by a query generation model and re-ranked and filtered by a\ncross-encoder ranker. The presence of these queries at indexing allows the DSI\nmodels to connect a document identifier to a set of queries, hence mitigating\ndata distribution mismatches present between the indexing and the retrieval\nphases. Empirical results on popular mono-lingual and cross-lingual passage\nretrieval datasets show that DSI-QG significantly outperforms the original DSI\nmodel.\n","authors":["Shengyao Zhuang","Houxing Ren","Linjun Shou","Jian Pei","Ming Gong","Guido Zuccon","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2206.10128v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2301.08832v1","updated":"2023-01-20T23:59:26Z","published":"2023-01-20T23:59:26Z","title":"Same Words, Different Meanings: Interpretable Predictions of\n  Polarization Trends in Broadcast Media Language and Granger Causal Effects on\n  Public Discourse","summary":"  With the growth of online news over the past decade, empirical studies on\npolitical discourse and news consumption have focused on the phenomenon of\nfilter bubbles and echo chambers. Yet recently, scholars have revealed limited\nevidence around the impact of such phenomenon, leading some to argue that\npartisan segregation across news audiences cannot be fully explained by online\nnews consumption alone and that the role of traditional legacy media may be as\nsalient in polarizing public discourse around current events. In this work, we\nexpand the scope of analysis to include both online and more traditional media\nby investigating the relationship between broadcast news media language and\nsocial media discourse. By analyzing a decade's worth of closed captions (2\nmillion speaker turns) from CNN and Fox News along with topically corresponding\ndiscourse from Twitter, we provide a novel framework for measuring semantic\npolarization between America's two major broadcast networks to demonstrate how\nsemantic polarization between these outlets has evolved (Study 1), peaked\n(Study 2) and influenced partisan discussions on Twitter (Study 3) across the\nlast decade. Our results demonstrate a sharp increase in polarization in how\ntopically important keywords are discussed between the two channels, especially\nafter 2016, with overall highest peaks occurring in 2020. The two stations\ndiscuss identical topics in drastically distinct contexts in 2020, to the\nextent that there is barely any linguistic overlap in how identical keywords\nare contextually discussed. Further, we demonstrate at scale, how such partisan\ndivision in broadcast media language significantly shapes semantic polarity\ntrends on Twitter (and vice-versa), empirically linking for the first time, how\nonline discussions are influenced by televised media.\n","authors":["Xiaohan Ding","Mike Horning","Eugenia H. Rho"],"pdf_url":"https://arxiv.org/pdf/2301.08832v1.pdf","comment":"11 pages. 3 figures and 11 tables"},{"id":"http://arxiv.org/abs/2301.08826v1","updated":"2023-01-20T23:38:58Z","published":"2023-01-20T23:38:58Z","title":"A Review of the Trends and Challenges in Adopting Natural Language\n  Processing Methods for Education Feedback Analysis","summary":"  Artificial Intelligence (AI) is a fast-growing area of study that stretching\nits presence to many business and research domains. Machine learning, deep\nlearning, and natural language processing (NLP) are subsets of AI to tackle\ndifferent areas of data processing and modelling. This review article presents\nan overview of AI impact on education outlining with current opportunities. In\nthe education domain, student feedback data is crucial to uncover the merits\nand demerits of existing services provided to students. AI can assist in\nidentifying the areas of improvement in educational infrastructure, learning\nmanagement systems, teaching practices and study environment. NLP techniques\nplay a vital role in analyzing student feedback in textual format. This\nresearch focuses on existing NLP methodologies and applications that could be\nadapted to educational domain applications like sentiment annotations, entity\nannotations, text summarization, and topic modelling. Trends and challenges in\nadopting NLP in education were reviewed and explored. Contextbased challenges\nin NLP like sarcasm, domain-specific language, ambiguity, and aspect-based\nsentiment analysis are explained with existing methodologies to overcome them.\nResearch community approaches to extract the semantic meaning of emoticons and\nspecial characters in feedback which conveys user opinion and challenges in\nadopting NLP in education are explored.\n","authors":["Thanveer Shaik","Xiaohui Tao","Yan Li","Christopher Dann","Jacquie Mcdonald","Petrea Redmond","Linda Galligan"],"pdf_url":"https://arxiv.org/pdf/2301.08826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08817v1","updated":"2023-01-20T22:24:22Z","published":"2023-01-20T22:24:22Z","title":"Document Summarization with Text Segmentation","summary":"  In this paper, we exploit the innate document segment structure for improving\nthe extractive summarization task. We build two text segmentation models and\nfind the most optimal strategy to introduce their output predictions in an\nextractive summarization model. Experimental results on a corpus of scientific\narticles show that extractive summarization benefits from using a highly\naccurate segmentation method. In particular, most of the improvement is in\ndocuments where the most relevant information is not at the beginning thus, we\nconclude that segmentation helps in reducing the lead bias problem.\n","authors":["Lesly Miculicich","Benjamin Han"],"pdf_url":"https://arxiv.org/pdf/2301.08817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08810v1","updated":"2023-01-20T21:36:16Z","published":"2023-01-20T21:36:16Z","title":"Phoneme-Level BERT for Enhanced Prosody of Text-to-Speech with Grapheme\n  Predictions","summary":"  Large-scale pre-trained language models have been shown to be helpful in\nimproving the naturalness of text-to-speech (TTS) models by enabling them to\nproduce more naturalistic prosodic patterns. However, these models are usually\nword-level or sup-phoneme-level and jointly trained with phonemes, making them\ninefficient for the downstream TTS task where only phonemes are needed. In this\nwork, we propose a phoneme-level BERT (PL-BERT) with a pretext task of\npredicting the corresponding graphemes along with the regular masked phoneme\npredictions. Subjective evaluations show that our phoneme-level BERT encoder\nhas significantly improved the mean opinion scores (MOS) of rated naturalness\nof synthesized speech compared with the state-of-the-art (SOTA) StyleTTS\nbaseline on out-of-distribution (OOD) texts.\n","authors":["Yinghao Aaron Li","Cong Han","Xilin Jiang","Nima Mesgarani"],"pdf_url":"https://arxiv.org/pdf/2301.08810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08784v1","updated":"2023-01-20T20:04:35Z","published":"2023-01-20T20:04:35Z","title":"Visual Semantic Relatedness Dataset for Image Captioning","summary":"  Modern image captioning system relies heavily on extracting knowledge from\nimages to capture the concept of a static story. In this paper, we propose a\ntextual visual context dataset for captioning, in which the publicly available\ndataset COCO Captions (Lin et al., 2014) has been extended with information\nabout the scene (such as objects in the image). Since this information has a\ntextual form, it can be used to leverage any NLP task, such as text similarity\nor semantic relation methods, into captioning systems, either as an end-to-end\ntraining strategy or a post-processing based approach.\n","authors":["Ahmed Sabir","Francesc Moreno-Noguer","Lluís Padró"],"pdf_url":"https://arxiv.org/pdf/2301.08784v1.pdf","comment":"Project Page: bit.ly/3Zq6ATs"},{"id":"http://arxiv.org/abs/2301.08771v1","updated":"2023-01-20T19:13:09Z","published":"2023-01-20T19:13:09Z","title":"Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt\n  Learning for Automatic Scoring in Science Education","summary":"  Developing models to automatically score students' written responses to\nscience problems is critical for science education. However, collecting and\nlabeling sufficient student responses for training models is time and\ncost-consuming. Recent studies suggest that pre-trained language models (PLMs)\ncan be adapted to downstream tasks without fine-tuning with prompts. However,\nno research has employed such a prompt approach in science education. As\nstudent responses are presented with natural language, aligning the scoring\nprocedure as the next sentence prediction task using prompts can skip the\ncostly fine-tuning stage. In this study, we developed a zero-shot approach to\nautomatically score student responses via Matching Exemplars as Next Sentence\nPrediction (MeNSP). This approach employs no training samples. We first apply\nMeNSP in scoring three assessment tasks of scientific argumentation and found\nmachine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and\nF1 score ranges from 0.54 to 0.81. To improve the performance, we extend our\nresearch to the few-shots setting, either randomly selecting labeled student\nresponses or manually constructing responses to fine-tune the models. We find\nthat one task's performance is improved with more samples, Cohen's Kappa from\n0.30 to 0.38, and F1 score from 0.54 to 0.59; for the two others, scoring\nperformance is not improved. We also find that randomly selected few-shots\nperform better than the human expert-crafted approach. This study suggests that\nMeNSP can yield referable automatic scoring for student responses while\nsignificantly reducing the cost of model training. This method can benefit\nlow-stakes classroom assessment practices in science education. Future research\nshould further explore the applicability of the MeNSP in different types of\nassessment tasks in science education and improve the model performance.\n","authors":["Xuansheng Wu","Xinyu He","Tianming Li","Ninghao Liu","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2301.08771v1.pdf","comment":"10+3 pages"},{"id":"http://arxiv.org/abs/2301.08745v1","updated":"2023-01-20T08:51:36Z","published":"2023-01-20T08:51:36Z","title":"Is ChatGPT A Good Translator? A Preliminary Study","summary":"  This report provides a preliminary evaluation of ChatGPT for machine\ntranslation, including translation prompt, multilingual translation, and\ntranslation robustness. We adopt the prompts advised by ChatGPT to trigger its\ntranslation ability and find that the candidate prompts generally work well and\nshow minor performance differences. By evaluating on a number of benchmark test\nsets, we find that ChatGPT performs competitively with commercial translation\nproducts (e.g., Google Translate) on high-resource European languages but lags\nbehind significantly on lowresource or distant languages. As for the\ntranslation robustness, ChatGPT does not perform as well as the commercial\nsystems on biomedical abstracts or Reddit comments but is potentially a good\ntranslator for spoken language. Scripts and data:\nhttps://github.com/wxjiao/Is-ChatGPT-A-Good-Translator\n","authors":["Wenxiang Jiao","Wenxuan Wang","Jen-tse Huang","Xing Wang","Zhaopeng Tu"],"pdf_url":"https://arxiv.org/pdf/2301.08745v1.pdf","comment":"4 pages; a delayed announcement"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.08739v1","updated":"2023-01-20T18:59:57Z","published":"2023-01-20T18:59:57Z","title":"FlatFormer: Flattened Window Attention for Efficient Point Cloud\n  Transformer","summary":"  Transformer, as an alternative to CNN, has been proven effective in many\nmodalities (e.g., texts and images). For 3D point cloud transformers, existing\nefforts focus primarily on pushing their accuracy to the state-of-the-art\nlevel. However, their latency lags behind sparse convolution-based models (3x\nslower), hindering their usage in resource-constrained, latency-sensitive\napplications (such as autonomous driving). This inefficiency comes from point\nclouds' sparse and irregular nature, whereas transformers are designed for\ndense, regular workloads. This paper presents FlatFormer to close this latency\ngap by trading spatial proximity for better computational regularity. We first\nflatten the point cloud with window-based sorting and partition points into\ngroups of equal sizes rather than windows of equal shapes. This effectively\navoids expensive structuring and padding overheads. We then apply\nself-attention within groups to extract local features, alternate sorting axis\nto gather features from different directions, and shift windows to exchange\nfeatures across groups. FlatFormer delivers state-of-the-art accuracy on Waymo\nOpen Dataset with 4.6x speedup over (transformer-based) SST and 1.4x speedup\nover (sparse convolutional) CenterPoint. This is the first point cloud\ntransformer that achieves real-time performance on edge GPUs and is faster than\nsparse convolutional methods while achieving on-par or even superior accuracy\non large-scale benchmarks. Code to reproduce our results will be made publicly\navailable.\n","authors":["Zhijian Liu","Xinyu Yang","Haotian Tang","Shang Yang","Song Han"],"pdf_url":"https://arxiv.org/pdf/2301.08739v1.pdf","comment":"The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2301.08730v1","updated":"2023-01-20T18:49:58Z","published":"2023-01-20T18:49:58Z","title":"Novel-View Acoustic Synthesis","summary":"  We introduce the novel-view acoustic synthesis (NVAS) task: given the sight\nand sound observed at a source viewpoint, can we synthesize the \\emph{sound} of\nthat scene from an unseen target viewpoint? We propose a neural rendering\napproach: Visually-Guided Acoustic Synthesis (ViGAS) network that learns to\nsynthesize the sound of an arbitrary point in space by analyzing the input\naudio-visual cues. To benchmark this task, we collect two first-of-their-kind\nlarge-scale multi-view audio-visual datasets, one synthetic and one real. We\nshow that our model successfully reasons about the spatial cues and synthesizes\nfaithful audio on both datasets. To our knowledge, this work represents the\nvery first formulation, dataset, and approach to solve the novel-view acoustic\nsynthesis task, which has exciting potential applications ranging from AR/VR to\nart and design. Unlocked by this work, we believe that the future of novel-view\nsynthesis is in multi-modal learning from videos.\n","authors":["Changan Chen","Alexander Richard","Roman Shapovalov","Vamsi Krishna Ithapu","Natalia Neverova","Kristen Grauman","Andrea Vedaldi"],"pdf_url":"https://arxiv.org/pdf/2301.08730v1.pdf","comment":"Project page: https://vision.cs.utexas.edu/projects/nvas"},{"id":"http://arxiv.org/abs/2208.05834v2","updated":"2023-01-20T17:58:02Z","published":"2022-08-11T14:01:38Z","title":"Joint reconstruction-segmentation on graphs","summary":"  Practical image segmentation tasks concern images which must be reconstructed\nfrom noisy, distorted, and/or incomplete observations. A recent approach for\nsolving such tasks is to perform this reconstruction jointly with the\nsegmentation, using each to guide the other. However, this work has so far\nemployed relatively simple segmentation methods, such as the Chan--Vese\nalgorithm. In this paper, we present a method for joint\nreconstruction-segmentation using graph-based segmentation methods, which have\nbeen seeing increasing recent interest. Complications arise due to the large\nsize of the matrices involved, and we show how these complications can be\nmanaged. We then analyse the convergence properties of our scheme. Finally, we\napply this scheme to distorted versions of ``two cows'' images familiar from\nprevious graph-based segmentation literature, first to a highly noised version\nand second to a blurred version, achieving highly accurate segmentations in\nboth cases. We compare these results to those obtained by sequential\nreconstruction-segmentation approaches, finding that our method competes with,\nor even outperforms, those approaches in terms of reconstruction and\nsegmentation accuracy.\n","authors":["Jeremy Budd","Yves van Gennip","Jonas Latz","Simone Parisotto","Carola-Bibiane Schönlieb"],"pdf_url":"https://arxiv.org/pdf/2208.05834v2.pdf","comment":"33 pages, 20 figures"},{"id":"http://arxiv.org/abs/2212.10772v3","updated":"2023-01-20T17:10:15Z","published":"2022-12-21T05:08:37Z","title":"Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond","summary":"  This paper presents a comprehensive survey of low-light image and video\nenhancement. We begin with the challenging mixed over-/under-exposed images,\nwhich are under-performed by existing methods. To this end, we propose two\nvariants of the SICE dataset named SICE_Grad and SICE_Mix. Next, we introduce\nNight Wenzhou, a large-scale, high-resolution video dataset, to address the\nissue of the lack of a low-light video dataset that discount the use of\nlow-light image enhancement (LLIE) to videos. Our Night Wenzhou dataset is\nchallenging since it consists of fast-moving aerial scenes and streetscapes\nwith varying illuminations and degradation. We conduct extensive key technique\nanalysis and experimental comparisons for representative LLIE approaches using\nthese newly proposed datasets and the current benchmark datasets. Finally, we\naddress unresolved issues and propose future research topics for the LLIE\ncommunity. Our datasets are available at\nhttps://github.com/ShenZheng2000/LLIE_Survey.\n","authors":["Shen Zheng","Yiling Ma","Jinqian Pan","Changjie Lu","Gaurav Gupta"],"pdf_url":"https://arxiv.org/pdf/2212.10772v3.pdf","comment":"13 pages, 8 tables, and 13 figures"},{"id":"http://arxiv.org/abs/2301.08669v1","updated":"2023-01-20T16:45:34Z","published":"2023-01-20T16:45:34Z","title":"Holistically Explainable Vision Transformers","summary":"  Transformers increasingly dominate the machine learning landscape across many\ntasks and domains, which increases the importance for understanding their\noutputs. While their attention modules provide partial insight into their inner\nworkings, the attention scores have been shown to be insufficient for\nexplaining the models as a whole. To address this, we propose B-cos\ntransformers, which inherently provide holistic explanations for their\ndecisions. Specifically, we formulate each model component - such as the\nmulti-layer perceptrons, attention layers, and the tokenisation module - to be\ndynamic linear, which allows us to faithfully summarise the entire transformer\nvia a single linear transform. We apply our proposed design to Vision\nTransformers (ViTs) and show that the resulting models, dubbed Bcos-ViTs, are\nhighly interpretable and perform competitively to baseline ViTs on ImageNet.\nCode will be made available soon.\n","authors":["Moritz Böhle","Mario Fritz","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2301.08669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08664v1","updated":"2023-01-20T16:30:44Z","published":"2023-01-20T16:30:44Z","title":"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","summary":"  The quality of the video stream is key to neural network-based video\nanalytics. However, low-quality video is inevitably collected by existing\nsurveillance systems because of poor quality cameras or over-compressed/pruned\nvideo streaming protocols, e.g., as a result of upstream bandwidth limit. To\naddress this issue, existing studies use quality enhancers (e.g., neural\nsuper-resolution) to improve the quality of videos (e.g., resolution) and\neventually ensure inference accuracy. Nevertheless, directly applying quality\nenhancers does not work in practice because it will introduce unacceptable\nlatency. In this paper, we present AccDecoder, a novel accelerated decoder for\nreal-time and neural-enhanced video analytics. AccDecoder can select a few\nframes adaptively via Deep Reinforcement Learning (DRL) to enhance the quality\nby neural super-resolution and then up-scale the unselected frames that\nreference them, which leads to 6-21% accuracy improvement. AccDecoder provides\nefficient inference capability via filtering important frames using DRL for\nDNN-based inference and reusing the results for the other frames via extracting\nthe reference relationship among frames and blocks, which results in a latency\nreduction of 20-80% than baselines.\n","authors":["Tingting Yuan","Liang Mi","Weijun Wang","Haipeng Dai","Xiaoming Fu"],"pdf_url":"https://arxiv.org/pdf/2301.08664v1.pdf","comment":"Accepted by 2023 IEEE INFOCOM"},{"id":"http://arxiv.org/abs/2301.08654v1","updated":"2023-01-20T16:03:30Z","published":"2023-01-20T16:03:30Z","title":"Automated extraction of capacitive coupling for quantum dot systems","summary":"  Gate-defined quantum dots (QDs) have appealing attributes as a quantum\ncomputing platform, however, near-term devices possess a range of possible\nimperfections that need to be accounted for during the tuning and operation of\nQD devices. One such problem is the capacitive cross-talk between the metallic\ngates that define and control QD qubits. A way to compensate for the capacitive\ncross-talk and enable targeted control of specific QDs independent of coupling\nis by the use of virtual gates. Here, we demonstrate a reliable automated\ncapacitive coupling identification method that combines machine learning with\ntraditional fitting to take advantage of the desirable properties of each. We\nalso show how the cross-capacitance measurement may be used for the\nidentification of spurious QDs sometimes formed during tuning experimental\ndevices. Our systems can autonomously flag devices with spurious dots near the\noperating regime which is crucial information for reliable tuning to a regime\nsuitable for qubit operations.\n","authors":["Joshua Ziegler","Florian Luthi","Mick Ramsey","Felix Borjans","Guoji Zheng","Justyna P. Zwolak"],"pdf_url":"https://arxiv.org/pdf/2301.08654v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.08647v1","updated":"2023-01-20T15:55:35Z","published":"2023-01-20T15:55:35Z","title":"Image Memorability Prediction with Vision Transformers","summary":"  Behavioral studies have shown that the memorability of images is similar\nacross groups of people, suggesting that memorability is a function of the\nintrinsic properties of images, and is unrelated to people's individual\nexperiences and traits. Deep learning networks can be trained on such\nproperties and be used to predict memorability in new data sets. Convolutional\nneural networks (CNN) have pioneered image memorability prediction, but more\nrecently developed vision transformer (ViT) models may have the potential to\nyield even better predictions. In this paper, we present the ViTMem, a new\nmemorability model based on ViT, and evaluate memorability predictions obtained\nby it with state-of-the-art CNN-derived models. Results showed that ViTMem\nperformed equal to or better than state-of-the-art models on all data sets.\nAdditional semantic level analyses revealed that ViTMem is particularly\nsensitive to the semantic content that drives memorability in images. We\nconclude that ViTMem provides a new step forward, and propose that ViT-derived\nmodels can replace CNNs for computational prediction of image memorability.\nResearchers, educators, advertisers, visual designers and other interested\nparties can leverage the model to improve the memorability of their image\nmaterial.\n","authors":["Thomas Hagen","Thomas Espeseth"],"pdf_url":"https://arxiv.org/pdf/2301.08647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.14645v2","updated":"2023-01-20T15:03:41Z","published":"2022-03-28T11:04:45Z","title":"REx: Data-Free Residual Quantization Error Expansion","summary":"  Deep neural networks (DNNs) are ubiquitous in computer vision and natural\nlanguage processing, but suffer from high inference cost. This problem can be\naddressed by quantization, which consists in converting floating point\noperations into a lower bit-width format. With the growing concerns on privacy\nrights, we focus our efforts on data-free methods. However, such techniques\nsuffer from their lack of adaptability to the target devices, as a hardware\ntypically only support specific bit widths. Thus, to adapt to a variety of\ndevices, a quantization method shall be flexible enough to find good accuracy\nv.s. speed trade-offs for every bit width and target device. To achieve this,\nwe propose REx, a quantization method that leverages residual error expansion,\nalong with group sparsity and an ensemble approximation for better\nparallelization. REx is backed off by strong theoretical guarantees and\nachieves superior performance on every benchmarked application (from vision to\nNLP tasks), architecture (ConvNets, transformers) and bit-width (from int8 to\nternary quantization).\n","authors":["Edouard Yvinec","Arnaud Dapgony","Matthieu Cord","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2203.14645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06484v3","updated":"2023-01-20T15:02:33Z","published":"2022-06-13T21:30:29Z","title":"On Image Segmentation With Noisy Labels: Characterization and Volume\n  Properties of the Optimal Solutions to Accuracy and Dice","summary":"  We study two of the most popular performance metrics in medical image\nsegmentation, Accuracy and Dice, when the target labels are noisy. For both\nmetrics, several statements related to characterization and volume properties\nof the set of optimal segmentations are proved, and associated experiments are\nprovided. Our main insights are: (i) the volume of the solutions to both\nmetrics may deviate significantly from the expected volume of the target, (ii)\nthe volume of a solution to Accuracy is always less than or equal to the volume\nof a solution to Dice and (iii) the optimal solutions to both of these metrics\ncoincide when the set of feasible segmentations is constrained to the set of\nsegmentations with the volume equal to the expected volume of the target.\n","authors":["Marcus Nordström","Henrik Hult","Jonas Söderberg","Fredrik Löfman"],"pdf_url":"https://arxiv.org/pdf/2206.06484v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08605v1","updated":"2023-01-20T14:34:03Z","published":"2023-01-20T14:34:03Z","title":"A Deep Learning Approach for SAR Tomographic Imaging of Forested Areas","summary":"  Synthetic aperture radar tomographic imaging reconstructs the\nthree-dimensional reflectivity of a scene from a set of coherent acquisitions\nperformed in an interferometric configuration. In forest areas, a large number\nof elements backscatter the radar signal within each resolution cell. To\nreconstruct the vertical reflectivity profile, state-of-the-art techniques\nperform a regularized inversion implemented in the form of iterative\nminimization algorithms. We show that light-weight neural networks can be\ntrained to perform the tomographic inversion with a single feed-forward pass,\nleading to fast reconstructions that could better scale to the amount of data\nprovided by the future BIOMASS mission. We train our encoder-decoder network\nusing simulated data and validate our technique on real L-band and P-band data.\n","authors":["Zoé Berenger","Loïc Denis","Florence Tupin","Laurent Ferro-Famil","Yue Huang"],"pdf_url":"https://arxiv.org/pdf/2301.08605v1.pdf","comment":"Submitted to IEEE Geoscience and Remote Sensing Letters, January 2023"},{"id":"http://arxiv.org/abs/2208.07360v2","updated":"2023-01-20T14:13:08Z","published":"2022-08-15T17:55:26Z","title":"Evaluating the Evaluators: Which UDA validation methods are most\n  effective? Can they be improved?","summary":"  This paper compares and ranks 8 UDA validation methods. Validators estimate\nmodel accuracy, which makes them an essential component of any UDA train-test\npipeline. We rank these validators to indicate which of them are most useful\nfor the purpose of selecting optimal model checkpoints and hyperparameters. To\nthe best of our knowledge, this large-scale benchmark study is the first of its\nkind in the UDA field. In addition, we propose three new validators that\noutperform all the existing checkpoint-based validators that we were able to\nfind in the existing literature. Code is available at\nhttps://www.github.com/KevinMusgrave/powerful-benchmarker.\n","authors":["Kevin Musgrave","Serge Belongie","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2208.07360v2.pdf","comment":"This paper was previously titled Benchmarking Validation Methods for\n  Unsupervised Domain Adaptation. This version contains new experiments,\n  analysis, and figures"},{"id":"http://arxiv.org/abs/2301.08590v1","updated":"2023-01-20T14:07:30Z","published":"2023-01-20T14:07:30Z","title":"Improving Sketch Colorization using Adversarial Segmentation Consistency","summary":"  We propose a new method for producing color images from sketches. Current\nsolutions in sketch colorization either necessitate additional user instruction\nor are restricted to the \"paired\" translation strategy. We leverage semantic\nimage segmentation from a general-purpose panoptic segmentation network to\ngenerate an additional adversarial loss function. The proposed loss function is\ncompatible with any GAN model. Our method is not restricted to datasets with\nsegmentation labels and can be applied to unpaired translation tasks as well.\nUsing qualitative, and quantitative analysis, and based on a user study, we\ndemonstrate the efficacy of our method on four distinct image datasets. On the\nFID metric, our model improves the baseline by up to 35 points. Our code,\npretrained models, scripts to produce newly introduced datasets and\ncorresponding sketch images are available at\nhttps://github.com/giddyyupp/AdvSegLoss.\n","authors":["Samet Hicsonmez","Nermin Samet","Emre Akbas","Pinar Duygulu"],"pdf_url":"https://arxiv.org/pdf/2301.08590v1.pdf","comment":"Under review at Pattern Recognition Letters. arXiv admin note:\n  substantial text overlap with arXiv:2102.06192"},{"id":"http://arxiv.org/abs/2205.13268v2","updated":"2023-01-20T14:00:26Z","published":"2022-05-26T10:50:29Z","title":"MemeTector: Enforcing deep focus for meme detection","summary":"  Image memes and specifically their widely-known variation image macros, is a\nspecial new media type that combines text with images and is used in social\nmedia to playfully or subtly express humour, irony, sarcasm and even hate. It\nis important to accurately retrieve image memes from social media to better\ncapture the cultural and social aspects of online phenomena and detect\npotential issues (hate-speech, disinformation). Essentially, the background\nimage of an image macro is a regular image easily recognized as such by humans\nbut cumbersome for the machine to do so due to feature map similarity with the\ncomplete image macro. Hence, accumulating suitable feature maps in such cases\ncan lead to deep understanding of the notion of image memes. To this end, we\npropose a methodology, called Visual Part Utilization, that utilizes the visual\npart of image memes as instances of the regular image class and the initial\nimage memes as instances of the image meme class to force the model to\nconcentrate on the critical parts that characterize an image meme.\nAdditionally, we employ a trainable attention mechanism on top of a standard\nViT architecture to enhance the model's ability to focus on these critical\nparts and make the predictions interpretable. Several training and test\nscenarios involving web-scraped regular images of controlled text presence are\nconsidered for evaluating the model in terms of robustness and accuracy. The\nfindings indicate that light visual part utilization combined with sufficient\ntext presence during training provides the best and most robust model,\nsurpassing state of the art. Source code and dataset are available at\nhttps://github.com/mever-team/memetector.\n","authors":["Christos Koutlis","Manos Schinas","Symeon Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2205.13268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16191v2","updated":"2023-01-20T13:56:39Z","published":"2022-11-28T14:58:15Z","title":"SgVA-CLIP: Semantic-guided Visual Adapting of Vision-Language Models for\n  Few-shot Image Classification","summary":"  Although significant progress has been made in few-shot learning, most of\nexisting few-shot image classification methods require supervised pre-training\non a large amount of samples of base classes, which limits their generalization\nability in real world application. Recently, large-scale Vision-Language\nPre-trained models (VLPs) have been gaining increasing attention in few-shot\nlearning because they can provide a new paradigm for transferable visual\nrepresentation learning with easily available text on the Web. However, the\nVLPs may neglect detailed visual information that is difficult to describe by\nlanguage sentences, but important for learning an effective classifier to\ndistinguish different images. To address the above problem, we propose a new\nframework, named Semantic-guided Visual Adapting (SgVA), which can effectively\nextend vision-language pre-trained models to produce discriminative adapted\nvisual features by comprehensively using an implicit knowledge distillation, a\nvision-specific contrastive loss, and a cross-modal contrastive loss. The\nimplicit knowledge distillation is designed to transfer the fine-grained\ncross-modal knowledge to guide the updating of the vision adapter.\nState-of-the-art results on 13 datasets demonstrate that the adapted visual\nfeatures can well complement the cross-modal features to improve few-shot image\nclassification.\n","authors":["Fang Peng","Xiaoshan Yang","Linhui Xiao","Yaowei Wang","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2211.16191v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08571v1","updated":"2023-01-20T13:38:24Z","published":"2023-01-20T13:38:24Z","title":"Visual Writing Prompts: Character-Grounded Story Generation with Curated\n  Image Sequences","summary":"  Current work on image-based story generation suffers from the fact that the\nexisting image sequence collections do not have coherent plots behind them. We\nimprove visual story generation by producing a new image-grounded dataset,\nVisual Writing Prompts (VWP). VWP contains almost 2K selected sequences of\nmovie shots, each including 5-10 images. The image sequences are aligned with a\ntotal of 12K stories which were collected via crowdsourcing given the image\nsequences and a set of grounded characters from the corresponding image\nsequence. Our new image sequence collection and filtering process has allowed\nus to obtain stories that are more coherent and have more narrativity compared\nto previous work. We also propose a character-based story generation model\ndriven by coherence as a strong baseline. Evaluations show that our generated\nstories are more coherent, visually grounded, and have more narrativity than\nstories generated with the current state-of-the-art model.\n","authors":["Xudong Hong","Asad Sayeed","Khushboo Mehra","Vera Demberg","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2301.08571v1.pdf","comment":"Paper accepted by Transactions of the Association for Computational\n  Linguistics (TACL). This is a pre-MIT Press publication version. 15 pages, 6\n  figures"},{"id":"http://arxiv.org/abs/2212.11614v2","updated":"2023-01-20T12:38:30Z","published":"2022-12-22T11:18:35Z","title":"Hybrid Quantum-Classical Generative Adversarial Network for High\n  Resolution Image Generation","summary":"  Quantum machine learning (QML) has received increasing attention due to its\npotential to outperform classical machine learning methods in problems\npertaining classification and identification tasks. A subclass of QML methods\nis quantum generative adversarial networks (QGANs) which have been studied as a\nquantum counterpart of classical GANs widely used in image manipulation and\ngeneration tasks. The existing work on QGANs is still limited to small-scale\nproof-of-concept examples based on images with significant downscaling. Here we\nintegrate classical and quantum techniques to propose a new hybrid\nquantum-classical GAN framework. We demonstrate its superior learning\ncapabilities by generating $28 \\times 28$ pixels grey-scale images without\ndimensionality reduction or classical pre/post-processing on multiple classes\nof the standard MNIST and Fashion MNIST datasets, which achieves comparable\nresults to classical frameworks with three orders of magnitude less trainable\ngenerator parameters. To gain further insight into the working of our hybrid\napproach, we systematically explore the impact of its parameter space by\nvarying the number of qubits, the size of image patches, the number of layers\nin the generator, the shape of the patches and the choice of prior\ndistribution. Our results show that increasing the quantum generator size\ngenerally improves the learning capability of the network. The developed\nframework provides a foundation for future design of QGANs with optimal\nparameter set tailored for complex image generation tasks.\n","authors":["Shu Lok Tsang","Maxwell T. West","Sarah M. Erfani","Muhammad Usman"],"pdf_url":"https://arxiv.org/pdf/2212.11614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08534v1","updated":"2023-01-20T12:30:28Z","published":"2023-01-20T12:30:28Z","title":"Prodromal Diagnosis of Lewy Body Diseases Based on the Assessment of\n  Graphomotor and Handwriting Difficulties","summary":"  To this date, studies focusing on the prodromal diagnosis of Lewy body\ndiseases (LBDs) based on quantitative analysis of graphomotor and handwriting\ndifficulties are missing. In this work, we enrolled 18 subjects diagnosed with\npossible or probable mild cognitive impairment with Lewy bodies (MCI-LB), 7\nsubjects having more than 50% probability of developing Parkinson's disease\n(PD), 21 subjects with both possible/probable MCI-LB and probability of PD >\n50%, and 37 age- and gender-matched healthy controls (HC). Each participant\nperformed three tasks: Archimedean spiral drawing (to quantify graphomotor\ndifficulties), sentence writing task (to quantify handwriting difficulties),\nand pentagon copying test (to quantify cognitive decline). Next, we\nparameterized the acquired data by various temporal, kinematic, dynamic,\nspatial, and task-specific features. And finally, we trained classification\nmodels for each task separately as well as a model for their combination to\nestimate the predictive power of the features for the identification of LBDs.\nUsing this approach we were able to identify prodromal LBDs with 74% accuracy\nand showed the promising potential of computerized objective and non-invasive\ndiagnosis of LBDs based on the assessment of graphomotor and handwriting\ndifficulties.\n","authors":["Zoltan Galaz","Jiri Mekyska","Jan Mucha","Vojtech Zvoncak","Zdenek Smekal","Marcos Faundez-Zanuy","Lubos Brabenec","Ivona Moravkova","Irena Rektorova"],"pdf_url":"https://arxiv.org/pdf/2301.08534v1.pdf","comment":"Print ISBN 978-3-031-19744-4"},{"id":"http://arxiv.org/abs/2301.08529v1","updated":"2023-01-20T12:18:05Z","published":"2023-01-20T12:18:05Z","title":"Exploration of Various Fractional Order Derivatives in Parkinson's\n  Disease Dysgraphia Analysis","summary":"  Parkinson's disease (PD) is a common neurodegenerative disorder with a\nprevalence rate estimated to 2.0% for people aged over 65 years. Cardinal motor\nsymptoms of PD such as rigidity and bradykinesia affect the muscles involved in\nthe handwriting process resulting in handwriting abnormalities called PD\ndysgraphia. Nowadays, online handwritten signal (signal with temporal\ninformation) acquired by the digitizing tablets is the most advanced approach\nof graphomotor difficulties analysis. Although the basic kinematic features\nwere proved to effectively quantify the symptoms of PD dysgraphia, a recent\nresearch identified that the theory of fractional calculus can be used to\nimprove the graphomotor difficulties analysis. Therefore, in this study, we\nfollow up on our previous research, and we aim to explore the utilization of\nvarious approaches of fractional order derivative (FD) in the analysis of PD\ndysgraphia. For this purpose, we used the repetitive loops task from the\nParkinson's disease handwriting database (PaHaW). Handwritten signals were\nparametrized by the kinematic features employing three FD approximations:\nGr\\\"unwald-Letnikov's, Riemann-Liouville's, and Caputo's. Results of the\ncorrelation analysis revealed a significant relationship between the clinical\nstate and the handwriting features based on the velocity. The extracted\nfeatures by Caputo's FD approximation outperformed the rest of the analyzed FD\napproaches. This was also confirmed by the results of the classification\nanalysis, where the best model trained by Caputo's handwriting features\nresulted in a balanced accuracy of 79.73% with a sensitivity of 83.78% and a\nspecificity of 75.68%.\n","authors":["Jan Mucha","Zoltan Galaz","Jiri Mekyska","Marcos Faundez-Zanuy","Vojtech Zvoncak","Zdenek Smekal","Lubos Brabenec","Irena Rektorova"],"pdf_url":"https://arxiv.org/pdf/2301.08529v1.pdf","comment":"Print ISBN 978-3-031-19744-4"},{"id":"http://arxiv.org/abs/2106.07075v5","updated":"2023-01-20T10:52:30Z","published":"2021-06-13T19:31:59Z","title":"Revisiting consistency for semi-supervised semantic segmentation","summary":"  Semi-supervised learning an attractive technique in practical deployments of\ndeep models since it relaxes the dependence on labeled data. It is especially\nimportant in the scope of dense prediction because pixel-level annotation\nrequires significant effort. This paper considers semi-supervised algorithms\nthat enforce consistent predictions over perturbed unlabeled inputs. We study\nthe advantages of perturbing only one of the two model instances and preventing\nthe backward pass through the unperturbed instance. We also propose a\ncompetitive perturbation model as a composition of geometric warp and\nphotometric jittering. We experiment with efficient models due to their\nimportance for real-time and low-power applications. Our experiments show clear\nadvantages of (1) one-way consistency, (2) perturbing only the student branch,\nand (3) strong photometric and geometric perturbations. Our perturbation model\noutperforms recent work and most of the contribution comes from photometric\ncomponent. Experiments with additional data from the large coarsely annotated\nsubset of Cityscapes suggest that semi-supervised training can outperform\nsupervised training with the coarse labels.\n","authors":["Ivan Grubišić","Marin Oršić","Siniša Šegvić"],"pdf_url":"https://arxiv.org/pdf/2106.07075v5.pdf","comment":"The source code is available at\n  https://github.com/Ivan1248/semisup-seg-efficient"},{"id":"http://arxiv.org/abs/2208.08241v3","updated":"2023-01-20T10:38:03Z","published":"2022-08-17T11:41:43Z","title":"ILLUME: Rationalizing Vision-Language Models through Human Interactions","summary":"  Bootstrapping from pre-trained language models has been proven to be an\nefficient approach for building vision-language models (VLM) for tasks such as\nimage captioning or visual question answering. However, outputs of these models\nrarely align with user's rationales for specific answers. In order to improve\nthis alignment and reinforce commonsense reasons, we propose a tuning paradigm\nbased on human interactions with machine generated data. Our ILLUME executes\nthe following loop: Given an image-question-answer prompt, the VLM samples\nmultiple candidate rationales, and a human critic provides minimal feedback via\npreference selection, used for fine-tuning. This loop increases the training\ndata and gradually carves out the VLM's rationalization capabilities that are\naligned with human intend. Our exhaustive experiments demonstrate that ILLUME\nis competitive with standard supervised fine-tuning while using significantly\nfewer training data and only requiring minimal feedback.\n","authors":["Manuel Brack","Patrick Schramowski","Björn Deiseroth","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2208.08241v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14447v2","updated":"2023-01-20T10:01:31Z","published":"2022-12-29T20:05:26Z","title":"A Theoretical Framework for AI Models Explainability","summary":"  EXplainable Artificial Intelligence (XAI) is a vibrant research topic in the\nartificial intelligence community, with growing interest across methods and\ndomains. Much has been written about the subject, yet XAI still lacks shared\nterminology and a framework capable of providing structural soundness to\nexplanations. In our work, we address these issues by proposing a novel\ndefinition of explanation that is a synthesis of what can be found in the\nliterature. We recognize that explanations are not atomic but the combination\nof evidence stemming from the model and its input-output mapping, and the human\ninterpretation of this evidence. Furthermore, we fit explanations into the\nproperties of faithfulness (i.e., the explanation being a true description of\nthe model's inner workings and decision-making process) and plausibility (i.e.,\nhow much the explanation looks convincing to the user). Using our proposed\ntheoretical framework simplifies how these properties are operationalized and\nit provides new insight into common explanation methods that we analyze as case\nstudies.\n","authors":["Matteo Rizzo","Alberto Veneri","Andrea Albarelli","Claudio Lucchese","Cristina Conati"],"pdf_url":"https://arxiv.org/pdf/2212.14447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08479v1","updated":"2023-01-20T09:17:39Z","published":"2023-01-20T09:17:39Z","title":"Pneumonia Detection in Chest X-Ray Images : Handling Class Imbalance","summary":"  People all over the globe are affected by pneumonia but deaths due to it are\nhighest in Sub-Saharan Asia and South Asia. In recent years, the overall\nincidence and mortality rate of pneumonia regardless of the utilization of\neffective vaccines and compelling antibiotics has escalated. Thus, pneumonia\nremains a disease that needs spry prevention and treatment. The widespread\nprevalence of pneumonia has caused the research community to come up with a\nframework that helps detect, diagnose and analyze diseases accurately and\npromptly. One of the major hurdles faced by the Artificial Intelligence (AI)\nresearch community is the lack of publicly available datasets for chest\ndiseases, including pneumonia . Secondly, few of the available datasets are\nhighly imbalanced (normal examples are over sampled, while samples with ailment\nare in severe minority) making the problem even more challenging. In this\narticle we present a novel framework for the detection of pneumonia. The\nnovelty of the proposed methodology lies in the tackling of class imbalance\nproblem. The Generative Adversarial Network (GAN), specifically a combination\nof Deep Convolutional Generative Adversarial Network (DCGAN) and Wasserstein\nGAN gradient penalty (WGAN-GP) was applied on the minority class ``Pneumonia''\nfor augmentation, whereas Random Under-Sampling (RUS) was done on the majority\nclass ``No Findings'' to deal with the imbalance problem. The ChestX-Ray8\ndataset, one of the biggest datasets, is used to validate the performance of\nthe proposed framework. The learning phase is completed using transfer learning\non state-of-the-art deep learning models i.e. ResNet-50, Xception, and VGG-16.\nResults obtained exceed state-of-the-art.\n","authors":["Wardah Ali","Eesha Qureshi","Omama Ahmed Farooqi","Rizwan Ahmed Khan"],"pdf_url":"https://arxiv.org/pdf/2301.08479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.02104v3","updated":"2023-01-20T08:46:35Z","published":"2021-08-04T15:11:48Z","title":"Point Discriminative Learning for Data-efficient 3D Point Cloud Analysis","summary":"  3D point cloud analysis has drawn a lot of research attention due to its wide\napplications. However, collecting massive labelled 3D point cloud data is both\ntime-consuming and labor-intensive. This calls for data-efficient learning\nmethods. In this work we propose PointDisc, a point discriminative learning\nmethod to leverage self-supervisions for data-efficient 3D point cloud\nclassification and segmentation. PointDisc imposes a novel point discrimination\nloss on the middle and global level features produced by the backbone network.\nThis point discrimination loss enforces learned features to be consistent with\npoints belonging to the corresponding local shape region and inconsistent with\nrandomly sampled noisy points. We conduct extensive experiments on 3D object\nclassification, 3D semantic and part segmentation, showing the benefits of\nPointDisc for data-efficient learning. Detailed analysis demonstrate that\nPointDisc learns unsupervised features that well capture local and global\ngeometry.\n","authors":["Fayao Liu","Guosheng Lin","Chuan-Sheng Foo","Chaitanya K. Joshi","Jie Lin"],"pdf_url":"https://arxiv.org/pdf/2108.02104v3.pdf","comment":"This work is published in 3DV 2022"},{"id":"http://arxiv.org/abs/2211.09590v2","updated":"2023-01-20T07:38:35Z","published":"2022-11-17T15:36:48Z","title":"Hypergraph Transformer for Skeleton-based Action Recognition","summary":"  Skeleton-based action recognition aims to predict human actions given human\njoint coordinates with skeletal interconnections. To model such off-grid data\npoints and their co-occurrences, Transformer-based formulations would be a\nnatural choice. However, Transformers still lag behind state-of-the-art methods\nusing graph convolutional networks (GCNs). Transformers assume that the input\nis permutation-invariant and homogeneous (partially alleviated by positional\nencoding), which ignores an important characteristic of skeleton data, i.e.,\nbone connectivity. Furthermore, each type of body joint has a clear physical\nmeaning in human motion, i.e., motion retains an intrinsic relationship\nregardless of the joint coordinates, which is not explored in Transformers. In\nfact, certain re-occurring groups of body joints are often involved in specific\nactions, such as the subconscious hand movement for keeping balance. Vanilla\nattention is incapable of describing such underlying relations that are\npersistent and beyond pair-wise. In this work, we aim to exploit these unique\naspects of skeleton data to close the performance gap between Transformers and\nGCNs. Specifically, we propose a new self-attention (SA) extension, named\nHypergraph Self-Attention (HyperSA), to incorporate inherently higher-order\nrelations into the model. The K-hop relative positional embeddings are also\nemployed to take bone connectivity into account. We name the resulting model\nHyperformer, and it achieves comparable or better performance w.r.t. accuracy\nand efficiency than state-of-the-art GCN architectures on NTU RGB+D, NTU RGB+D\n120, and Northwestern-UCLA datasets. On the largest NTU RGB+D 120 dataset, the\nsignificantly improved performance reached by our Hyperformer demonstrates the\nunderestimated potential of Transformer models in this field.\n","authors":["Yuxuan Zhou","Chao Li","Zhi-Qi Cheng","Yifeng Geng","Xuansong Xie","Margret Keuper"],"pdf_url":"https://arxiv.org/pdf/2211.09590v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08455v1","updated":"2023-01-20T07:36:29Z","published":"2023-01-20T07:36:29Z","title":"Spatial Steerability of GANs via Self-Supervision from Discriminator","summary":"  Generative models make huge progress to the photorealistic image synthesis in\nrecent years. To enable human to steer the image generation process and\ncustomize the output, many works explore the interpretable dimensions of the\nlatent space in GANs. Existing methods edit the attributes of the output image\nsuch as orientation or color scheme by varying the latent code along certain\ndirections. However, these methods usually require additional human annotations\nfor each pretrained model, and they mostly focus on editing global attributes.\nIn this work, we propose a self-supervised approach to improve the spatial\nsteerability of GANs without searching for steerable directions in the latent\nspace or requiring extra annotations. Specifically, we design randomly sampled\nGaussian heatmaps to be encoded into the intermediate layers of generative\nmodels as spatial inductive bias. Along with training the GAN model from\nscratch, these heatmaps are being aligned with the emerging attention of the\nGAN's discriminator in a self-supervised learning manner. During inference,\nhuman users can intuitively interact with the spatial heatmaps to edit the\noutput image, such as varying the scene layout or moving objects in the scene.\nExtensive experiments show that the proposed method not only enables spatial\nediting over human faces, animal faces, outdoor scenes, and complicated indoor\nscenes, but also brings improvement in synthesis quality.\n","authors":["Jianyuan Wang","Ceyuan Yang","Yinghao Xu","Yujun Shen","Hongdong Li","Bolei Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.08455v1.pdf","comment":"This manuscript is a journal extension of our previous conference\n  work (arXiv:2112.00718), submitted to TPAMI"},{"id":"http://arxiv.org/abs/2204.10419v2","updated":"2023-01-20T07:11:44Z","published":"2022-04-21T21:59:24Z","title":"Learning Sequential Latent Variable Models from Multimodal Time Series\n  Data","summary":"  Sequential modelling of high-dimensional data is an important problem that\nappears in many domains including model-based reinforcement learning and\ndynamics identification for control. Latent variable models applied to\nsequential data (i.e., latent dynamics models) have been shown to be a\nparticularly effective probabilistic approach to solve this problem, especially\nwhen dealing with images. However, in many application areas (e.g., robotics),\ninformation from multiple sensing modalities is available -- existing latent\ndynamics methods have not yet been extended to effectively make use of such\nmultimodal sequential data. Multimodal sensor streams can be correlated in a\nuseful manner and often contain complementary information across modalities. In\nthis work, we present a self-supervised generative modelling framework to\njointly learn a probabilistic latent state representation of multimodal data\nand the respective dynamics. Using synthetic and real-world datasets from a\nmultimodal robotic planar pushing task, we demonstrate that our approach leads\nto significant improvements in prediction and representation quality.\nFurthermore, we compare to the common learning baseline of concatenating each\nmodality in the latent space and show that our principled probabilistic\nformulation performs better. Finally, despite being fully self-supervised, we\ndemonstrate that our method is nearly as effective as an existing supervised\napproach that relies on ground truth labels.\n","authors":["Oliver Limoyo","Trevor Ablett","Jonathan Kelly"],"pdf_url":"https://arxiv.org/pdf/2204.10419v2.pdf","comment":"In: Petrovic, I., Menegatti, E., Markovi\\'c, I. (eds) Intelligent\n  Autonomous Systems 17. IAS 2022. Lecture Notes in Networks and Systems, vol\n  577. Springer, Cham"},{"id":"http://arxiv.org/abs/2204.04457v3","updated":"2023-01-20T07:05:59Z","published":"2022-04-09T12:02:50Z","title":"Refining time-space traffic diagrams: A multiple linear regression model","summary":"  A time-space traffic (TS) diagram, which presents traffic states in\ntime-space cells with color, is an important traffic analysis and visualization\ntool. Despite its importance for transportation research and engineering, most\nTS diagrams that have already existed or are being produced are too coarse to\nexhibit detailed traffic dynamics due to the limitations of existing\ninformation technology and traffic infrastructure investment. To increase the\nresolution of a TS diagram and enable it to present ample traffic details, this\npaper introduces the TS diagram refinement problem and proposes a multiple\nlinear regression-based model to solve the problem. Two tests, which attempt to\nincrease the resolution of a TS diagram 4 and 16 times, are carried out to\nevaluate the performance of the proposed model. Data collected at different\ntimes, in different locations and even in different countries are employed to\nthoroughly evaluate the accuracy and transferability of the proposed model.\nStrict tests with diverse data show that the proposed model, despite its\nsimplicity, is able to refine a TS diagram with promising accuracy and reliable\ntransferability. The proposed refinement model will \"save\" widely existing TS\ndiagrams from their blurry \"faces\" and enable TS diagrams to show more traffic\ndetails.\n","authors":["Zhengbing He"],"pdf_url":"https://arxiv.org/pdf/2204.04457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08448v1","updated":"2023-01-20T07:01:01Z","published":"2023-01-20T07:01:01Z","title":"Source-free Subject Adaptation for EEG-based Visual Recognition","summary":"  This paper focuses on subject adaptation for EEG-based visual recognition. It\naims at building a visual stimuli recognition system customized for the target\nsubject whose EEG samples are limited, by transferring knowledge from abundant\ndata of source subjects. Existing approaches consider the scenario that samples\nof source subjects are accessible during training. However, it is often\ninfeasible and problematic to access personal biological data like EEG signals\ndue to privacy issues. In this paper, we introduce a novel and practical\nproblem setup, namely source-free subject adaptation, where the source subject\ndata are unavailable and only the pre-trained model parameters are provided for\nsubject adaptation. To tackle this challenging problem, we propose\nclassifier-based data generation to simulate EEG samples from source subjects\nusing classifier responses. Using the generated samples and target subject\ndata, we perform subject-independent feature learning to exploit the common\nknowledge shared across different subjects. Notably, our framework is\ngeneralizable and can adopt any subject-independent learning method. In the\nexperiments on the EEG-ImageNet40 benchmark, our model brings consistent\nimprovements regardless of the choice of subject-independent learning. Also,\nour method shows promising performance, recording top-1 test accuracy of 74.6%\nunder the 5-shot setting even without relying on source data. Our code can be\nfound at\nhttps://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Source_Free_Subject_Adaptation_for_EEG.\n","authors":["Pilhyeon Lee","Seogkyu Jeon","Sunhee Hwang","Minjung Shin","Hyeran Byun"],"pdf_url":"https://arxiv.org/pdf/2301.08448v1.pdf","comment":"Accepted by the 11th IEEE International Winter Conference on\n  Brain-Computer Interface (BCI 2023). Code is available at\n  https://github.com/DeepBCI/Deep-BCI"},{"id":"http://arxiv.org/abs/2301.08443v1","updated":"2023-01-20T06:51:34Z","published":"2023-01-20T06:51:34Z","title":"DIFAI: Diverse Facial Inpainting using StyleGAN Inversion","summary":"  Image inpainting is an old problem in computer vision that restores occluded\nregions and completes damaged images. In the case of facial image inpainting,\nmost of the methods generate only one result for each masked image, even though\nthere are other reasonable possibilities. To prevent any potential biases and\nunnatural constraints stemming from generating only one image, we propose a\nnovel framework for diverse facial inpainting exploiting the embedding space of\nStyleGAN. Our framework employs pSp encoder and SeFa algorithm to identify\nsemantic components of the StyleGAN embeddings and feed them into our proposed\nSPARN decoder that adopts region normalization for plausible inpainting. We\ndemonstrate that our proposed method outperforms several state-of-the-art\nmethods.\n","authors":["Dongsik Yoon","Jeong-gi Kwak","Yuanming Li","David Han","Hanseok Ko"],"pdf_url":"https://arxiv.org/pdf/2301.08443v1.pdf","comment":"ICIP 2022"},{"id":"http://arxiv.org/abs/2301.08433v1","updated":"2023-01-20T06:11:17Z","published":"2023-01-20T06:11:17Z","title":"Unsupervised Light Field Depth Estimation via Multi-view Feature\n  Matching with Occlusion Prediction","summary":"  Depth estimation from light field (LF) images is a fundamental step for some\napplications. Recently, learning-based methods have achieved higher accuracy\nand efficiency than the traditional methods. However, it is costly to obtain\nsufficient depth labels for supervised training. In this paper, we propose an\nunsupervised framework to estimate depth from LF images. First, we design a\ndisparity estimation network (DispNet) with a coarse-to-fine structure to\npredict disparity maps from different view combinations by performing\nmulti-view feature matching to learn the correspondences more effectively. As\nocclusions may cause the violation of photo-consistency, we design an occlusion\nprediction network (OccNet) to predict the occlusion maps, which are used as\nthe element-wise weights of photometric loss to solve the occlusion issue and\nassist the disparity learning. With the disparity maps estimated by multiple\ninput combinations, we propose a disparity fusion strategy based on the\nestimated errors with effective occlusion handling to obtain the final\ndisparity map. Experimental results demonstrate that our method achieves\nsuperior performance on both the dense and sparse LF images, and also has\nbetter generalization ability to the real-world LF images.\n","authors":["Shansi Zhang","Nan Meng","Edmund Y. Lam"],"pdf_url":"https://arxiv.org/pdf/2301.08433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.14030v4","updated":"2023-01-20T05:47:22Z","published":"2022-04-29T11:55:35Z","title":"Neural Implicit Representations for Physical Parameter Inference from a\n  Single Video","summary":"  Neural networks have recently been used to analyze diverse physical systems\nand to identify the underlying dynamics. While existing methods achieve\nimpressive results, they are limited by their strong demand for training data\nand their weak generalization abilities to out-of-distribution data. To\novercome these limitations, in this work we propose to combine neural implicit\nrepresentations for appearance modeling with neural ordinary differential\nequations (ODEs) for modelling physical phenomena to obtain a dynamic scene\nrepresentation that can be identified directly from visual observations. Our\nproposed model combines several unique advantages: (i) Contrary to existing\napproaches that require large training datasets, we are able to identify\nphysical parameters from only a single video. (ii) The use of neural implicit\nrepresentations enables the processing of high-resolution videos and the\nsynthesis of photo-realistic images. (iii) The embedded neural ODE has a known\nparametric form that allows for the identification of interpretable physical\nparameters, and (iv) long-term prediction in state space. (v) Furthermore, the\nphoto-realistic rendering of novel scenes with modified physical parameters\nbecomes possible.\n","authors":["Florian Hofherr","Lukas Koestler","Florian Bernard","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2204.14030v4.pdf","comment":"Published in IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2023"},{"id":"http://arxiv.org/abs/2301.08414v1","updated":"2023-01-20T04:02:13Z","published":"2023-01-20T04:02:13Z","title":"FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation","summary":"  The great potential of unsupervised monocular depth estimation has been\ndemonstrated by many works due to low annotation cost and impressive accuracy\ncomparable to supervised methods. To further improve the performance, recent\nworks mainly focus on designing more complex network structures and exploiting\nextra supervised information, e.g., semantic segmentation. These methods\noptimize the models by exploiting the reconstructed relationship between the\ntarget and reference images in varying degrees. However, previous methods prove\nthat this image reconstruction optimization is prone to get trapped in local\nminima. In this paper, our core idea is to guide the optimization with prior\nknowledge from pretrained Flow-Net. And we show that the bottleneck of\nunsupervised monocular depth estimation can be broken with our simple but\neffective framework named FG-Depth. In particular, we propose (i) a flow\ndistillation loss to replace the typical photometric loss that limits the\ncapacity of the model and (ii) a prior flow based mask to remove invalid pixels\nthat bring the noise in training loss. Extensive experiments demonstrate the\neffectiveness of each component, and our approach achieves state-of-the-art\nresults on both KITTI and NYU-Depth-v2 datasets.\n","authors":["Junyu Zhu","Lina Liu","Yong Liu","Wanlong Li","Feng Wen","Hongbo Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08414v1.pdf","comment":"Accepted by ICRA2023"},{"id":"http://arxiv.org/abs/2301.08413v1","updated":"2023-01-20T03:39:35Z","published":"2023-01-20T03:39:35Z","title":"When Source-Free Domain Adaptation Meets Label Propagation","summary":"  Source-free domain adaptation, where only a pre-trained source model is used\nto adapt to the target distribution, is a more general approach to achieving\ndomain adaptation. However, it can be challenging to capture the inherent\nstructure of the target features accurately due to the lack of supervised\ninformation on the target domain. To tackle this problem, we propose a novel\napproach called Adaptive Local Transfer (ALT) that tries to achieve efficient\nfeature clustering from the perspective of label propagation. ALT divides the\ntarget data into inner and outlier samples based on the adaptive threshold of\nthe learning state, and applies a customized learning strategy to best fits the\ndata property. Specifically, inner samples are utilized for learning\nintra-class structure thanks to their relatively well-clustered properties. The\nlow-density outlier samples are regularized by input consistency to achieve\nhigh accuracy with respect to the ground truth labels. In this way, local\nclustering can be prevented from forming spurious clusters while effectively\npropagating label information among subpopulations. Empirical evidence\ndemonstrates that ALT outperforms the state of the arts on three public\nbenchmarks: Office-31, Office-Home, and VisDA.\n","authors":["Chunwei Wu","Guitao Cao","Yan Li","Xidong Xi","Wenming Cao","Hong Wang"],"pdf_url":"https://arxiv.org/pdf/2301.08413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01201v2","updated":"2023-01-20T03:13:47Z","published":"2022-12-20T07:32:12Z","title":"Uncertainty in Real-Time Semantic Segmentation on Embedded Systems","summary":"  Application for semantic segmentation models in areas such as autonomous\nvehicles and human computer interaction require real-time predictive\ncapabilities. The challenges of addressing real-time application is amplified\nby the need to operate on resource constrained hardware. Whilst development of\nreal-time methods for these platforms has increased, these models are unable to\nsufficiently reason about uncertainty present. This paper addresses this by\ncombining deep feature extraction from pre-trained models with Bayesian\nregression and moment propagation for uncertainty aware predictions. We\ndemonstrate how the proposed method can yield meaningful uncertainty on\nembedded hardware in real-time whilst maintaining predictive performance.\n","authors":["Ethan Goan","Clinton Fookes"],"pdf_url":"https://arxiv.org/pdf/2301.01201v2.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.08408v1","updated":"2023-01-20T03:10:19Z","published":"2023-01-20T03:10:19Z","title":"Identity masking effectiveness and gesture recognition: Effects of eye\n  enhancement in seeing through the mask","summary":"  Face identity masking algorithms developed in recent years aim to protect the\nprivacy of people in video recordings. These algorithms are designed to\ninterfere with identification, while preserving information about facial\nactions. An important challenge is to preserve subtle actions in the eye\nregion, while obscuring the salient identity cues from the eyes. We evaluated\nthe effectiveness of identity-masking algorithms based on Canny filters,\napplied with and without eye enhancement, for interfering with identification\nand preserving facial actions. In Experiments 1 and 2, we tested human\nparticipants' ability to match the facial identity of a driver in a low\nresolution video to a high resolution facial image. Results showed that both\nmasking methods impaired identification, and that eye enhancement did not alter\nthe effectiveness of the Canny filter mask. In Experiment 3, we tested action\npreservation and found that neither method interfered significantly with driver\naction perception. We conclude that relatively simple, filter-based masking\nalgorithms, which are suitable for application to low quality video, can be\nused in privacy protection without compromising action perception.\n","authors":["Madeline Rachow","Thomas Karnowski","Alice J. O'Toole"],"pdf_url":"https://arxiv.org/pdf/2301.08408v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2209.08162v2","updated":"2023-01-20T02:57:46Z","published":"2022-09-16T20:30:45Z","title":"Uncertainty Quantification of Collaborative Detection for Self-Driving","summary":"  Sharing information between connected and autonomous vehicles (CAVs)\nfundamentally improves the performance of collaborative object detection for\nself-driving. However, CAVs still have uncertainties on object detection due to\npractical challenges, which will affect the later modules in self-driving such\nas planning and control. Hence, uncertainty quantification is crucial for\nsafety-critical systems such as CAVs. Our work is the first to estimate the\nuncertainty of collaborative object detection. We propose a novel uncertainty\nquantification method, called Double-M Quantification, which tailors a moving\nblock bootstrap (MBB) algorithm with direct modeling of the multivariant\nGaussian distribution of each corner of the bounding box. Our method captures\nboth the epistemic uncertainty and aleatoric uncertainty with one inference\npass based on the offline Double-M training process. And it can be used with\ndifferent collaborative object detectors. Through experiments on the\ncomprehensive collaborative perception dataset, we show that our Double-M\nmethod achieves more than 4X improvement on uncertainty score and more than 3%\naccuracy improvement, compared with the state-of-the-art uncertainty\nquantification methods. Our code is public on\nhttps://coperception.github.io/double-m-quantification.\n","authors":["Sanbao Su","Yiming Li","Sihong He","Songyang Han","Chen Feng","Caiwen Ding","Fei Miao"],"pdf_url":"https://arxiv.org/pdf/2209.08162v2.pdf","comment":"This paper has been accepted by the 2023 IEEE International\n  Conference on Robotics and Automation (ICRA 2023)"},{"id":"http://arxiv.org/abs/2201.09169v2","updated":"2023-01-20T02:57:36Z","published":"2022-01-23T03:39:31Z","title":"Rich Action-semantic Consistent Knowledge for Early Action Prediction","summary":"  Early action prediction (EAP) aims to recognize human actions from a part of\naction execution in ongoing videos, which is an important task for many\npractical applications. Most prior works treat partial or full videos as a\nwhole, ignoring rich action knowledge hidden in videos, i.e., semantic\nconsistencies among different partial videos. In contrast, we partition\noriginal partial or full videos to form a new series of partial videos and mine\nthe Action Semantic Consistent Knowledge (ASCK) among these new partial videos\nevolving in arbitrary progress levels. Moreover, a novel Rich Action-semantic\nConsistent Knowledge network (RACK) under the teacher-student framework is\nproposed for EAP. Firstly, we use a two-stream pre-trained model to extract\nfeatures of videos. Secondly, we treat the RGB or flow features of the partial\nvideos as nodes and their action semantic consistencies as edges. Next, we\nbuild a bi-directional semantic graph for the teacher network and a\nsingle-directional semantic graph for the student network to model rich ASCK\namong partial videos. The MSE and MMD losses are incorporated as our\ndistillation loss to enrich the ASCK of partial videos from the teacher to the\nstudent network. Finally, we obtain the final prediction by summering the\nlogits of different sub-networks and applying a softmax layer. Extensive\nexperiments and ablative studies have been conducted, demonstrating the\neffectiveness of modeling rich ASCK for EAP. With the proposed RACK, we have\nachieved state-of-the-art performance on three benchmarks. The code will be\nreleased if the paper is accepted.\n","authors":["Xiaoli Liu","Jianqin Yin","Di Guo"],"pdf_url":"https://arxiv.org/pdf/2201.09169v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2301.08390v1","updated":"2023-01-20T01:56:19Z","published":"2023-01-20T01:56:19Z","title":"Open-Set Likelihood Maximization for Few-Shot Learning","summary":"  We tackle the Few-Shot Open-Set Recognition (FSOSR) problem, i.e. classifying\ninstances among a set of classes for which we only have a few labeled samples,\nwhile simultaneously detecting instances that do not belong to any known class.\nWe explore the popular transductive setting, which leverages the unlabelled\nquery instances at inference. Motivated by the observation that existing\ntransductive methods perform poorly in open-set scenarios, we propose a\ngeneralization of the maximum likelihood principle, in which latent scores\ndown-weighing the influence of potential outliers are introduced alongside the\nusual parametric model. Our formulation embeds supervision constraints from the\nsupport set and additional penalties discouraging overconfident predictions on\nthe query set. We proceed with a block-coordinate descent, with the latent\nscores and parametric model co-optimized alternately, thereby benefiting from\neach other. We call our resulting formulation \\textit{Open-Set Likelihood\nOptimization} (OSLO). OSLO is interpretable and fully modular; it can be\napplied on top of any pre-trained model seamlessly. Through extensive\nexperiments, we show that our method surpasses existing inductive and\ntransductive methods on both aspects of open-set recognition, namely inlier\nclassification and outlier detection.\n","authors":["Malik Boudiaf","Etienne Bennequin","Myriam Tami","Antoine Toubhans","Pablo Piantanida","Céline Hudelot","Ismail Ben Ayed"],"pdf_url":"https://arxiv.org/pdf/2301.08390v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2206.09236"},{"id":"http://arxiv.org/abs/2301.08387v1","updated":"2023-01-20T01:46:07Z","published":"2023-01-20T01:46:07Z","title":"Occlusion Reasoning for Skeleton Extraction of Self-Occluded Tree\n  Canopies","summary":"  In this work, we present a method to extract the skeleton of a self-occluded\ntree canopy by estimating the unobserved structures of the tree. A tree\nskeleton compactly describes the topological structure and contains useful\ninformation such as branch geometry, positions and hierarchy. This can be\ncritical to planning contact interactions for agricultural manipulation, yet is\ndifficult to gain due to occlusion by leaves, fruits and other branches. Our\nmethod uses an instance segmentation network to detect visible trunk, branches,\nand twigs. Then, based on the observed tree structures, we build a custom 3D\nlikelihood map in the form of an occupancy grid to hypothesize on the presence\nof occluded skeletons through a series of minimum cost path searches. We show\nthat our method outperforms baseline methods in highly occluded scenes,\ndemonstrated through a set of experiments on a synthetic tree dataset.\nQualitative results are also presented on a real tree dataset collected from\nthe field.\n","authors":["Chung Hee Kim","George Kantor"],"pdf_url":"https://arxiv.org/pdf/2301.08387v1.pdf","comment":"7 pages, 10 figures, submitted to ICRA 2023"},{"id":"http://arxiv.org/abs/2212.07398v2","updated":"2023-01-20T00:47:23Z","published":"2022-12-14T18:31:47Z","title":"Self-Play and Self-Describe: Policy Adaptation with Vision-Language\n  Foundation Models","summary":"  Recent progress on vision-language foundation models have brought significant\nadvancement to building general-purpose robots. By using the pre-trained models\nto encode the scene and instructions as inputs for decision making, the\ninstruction-conditioned policy can generalize across different objects and\ntasks. While this is encouraging, the policy still fails in most cases given an\nunseen task or environment. To adapt the policy to unseen tasks and\nenvironments, we explore a new paradigm on leveraging the pre-trained\nfoundation models with Self-PLAY and Self-Describe (SPLAYD). When deploying the\ntrained policy to a new task or a new environment, we first let the policy\nself-play with randomly generated instructions to record the demonstrations.\nWhile the execution could be wrong, we can use the pre-trained foundation\nmodels to accurately self-describe (i.e., re-label or classify) the\ndemonstrations. This automatically provides new pairs of\ndemonstration-instruction data for policy fine-tuning. We evaluate our method\non a broad range of experiments with the focus on generalization on unseen\nobjects, unseen tasks, unseen environments, and sim-to-real transfer. We show\nSPLAYD improves baselines by a large margin in all cases. Our project page is\navailable at https://geyuying.github.io/SPLAYD/\n","authors":["Yuying Ge","Annabella Macaluso","Li Erran Li","Ping Luo","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2212.07398v2.pdf","comment":"Project page: https://geyuying.github.io/SPLAYD/"},{"id":"http://arxiv.org/abs/2301.08365v1","updated":"2023-01-20T00:05:18Z","published":"2023-01-20T00:05:18Z","title":"On Retrospective $k$-space Subsampling schemes For Deep MRI\n  Reconstruction","summary":"  $\\textbf{Purpose:}$ The MRI $k$-space acquisition is time consuming.\nTraditional techniques aim to acquire accelerated data, which in conjunction\nwith recent DL methods, aid in producing high-fidelity images in truncated\ntimes. Conventionally, subsampling the $k$-space is performed by utilizing\nCartesian-rectilinear trajectories, which even with the use of DL, provide\nimprecise reconstructions, though, a plethora of non-rectilinear or\nnon-Cartesian trajectories can be implemented in modern MRI scanners. This work\ninvestigates the effect of the $k$-space subsampling scheme on the quality of\nreconstructed accelerated MRI measurements produced by trained DL models.\n  $\\textbf{Methods:}$ The RecurrentVarNet was used as the DL-based\nMRI-reconstruction architecture. Cartesian fully-sampled multi-coil $k$-space\nmeasurements from three datasets with different accelerations were\nretrospectively subsampled using eight distinct subsampling schemes (four\nCartesian-rectilinear, two Cartesian non-rectilinear, two non-Cartesian).\nExperiments were conducted in two frameworks: Scheme-specific, where a distinct\nmodel was trained and evaluated for each dataset-subsampling scheme pair, and\nmulti-scheme, where for each dataset a single model was trained on data\nrandomly subsampled by any of the eight schemes and evaluated on data\nsubsampled by all schemes.\n  $\\textbf{Results:}$ In the scheme-specific setting RecurrentVarNets trained\nand evaluated on non-rectilinearly subsampled data demonstrated superior\nperformance especially for high accelerations, whilst in the multi-scheme\nsetting, reconstruction performance on rectilinearly subsampled data improved\nwhen compared to the scheme-specific experiments.\n  $\\textbf{Conclusion:}$ Training DL-based MRI reconstruction algorithms on\nnon-rectilinearly subsampled measurements can produce more faithful\nreconstructions.\n","authors":["George Yiasemis","Clara I. Sánchez","Jan-Jakob Sonke","Jonas Teuwen"],"pdf_url":"https://arxiv.org/pdf/2301.08365v1.pdf","comment":"25 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2301.07836v2","updated":"2023-01-20T22:26:21Z","published":"2023-01-19T01:05:18Z","title":"Self Supervision Does Not Help Natural Language Supervision at Scale","summary":"  Self supervision and natural language supervision have emerged as two\nexciting ways to train general purpose image encoders which excel at a variety\nof downstream tasks. Recent works such as M3AE and SLIP have suggested that\nthese approaches can be effectively combined, but most notably their results\nuse small pre-training datasets (<50M samples) and don't effectively reflect\nthe large-scale regime (>100M examples) that is commonly used for these\napproaches. Here we investigate whether a similar approach can be effective\nwhen trained with a much larger amount of data. We find that a combination of\ntwo state of the art approaches: masked auto-encoders, MAE and contrastive\nlanguage image pre-training, CLIP provides a benefit over CLIP when trained on\na corpus of 11.3M image-text pairs, but little to no benefit (as evaluated on a\nsuite of common vision tasks) over CLIP when trained on a large corpus of 1.4B\nimages. Our work provides some much needed clarity into the effectiveness (or\nlack thereof) of self supervision for large-scale image-text training.\n","authors":["Floris Weers","Vaishaal Shankar","Angelos Katharopoulos","Yinfei Yang","Tom Gunter"],"pdf_url":"https://arxiv.org/pdf/2301.07836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08815v1","updated":"2023-01-20T22:13:48Z","published":"2023-01-20T22:13:48Z","title":"DiffusionCT: Latent Diffusion Model for CT Image Standardization","summary":"  Computed tomography (CT) imaging is a widely used modality for early lung\ncancer diagnosis, treatment, and prognosis. Features extracted from CT images\nare now accepted to quantify spatial and temporal variations in tumor\narchitecture and function. However, CT images are often acquired using scanners\nfrom different vendors with customized acquisition standards, resulting in\nsignificantly different texture features even for the same patient, posing a\nfundamental challenge to downstream studies. Existing CT image harmonization\nmodels rely on supervised or semi-supervised techniques, with limited\nperformance. In this paper, we have proposed a diffusion-based CT image\nstandardization model called DiffusionCT which works on latent space by mapping\nlatent distribution into a standard distribution. DiffusionCT incorporates an\nUnet-based encoder-decoder and a diffusion model embedded in its bottleneck\npart. The Unet first trained without the diffusion model to learn the latent\nrepresentation of the input data. The diffusion model is trained in the next\ntraining phase. All the trained models work together on image standardization.\nThe encoded representation outputted from the Unet encoder passes through the\ndiffusion model, and the diffusion model maps the distribution in to target\nstandard image domain. Finally, the decode takes that transformed latent\nrepresentation to synthesize a standardized image. The experimental results\nshow that DiffusionCT significantly improves the performance of the\nstandardization task.\n","authors":["Md Selim","Jie Zhang","Michael A. Brooks","Ge Wang","Jin Chen"],"pdf_url":"https://arxiv.org/pdf/2301.08815v1.pdf","comment":"6 pages, 03 figures and 01 tables"},{"id":"http://arxiv.org/abs/2212.01548v2","updated":"2023-01-20T21:53:11Z","published":"2022-12-03T06:04:11Z","title":"FedRolex: Model-Heterogeneous Federated Learning with Rolling Sub-Model\n  Extraction","summary":"  Most cross-device federated learning (FL) studies focus on the\nmodel-homogeneous setting where the global server model and local client models\nare identical. However, such constraint not only excludes low-end clients who\nwould otherwise make unique contributions to model training but also restrains\nclients from training large models due to on-device resource bottlenecks. In\nthis work, we propose FedRolex, a partial training (PT)-based approach that\nenables model-heterogeneous FL and can train a global server model larger than\nthe largest client model. At its core, FedRolex employs a rolling sub-model\nextraction scheme that allows different parts of the global server model to be\nevenly trained, which mitigates the client drift induced by the inconsistency\nbetween individual client models and server model architectures. We show that\nFedRolex outperforms state-of-the-art PT-based model-heterogeneous FL methods\n(e.g. Federated Dropout) and reduces the gap between model-heterogeneous and\nmodel-homogeneous FL, especially under the large-model large-dataset regime. In\naddition, we provide theoretical statistical analysis on its advantage over\nFederated Dropout and evaluate FedRolex on an emulated real-world device\ndistribution to show that FedRolex can enhance the inclusiveness of FL and\nboost the performance of low-end devices that would otherwise not benefit from\nFL. Our code is available at: https://github.com/AIoT-MLSys-Lab/FedRolex\n","authors":["Samiul Alam","Luyang Liu","Ming Yan","Mi Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.01548v2.pdf","comment":"20 pages, 7 Figures, Published in 36th Conference on Neural\n  Information Processing And Systems"},{"id":"http://arxiv.org/abs/2208.11050v2","updated":"2023-01-20T21:17:20Z","published":"2022-08-23T15:57:19Z","title":"Self-Trained Proposal Networks for the Open World","summary":"  Current state-of-the-art object proposal networks are trained with a\nclosed-world assumption, meaning they learn to only detect objects of the\ntraining classes. These models fail to provide high recall in open-world\nenvironments where important novel objects may be encountered. While a handful\nof recent works attempt to tackle this problem, they fail to consider that the\noptimal behavior of a proposal network can vary significantly depending on the\ndata and application. Our goal is to provide a flexible proposal solution that\ncan be easily tuned to suit a variety of open-world settings. To this end, we\ndesign a Self-Trained Proposal Network (STPN) that leverages an adjustable\nhybrid architecture, a novel self-training procedure, and dynamic loss\ncomponents to optimize the tradeoff between known and unknown object detection\nperformance. To thoroughly evaluate our method, we devise several new\nchallenges which invoke varying degrees of label bias by altering known class\ndiversity and label count. We find that in every task, STPN easily outperforms\nexisting baselines (e.g., RPN, OLN). Our method is also highly data efficient,\nsurpassing baseline recall with a fraction of the labeled data.\n","authors":["Matthew Inkawhich","Nathan Inkawhich","Hai Li","Yiran Chen"],"pdf_url":"https://arxiv.org/pdf/2208.11050v2.pdf","comment":"19 pages, 9 figures, 10 tables"},{"id":"http://arxiv.org/abs/2301.08802v1","updated":"2023-01-20T21:01:39Z","published":"2023-01-20T21:01:39Z","title":"Impact of PCA-based preprocessing and different CNN structures on\n  deformable registration of sonograms","summary":"  Central venous catheters (CVC) are commonly inserted into the large veins of\nthe neck, e.g. the internal jugular vein (IJV). CVC insertion may cause serious\ncomplications like misplacement into an artery or perforation of cervical\nvessels. Placing a CVC under sonographic guidance is an appropriate method to\nreduce such adverse events, if anatomical landmarks like venous and arterial\nvessels can be detected reliably. This task shall be solved by registration of\npatient individual images vs. an anatomically labelled reference image. In this\nwork, a linear, affine transformation is performed on cervical sonograms,\nfollowed by a non-linear transformation to achieve a more precise registration.\nVoxelmorph (VM), a learning-based library for deformable image registration\nusing a convolutional neural network (CNN) with U-Net structure was used for\nnon-linear transformation. The impact of principal component analysis\n(PCA)-based pre-denoising of patient individual images, as well as the impact\nof modified net structures with differing complexities on registration results\nwere examined visually and quantitatively, the latter using metrics for\ndeformation and image similarity. Using the PCA-approximated cervical sonograms\nresulted in decreased mean deformation lengths between 18% and 66% compared to\ntheir original image counterparts, depending on net structure. In addition,\nreducing the number of convolutional layers led to improved image similarity\nwith PCA images, while worsening in original images. Despite a large reduction\nof network parameters, no overall decrease in registration quality was\nobserved, leading to the conclusion that the original net structure is\noversized for the task at hand.\n","authors":["Christian Schmidt","Heinrich Martin Overhoff"],"pdf_url":"https://arxiv.org/pdf/2301.08802v1.pdf","comment":"8 pages, 7 figures Presented at WSCG 2022"},{"id":"http://arxiv.org/abs/2301.08800v1","updated":"2023-01-20T20:56:52Z","published":"2023-01-20T20:56:52Z","title":"In-situ Water quality monitoring in Oil and Gas operations","summary":"  From agriculture to mining, to energy, surface water quality monitoring is an\nessential task. As oil and gas operators work to reduce the consumption of\nfreshwater, it is increasingly important to actively manage fresh and non-fresh\nwater resources over the long term. For large-scale monitoring, manual sampling\nat many sites has become too time-consuming and unsustainable, given the sheer\nnumber of dispersed ponds, small lakes, playas, and wetlands over a large area.\nTherefore, satellite-based environmental monitoring presents great potential.\nMany existing satellite-based monitoring studies utilize index-based methods to\nmonitor large water bodies such as rivers and oceans. However, these existing\nmethods fail when monitoring small ponds-the reflectance signal received from\nsmall water bodies is too weak to detect. To address this challenge, we propose\na new Water Quality Enhanced Index (WQEI) Model, which is designed to enable\nusers to determine contamination levels in water bodies with weak reflectance\npatterns. Our results show that 1) WQEI is a good indicator of water turbidity\nvalidated with 1200 water samples measured in the laboratory, and 2) by\napplying our method to commonly available satellite data (e.g. LandSat8), one\ncan achieve high accuracy water quality monitoring efficiently in large\nregions. This provides a tool for operators to optimize the quality of water\nstored within surface storage ponds and increasing the readiness and\navailability of non-fresh water.\n","authors":["Satish Kumar","Rui Kou","Henry Hill","Jake Lempges","Eric Qian","Vikram Jayaram"],"pdf_url":"https://arxiv.org/pdf/2301.08800v1.pdf","comment":"15 pages, 8 figures, SPIE Defense + Commercial: Algorithms,\n  Technologies, and Applications for Multispectral and Hyperspectral Imaging\n  XXIX"},{"id":"http://arxiv.org/abs/2301.08798v1","updated":"2023-01-20T20:54:25Z","published":"2023-01-20T20:54:25Z","title":"DeepCOVID-Fuse: A Multi-modality Deep Learning Model Fusing Chest\n  X-Radiographs and Clinical Variables to Predict COVID-19 Risk Levels","summary":"  Propose: To present DeepCOVID-Fuse, a deep learning fusion model to predict\nrisk levels in patients with confirmed coronavirus disease 2019 (COVID-19) and\nto evaluate the performance of pre-trained fusion models on full or partial\ncombination of chest x-ray (CXRs) or chest radiograph and clinical variables.\n  Materials and Methods: The initial CXRs, clinical variables and outcomes\n(i.e., mortality, intubation, hospital length of stay, ICU admission) were\ncollected from February 2020 to April 2020 with reverse-transcription\npolymerase chain reaction (RT-PCR) test results as the reference standard. The\nrisk level was determined by the outcome. The fusion model was trained on 1657\npatients (Age: 58.30 +/- 17.74; Female: 807) and validated on 428 patients\n(56.41 +/- 17.03; 190) from Northwestern Memorial HealthCare system and was\ntested on 439 patients (56.51 +/- 17.78; 205) from a single holdout hospital.\nPerformance of pre-trained fusion models on full or partial modalities were\ncompared on the test set using the DeLong test for the area under the receiver\noperating characteristic curve (AUC) and the McNemar test for accuracy,\nprecision, recall and F1.\n  Results: The accuracy of DeepCOVID-Fuse trained on CXRs and clinical\nvariables is 0.658, with an AUC of 0.842, which significantly outperformed (p <\n0.05) models trained only on CXRs with an accuracy of 0.621 and AUC of 0.807\nand only on clinical variables with an accuracy of 0.440 and AUC of 0.502. The\npre-trained fusion model with only CXRs as input increases accuracy to 0.632\nand AUC to 0.813 and with only clinical variables as input increases accuracy\nto 0.539 and AUC to 0.733.\n  Conclusion: The fusion model learns better feature representations across\ndifferent modalities during training and achieves good outcome predictions even\nwhen only some of the modalities are used in testing.\n","authors":["Yunan Wu","Amil Dravid","Ramsey Michael Wehbe","Aggelos K. Katsaggelos"],"pdf_url":"https://arxiv.org/pdf/2301.08798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08794v1","updated":"2023-01-20T20:37:46Z","published":"2023-01-20T20:37:46Z","title":"Robot Skill Learning Via Classical Robotics-Based Generated Datasets:\n  Advantages, Disadvantages, and Future Improvement","summary":"  Why do we not profit from our long-existing classical robotics knowledge and\nlook for some alternative way for data collection? The situation ignoring all\nexisting methods might be such a waste. This article argues that a dataset\ncreated using a classical robotics algorithm is a crucial part of future\ndevelopment. This developed classic algorithm has a perfect domain adaptation\nand generalization property, and most importantly, collecting datasets based on\nthem is quite easy. It is well known that current robot skill-learning\napproaches perform exceptionally badly in the unseen domain, and their\nperformance against adversarial attacks is quite limited as long as they do not\nhave a very exclusive big dataset. Our experiment is the initial steps of using\na dataset created by classical robotics codes. Our experiment investigated\npossible trajectory collection based on classical robotics. It addressed some\nadvantages and disadvantages and pointed out other future development ideas.\n","authors":["Batu Kaan Oezen"],"pdf_url":"https://arxiv.org/pdf/2301.08794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08784v1","updated":"2023-01-20T20:04:35Z","published":"2023-01-20T20:04:35Z","title":"Visual Semantic Relatedness Dataset for Image Captioning","summary":"  Modern image captioning system relies heavily on extracting knowledge from\nimages to capture the concept of a static story. In this paper, we propose a\ntextual visual context dataset for captioning, in which the publicly available\ndataset COCO Captions (Lin et al., 2014) has been extended with information\nabout the scene (such as objects in the image). Since this information has a\ntextual form, it can be used to leverage any NLP task, such as text similarity\nor semantic relation methods, into captioning systems, either as an end-to-end\ntraining strategy or a post-processing based approach.\n","authors":["Ahmed Sabir","Francesc Moreno-Noguer","Lluís Padró"],"pdf_url":"https://arxiv.org/pdf/2301.08784v1.pdf","comment":"Project Page: bit.ly/3Zq6ATs"},{"id":"http://arxiv.org/abs/2301.08783v1","updated":"2023-01-20T19:46:23Z","published":"2023-01-20T19:46:23Z","title":"An Asynchronous Intensity Representation for Framed and Event Video\n  Sources","summary":"  Neuromorphic \"event\" cameras, designed to mimic the human vision system with\nasynchronous sensing, unlock a new realm of high-speed and high dynamic range\napplications. However, researchers often either revert to a framed\nrepresentation of event data for applications, or build bespoke applications\nfor a particular camera's event data type. To usher in the next era of video\nsystems, accommodate new event camera designs, and explore the benefits to\nasynchronous video in classical applications, we argue that there is a need for\nan asynchronous, source-agnostic video representation. In this paper, we\nintroduce a novel, asynchronous intensity representation for both framed and\nnon-framed data sources. We show that our representation can increase intensity\nprecision and greatly reduce the number of samples per pixel compared to\ngrid-based representations. With framed sources, we demonstrate that by\npermitting a small amount of loss through the temporal averaging of similar\npixel values, we can reduce our representational sample rate by more than half,\nwhile incurring a drop in VMAF quality score of only 4.5. We also demonstrate\nlower latency than the state-of-the-art method for fusing and transcoding\nframed and event camera data to an intensity representation, while maintaining\n$2000\\times$ the temporal resolution. We argue that our method provides the\ncomputational efficiency and temporal granularity necessary to build real-time\nintensity-based applications for event cameras.\n","authors":["Andrew C. Freeman","Montek Singh","Ketan Mayer-Patel"],"pdf_url":"https://arxiv.org/pdf/2301.08783v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2301.08782v1","updated":"2023-01-20T19:46:16Z","published":"2023-01-20T19:46:16Z","title":"Estimation of mitral valve hinge point coordinates -- deep neural net\n  for echocardiogram segmentation","summary":"  Cardiac image segmentation is a powerful tool in regard to diagnostics and\ntreatment of cardiovascular diseases. Purely feature-based detection of\nanatomical structures like the mitral valve is a laborious task due to\nspecifically required feature engineering and is especially challenging in\nechocardiograms, because of their inherently low contrast and blurry boundaries\nbetween some anatomical structures. With the publication of further annotated\nmedical datasets and the increase in GPU processing power, deep learning-based\nmethods in medical image segmentation became more feasible in the past years.\nWe propose a fully automatic detection method for mitral valve hinge points,\nwhich uses a U-Net based deep neural net to segment cardiac chambers in\nechocardiograms in a first step, and subsequently extracts the mitral valve\nhinge points from the resulting segmentations in a second step. Results\nmeasured with this automatic detection method were compared to reference\ncoordinate values, which with median absolute hinge point coordinate errors of\n1.35 mm for the x- (15-85 percentile range: [0.3 mm; 3.15 mm]) and 0.75 mm for\nthe y- coordinate (15-85 percentile range: [0.15 mm; 1.88 mm]).\n","authors":["Christian Schmidt","Heinrich Martin Overhoff"],"pdf_url":"https://arxiv.org/pdf/2301.08782v1.pdf","comment":"8 Pages, 11 figures Presented at WSCG 2022"},{"id":"http://arxiv.org/abs/2301.09416v1","updated":"2023-01-20T05:22:16Z","published":"2023-01-20T05:22:16Z","title":"Towards Robust Video Instance Segmentation with Temporal-Aware\n  Transformer","summary":"  Most existing transformer based video instance segmentation methods extract\nper frame features independently, hence it is challenging to solve the\nappearance deformation problem. In this paper, we observe the temporal\ninformation is important as well and we propose TAFormer to aggregate\nspatio-temporal features both in transformer encoder and decoder. Specifically,\nin transformer encoder, we propose a novel spatio-temporal joint multi-scale\ndeformable attention module which dynamically integrates the spatial and\ntemporal information to obtain enriched spatio-temporal features. In\ntransformer decoder, we introduce a temporal self-attention module to enhance\nthe frame level box queries with the temporal relation. Moreover, TAFormer\nadopts an instance level contrastive loss to increase the discriminability of\ninstance query embeddings. Therefore the tracking error caused by visually\nsimilar instances can be decreased. Experimental results show that TAFormer\neffectively leverages the spatial and temporal information to obtain\ncontext-aware feature representation and outperforms state-of-the-art methods.\n","authors":["Zhenghao Zhang","Fangtao Shao","Zuozhuo Dai","Siyu Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.09416v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.08632v1","updated":"2023-01-20T15:28:09Z","published":"2023-01-20T15:28:09Z","title":"Generative Slate Recommendation with Reinforcement Learning","summary":"  Recent research has employed reinforcement learning (RL) algorithms to\noptimize long-term user engagement in recommender systems, thereby avoiding\ncommon pitfalls such as user boredom and filter bubbles. They capture the\nsequential and interactive nature of recommendations, and thus offer a\nprincipled way to deal with long-term rewards and avoid myopic behaviors.\nHowever, RL approaches are intractable in the slate recommendation scenario -\nwhere a list of items is recommended at each interaction turn - due to the\ncombinatorial action space. In that setting, an action corresponds to a slate\nthat may contain any combination of items.\n  While previous work has proposed well-chosen decompositions of actions so as\nto ensure tractability, these rely on restrictive and sometimes unrealistic\nassumptions. Instead, in this work we propose to encode slates in a continuous,\nlow-dimensional latent space learned by a variational auto-encoder. Then, the\nRL agent selects continuous actions in this latent space, which are ultimately\ndecoded into the corresponding slates. By doing so, we are able to (i) relax\nassumptions required by previous work, and (ii) improve the quality of the\naction selection by modeling full slates instead of independent items, in\nparticular by enabling diversity. Our experiments performed on a wide array of\nsimulated environments confirm the effectiveness of our generative modeling of\nslates over baselines in practical scenarios where the restrictive assumptions\nunderlying the baselines are lifted. Our findings suggest that representation\nlearning using generative models is a promising direction towards generalizable\nRL-based slate recommendation.\n","authors":["Romain Deffayet","Thibaut Thonet","Jean-Michel Render","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2301.08632v1.pdf","comment":"WSDM 2023, 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.08613v1","updated":"2023-01-20T14:52:38Z","published":"2023-01-20T14:52:38Z","title":"The Evolution of Web Search User Interfaces -- An Archaeological\n  Analysis of Google Search Engine Result Pages","summary":"  Web search engines have marked everyone's life by transforming how one\nsearches and accesses information. Search engines give special attention to the\nuser interface, especially search engine result pages (SERP). The well-known\n''10 blue links'' list has evolved into richer interfaces, often personalized\nto the search query, the user, and other aspects. More than 20 years later, the\nliterature has not adequately portrayed this development. We present a study on\nthe evolution of SERP interfaces during the last two decades using Google\nSearch as a case study. We used the most searched queries by year to extract a\nsample of SERP from the Internet Archive. Using this dataset, we analyzed how\nSERP evolved in content, layout, design (e.g., color scheme, text styling,\ngraphics), navigation, and file size. We have also analyzed the user interface\ndesign patterns associated with SERP elements. We found that SERP are becoming\nmore diverse in terms of elements, aggregating content from different verticals\nand including more features that provide direct answers. This systematic\nanalysis portrays evolution trends in search engine user interfaces and, more\ngenerally, web design. We expect this work will trigger other, more specific\nstudies that can take advantage of our dataset.\n","authors":["B. Oliveira","C. T. Lopes"],"pdf_url":"https://arxiv.org/pdf/2301.08613v1.pdf","comment":"10 pages, Full Paper of CHIIR 2023"},{"id":"http://arxiv.org/abs/2206.10128v2","updated":"2023-01-20T00:55:24Z","published":"2022-06-21T06:21:23Z","title":"Bridging the Gap Between Indexing and Retrieval for Differentiable\n  Search Index with Query Generation","summary":"  The Differentiable Search Index (DSI) is an emerging paradigm for information\nretrieval. Unlike traditional retrieval architectures where index and retrieval\nare two different and separate components, DSI uses a single transformer model\nto perform both indexing and retrieval.\n  In this paper, we identify and tackle an important issue of current DSI\nmodels: the data distribution mismatch that occurs between the DSI indexing and\nretrieval processes. Specifically, we argue that, at indexing, current DSI\nmethods learn to build connections between the text of long documents and the\nidentifier of the documents, but then retrieval of document identifiers is\nbased on queries that are commonly much shorter than the indexed documents.\nThis problem is further exacerbated when using DSI for cross-lingual retrieval,\nwhere document text and query text are in different languages.\n  To address this fundamental problem of current DSI models, we propose a\nsimple yet effective indexing framework for DSI, called DSI-QG. When indexing,\nDSI-QG represents documents with a number of potentially relevant queries\ngenerated by a query generation model and re-ranked and filtered by a\ncross-encoder ranker. The presence of these queries at indexing allows the DSI\nmodels to connect a document identifier to a set of queries, hence mitigating\ndata distribution mismatches present between the indexing and the retrieval\nphases. Empirical results on popular mono-lingual and cross-lingual passage\nretrieval datasets show that DSI-QG significantly outperforms the original DSI\nmodel.\n","authors":["Shengyao Zhuang","Houxing Ren","Linjun Shou","Jian Pei","Ming Gong","Guido Zuccon","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2206.10128v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2301.08801v1","updated":"2023-01-20T21:00:39Z","published":"2023-01-20T21:00:39Z","title":"Information Retrieval: Recent Advances and Beyond","summary":"  In this paper, we provide a detailed overview of the models used for\ninformation retrieval in the first and second stages of the typical processing\nchain. We discuss the current state-of-the-art models, including methods based\non terms, semantic retrieval, and neural. Additionally, we delve into the key\ntopics related to the learning process of these models. This way, this survey\noffers a comprehensive understanding of the field and is of interest for for\nresearchers and practitioners entering/working in the information retrieval\ndomain.\n","authors":["Kailash A. Hambarde","Hugo Proenca"],"pdf_url":"https://arxiv.org/pdf/2301.08801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08794v1","updated":"2023-01-20T20:37:46Z","published":"2023-01-20T20:37:46Z","title":"Robot Skill Learning Via Classical Robotics-Based Generated Datasets:\n  Advantages, Disadvantages, and Future Improvement","summary":"  Why do we not profit from our long-existing classical robotics knowledge and\nlook for some alternative way for data collection? The situation ignoring all\nexisting methods might be such a waste. This article argues that a dataset\ncreated using a classical robotics algorithm is a crucial part of future\ndevelopment. This developed classic algorithm has a perfect domain adaptation\nand generalization property, and most importantly, collecting datasets based on\nthem is quite easy. It is well known that current robot skill-learning\napproaches perform exceptionally badly in the unseen domain, and their\nperformance against adversarial attacks is quite limited as long as they do not\nhave a very exclusive big dataset. Our experiment is the initial steps of using\na dataset created by classical robotics codes. Our experiment investigated\npossible trajectory collection based on classical robotics. It addressed some\nadvantages and disadvantages and pointed out other future development ideas.\n","authors":["Batu Kaan Oezen"],"pdf_url":"https://arxiv.org/pdf/2301.08794v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.07733v2","updated":"2023-01-20T18:53:01Z","published":"2023-01-18T19:00:50Z","title":"Learning-Rate-Free Learning by D-Adaptation","summary":"  The speed of gradient descent for convex Lipschitz functions is highly\ndependent on the choice of learning rate. Setting the learning rate to achieve\nthe optimal convergence rate requires knowing the distance D from the initial\npoint to the solution set. In this work, we describe a single-loop method, with\nno back-tracking or line searches, which does not require knowledge of $D$ yet\nasymptotically achieves the optimal rate of convergence for the complexity\nclass of convex Lipschitz functions. Our approach is the first parameter-free\nmethod for this class without additional multiplicative log factors in the\nconvergence rate. We present extensive experiments for SGD and Adam variants of\nour method, where the method automatically matches hand-tuned learning rates\nacross more than a dozen diverse machine learning problems, including\nlarge-scale vision and language problems. Our method is practical, efficient\nand requires no additional function value or gradient evaluations each step. An\nopen-source implementation is available\n(https://github.com/facebookresearch/dadaptation).\n","authors":["Aaron Defazio","Konstantin Mishchenko"],"pdf_url":"https://arxiv.org/pdf/2301.07733v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08727v1","updated":"2023-01-20T18:47:24Z","published":"2023-01-20T18:47:24Z","title":"Neural Architecture Search: Insights from 1000 Papers","summary":"  In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020. In this survey, we provide an organized and comprehensive guide to\nneural architecture search. We give a taxonomy of search spaces, algorithms,\nand speedup techniques, and we discuss resources such as benchmarks, best\npractices, other surveys, and open-source libraries.\n","authors":["Colin White","Mahmoud Safari","Rhea Sukthanker","Binxin Ru","Thomas Elsken","Arber Zela","Debadeepta Dey","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2301.08727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.06651v2","updated":"2023-01-20T18:25:50Z","published":"2021-08-15T03:20:10Z","title":"SamBaS: Sampling-Based Stochastic Block Partitioning","summary":"  Community detection is a well-studied problem with applications in domains\nranging from networking to bioinformatics. Due to the rapid growth in the\nvolume of real-world data, there is growing interest in accelerating\ncontemporary community detection algorithms. However, the more accurate and\nstatistically robust methods tend to be hard to parallelize. One such method is\nstochastic block partitioning (SBP) - a community detection algorithm that\nworks well on graphs with complex and heterogeneous community structure. In\nthis paper, we present a sampling-based SBP (SamBaS) for accelerating SBP on\nsparse graphs. We characterize how various graph parameters affect the speedup\nand result quality of community detection with SamBaS and quantify the\ntrade-offs therein. To evaluate SamBas on real-world web graphs without known\nground-truth communities, we introduce partition quality score (PQS), an\nevaluation metric that outperforms modularity in terms of correlation with F1\nscore. Overall, SamBaS achieves speedups of up to 10X while maintaining result\nquality (and even improving result quality by over 150% on certain graphs,\nrelative to F1 score).\n","authors":["Frank Wanye","Vitaliy Gleyzer","Edward Kao","Wu-chun Feng"],"pdf_url":"https://arxiv.org/pdf/2108.06651v2.pdf","comment":"Updated to latest submitted version"},{"id":"http://arxiv.org/abs/2212.14618v2","updated":"2023-01-20T18:03:53Z","published":"2022-12-30T10:11:57Z","title":"Blind Restoration of Real-World Audio by 1D Operational GANs","summary":"  Objective: Despite numerous studies proposed for audio restoration in the\nliterature, most of them focus on an isolated restoration problem such as\ndenoising or dereverberation, ignoring other artifacts. Moreover, assuming a\nnoisy or reverberant environment with limited number of fixed\nsignal-to-distortion ratio (SDR) levels is a common practice. However,\nreal-world audio is often corrupted by a blend of artifacts such as\nreverberation, sensor noise, and background audio mixture with varying types,\nseverities, and duration. In this study, we propose a novel approach for blind\nrestoration of real-world audio signals by Operational Generative Adversarial\nNetworks (Op-GANs) with temporal and spectral objective metrics to enhance the\nquality of restored audio signal regardless of the type and severity of each\nartifact corrupting it. Methods: 1D Operational-GANs are used with generative\nneuron model optimized for blind restoration of any corrupted audio signal.\nResults: The proposed approach has been evaluated extensively over the\nbenchmark TIMIT-RAR (speech) and GTZAN-RAR (non-speech) datasets corrupted with\na random blend of artifacts each with a random severity to mimic real-world\naudio signals. Average SDR improvements of over 7.2 dB and 4.9 dB are achieved,\nrespectively, which are substantial when compared with the baseline methods.\nSignificance: This is a pioneer study in blind audio restoration with the\nunique capability of direct (time-domain) restoration of real-world audio\nwhilst achieving an unprecedented level of performance for a wide SDR range and\nartifact types. Conclusion: 1D Op-GANs can achieve robust and computationally\neffective real-world audio restoration with significantly improved performance.\nThe source codes and the generated real-world audio datasets are shared\npublicly with the research community in a dedicated GitHub repository1.\n","authors":["Turker Ince","Serkan Kiranyaz","Ozer Can Devecioglu","Muhammad Salman Khan","Muhammad Chowdhury","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2212.14618v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.07621v3","updated":"2023-01-20T17:59:14Z","published":"2020-12-11T18:54:36Z","title":"Intrinsic persistent homology via density-based metric learning","summary":"  We address the problem of estimating topological features from data in high\ndimensional Euclidean spaces under the manifold assumption. Our approach is\nbased on the computation of persistent homology of the space of data points\nendowed with a sample metric known as Fermat distance. We prove that such\nmetric space converges almost surely to the manifold itself endowed with an\nintrinsic metric that accounts for both the geometry of the manifold and the\ndensity that produces the sample. This fact implies the convergence of the\nassociated persistence diagrams. The use of this intrinsic distance when\ncomputing persistent homology presents advantageous properties such as\nrobustness to the presence of outliers in the input data and less sensitiveness\nto the particular embedding of the underlying manifold in the ambient space. We\nuse these ideas to propose and implement a method for pattern recognition and\nanomaly detection in time series, which is evaluated in applications to real\ndata.\n","authors":["Ximena Fernández","Eugenio Borghini","Gabriel Mindlin","Pablo Groisman"],"pdf_url":"https://arxiv.org/pdf/2012.07621v3.pdf","comment":"37 pages. v3: major revision. Final version accepted for publication\n  at Journal of Machine Learning Research"},{"id":"http://arxiv.org/abs/2301.08695v1","updated":"2023-01-20T17:26:37Z","published":"2023-01-20T17:26:37Z","title":"Baechi: Fast Device Placement of Machine Learning Graphs","summary":"  Machine Learning graphs (or models) can be challenging or impossible to train\nwhen either devices have limited memory, or models are large. To split the\nmodel across devices, learning-based approaches are still popular. While these\nresult in model placements that train fast on data (i.e., low step times),\nlearning-based model-parallelism is time-consuming, taking many hours or days\nto create a placement plan of operators on devices. We present the Baechi\nsystem, the first to adopt an algorithmic approach to the placement problem for\nrunning machine learning training graphs on small clusters of\nmemory-constrained devices. We integrate our implementation of Baechi into two\npopular open-source learning frameworks: TensorFlow and PyTorch. Our\nexperimental results using GPUs show that: (i) Baechi generates placement plans\n654 X - 206K X faster than state-of-the-art learning-based approaches, and (ii)\nBaechi-placed model's step (training) time is comparable to expert placements\nin PyTorch, and only up to 6.2% worse than expert placements in TensorFlow. We\nprove mathematically that our two algorithms are within a constant factor of\nthe optimal. Our work shows that compared to learning-based approaches,\nalgorithmic approaches can face different challenges for adaptation to Machine\nlearning systems, but also they offer proven bounds, and significant\nperformance benefits.\n","authors":["Beomyeol Jeon","Linda Cai","Chirag Shetty","Pallavi Srivastava","Jintao Jiang","Xiaolan Ke","Yitao Meng","Cong Xie","Indranil Gupta"],"pdf_url":"https://arxiv.org/pdf/2301.08695v1.pdf","comment":"Extended version of SoCC 2020 paper:\n  https://dl.acm.org/doi/10.1145/3419111.3421302"},{"id":"http://arxiv.org/abs/2301.08688v1","updated":"2023-01-20T17:19:18Z","published":"2023-01-20T17:19:18Z","title":"Asynchronous Deep Double Duelling Q-Learning for Trading-Signal\n  Execution in Limit Order Book Markets","summary":"  We employ deep reinforcement learning (RL) to train an agent to successfully\ntranslate a high-frequency trading signal into a trading strategy that places\nindividual limit orders. Based on the ABIDES limit order book simulator, we\nbuild a reinforcement learning OpenAI gym environment and utilise it to\nsimulate a realistic trading environment for NASDAQ equities based on historic\norder book messages. To train a trading agent that learns to maximise its\ntrading return in this environment, we use Deep Duelling Double Q-learning with\nthe APEX (asynchronous prioritised experience replay) architecture. The agent\nobserves the current limit order book state, its recent history, and a\nshort-term directional forecast. To investigate the performance of RL for\nadaptive trading independently from a concrete forecasting algorithm, we study\nthe performance of our approach utilising synthetic alpha signals obtained by\nperturbing forward-looking returns with varying levels of noise. Here, we find\nthat the RL agent learns an effective trading strategy for inventory management\nand order placing that outperforms a heuristic benchmark trading strategy\nhaving access to the same signal.\n","authors":["Peer Nagy","Jan-Peter Calliess","Stefan Zohren"],"pdf_url":"https://arxiv.org/pdf/2301.08688v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2208.04955v2","updated":"2023-01-20T16:41:54Z","published":"2022-08-09T14:30:51Z","title":"Explainable prediction of Qcodes for NOTAMs using column generation","summary":"  A NOtice To AirMen (NOTAM) contains important flight route related\ninformation. To search and filter them, NOTAMs are grouped into categories\ncalled QCodes. In this paper, we develop a tool to predict, with some\nexplanations, a Qcode for a NOTAM. We present a way to extend the interpretable\nbinary classification using column generation proposed in Dash, Gunluk, and Wei\n(2018) to a multiclass text classification method. We describe the techniques\nused to tackle the issues related to one vs-rest classification, such as\nmultiple outputs and class imbalances. Furthermore, we introduce some\nheuristics, including the use of a CP-SAT solver for the subproblems, to reduce\nthe training time. Finally, we show that our approach compares favorably with\nstate-of-the-art machine learning algorithms like Linear SVM and small neural\nnetworks while adding the needed interpretability component.\n","authors":["Krunal Kishor Patel","Guy Desaulniers","Andrea Lodi","Freddy Lecue"],"pdf_url":"https://arxiv.org/pdf/2208.04955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08664v1","updated":"2023-01-20T16:30:44Z","published":"2023-01-20T16:30:44Z","title":"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","summary":"  The quality of the video stream is key to neural network-based video\nanalytics. However, low-quality video is inevitably collected by existing\nsurveillance systems because of poor quality cameras or over-compressed/pruned\nvideo streaming protocols, e.g., as a result of upstream bandwidth limit. To\naddress this issue, existing studies use quality enhancers (e.g., neural\nsuper-resolution) to improve the quality of videos (e.g., resolution) and\neventually ensure inference accuracy. Nevertheless, directly applying quality\nenhancers does not work in practice because it will introduce unacceptable\nlatency. In this paper, we present AccDecoder, a novel accelerated decoder for\nreal-time and neural-enhanced video analytics. AccDecoder can select a few\nframes adaptively via Deep Reinforcement Learning (DRL) to enhance the quality\nby neural super-resolution and then up-scale the unselected frames that\nreference them, which leads to 6-21% accuracy improvement. AccDecoder provides\nefficient inference capability via filtering important frames using DRL for\nDNN-based inference and reusing the results for the other frames via extracting\nthe reference relationship among frames and blocks, which results in a latency\nreduction of 20-80% than baselines.\n","authors":["Tingting Yuan","Liang Mi","Weijun Wang","Haipeng Dai","Xiaoming Fu"],"pdf_url":"https://arxiv.org/pdf/2301.08664v1.pdf","comment":"Accepted by 2023 IEEE INFOCOM"},{"id":"http://arxiv.org/abs/2202.12119v2","updated":"2023-01-20T16:12:39Z","published":"2022-02-24T14:22:32Z","title":"Optimal Convergence Rates of Deep Convolutional Neural Networks:\n  Additive Ridge Functions","summary":"  Convolutional neural networks have shown impressive abilities in many\napplications, especially those related to the classification tasks. However,\nfor the regression problem, the abilities of convolutional structures have not\nbeen fully understood, and further investigation is needed. In this paper, we\nconsider the mean squared error analysis for deep convolutional neural\nnetworks. We show that, for additive ridge functions, convolutional neural\nnetworks followed by one fully connected layer with ReLU activation functions\ncan reach optimal mini-max rates (up to a log factor). The input dimension only\nappears in the constant of convergence rates. This work shows the statistical\noptimality of convolutional neural networks and may shed light on why\nconvolutional neural networks are able to behave well for high dimensional\ninput.\n","authors":["Zhiying Fang","Guang Cheng"],"pdf_url":"https://arxiv.org/pdf/2202.12119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07568v4","updated":"2023-01-20T16:07:26Z","published":"2022-02-15T16:51:53Z","title":"StratDef: Strategic Defense Against Adversarial Attacks in ML-based\n  Malware Detection","summary":"  Over the years, most research towards defenses against adversarial attacks on\nmachine learning models has been in the image recognition domain. The malware\ndetection domain has received less attention despite its importance. Moreover,\nmost work exploring these defenses has focused on several methods but with no\nstrategy when applying them. In this paper, we introduce StratDef, which is a\nstrategic defense system based on a moving target defense approach. We overcome\nchallenges related to the systematic construction, selection, and strategic use\nof models to maximize adversarial robustness. StratDef dynamically and\nstrategically chooses the best models to increase the uncertainty for the\nattacker while minimizing critical aspects in the adversarial ML domain, like\nattack transferability. We provide the first comprehensive evaluation of\ndefenses against adversarial attacks on machine learning for malware detection,\nwhere our threat model explores different levels of threat, attacker knowledge,\ncapabilities, and attack intensities. We show that StratDef performs better\nthan other defenses even when facing the peak adversarial threat. We also show\nthat, of the existing defenses, only a few adversarially-trained models provide\nsubstantially better protection than just using vanilla models but are still\noutperformed by StratDef.\n","authors":["Aqib Rashid","Jose Such"],"pdf_url":"https://arxiv.org/pdf/2202.07568v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08654v1","updated":"2023-01-20T16:03:30Z","published":"2023-01-20T16:03:30Z","title":"Automated extraction of capacitive coupling for quantum dot systems","summary":"  Gate-defined quantum dots (QDs) have appealing attributes as a quantum\ncomputing platform, however, near-term devices possess a range of possible\nimperfections that need to be accounted for during the tuning and operation of\nQD devices. One such problem is the capacitive cross-talk between the metallic\ngates that define and control QD qubits. A way to compensate for the capacitive\ncross-talk and enable targeted control of specific QDs independent of coupling\nis by the use of virtual gates. Here, we demonstrate a reliable automated\ncapacitive coupling identification method that combines machine learning with\ntraditional fitting to take advantage of the desirable properties of each. We\nalso show how the cross-capacitance measurement may be used for the\nidentification of spurious QDs sometimes formed during tuning experimental\ndevices. Our systems can autonomously flag devices with spurious dots near the\noperating regime which is crucial information for reliable tuning to a regime\nsuitable for qubit operations.\n","authors":["Joshua Ziegler","Florian Luthi","Mick Ramsey","Felix Borjans","Guoji Zheng","Justyna P. Zwolak"],"pdf_url":"https://arxiv.org/pdf/2301.08654v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.08649v1","updated":"2023-01-20T15:56:39Z","published":"2023-01-20T15:56:39Z","title":"Offline Policy Evaluation with Out-of-Sample Guarantees","summary":"  We consider the problem of evaluating the performance of a decision policy\nusing past observational data. The outcome of a policy is measured in terms of\na loss or disutility (or negative reward) and the problem is to draw valid\ninferences about the out-of-sample loss of the specified policy when the past\ndata is observed under a, possibly unknown, policy. Using a sample-splitting\nmethod, we show that it is possible to draw such inferences with finite-sample\ncoverage guarantees that evaluate the entire loss distribution. Importantly,\nthe method takes into account model misspecifications of the past policy --\nincluding unmeasured confounding. The evaluation method can be used to certify\nthe performance of a policy using observational data under an explicitly\nspecified range of credible model assumptions.\n","authors":["Sofia Ek","Dave Zachariah"],"pdf_url":"https://arxiv.org/pdf/2301.08649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08648v1","updated":"2023-01-20T15:55:41Z","published":"2023-01-20T15:55:41Z","title":"STORM-GAN: Spatio-Temporal Meta-GAN for Cross-City Estimation of Human\n  Mobility Responses to COVID-19","summary":"  Human mobility estimation is crucial during the COVID-19 pandemic due to its\nsignificant guidance for policymakers to make non-pharmaceutical interventions.\nWhile deep learning approaches outperform conventional estimation techniques on\ntasks with abundant training data, the continuously evolving pandemic poses a\nsignificant challenge to solving this problem due to data nonstationarity,\nlimited observations, and complex social contexts. Prior works on mobility\nestimation either focus on a single city or lack the ability to model the\nspatio-temporal dependencies across cities and time periods. To address these\nissues, we make the first attempt to tackle the cross-city human mobility\nestimation problem through a deep meta-generative framework. We propose a\nSpatio-Temporal Meta-Generative Adversarial Network (STORM-GAN) model that\nestimates dynamic human mobility responses under a set of social and policy\nconditions related to COVID-19. Facilitated by a novel spatio-temporal\ntask-based graph (STTG) embedding, STORM-GAN is capable of learning shared\nknowledge from a spatio-temporal distribution of estimation tasks and quickly\nadapting to new cities and time periods with limited training samples. The STTG\nembedding component is designed to capture the similarities among cities to\nmitigate cross-task heterogeneity. Experimental results on real-world data show\nthat the proposed approach can greatly improve estimation performance and\nout-perform baselines.\n","authors":["Han Bao","Xun Zhou","Yiqun Xie","Yanhua Li","Xiaowei Jia"],"pdf_url":"https://arxiv.org/pdf/2301.08648v1.pdf","comment":"Accepted at the 22nd IEEE International Conference on Data Mining\n  (ICDM 2022) Full Paper"},{"id":"http://arxiv.org/abs/2212.01282v2","updated":"2023-01-20T15:53:49Z","published":"2022-12-01T08:50:12Z","title":"CHAPTER: Exploiting Convolutional Neural Network Adapters for\n  Self-supervised Speech Models","summary":"  Self-supervised learning (SSL) is a powerful technique for learning\nrepresentations from unlabeled data. Transformer based models such as HuBERT,\nwhich consist a feature extractor and transformer layers, are leading the field\nin the speech domain. SSL models are fine-tuned on a wide range of downstream\ntasks, which involves re-training the majority of the model for each task.\nPrevious studies have introduced applying adapters, which are small lightweight\nmodules commonly used in Natural Language Processing (NLP) to adapt pre-trained\nmodels to new tasks. However, such efficient tuning techniques only provide\nadaptation at the transformer layer, but failed to perform adaptation at the\nfeature extractor. In this paper, we propose CHAPTER, an efficient tuning\nmethod specifically designed for SSL speech model, by applying CNN adapters at\nthe feature extractor. Using this method, we can only fine-tune fewer than 5%\nof parameters per task compared to fully fine-tuning and achieve better and\nmore stable performance. We empirically found that adding CNN adapters to the\nfeature extractor can help the adaptation on emotion and speaker tasks. For\ninstance, the accuracy of SID is improved from 87.71 to 91.56, and the accuracy\nof ER is improved by 5%.\n","authors":["Zih-Ching Chen","Yu-Shun Sung","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2212.01282v2.pdf","comment":"Submitted to ICASSP 2023. Under review"},{"id":"http://arxiv.org/abs/2109.01904v6","updated":"2023-01-20T15:37:51Z","published":"2021-09-04T17:11:43Z","title":"Estimating Categorical Counterfactuals via Deep Twin Networks","summary":"  Counterfactual inference is a powerful tool, capable of solving challenging\nproblems in high-profile sectors. To perform counterfactual inference, one\nrequires knowledge of the underlying causal mechanisms. However, causal\nmechanisms cannot be uniquely determined from observations and interventions\nalone. This raises the question of how to choose the causal mechanisms so that\nresulting counterfactual inference is trustworthy in a given domain. This\nquestion has been addressed in causal models with binary variables, but the\ncase of categorical variables remains unanswered. We address this challenge by\nintroducing for causal models with categorical variables the notion of\ncounterfactual ordering, a principle that posits desirable properties causal\nmechanisms should posses, and prove that it is equivalent to specific\nfunctional constraints on the causal mechanisms. To learn causal mechanisms\nsatisfying these constraints, and perform counterfactual inference with them,\nwe introduce deep twin networks. These are deep neural networks that, when\ntrained, are capable of twin network counterfactual inference -- an alternative\nto the abduction, action, & prediction method. We empirically test our approach\non diverse real-world and semi-synthetic data from medicine, epidemiology, and\nfinance, reporting accurate estimation of counterfactual probabilities while\ndemonstrating the issues that arise with counterfactual reasoning when\ncounterfactual ordering is not enforced.\n","authors":["Athanasios Vlontzos","Bernhard Kainz","Ciaran M. Gilligan-Lee"],"pdf_url":"https://arxiv.org/pdf/2109.01904v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09006v2","updated":"2023-01-20T15:31:04Z","published":"2022-09-19T13:32:09Z","title":"Enforcing the consensus between Trajectory Optimization and Policy\n  Learning for precise robot control","summary":"  Reinforcement learning (RL) and trajectory optimization (TO) present strong\ncomplementary advantages. On one hand, RL approaches are able to learn global\ncontrol policies directly from data, but generally require large sample sizes\nto properly converge towards feasible policies. On the other hand, TO methods\nare able to exploit gradient-based information extracted from simulators to\nquickly converge towards a locally optimal control trajectory which is only\nvalid within the vicinity of the solution. Over the past decade, several\napproaches have aimed to adequately combine the two classes of methods in order\nto obtain the best of both worlds. Following on from this line of research, we\npropose several improvements on top of these approaches to learn global control\npolicies quicker, notably by leveraging sensitivity information stemming from\nTO methods via Sobolev learning, and augmented Lagrangian techniques to enforce\nthe consensus between TO and policy learning. We evaluate the benefits of these\nimprovements on various classical tasks in robotics through comparison with\nexisting approaches in the literature.\n","authors":["Quentin Le Lidec","Wilson Jallet","Ivan Laptev","Cordelia Schmid","Justin Carpentier"],"pdf_url":"https://arxiv.org/pdf/2209.09006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03783v2","updated":"2023-01-20T15:29:55Z","published":"2022-12-07T17:05:31Z","title":"Tight bounds for maximum $\\ell_1$-margin classifiers","summary":"  Popular iterative algorithms such as boosting methods and coordinate descent\non linear models converge to the maximum $\\ell_1$-margin classifier, a.k.a.\nsparse hard-margin SVM, in high dimensional regimes where the data is linearly\nseparable. Previous works consistently show that many estimators relying on the\n$\\ell_1$-norm achieve improved statistical rates for hard sparse ground truths.\nWe show that surprisingly, this adaptivity does not apply to the maximum\n$\\ell_1$-margin classifier for a standard discriminative setting. In\nparticular, for the noiseless setting, we prove tight upper and lower bounds\nfor the prediction error that match existing rates of order\n$\\frac{\\|w^*\\|_1^{2/3}}{n^{1/3}}$ for general ground truths. To complete the\npicture, we show that when interpolating noisy observations, the error vanishes\nat a rate of order $\\frac{1}{\\sqrt{\\log(d/n)}}$. We are therefore first to show\nbenign overfitting for the maximum $\\ell_1$-margin classifier.\n","authors":["Stefan Stojanovic","Konstantin Donhauser","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2212.03783v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08632v1","updated":"2023-01-20T15:28:09Z","published":"2023-01-20T15:28:09Z","title":"Generative Slate Recommendation with Reinforcement Learning","summary":"  Recent research has employed reinforcement learning (RL) algorithms to\noptimize long-term user engagement in recommender systems, thereby avoiding\ncommon pitfalls such as user boredom and filter bubbles. They capture the\nsequential and interactive nature of recommendations, and thus offer a\nprincipled way to deal with long-term rewards and avoid myopic behaviors.\nHowever, RL approaches are intractable in the slate recommendation scenario -\nwhere a list of items is recommended at each interaction turn - due to the\ncombinatorial action space. In that setting, an action corresponds to a slate\nthat may contain any combination of items.\n  While previous work has proposed well-chosen decompositions of actions so as\nto ensure tractability, these rely on restrictive and sometimes unrealistic\nassumptions. Instead, in this work we propose to encode slates in a continuous,\nlow-dimensional latent space learned by a variational auto-encoder. Then, the\nRL agent selects continuous actions in this latent space, which are ultimately\ndecoded into the corresponding slates. By doing so, we are able to (i) relax\nassumptions required by previous work, and (ii) improve the quality of the\naction selection by modeling full slates instead of independent items, in\nparticular by enabling diversity. Our experiments performed on a wide array of\nsimulated environments confirm the effectiveness of our generative modeling of\nslates over baselines in practical scenarios where the restrictive assumptions\nunderlying the baselines are lifted. Our findings suggest that representation\nlearning using generative models is a promising direction towards generalizable\nRL-based slate recommendation.\n","authors":["Romain Deffayet","Thibaut Thonet","Jean-Michel Render","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2301.08632v1.pdf","comment":"WSDM 2023, 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2206.06484v3","updated":"2023-01-20T15:02:33Z","published":"2022-06-13T21:30:29Z","title":"On Image Segmentation With Noisy Labels: Characterization and Volume\n  Properties of the Optimal Solutions to Accuracy and Dice","summary":"  We study two of the most popular performance metrics in medical image\nsegmentation, Accuracy and Dice, when the target labels are noisy. For both\nmetrics, several statements related to characterization and volume properties\nof the set of optimal segmentations are proved, and associated experiments are\nprovided. Our main insights are: (i) the volume of the solutions to both\nmetrics may deviate significantly from the expected volume of the target, (ii)\nthe volume of a solution to Accuracy is always less than or equal to the volume\nof a solution to Dice and (iii) the optimal solutions to both of these metrics\ncoincide when the set of feasible segmentations is constrained to the set of\nsegmentations with the volume equal to the expected volume of the target.\n","authors":["Marcus Nordström","Henrik Hult","Jonas Söderberg","Fredrik Löfman"],"pdf_url":"https://arxiv.org/pdf/2206.06484v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08618v1","updated":"2023-01-20T14:59:33Z","published":"2023-01-20T14:59:33Z","title":"Coupled Physics-informed Neural Networks for Inferring Solutions of\n  Partial Differential Equations with Unknown Source Terms","summary":"  Physics-informed neural networks (PINNs) provide a transformative development\nfor approximating the solutions to partial differential equations (PDEs). This\nwork proposes a coupled physics-informed neural network (C-PINN) for the\nnonhomogeneous PDEs with unknown dynamical source terms, which is used to\ndescribe the systems with external forces and cannot be well approximated by\nthe existing PINNs. In our method, two neural networks, NetU and NetG, are\nproposed. NetU is constructed to generate a quasi-solution satisfying PDEs\nunder study. NetG is used to regularize the training of NetU. Then, the two\nnetworks are integrated into a data-physics-hybrid cost function. Finally, we\npropose a hierarchical training strategy to optimize and couple the two\nnetworks. The performance of C-PINN is proved by approximating several\nclassical PDEs.\n","authors":["Aina Wang","Pan Qin","Xi-Ming Sun"],"pdf_url":"https://arxiv.org/pdf/2301.08618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06957v2","updated":"2023-01-20T14:31:00Z","published":"2023-01-17T15:32:34Z","title":"FewSOME: Few Shot Anomaly Detection","summary":"  Recent years have seen considerable progress in the field of Anomaly\nDetection but at the cost of increasingly complex training pipelines. Such\ntechniques require large amounts of training data, resulting in computationally\nexpensive algorithms. We propose Few Shot anomaly detection (FewSOME), a deep\nOne-Class Anomaly Detection algorithm with the ability to accurately detect\nanomalies having trained on 'few' examples of the normal class and no examples\nof the anomalous class. We describe FewSOME to be of low complexity given its\nlow data requirement and short training time. FewSOME is aided by pretrained\nweights with an architecture based on Siamese Networks. By means of an ablation\nstudy, we demonstrate how our proposed loss, 'Stop Loss', improves the\nrobustness of FewSOME. Our experiments demonstrate that FewSOME performs at\nstate-of-the-art level on benchmark datasets MNIST, CIFAR-10, F-MNIST and MVTec\nAD while training on only 30 normal samples, a minute fraction of the data that\nexisting methods are trained on. Most notably, we found that FewSOME\noutperforms even highly complex models in the setting where only few examples\nof the normal class exist. Moreover, our extensive experiments show FewSOME to\nbe robust to contaminated datasets. We also report F1 score and Balanced\nAccuracy in addition to AUC as a benchmark for future techniques to be compared\nagainst.\n","authors":["Niamh Belton","Misgina Tsighe Hagos","Aonghus Lawlor","Kathleen M. Curran"],"pdf_url":"https://arxiv.org/pdf/2301.06957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08173v2","updated":"2023-01-20T14:19:25Z","published":"2023-01-19T17:04:59Z","title":"Time-Warping Invariant Quantum Recurrent Neural Networks via\n  Quantum-Classical Adaptive Gating","summary":"  Adaptive gating plays a key role in temporal data processing via classical\nrecurrent neural networks (RNN), as it facilitates retention of past\ninformation necessary to predict the future, providing a mechanism that\npreserves invariance to time warping transformations. This paper builds on\nquantum recurrent neural networks (QRNNs), a dynamic model with quantum memory,\nto introduce a novel class of temporal data processing quantum models that\npreserve invariance to time-warping transformations of the (classical)\ninput-output sequences. The model, referred to as time warping-invariant QRNN\n(TWI-QRNN), augments a QRNN with a quantum-classical adaptive gating mechanism\nthat chooses whether to apply a parameterized unitary transformation at each\ntime step as a function of the past samples of the input sequence via a\nclassical recurrent model. The TWI-QRNN model class is derived from first\nprinciples, and its capacity to successfully implement time-warping\ntransformations is experimentally demonstrated on examples with classical or\nquantum dynamics.\n","authors":["Ivana Nikoloska","Osvaldo Simeone","Leonardo Banchi","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2301.08173v2.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2208.07360v2","updated":"2023-01-20T14:13:08Z","published":"2022-08-15T17:55:26Z","title":"Evaluating the Evaluators: Which UDA validation methods are most\n  effective? Can they be improved?","summary":"  This paper compares and ranks 8 UDA validation methods. Validators estimate\nmodel accuracy, which makes them an essential component of any UDA train-test\npipeline. We rank these validators to indicate which of them are most useful\nfor the purpose of selecting optimal model checkpoints and hyperparameters. To\nthe best of our knowledge, this large-scale benchmark study is the first of its\nkind in the UDA field. In addition, we propose three new validators that\noutperform all the existing checkpoint-based validators that we were able to\nfind in the existing literature. Code is available at\nhttps://www.github.com/KevinMusgrave/powerful-benchmarker.\n","authors":["Kevin Musgrave","Serge Belongie","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2208.07360v2.pdf","comment":"This paper was previously titled Benchmarking Validation Methods for\n  Unsupervised Domain Adaptation. This version contains new experiments,\n  analysis, and figures"},{"id":"http://arxiv.org/abs/2204.03994v2","updated":"2023-01-20T14:02:43Z","published":"2022-04-08T10:55:45Z","title":"LaF: Labeling-Free Model Selection for Automated Deep Neural Network\n  Reusing","summary":"  Applying deep learning to science is a new trend in recent years which leads\nDL engineering to become an important problem. Although training data\npreparation, model architecture design, and model training are the normal\nprocesses to build DL models, all of them are complex and costly. Therefore,\nreusing the open-sourced pre-trained model is a practical way to bypass this\nhurdle for developers. Given a specific task, developers can collect massive\npre-trained deep neural networks from public sources for re-using. However,\ntesting the performance (e.g., accuracy and robustness) of multiple DNNs and\nrecommending which model should be used is challenging regarding the scarcity\nof labeled data and the demand for domain expertise. In this paper, we propose\na labeling-free (LaF) model selection approach to overcome the limitations of\nlabeling efforts for automated model reusing. The main idea is to statistically\nlearn a Bayesian model to infer the models' specialty only based on predicted\nlabels. We evaluate LaF using 9 benchmark datasets including image, text, and\nsource code, and 165 DNNs, considering both the accuracy and robustness of\nmodels. The experimental results demonstrate that LaF outperforms the baseline\nmethods by up to 0.74 and 0.53 on Spearman's correlation and Kendall's $\\tau$,\nrespectively.\n","authors":["Qiang Hu","Yuejun Guo","Maxime Cordy","Xiaofei Xie","Mike Papadakis","Yves Le Traon"],"pdf_url":"https://arxiv.org/pdf/2204.03994v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2301.08577v1","updated":"2023-01-20T13:47:11Z","published":"2023-01-20T13:47:11Z","title":"Ontology Pre-training for Poison Prediction","summary":"  Integrating human knowledge into neural networks has the potential to improve\ntheir robustness and interpretability. We have developed a novel approach to\nintegrate knowledge from ontologies into the structure of a Transformer network\nwhich we call ontology pre-training: we train the network to predict membership\nin ontology classes as a way to embed the structure of the ontology into the\nnetwork, and subsequently fine-tune the network for the particular prediction\ntask. We apply this approach to a case study in predicting the potential\ntoxicity of a small molecule based on its molecular structure, a challenging\ntask for machine learning in life sciences chemistry. Our approach improves on\nthe state of the art, and moreover has several additional benefits. First, we\nare able to show that the model learns to focus attention on more meaningful\nchemical groups when making predictions with ontology pre-training than\nwithout, paving a path towards greater robustness and interpretability. Second,\nthe training time is reduced after ontology pre-training, indicating that the\nmodel is better placed to learn what matters for toxicity prediction with the\nontology pre-training than without. This strategy has general applicability as\na neuro-symbolic approach to embed meaningful semantics into neural networks.\n","authors":["Martin Glauer","Fabian Neuhaus","Till Mossakowski","Janna Hastings"],"pdf_url":"https://arxiv.org/pdf/2301.08577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08571v1","updated":"2023-01-20T13:38:24Z","published":"2023-01-20T13:38:24Z","title":"Visual Writing Prompts: Character-Grounded Story Generation with Curated\n  Image Sequences","summary":"  Current work on image-based story generation suffers from the fact that the\nexisting image sequence collections do not have coherent plots behind them. We\nimprove visual story generation by producing a new image-grounded dataset,\nVisual Writing Prompts (VWP). VWP contains almost 2K selected sequences of\nmovie shots, each including 5-10 images. The image sequences are aligned with a\ntotal of 12K stories which were collected via crowdsourcing given the image\nsequences and a set of grounded characters from the corresponding image\nsequence. Our new image sequence collection and filtering process has allowed\nus to obtain stories that are more coherent and have more narrativity compared\nto previous work. We also propose a character-based story generation model\ndriven by coherence as a strong baseline. Evaluations show that our generated\nstories are more coherent, visually grounded, and have more narrativity than\nstories generated with the current state-of-the-art model.\n","authors":["Xudong Hong","Asad Sayeed","Khushboo Mehra","Vera Demberg","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2301.08571v1.pdf","comment":"Paper accepted by Transactions of the Association for Computational\n  Linguistics (TACL). This is a pre-MIT Press publication version. 15 pages, 6\n  figures"},{"id":"http://arxiv.org/abs/2207.01393v2","updated":"2023-01-20T13:33:13Z","published":"2022-07-04T13:21:31Z","title":"Autonomous Drug Design with Multi-Armed Bandits","summary":"  Recent developments in artificial intelligence and automation support a new\ndrug design paradigm: autonomous drug design. Under this paradigm, generative\nmodels can provide suggestions on thousands of molecules with specific\nproperties, and automated laboratories can potentially make, test and analyze\nmolecules with minimal human supervision. However, since still only a limited\nnumber of molecules can be synthesized and tested, an obvious challenge is how\nto efficiently select among provided suggestions in a closed-loop system. We\nformulate this task as a stochastic multi-armed bandit problem with multiple\nplays, volatile arms and similarity information. To solve this task, we adapt\nprevious work on multi-armed bandits to this setting, and compare our solution\nwith random sampling, greedy selection and decaying-epsilon-greedy selection\nstrategies. According to our simulation results, our approach has the potential\nto perform better exploration and exploitation of the chemical space for\nautonomous drug design.\n","authors":["Hampus Gummesson Svensson","Esben Jannik Bjerrum","Christian Tyrchan","Ola Engkvist","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2207.01393v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.13157v4","updated":"2023-01-20T13:19:39Z","published":"2022-02-26T15:13:04Z","title":"High Dimensional Statistical Estimation under Uniformly Dithered One-bit\n  Quantization","summary":"  In this paper, we propose a uniformly dithered 1-bit quantization scheme for\nhigh-dimensional statistical estimation. The scheme contains truncation,\ndithering, and quantization as typical steps. As canonical examples, the\nquantization scheme is applied to the estimation problems of sparse covariance\nmatrix estimation, sparse linear regression (i.e., compressed sensing), and\nmatrix completion. We study both sub-Gaussian and heavy-tailed regimes, where\nthe underlying distribution of heavy-tailed data is assumed to have bounded\nmoments of some order. We propose new estimators based on 1-bit quantized data.\nIn sub-Gaussian regime, our estimators achieve near minimax rates, indicating\nthat our quantization scheme costs very little. In heavy-tailed regime, while\nthe rates of our estimators become essentially slower, these results are either\nthe first ones in an 1-bit quantized and heavy-tailed setting, or already\nimprove on existing comparable results from some respect. Under the\nobservations in our setting, the rates are almost tight in compressed sensing\nand matrix completion. Our 1-bit compressed sensing results feature general\nsensing vector that is sub-Gaussian or even heavy-tailed. We also first\ninvestigate a novel setting where both the covariate and response are\nquantized. In addition, our approach to 1-bit matrix completion does not rely\non likelihood and represent the first method robust to pre-quantization noise\nwith unknown distribution. Experimental results on synthetic data are presented\nto support our theoretical analysis.\n","authors":["Junren Chen","Cheng-Long Wang","Michael K. Ng","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2202.13157v4.pdf","comment":"We add lower bounds for 1-bit quantization of heavy-tailed data\n  (Theorems 11, 14)"},{"id":"http://arxiv.org/abs/2109.03099v3","updated":"2023-01-20T13:07:55Z","published":"2021-09-07T13:58:23Z","title":"Optimizing model-agnostic Random Subspace ensembles","summary":"  This paper presents a model-agnostic ensemble approach for supervised\nlearning. The proposed approach is based on a parametric version of Random\nSubspace, in which each base model is learned from a feature subset sampled\naccording to a Bernoulli distribution. Parameter optimization is performed\nusing gradient descent and is rendered tractable by using an importance\nsampling approach that circumvents frequent re-training of the base models\nafter each gradient descent step. The degree of randomization in our parametric\nRandom Subspace is thus automatically tuned through the optimization of the\nfeature selection probabilities. This is an advantage over the standard Random\nSubspace approach, where the degree of randomization is controlled by a\nhyper-parameter. Furthermore, the optimized feature selection probabilities can\nbe interpreted as feature importance scores. Our algorithm can also easily\nincorporate any differentiable regularization term to impose constraints on\nthese importance scores.\n","authors":["Vân Anh Huynh-Thu","Pierre Geurts"],"pdf_url":"https://arxiv.org/pdf/2109.03099v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11614v2","updated":"2023-01-20T12:38:30Z","published":"2022-12-22T11:18:35Z","title":"Hybrid Quantum-Classical Generative Adversarial Network for High\n  Resolution Image Generation","summary":"  Quantum machine learning (QML) has received increasing attention due to its\npotential to outperform classical machine learning methods in problems\npertaining classification and identification tasks. A subclass of QML methods\nis quantum generative adversarial networks (QGANs) which have been studied as a\nquantum counterpart of classical GANs widely used in image manipulation and\ngeneration tasks. The existing work on QGANs is still limited to small-scale\nproof-of-concept examples based on images with significant downscaling. Here we\nintegrate classical and quantum techniques to propose a new hybrid\nquantum-classical GAN framework. We demonstrate its superior learning\ncapabilities by generating $28 \\times 28$ pixels grey-scale images without\ndimensionality reduction or classical pre/post-processing on multiple classes\nof the standard MNIST and Fashion MNIST datasets, which achieves comparable\nresults to classical frameworks with three orders of magnitude less trainable\ngenerator parameters. To gain further insight into the working of our hybrid\napproach, we systematically explore the impact of its parameter space by\nvarying the number of qubits, the size of image patches, the number of layers\nin the generator, the shape of the patches and the choice of prior\ndistribution. Our results show that increasing the quantum generator size\ngenerally improves the learning capability of the network. The developed\nframework provides a foundation for future design of QGANs with optimal\nparameter set tailored for complex image generation tasks.\n","authors":["Shu Lok Tsang","Maxwell T. West","Sarah M. Erfani","Muhammad Usman"],"pdf_url":"https://arxiv.org/pdf/2212.11614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13960v4","updated":"2023-01-20T12:36:52Z","published":"2022-11-25T09:08:11Z","title":"The European AI Liability Directives -- Critique of a Half-Hearted\n  Approach and Lessons for the Future","summary":"  As ChatGPT et al. conquer the world, the optimal liability framework for AI\nsystems remains an unsolved problem across the globe. In a much-anticipated\nmove, the European Commission advanced two proposals outlining the European\napproach to AI liability in September 2022: a novel AI Liability Directive and\na revision of the Product Liability Directive. They constitute the final\ncornerstone of EU AI regulation. Crucially, the liability proposals and the EU\nAI Act are inherently intertwined: the latter does not contain any individual\nrights of affected persons, and the former lack specific, substantive rules on\nAI development and deployment. Taken together, these acts may well trigger a\nBrussels Effect in AI regulation, with significant consequences for the US and\nbeyond.\n  This paper makes three novel contributions. First, it examines in detail the\nCommission proposals and shows that, while making steps in the right direction,\nthey ultimately represent a half-hearted approach: if enacted as foreseen, AI\nliability in the EU will primarily rest on disclosure of evidence mechanisms\nand a set of narrowly defined presumptions concerning fault, defectiveness and\ncausality. Hence, second, the article suggests amendments, which are collected\nin an Annex at the end of the paper. Third, based on an analysis of the key\nrisks AI poses, the final part of the paper maps out a road for the future of\nAI liability and regulation, in the EU and beyond. This includes: a\ncomprehensive framework for AI liability; provisions to support innovation; an\nextension to non-discrimination/algorithmic fairness, as well as explainable\nAI; and sustainability. I propose to jump-start sustainable AI regulation via\nsustainability impact assessments in the AI Act and sustainable design defects\nin the liability regime. In this way, the law may help spur not only fair AI\nand XAI, but potentially also sustainable AI (SAI).\n","authors":["Philipp Hacker"],"pdf_url":"https://arxiv.org/pdf/2211.13960v4.pdf","comment":"under peer-review; contains 3 Tables"},{"id":"http://arxiv.org/abs/2208.09538v2","updated":"2023-01-20T12:14:18Z","published":"2022-08-19T20:24:10Z","title":"Predicting the Masses of Exotic Hadrons with Data Augmentation Using\n  Multilayer Perceptron","summary":"  Recently, there have been significant developments in neural networks, which\nled to the frequent use of neural networks in the physics literature. This work\nis focused on predicting the masses of exotic hadrons, doubly charmed and\nbottomed baryons using neural networks trained on meson and baryon masses that\nare determined by experiments. The original data set has been extended using\nthe recently proposed artificial data augmentation methods. We have observed\nthat the neural network's predictive ability increases with the use of\naugmented data. The results indicated that data augmentation techniques play an\nessential role in improving neural network predictions; moreover, neural\nnetworks can make reasonable predictions for exotic hadrons, doubly charmed,\nand doubly bottomed baryons. The results are also comparable to Gaussian\nProcess and Constituent Quark Model.\n","authors":["Huseyin Bahtiyar"],"pdf_url":"https://arxiv.org/pdf/2208.09538v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.08527v1","updated":"2023-01-20T12:11:03Z","published":"2023-01-20T12:11:03Z","title":"Predicting Surface Texture in Steel Manufacturing at Speed","summary":"  Control of the surface texture of steel strip during the galvanizing and\ntemper rolling processes is essential to satisfy customer requirements and is\nconventionally measured post-production using a stylus. In-production laser\nreflection measurement is less consistent than physical measurement but enables\nreal time adjustment of processing parameters to optimize product surface\ncharacteristics. We propose the use of machine learning to improve accuracy of\nthe transformation from inline laser reflection measurements to a prediction of\nsurface properties. In addition to accuracy, model evaluation speed is\nimportant for fast feedback control. The ROCKET model is one of the fastest\nstate of the art models, however it can be sped up by utilizing a GPU. Our\ncontribution is to implement the model in PyTorch for fast GPU kernel\ntransforms and provide a soft version of the Proportion of Positive Values\n(PPV) nonlinear pooling function, allowing gradient flow. We perform timing and\nperformance experiments comparing the implementations\n","authors":["Alexander J. M. Milne","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2301.08527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08525v1","updated":"2023-01-20T12:05:59Z","published":"2023-01-20T12:05:59Z","title":"Promises and pitfalls of deep neural networks in neuroimaging-based\n  psychiatric research","summary":"  By promising more accurate diagnostics and individual treatment\nrecommendations, deep neural networks and in particular convolutional neural\nnetworks have advanced to a powerful tool in medical imaging. Here, we first\ngive an introduction into methodological key concepts and resulting\nmethodological promises including representation and transfer learning, as well\nas modelling domain-specific priors. After reviewing recent applications within\nneuroimaging-based psychiatric research, such as the diagnosis of psychiatric\ndiseases, delineation of disease subtypes, normative modeling, and the\ndevelopment of neuroimaging biomarkers, we discuss current challenges. This\nincludes for example the difficulty of training models on small, heterogeneous\nand biased data sets, the lack of validity of clinical labels, algorithmic\nbias, and the influence of confounding variables.\n","authors":["Fabian Eitel","Marc-André Schulz","Moritz Seiler","Henrik Walter","Kerstin Ritter"],"pdf_url":"https://arxiv.org/pdf/2301.08525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08524v1","updated":"2023-01-20T12:02:30Z","published":"2023-01-20T12:02:30Z","title":"Clustering Human Mobility with Multiple Spaces","summary":"  Human mobility clustering is an important problem for understanding human\nmobility behaviors (e.g., work and school commutes). Existing methods typically\ncontain two steps: choosing or learning a mobility representation and applying\na clustering algorithm to the representation. However, these methods rely on\nstrict visiting orders in trajectories and cannot take advantage of multiple\ntypes of mobility representations. This paper proposes a novel mobility\nclustering method for mobility behavior detection. First, the proposed method\ncontains a permutation-equivalent operation to handle sub-trajectories that\nmight have different visiting orders but similar impacts on mobility behaviors.\nSecond, the proposed method utilizes a variational autoencoder architecture to\nsimultaneously perform clustering in both latent and original spaces. Also, in\norder to handle the bias of a single latent space, our clustering assignment\nprediction considers multiple learned latent spaces at different epochs. This\nway, the proposed method produces accurate results and can provide reliability\nestimates of each trajectory's cluster assignment. The experiment shows that\nthe proposed method outperformed state-of-the-art methods in mobility behavior\ndetection from trajectories with better accuracy and more interpretability.\n","authors":["Haoji Hu","Haowen Lin","Yao-Yi Chiang"],"pdf_url":"https://arxiv.org/pdf/2301.08524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08518v1","updated":"2023-01-20T11:34:12Z","published":"2023-01-20T11:34:12Z","title":"Regular Time-series Generation using SGM","summary":"  Score-based generative models (SGMs) are generative models that are in the\nspotlight these days. Time-series frequently occurs in our daily life, e.g.,\nstock data, climate data, and so on. Especially, time-series forecasting and\nclassification are popular research topics in the field of machine learning.\nSGMs are also known for outperforming other generative models. As a result, we\napply SGMs to synthesize time-series data by learning conditional score\nfunctions. We propose a conditional score network for the time-series\ngeneration domain. Furthermore, we also derive the loss function between the\nscore matching and the denoising score matching in the time-series generation\ndomain. Finally, we achieve state-of-the-art results on real-world datasets in\nterms of sampling diversity and quality.\n","authors":["Haksoo Lim","Minjung Kim","Sewon Park","Noseong Park"],"pdf_url":"https://arxiv.org/pdf/2301.08518v1.pdf","comment":"9 pages, appendix 3 pages, under review"},{"id":"http://arxiv.org/abs/2209.02009v2","updated":"2023-01-20T11:19:39Z","published":"2022-09-05T15:26:08Z","title":"Online Decision Making for Trading Wind Energy","summary":"  This paper proposes and develops a new algorithm for trading wind energy in\nelectricity markets, within an online learning and optimization framework. In\nparticular, we combine a component-wise adaptive variant of the gradient\ndescent algorithm with recent advances in the feature-driven newsvendor model.\nThis results in an online offering approach capable of leveraging data-rich\nenvironments, while adapting to non-stationary characteristics of energy\ngeneration and electricity markets, and with a minimal computational burden.\nThe performance of our approach is analyzed based on several numerical\nexperiments, showing both better adaptability to non-stationary uncertain\nparameters and significant economic gains.\n","authors":["Miguel Angel Muñoz","Pierre Pinson","Jalal Kazempour"],"pdf_url":"https://arxiv.org/pdf/2209.02009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.07075v5","updated":"2023-01-20T10:52:30Z","published":"2021-06-13T19:31:59Z","title":"Revisiting consistency for semi-supervised semantic segmentation","summary":"  Semi-supervised learning an attractive technique in practical deployments of\ndeep models since it relaxes the dependence on labeled data. It is especially\nimportant in the scope of dense prediction because pixel-level annotation\nrequires significant effort. This paper considers semi-supervised algorithms\nthat enforce consistent predictions over perturbed unlabeled inputs. We study\nthe advantages of perturbing only one of the two model instances and preventing\nthe backward pass through the unperturbed instance. We also propose a\ncompetitive perturbation model as a composition of geometric warp and\nphotometric jittering. We experiment with efficient models due to their\nimportance for real-time and low-power applications. Our experiments show clear\nadvantages of (1) one-way consistency, (2) perturbing only the student branch,\nand (3) strong photometric and geometric perturbations. Our perturbation model\noutperforms recent work and most of the contribution comes from photometric\ncomponent. Experiments with additional data from the large coarsely annotated\nsubset of Cityscapes suggest that semi-supervised training can outperform\nsupervised training with the coarse labels.\n","authors":["Ivan Grubišić","Marin Oršić","Siniša Šegvić"],"pdf_url":"https://arxiv.org/pdf/2106.07075v5.pdf","comment":"The source code is available at\n  https://github.com/Ivan1248/semisup-seg-efficient"},{"id":"http://arxiv.org/abs/2208.08241v3","updated":"2023-01-20T10:38:03Z","published":"2022-08-17T11:41:43Z","title":"ILLUME: Rationalizing Vision-Language Models through Human Interactions","summary":"  Bootstrapping from pre-trained language models has been proven to be an\nefficient approach for building vision-language models (VLM) for tasks such as\nimage captioning or visual question answering. However, outputs of these models\nrarely align with user's rationales for specific answers. In order to improve\nthis alignment and reinforce commonsense reasons, we propose a tuning paradigm\nbased on human interactions with machine generated data. Our ILLUME executes\nthe following loop: Given an image-question-answer prompt, the VLM samples\nmultiple candidate rationales, and a human critic provides minimal feedback via\npreference selection, used for fine-tuning. This loop increases the training\ndata and gradually carves out the VLM's rationalization capabilities that are\naligned with human intend. Our exhaustive experiments demonstrate that ILLUME\nis competitive with standard supervised fine-tuning while using significantly\nfewer training data and only requiring minimal feedback.\n","authors":["Manuel Brack","Patrick Schramowski","Björn Deiseroth","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2208.08241v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08506v1","updated":"2023-01-20T10:33:03Z","published":"2023-01-20T10:33:03Z","title":"Language Agnostic Data-Driven Inverse Text Normalization","summary":"  With the emergence of automatic speech recognition (ASR) models, converting\nthe spoken form text (from ASR) to the written form is in urgent need. This\ninverse text normalization (ITN) problem attracts the attention of researchers\nfrom various fields. Recently, several works show that data-driven ITN methods\ncan output high-quality written form text. Due to the scarcity of labeled\nspoken-written datasets, the studies on non-English data-driven ITN are quite\nlimited. In this work, we propose a language-agnostic data-driven ITN framework\nto fill this gap. Specifically, we leverage the data augmentation in\nconjunction with neural machine translated data for low resource languages.\nMoreover, we design an evaluation method for language agnostic ITN model when\nonly English data is available. Our empirical evaluation shows this language\nagnostic modeling approach is effective for low resource languages while\npreserving the performance for high resource languages.\n","authors":["Szu-Jui Chen","Debjyoti Paul","Yutong Pang","Peng Su","Xuedong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08502v1","updated":"2023-01-20T10:17:22Z","published":"2023-01-20T10:17:22Z","title":"Plan To Predict: Learning an Uncertainty-Foreseeing Model for\n  Model-Based Reinforcement Learning","summary":"  In Model-based Reinforcement Learning (MBRL), model learning is critical\nsince an inaccurate model can bias policy learning via generating misleading\nsamples. However, learning an accurate model can be difficult since the policy\nis continually updated and the induced distribution over visited states used\nfor model learning shifts accordingly. Prior methods alleviate this issue by\nquantifying the uncertainty of model-generated samples. However, these methods\nonly quantify the uncertainty passively after the samples were generated,\nrather than foreseeing the uncertainty before model trajectories fall into\nthose highly uncertain regions. The resulting low-quality samples can induce\nunstable learning targets and hinder the optimization of the policy. Moreover,\nwhile being learned to minimize one-step prediction errors, the model is\ngenerally used to predict for multiple steps, leading to a mismatch between the\nobjectives of model learning and model usage. To this end, we propose\n\\emph{Plan To Predict} (P2P), an MBRL framework that treats the model rollout\nprocess as a sequential decision making problem by reversely considering the\nmodel as a decision maker and the current policy as the dynamics. In this way,\nthe model can quickly adapt to the current policy and foresee the multi-step\nfuture uncertainty when generating trajectories. Theoretically, we show that\nthe performance of P2P can be guaranteed by approximately optimizing a lower\nbound of the true environment return. Empirical results demonstrate that P2P\nachieves state-of-the-art performance on several challenging benchmark tasks.\n","authors":["Zifan Wu","Chao Yu","Chen Chen","Jianye Hao","Hankz Hankui Zhuo"],"pdf_url":"https://arxiv.org/pdf/2301.08502v1.pdf","comment":"Accepted by NeurIPS2022"},{"id":"http://arxiv.org/abs/2212.14447v2","updated":"2023-01-20T10:01:31Z","published":"2022-12-29T20:05:26Z","title":"A Theoretical Framework for AI Models Explainability","summary":"  EXplainable Artificial Intelligence (XAI) is a vibrant research topic in the\nartificial intelligence community, with growing interest across methods and\ndomains. Much has been written about the subject, yet XAI still lacks shared\nterminology and a framework capable of providing structural soundness to\nexplanations. In our work, we address these issues by proposing a novel\ndefinition of explanation that is a synthesis of what can be found in the\nliterature. We recognize that explanations are not atomic but the combination\nof evidence stemming from the model and its input-output mapping, and the human\ninterpretation of this evidence. Furthermore, we fit explanations into the\nproperties of faithfulness (i.e., the explanation being a true description of\nthe model's inner workings and decision-making process) and plausibility (i.e.,\nhow much the explanation looks convincing to the user). Using our proposed\ntheoretical framework simplifies how these properties are operationalized and\nit provides new insight into common explanation methods that we analyze as case\nstudies.\n","authors":["Matteo Rizzo","Alberto Veneri","Andrea Albarelli","Claudio Lucchese","Cristina Conati"],"pdf_url":"https://arxiv.org/pdf/2212.14447v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08496v1","updated":"2023-01-20T09:54:44Z","published":"2023-01-20T09:54:44Z","title":"Introducing Expertise Logic into Graph Representation Learning from A\n  Causal Perspective","summary":"  Benefiting from the injection of human prior knowledge, graphs, as derived\ndiscrete data, are semantically dense so that models can efficiently learn the\nsemantic information from such data. Accordingly, graph neural networks (GNNs)\nindeed achieve impressive success in various fields. Revisiting the GNN\nlearning paradigms, we discover that the relationship between human expertise\nand the knowledge modeled by GNNs still confuses researchers. To this end, we\nintroduce motivating experiments and derive an empirical observation that the\nhuman expertise is gradually learned by the GNNs in general domains. By further\nobserving the ramifications of introducing expertise logic into graph\nrepresentation learning, we conclude that leading the GNNs to learn human\nexpertise can improve the model performance. By exploring the intrinsic\nmechanism behind such observations, we elaborate the Structural Causal Model\nfor the graph representation learning paradigm. Following the theoretical\nguidance, we innovatively introduce the auxiliary causal logic learning\nparadigm to improve the model to learn the expertise logic causally related to\nthe graph representation learning task. In practice, the counterfactual\ntechnique is further performed to tackle the insufficient training issue during\noptimization. Plentiful experiments on the crafted and real-world domains\nsupport the consistent effectiveness of the proposed method.\n","authors":["Hang Gao","Jiangmeng Li","Wenwen Qiang","Lingyu Si","Xingzhe Su","Fengge Wu","Changwen Zheng","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2301.08496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.05757v2","updated":"2023-01-20T09:39:32Z","published":"2020-12-10T15:41:17Z","title":"Estimation of Large Financial Covariances: A Cross-Validation Approach","summary":"  We introduce a novel covariance estimator for portfolio selection that adapts\nto the non-stationary or persistent heteroskedastic environments of financial\ntime series by employing exponentially weighted averages and nonlinearly\nshrinking the sample eigenvalues through cross-validation. Our estimator is\nstructure agnostic, transparent, and computationally feasible in large\ndimensions. By correcting the biases in the sample eigenvalues and aligning our\nestimator to more recent risk, we demonstrate that our estimator performs well\nin large dimensions against existing state-of-the-art static and dynamic\ncovariance shrinkage estimators through simulations and with an empirical\napplication in active portfolio management.\n","authors":["Vincent Tan","Stefan Zohren"],"pdf_url":"https://arxiv.org/pdf/2012.05757v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08491v1","updated":"2023-01-20T09:36:42Z","published":"2023-01-20T09:36:42Z","title":"Modeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement\n  Learning","summary":"  Practical uses of Artificial Intelligence (AI) in the real world have\ndemonstrated the importance of embedding moral choices into intelligent agents.\nThey have also highlighted that defining top-down ethical constraints on AI\naccording to any one type of morality is extremely challenging and can pose\nrisks. A bottom-up learning approach may be more appropriate for studying and\ndeveloping ethical behavior in AI agents. In particular, we believe that an\ninteresting and insightful starting point is the analysis of emergent behavior\nof Reinforcement Learning (RL) agents that act according to a predefined set of\nmoral rewards in social dilemmas.\n  In this work, we present a systematic analysis of the choices made by\nintrinsically-motivated RL agents whose rewards are based on moral theories. We\naim to design reward structures that are simplified yet representative of a set\nof key ethical systems. Therefore, we first define moral reward functions that\ndistinguish between consequence- and norm-based agents, between morality based\non societal norms or internal virtues, and between single- and mixed-virtue\n(e.g., multi-objective) methodologies. Then, we evaluate our approach by\nmodeling repeated dyadic interactions between learning moral agents in three\niterated social dilemma games (Prisoner's Dilemma, Volunteer's Dilemma and Stag\nHunt). We analyze the impact of different types of morality on the emergence of\ncooperation, defection or exploitation, and the corresponding social outcomes.\nFinally, we discuss the implications of these findings for the development of\nmoral agents in artificial and mixed human-AI societies.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2301.08491v1.pdf","comment":"7 pages, currently under review for a conference"},{"id":"http://arxiv.org/abs/2301.08479v1","updated":"2023-01-20T09:17:39Z","published":"2023-01-20T09:17:39Z","title":"Pneumonia Detection in Chest X-Ray Images : Handling Class Imbalance","summary":"  People all over the globe are affected by pneumonia but deaths due to it are\nhighest in Sub-Saharan Asia and South Asia. In recent years, the overall\nincidence and mortality rate of pneumonia regardless of the utilization of\neffective vaccines and compelling antibiotics has escalated. Thus, pneumonia\nremains a disease that needs spry prevention and treatment. The widespread\nprevalence of pneumonia has caused the research community to come up with a\nframework that helps detect, diagnose and analyze diseases accurately and\npromptly. One of the major hurdles faced by the Artificial Intelligence (AI)\nresearch community is the lack of publicly available datasets for chest\ndiseases, including pneumonia . Secondly, few of the available datasets are\nhighly imbalanced (normal examples are over sampled, while samples with ailment\nare in severe minority) making the problem even more challenging. In this\narticle we present a novel framework for the detection of pneumonia. The\nnovelty of the proposed methodology lies in the tackling of class imbalance\nproblem. The Generative Adversarial Network (GAN), specifically a combination\nof Deep Convolutional Generative Adversarial Network (DCGAN) and Wasserstein\nGAN gradient penalty (WGAN-GP) was applied on the minority class ``Pneumonia''\nfor augmentation, whereas Random Under-Sampling (RUS) was done on the majority\nclass ``No Findings'' to deal with the imbalance problem. The ChestX-Ray8\ndataset, one of the biggest datasets, is used to validate the performance of\nthe proposed framework. The learning phase is completed using transfer learning\non state-of-the-art deep learning models i.e. ResNet-50, Xception, and VGG-16.\nResults obtained exceed state-of-the-art.\n","authors":["Wardah Ali","Eesha Qureshi","Omama Ahmed Farooqi","Rizwan Ahmed Khan"],"pdf_url":"https://arxiv.org/pdf/2301.08479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01581v2","updated":"2023-01-20T08:39:42Z","published":"2022-03-03T09:18:21Z","title":"A shallow physics-informed neural network for solving partial\n  differential equations on surfaces","summary":"  In this paper, we introduce a shallow (one-hidden-layer) physics-informed\nneural network for solving partial differential equations on static and\nevolving surfaces. For the static surface case, with the aid of level set\nfunction, the surface normal and mean curvature used in the surface\ndifferential expressions can be computed easily. So instead of imposing the\nnormal extension constraints used in literature, we write the surface\ndifferential operators in the form of traditional Cartesian differential\noperators and use them in the loss function directly. We perform a series of\nperformance study for the present methodology by solving Laplace-Beltrami\nequation and surface diffusion equation on complex static surfaces. With just a\nmoderate number of neurons used in the hidden layer, we are able to attain\nsatisfactory prediction results. Then we extend the present methodology to\nsolve the advection-diffusion equation on an evolving surface with given\nvelocity. To track the surface, we additionally introduce a prescribed hidden\nlayer to enforce the topological structure of the surface and use the network\nto learn the homeomorphism between the surface and the prescribed topology. The\nproposed network structure is designed to track the surface and solve the\nequation simultaneously. Again, the numerical results show comparable accuracy\nas the static cases. As an application, we simulate the surfactant transport on\nthe droplet surface under shear flow and obtain some physically plausible\nresults.\n","authors":["Wei-Fan Hu","Yi-Jun Shih","Te-Sheng Lin","Ming-Chih Lai"],"pdf_url":"https://arxiv.org/pdf/2203.01581v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.04338v2","updated":"2023-01-20T08:16:41Z","published":"2021-10-08T19:00:19Z","title":"Learning from non-irreducible Markov chains","summary":"  Mostof the existing literature on supervised machine learning problems\nfocuses on the case when the training data set is drawn from an i.i.d. sample.\nHowever, many practical problems are characterized by temporal dependence and\nstrong correlation between the marginals of the data-generating process,\nsuggesting that the i.i.d. assumption is not always justified. This problem has\nbeen already considered in the context of Markov chains satisfying the Doeblin\ncondition. This condition, among other things, implies that the chain is not\nsingular in its behavior, i.e. it is irreducible. In this article, we focus on\nthe case when the training data set is drawn from a not necessarily irreducible\nMarkov chain. Under the assumption that the chain is uniformly ergodic with\nrespect to the $\\mathrm{L}^1$-Wasserstein distance, and certain regularity\nassumptions on the hypothesis class and the state space of the chain, we first\nobtain a uniform convergence result for the corresponding sample error, and\nthen we conclude learnability of the approximate sample error minimization\nalgorithm and find its generalization bounds. At the end, a relative uniform\nconvergence result for the sample error is also discussed.\n","authors":["Nikola Sandrić","Stjepan Šebek"],"pdf_url":"https://arxiv.org/pdf/2110.04338v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07882v2","updated":"2023-01-20T08:15:45Z","published":"2023-01-19T05:13:03Z","title":"Understanding the diffusion models by conditional expectations","summary":"  This paper provide several mathematical analyses of the diffusion model in\nmachine learning. The drift term of the backwards sampling process is\nrepresented as a conditional expectation involving the data distribution and\nthe forward diffusion. The training process aims to find such a drift function\nby minimizing the mean-squared residue related to the conditional expectation.\nUsing small-time approximations of the Green's function of the forward\ndiffusion, we show that the analytical mean drift function in DDPM and the\nscore function in SGM asymptotically blow up in the final stages of the\nsampling process for singular data distributions such as those concentrated on\nlower-dimensional manifolds, and is therefore difficult to approximate by a\nnetwork. To overcome this difficulty, we derive a new target function and\nassociated loss, which remains bounded even for singular data distributions. We\nillustrate the theoretical findings with several numerical examples.\n","authors":["Yubin Lu","Zhongjian Wang","Guillaume Bal"],"pdf_url":"https://arxiv.org/pdf/2301.07882v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08133v4","updated":"2023-01-20T07:38:18Z","published":"2022-08-17T08:04:41Z","title":"Metric Residual Networks for Sample Efficient Goal-Conditioned\n  Reinforcement Learning","summary":"  Goal-conditioned reinforcement learning (GCRL) has a wide range of potential\nreal-world applications, including manipulation and navigation problems in\nrobotics. Especially in such robotics tasks, sample efficiency is of the utmost\nimportance for GCRL since, by default, the agent is only rewarded when it\nreaches its goal. While several methods have been proposed to improve the\nsample efficiency of GCRL, one relatively under-studied approach is the design\nof neural architectures to support sample efficiency. In this work, we\nintroduce a novel neural architecture for GCRL that achieves significantly\nbetter sample efficiency than the commonly-used monolithic network\narchitecture. The key insight is that the optimal action-value function Q^*(s,\na, g) must satisfy the triangle inequality in a specific sense. Furthermore, we\nintroduce the metric residual network (MRN) that deliberately decomposes the\naction-value function Q(s,a,g) into the negated summation of a metric plus a\nresidual asymmetric component. MRN provably approximates any optimal\naction-value function Q^*(s,a,g), thus making it a fitting neural architecture\nfor GCRL. We conduct comprehensive experiments across 12 standard benchmark\nenvironments in GCRL. The empirical results demonstrate that MRN uniformly\noutperforms other state-of-the-art GCRL neural architectures in terms of sample\nefficiency.\n","authors":["Bo Liu","Yihao Feng","Qiang Liu","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2208.08133v4.pdf","comment":"Goal-conditioned reinforcement learning, neural architecture design"},{"id":"http://arxiv.org/abs/2301.08453v1","updated":"2023-01-20T07:34:27Z","published":"2023-01-20T07:34:27Z","title":"Feature Relevance Analysis to Explain Concept Drift -- A Case Study in\n  Human Activity Recognition","summary":"  This article studies how to detect and explain concept drift. Human activity\nrecognition is used as a case study together with a online batch learning\nsituation where the quality of the labels used in the model updating process\nstarts to decrease. Drift detection is based on identifying a set of features\nhaving the largest relevance difference between the drifting model and a model\nthat is known to be accurate and monitoring how the relevance of these features\nchanges over time. As a main result of this article, it is shown that feature\nrelevance analysis cannot only be used to detect the concept drift but also to\nexplain the reason for the drift when a limited number of typical reasons for\nthe concept drift are predefined. To explain the reason for the concept drift,\nit is studied how these predefined reasons effect to feature relevance. In\nfact, it is shown that each of these has an unique effect to features relevance\nand these can be used to explain the reason for concept drift.\n","authors":["Pekka Siirtola","Juha Röning"],"pdf_url":"https://arxiv.org/pdf/2301.08453v1.pdf","comment":"Accepted to HASCA 2022 workshop in conjunction with UbiComp/ISWC2022"},{"id":"http://arxiv.org/abs/2301.08451v1","updated":"2023-01-20T07:22:24Z","published":"2023-01-20T07:22:24Z","title":"Accelerating Multi-Agent Planning Using Graph Transformers with Bounded\n  Suboptimality","summary":"  Conflict-Based Search is one of the most popular methods for multi-agent path\nfinding. Though it is complete and optimal, it does not scale well. Recent\nworks have been proposed to accelerate it by introducing various heuristics.\nHowever, whether these heuristics can apply to non-grid-based problem settings\nwhile maintaining their effectiveness remains an open question. In this work,\nwe find that the answer is prone to be no. To this end, we propose a\nlearning-based component, i.e., the Graph Transformer, as a heuristic function\nto accelerate the planning. The proposed method is provably complete and\nbounded-suboptimal with any desired factor. We conduct extensive experiments on\ntwo environments with dense graphs. Results show that the proposed Graph\nTransformer can be trained in problem instances with relatively few agents and\ngeneralizes well to a larger number of agents, while achieving better\nperformance than state-of-the-art methods.\n","authors":["Chenning Yu","Qingbiao Li","Sicun Gao","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2301.08451v1.pdf","comment":"Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2204.10419v2","updated":"2023-01-20T07:11:44Z","published":"2022-04-21T21:59:24Z","title":"Learning Sequential Latent Variable Models from Multimodal Time Series\n  Data","summary":"  Sequential modelling of high-dimensional data is an important problem that\nappears in many domains including model-based reinforcement learning and\ndynamics identification for control. Latent variable models applied to\nsequential data (i.e., latent dynamics models) have been shown to be a\nparticularly effective probabilistic approach to solve this problem, especially\nwhen dealing with images. However, in many application areas (e.g., robotics),\ninformation from multiple sensing modalities is available -- existing latent\ndynamics methods have not yet been extended to effectively make use of such\nmultimodal sequential data. Multimodal sensor streams can be correlated in a\nuseful manner and often contain complementary information across modalities. In\nthis work, we present a self-supervised generative modelling framework to\njointly learn a probabilistic latent state representation of multimodal data\nand the respective dynamics. Using synthetic and real-world datasets from a\nmultimodal robotic planar pushing task, we demonstrate that our approach leads\nto significant improvements in prediction and representation quality.\nFurthermore, we compare to the common learning baseline of concatenating each\nmodality in the latent space and show that our principled probabilistic\nformulation performs better. Finally, despite being fully self-supervised, we\ndemonstrate that our method is nearly as effective as an existing supervised\napproach that relies on ground truth labels.\n","authors":["Oliver Limoyo","Trevor Ablett","Jonathan Kelly"],"pdf_url":"https://arxiv.org/pdf/2204.10419v2.pdf","comment":"In: Petrovic, I., Menegatti, E., Markovi\\'c, I. (eds) Intelligent\n  Autonomous Systems 17. IAS 2022. Lecture Notes in Networks and Systems, vol\n  577. Springer, Cham"},{"id":"http://arxiv.org/abs/2301.08448v1","updated":"2023-01-20T07:01:01Z","published":"2023-01-20T07:01:01Z","title":"Source-free Subject Adaptation for EEG-based Visual Recognition","summary":"  This paper focuses on subject adaptation for EEG-based visual recognition. It\naims at building a visual stimuli recognition system customized for the target\nsubject whose EEG samples are limited, by transferring knowledge from abundant\ndata of source subjects. Existing approaches consider the scenario that samples\nof source subjects are accessible during training. However, it is often\ninfeasible and problematic to access personal biological data like EEG signals\ndue to privacy issues. In this paper, we introduce a novel and practical\nproblem setup, namely source-free subject adaptation, where the source subject\ndata are unavailable and only the pre-trained model parameters are provided for\nsubject adaptation. To tackle this challenging problem, we propose\nclassifier-based data generation to simulate EEG samples from source subjects\nusing classifier responses. Using the generated samples and target subject\ndata, we perform subject-independent feature learning to exploit the common\nknowledge shared across different subjects. Notably, our framework is\ngeneralizable and can adopt any subject-independent learning method. In the\nexperiments on the EEG-ImageNet40 benchmark, our model brings consistent\nimprovements regardless of the choice of subject-independent learning. Also,\nour method shows promising performance, recording top-1 test accuracy of 74.6%\nunder the 5-shot setting even without relying on source data. Our code can be\nfound at\nhttps://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Source_Free_Subject_Adaptation_for_EEG.\n","authors":["Pilhyeon Lee","Seogkyu Jeon","Sunhee Hwang","Minjung Shin","Hyeran Byun"],"pdf_url":"https://arxiv.org/pdf/2301.08448v1.pdf","comment":"Accepted by the 11th IEEE International Winter Conference on\n  Brain-Computer Interface (BCI 2023). Code is available at\n  https://github.com/DeepBCI/Deep-BCI"},{"id":"http://arxiv.org/abs/2301.08442v1","updated":"2023-01-20T06:46:43Z","published":"2023-01-20T06:46:43Z","title":"Revisiting Estimation Bias in Policy Gradients for Deep Reinforcement\n  Learning","summary":"  We revisit the estimation bias in policy gradients for the discounted\nepisodic Markov decision process (MDP) from Deep Reinforcement Learning (DRL)\nperspective. The objective is formulated theoretically as the expected returns\ndiscounted over the time horizon. One of the major policy gradient biases is\nthe state distribution shift: the state distribution used to estimate the\ngradients differs from the theoretical formulation in that it does not take\ninto account the discount factor. Existing discussion of the influence of this\nbias was limited to the tabular and softmax cases in the literature. Therefore,\nin this paper, we extend it to the DRL setting where the policy is\nparameterized and demonstrate how this bias can lead to suboptimal policies\ntheoretically. We then discuss why the empirically inaccurate implementations\nwith shifted state distribution can still be effective. We show that, despite\nsuch state distribution shift, the policy gradient estimation bias can be\nreduced in the following three ways: 1) a small learning rate; 2) an\nadaptive-learning-rate-based optimizer; and 3) KL regularization. Specifically,\nwe show that a smaller learning rate, or, an adaptive learning rate, such as\nthat used by Adam and RSMProp optimizers, makes the policy optimization robust\nto the bias. We further draw connections between optimizers and the\noptimization regularization to show that both the KL and the reverse KL\nregularization can significantly rectify this bias. Moreover, we provide\nextensive experiments on continuous control tasks to support our analysis. Our\npaper sheds light on how successful PG algorithms optimize policies in the DRL\nsetting, and contributes insights into the practical issues in DRL.\n","authors":["Haoxuan Pan","Deheng Ye","Xiaoming Duan","Qiang Fu","Wei Yang","Jianping He","Mingfei Sun"],"pdf_url":"https://arxiv.org/pdf/2301.08442v1.pdf","comment":"12 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.08441v1","updated":"2023-01-20T06:45:32Z","published":"2023-01-20T06:45:32Z","title":"Self-Supervised Learning for Data Scarcity in a Fatigue Damage\n  Prognostic Problem","summary":"  With the increasing availability of data for Prognostics and Health\nManagement (PHM), Deep Learning (DL) techniques are now the subject of\nconsiderable attention for this application, often achieving more accurate\nRemaining Useful Life (RUL) predictions. However, one of the major challenges\nfor DL techniques resides in the difficulty of obtaining large amounts of\nlabelled data on industrial systems. To overcome this lack of labelled data, an\nemerging learning technique is considered in our work: Self-Supervised\nLearning, a sub-category of unsupervised learning approaches. This paper aims\nto investigate whether pre-training DL models in a self-supervised way on\nunlabelled sensors data can be useful for RUL estimation with only Few-Shots\nLearning, i.e. with scarce labelled data. In this research, a fatigue damage\nprognostics problem is addressed, through the estimation of the RUL of aluminum\nalloy panels (typical of aerospace structures) subject to fatigue cracks from\nstrain gauge data. Synthetic datasets composed of strain data are used allowing\nto extensively investigate the influence of the dataset size on the predictive\nperformance. Results show that the self-supervised pre-trained models are able\nto significantly outperform the non-pre-trained models in downstream RUL\nprediction task, and with less computational expense, showing promising results\nin prognostic tasks when only limited labelled data is available.\n","authors":["Anass Akrim","Christian Gogu","Rob Vingerhoeds","Michel Salaün"],"pdf_url":"https://arxiv.org/pdf/2301.08441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08435v1","updated":"2023-01-20T06:16:40Z","published":"2023-01-20T06:16:40Z","title":"Optimization of body configuration and joint-driven attitude\n  stabilization for transformable spacecrafts under solar radiation pressure","summary":"  A solar sail is one of the most promising space exploration system because of\nits theoretically infinite specific impulse using solar radiation pressure\n(SRP). Recently, some researchers proposed \"transformable spacecrafts\" that can\nactively reconfigure their body configurations with actuatable joints. The\ntransformable spacecrafts are expected to greatly enhance orbit and attitude\ncontrol capability due to its high redundancy in control degree of freedom if\nthey are used as solar sails. However, its large number of input poses\ndifficulties in control, and therefore, previous researchers imposed strong\nconstraints to limit its potential control capabilities. This paper addresses\nnovel attitude control techniques for the transformable spacecrafts under SRP.\nThe authors have constructed two proposed methods; one of those is a joint\nangle optimization to acquire arbitrary SRP force and torque, and the other is\na momentum damping control driven by joint angle actuation. Our proposed\nmethods are formulated in general forms and applicable to any transformable\nsolar sail that consists of flat and thin body components. Validity of the\nproposed methods are confirmed by numerical simulations. This paper contributes\nto making most of the high control redundancy of transformable solar sails\nwithout consuming any expendable propellants, which is expected to greatly\nenhance orbit and attitude control capability.\n","authors":["Yuki Kubo","Toshihiro Chujo"],"pdf_url":"https://arxiv.org/pdf/2301.08435v1.pdf","comment":"16 pages, 11 figures, submitted to Astrodynamics published by\n  Tsinghua University Press and Springer"},{"id":"http://arxiv.org/abs/2301.08427v1","updated":"2023-01-20T05:39:26Z","published":"2023-01-20T05:39:26Z","title":"Which Features are Learned by CodeBert: An Empirical Study of the\n  BERT-based Source Code Representation Learning","summary":"  The Bidirectional Encoder Representations from Transformers (BERT) were\nproposed in the natural language process (NLP) and shows promising results.\nRecently researchers applied the BERT to source-code representation learning\nand reported some good news on several downstream tasks. However, in this\npaper, we illustrated that current methods cannot effectively understand the\nlogic of source codes. The representation of source code heavily relies on the\nprogrammer-defined variable and function names. We design and implement a set\nof experiments to demonstrate our conjecture and provide some insights for\nfuture works.\n","authors":["Lan Zhang","Chen Cao","Zhilong Wang","Peng Liu"],"pdf_url":"https://arxiv.org/pdf/2301.08427v1.pdf","comment":"1 table, 2 figures"},{"id":"http://arxiv.org/abs/2208.08655v2","updated":"2023-01-20T05:20:24Z","published":"2022-08-18T06:19:46Z","title":"Generating Synthetic Clinical Data that Capture Class Imbalanced\n  Distributions with Generative Adversarial Networks: Example using\n  Antiretroviral Therapy for HIV","summary":"  Clinical data usually cannot be freely distributed due to their highly\nconfidential nature and this hampers the development of machine learning in the\nhealthcare domain. One way to mitigate this problem is by generating realistic\nsynthetic datasets using generative adversarial networks (GANs). However, GANs\nare known to suffer from mode collapse thus creating outputs of low diversity.\nThis lowers the quality of the synthetic healthcare data, and may cause it to\nomit patients of minority demographics or neglect less common clinical\npractices. In this paper, we extend the classic GAN setup with an additional\nvariational autoencoder (VAE) and include an external memory to replay latent\nfeatures observed from the real samples to the GAN generator. Using\nantiretroviral therapy for human immunodeficiency virus (ART for HIV) as a case\nstudy, we show that our extended setup overcomes mode collapse and generates a\nsynthetic dataset that accurately describes severely imbalanced class\ndistributions commonly found in real-world clinical variables. In addition, we\ndemonstrate that our synthetic dataset is associated with a very low patient\ndisclosure risk, and that it retains a high level of utility from the ground\ntruth dataset to support the development of downstream machine learning\nalgorithms.\n","authors":["Nicholas I-Hsien Kuo","Federico Garcia","Anders Sönnerborg","Maurizio Zazzi","Michael Böhm","Rolf Kaiser","Mark Polizzotto","Louisa Jorm","Sebastiano Barbieri"],"pdf_url":"https://arxiv.org/pdf/2208.08655v2.pdf","comment":"In the near future, we will make our codes and synthetic datasets\n  publicly available to facilitate future research. Follow us on\n  https://healthgym.ai/"},{"id":"http://arxiv.org/abs/2009.01742v2","updated":"2023-01-20T05:08:47Z","published":"2020-09-03T15:39:55Z","title":"Online Estimation of Network Point Processes for Event Streams","summary":"  A common goal in network modeling is to uncover the latent community\nstructure present among nodes. For many real-world networks, the true\nconnections consist of events arriving as streams, which are then aggregated to\nform edges, ignoring the dynamic temporal component. A natural way to take\naccount of these temporal dynamics of interactions is to use point processes as\nthe foundation of network models for community detection. Computational\ncomplexity hampers the scalability of such approaches to large sparse networks.\nTo circumvent this challenge, we propose a fast online variational inference\nalgorithm for estimating the latent structure underlying dynamic event arrivals\non a network, using continuous-time point process latent network models. We\ndescribe this procedure for networks models capturing community structure. This\nstructure can be learned as new events are observed on the network, updating\nthe inferred community assignments. We investigate the theoretical properties\nof such an inference scheme, and provide regret bounds on the loss function of\nthis procedure. The proposed inference procedure is then thoroughly compared,\nusing both simulation studies and real data, to non-online variants. We\ndemonstrate that online inference can obtain comparable performance, in terms\nof community recovery, to non-online variants, while realising computational\ngains. Our proposed inference framework can also be readily modified to\nincorporate other popular network structures.\n","authors":["Guanhua Fang","Owen G. Ward","Tian Zheng"],"pdf_url":"https://arxiv.org/pdf/2009.01742v2.pdf","comment":"45 pages"},{"id":"http://arxiv.org/abs/2301.07492v2","updated":"2023-01-20T04:23:06Z","published":"2023-01-14T05:59:07Z","title":"Failure Tolerant Training with Persistent Memory Disaggregation over CXL","summary":"  This paper proposes TRAININGCXL that can efficiently process large-scale\nrecommendation datasets in the pool of disaggregated memory while making\ntraining fault tolerant with low overhead. To this end, i) we integrate\npersistent memory (PMEM) and GPU into a cache-coherent domain as Type-2.\nEnabling CXL allows PMEM to be directly placed in GPU's memory hierarchy, such\nthat GPU can access PMEM without software intervention. TRAININGCXL introduces\ncomputing and checkpointing logic near the CXL controller, thereby training\ndata and managing persistency in an active manner. Considering PMEM's\nvulnerability, ii) we utilize the unique characteristics of recommendation\nmodels and take the checkpointing overhead off the critical path of their\ntraining. Lastly, iii) TRAININGCXL employs an advanced checkpointing technique\nthat relaxes the updating sequence of model parameters and embeddings across\ntraining batches. The evaluation shows that TRAININGCXL achieves 5.2x training\nperformance improvement and 76% energy savings, compared to the modern\nPMEM-based recommendation systems.\n","authors":["Miryeong Kwon","Junhyeok Jang","Hanjin Choi","Sangwon Lee","Myoungsoo Jung"],"pdf_url":"https://arxiv.org/pdf/2301.07492v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08412v1","updated":"2023-01-20T03:35:03Z","published":"2023-01-20T03:35:03Z","title":"Fair Credit Scorer through Bayesian Approach","summary":"  Machine learning currently plays an increasingly important role in people's\nlives in areas such as credit scoring, auto-driving, disease diagnosing, and\ninsurance quoting. However, in many of these areas, machine learning models\nhave performed unfair behaviors against some sub-populations, such as some\nparticular groups of race, sex, and age. These unfair behaviors can be on\naccount of the pre-existing bias in the training dataset due to historical and\nsocial factors. In this paper, we focus on a real-world application of credit\nscoring and construct a fair prediction model by introducing latent variables\nto remove the correlation between protected attributes, such as sex and age,\nwith the observable feature inputs, including house and job. For detailed\nimplementation, we apply Bayesian approaches, including the Markov Chain Monte\nCarlo simulation, to estimate our proposed fair model.\n","authors":["Zhuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.08412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.04469v2","updated":"2023-01-20T03:14:10Z","published":"2021-11-04T20:19:55Z","title":"Mixed-Integer Optimization with Constraint Learning","summary":"  We establish a broad methodological foundation for mixed-integer optimization\nwith learned constraints. We propose an end-to-end pipeline for data-driven\ndecision making in which constraints and objectives are directly learned from\ndata using machine learning, and the trained models are embedded in an\noptimization formulation. We exploit the mixed-integer\noptimization-representability of many machine learning methods, including\nlinear models, decision trees, ensembles, and multi-layer perceptrons, which\nallows us to capture various underlying relationships between decisions,\ncontextual variables, and outcomes. We also introduce two approaches for\nhandling the inherent uncertainty of learning from data. First, we characterize\na decision trust region using the convex hull of the observations, to ensure\ncredible recommendations and avoid extrapolation. We efficiently incorporate\nthis representation using column generation and propose a more flexible\nformulation to deal with low-density regions and high-dimensional datasets.\nThen, we propose an ensemble learning approach that enforces constraint\nsatisfaction over multiple bootstrapped estimators or multiple algorithms. In\ncombination with domain-driven components, the embedded models and trust region\ndefine a mixed-integer optimization problem for prescription generation. We\nimplement this framework as a Python package (OptiCL) for practitioners. We\ndemonstrate the method in both World Food Programme planning and chemotherapy\noptimization. The case studies illustrate the framework's ability to generate\nhigh-quality prescriptions as well as the value added by the trust region, the\nuse of ensembles to control model robustness, the consideration of multiple\nmachine learning methods, and the inclusion of multiple learned constraints.\n","authors":["Donato Maragno","Holly Wiberg","Dimitris Bertsimas","S. Ilker Birbil","Dick den Hertog","Adejuyigbe Fajemisin"],"pdf_url":"https://arxiv.org/pdf/2111.04469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01201v2","updated":"2023-01-20T03:13:47Z","published":"2022-12-20T07:32:12Z","title":"Uncertainty in Real-Time Semantic Segmentation on Embedded Systems","summary":"  Application for semantic segmentation models in areas such as autonomous\nvehicles and human computer interaction require real-time predictive\ncapabilities. The challenges of addressing real-time application is amplified\nby the need to operate on resource constrained hardware. Whilst development of\nreal-time methods for these platforms has increased, these models are unable to\nsufficiently reason about uncertainty present. This paper addresses this by\ncombining deep feature extraction from pre-trained models with Bayesian\nregression and moment propagation for uncertainty aware predictions. We\ndemonstrate how the proposed method can yield meaningful uncertainty on\nembedded hardware in real-time whilst maintaining predictive performance.\n","authors":["Ethan Goan","Clinton Fookes"],"pdf_url":"https://arxiv.org/pdf/2301.01201v2.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.08403v1","updated":"2023-01-20T02:35:43Z","published":"2023-01-20T02:35:43Z","title":"Sequence Generation via Subsequence Similarity: Theory and Application\n  to UAV Identification","summary":"  The ability to generate synthetic sequences is crucial for a wide range of\napplications, and recent advances in deep learning architectures and generative\nframeworks have greatly facilitated this process. Particularly, unconditional\none-shot generative models constitute an attractive line of research that\nfocuses on capturing the internal information of a single image, video, etc. to\ngenerate samples with similar contents. Since many of those one-shot models are\nshifting toward efficient non-deep and non-adversarial approaches, we examine\nthe versatility of a one-shot generative model for augmenting whole datasets.\nIn this work, we focus on how similarity at the subsequence level affects\nsimilarity at the sequence level, and derive bounds on the optimal transport of\nreal and generated sequences based on that of corresponding subsequences. We\nuse a one-shot generative model to sample from the vicinity of individual\nsequences and generate subsequence-similar ones and demonstrate the improvement\nof this approach by applying it to the problem of Unmanned Aerial Vehicle (UAV)\nidentification using limited radio-frequency (RF) signals. In the context of\nUAV identification, RF fingerprinting is an effective method for distinguishing\nlegitimate devices from malicious ones, but heterogenous environments and\nchannel impairments can impose data scarcity and affect the performance of\nclassification models. By using subsequence similarity to augment sequences of\nRF data with a low ratio (5\\%-20\\%) of training dataset, we achieve significant\nimprovements in performance metrics such as accuracy, precision, recall, and F1\nscore.\n","authors":["Amir Kazemi","Salar Basiri","Volodymyr Kindratenko","Srinivasa Salapaka"],"pdf_url":"https://arxiv.org/pdf/2301.08403v1.pdf","comment":"12 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2301.08399v1","updated":"2023-01-20T02:22:55Z","published":"2023-01-20T02:22:55Z","title":"Who Should I Engage with At What Time? A Missing Event Aware Temporal\n  Graph Neural Network","summary":"  Temporal graph neural network has recently received significant attention due\nto its wide application scenarios, such as bioinformatics, knowledge graphs,\nand social networks. There are some temporal graph neural networks that achieve\nremarkable results. However, these works focus on future event prediction and\nare performed under the assumption that all historical events are observable.\nIn real-world applications, events are not always observable, and estimating\nevent time is as important as predicting future events. In this paper, we\npropose MTGN, a missing event-aware temporal graph neural network, which\nuniformly models evolving graph structure and timing of events to support\npredicting what will happen in the future and when it will happen.MTGN models\nthe dynamic of both observed and missing events as two coupled temporal point\nprocesses, thereby incorporating the effects of missing events into the\nnetwork. Experimental results on several real-world temporal graphs demonstrate\nthat MTGN significantly outperforms existing methods with up to 89% and 112%\nmore accurate time and link prediction. Code can be found on\nhttps://github.com/HIT-ICES/TNNLS-MTGN.\n","authors":["Mingyi Liu","Zhiying Tu","Xiaofei Xu","Zhongjie Wang"],"pdf_url":"https://arxiv.org/pdf/2301.08399v1.pdf","comment":"submitted to TNNLS"},{"id":"http://arxiv.org/abs/2301.08391v1","updated":"2023-01-20T02:02:54Z","published":"2023-01-20T02:02:54Z","title":"Brain Model State Space Reconstruction Using an LSTM Neural Network","summary":"  Objective\n  Kalman filtering has previously been applied to track neural model states and\nparameters, particularly at the scale relevant to EEG. However, this approach\nlacks a reliable method to determine the initial filter conditions and assumes\nthat the distribution of states remains Gaussian. This study presents an\nalternative, data-driven method to track the states and parameters of neural\nmass models (NMMs) from EEG recordings using deep learning techniques,\nspecifically an LSTM neural network.\n  Approach\n  An LSTM filter was trained on simulated EEG data generated by a neural mass\nmodel using a wide range of parameters. With an appropriately customised loss\nfunction, the LSTM filter can learn the behaviour of NMMs. As a result, it can\noutput the state vector and parameters of NMMs given observation data as the\ninput.\n  Main Results\n  Test results using simulated data yielded correlations with R squared of\naround 0.99 and verified that the method is robust to noise and can be more\naccurate than a nonlinear Kalman filter when the initial conditions of the\nKalman filter are not accurate. As an example of real-world application, the\nLSTM filter was also applied to real EEG data that included epileptic seizures,\nand revealed changes in connectivity strength parameters at the beginnings of\nseizures.\n  Significance\n  Tracking the state vector and parameters of mathematical brain models is of\ngreat importance in the area of brain modelling, monitoring, imaging and\ncontrol. This approach has no need to specify the initial state vector and\nparameters, which is very difficult to do in practice because many of the\nvariables being estimated cannot be measured directly in physiological\nexperiments. This method may be applied using any neural mass model and,\ntherefore, provides a general, novel, efficient approach to estimate brain\nmodel variables that are often difficult to measure.\n","authors":["Yueyang Liu","Artemio Soto-Breceda","Yun Zhao","Phillipa Karoly","Mark J. Cook","David B. Grayden","Daniel Schmidt","Levin Kuhlmann1"],"pdf_url":"https://arxiv.org/pdf/2301.08391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08390v1","updated":"2023-01-20T01:56:19Z","published":"2023-01-20T01:56:19Z","title":"Open-Set Likelihood Maximization for Few-Shot Learning","summary":"  We tackle the Few-Shot Open-Set Recognition (FSOSR) problem, i.e. classifying\ninstances among a set of classes for which we only have a few labeled samples,\nwhile simultaneously detecting instances that do not belong to any known class.\nWe explore the popular transductive setting, which leverages the unlabelled\nquery instances at inference. Motivated by the observation that existing\ntransductive methods perform poorly in open-set scenarios, we propose a\ngeneralization of the maximum likelihood principle, in which latent scores\ndown-weighing the influence of potential outliers are introduced alongside the\nusual parametric model. Our formulation embeds supervision constraints from the\nsupport set and additional penalties discouraging overconfident predictions on\nthe query set. We proceed with a block-coordinate descent, with the latent\nscores and parametric model co-optimized alternately, thereby benefiting from\neach other. We call our resulting formulation \\textit{Open-Set Likelihood\nOptimization} (OSLO). OSLO is interpretable and fully modular; it can be\napplied on top of any pre-trained model seamlessly. Through extensive\nexperiments, we show that our method surpasses existing inductive and\ntransductive methods on both aspects of open-set recognition, namely inlier\nclassification and outlier detection.\n","authors":["Malik Boudiaf","Etienne Bennequin","Myriam Tami","Antoine Toubhans","Pablo Piantanida","Céline Hudelot","Ismail Ben Ayed"],"pdf_url":"https://arxiv.org/pdf/2301.08390v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2206.09236"},{"id":"http://arxiv.org/abs/2301.08379v1","updated":"2023-01-20T01:15:56Z","published":"2023-01-20T01:15:56Z","title":"Asynchronously Trained Distributed Topographic Maps","summary":"  Topographic feature maps are low dimensional representations of data, that\npreserve spatial dependencies. Current methods of training such maps (e.g. self\norganizing maps - SOM, generative topographic maps) require centralized control\nand synchronous execution, which restricts scalability. We present an algorithm\nthat uses $N$ autonomous units to generate a feature map by distributed\nasynchronous training. Unit autonomy is achieved by sparse interaction in time\n\\& space through the combination of a distributed heuristic search, and a\ncascade-driven weight updating scheme governed by two rules: a unit i) adapts\nwhen it receives either a sample, or the weight vector of a neighbor, and ii)\nbroadcasts its weight vector to its neighbors after adapting for a predefined\nnumber of times. Thus, a vector update can trigger an avalanche of adaptation.\nWe map avalanching to a statistical mechanics model, which allows us to\nparametrize the statistical properties of cascading. Using MNIST, we\nempirically investigate the effect of the heuristic search accuracy and the\ncascade parameters on map quality. We also provide empirical evidence that\nalgorithm complexity scales at most linearly with system size $N$. The proposed\napproach is found to perform comparably with similar methods in classification\ntasks across multiple datasets.\n","authors":["Abbas Siddiqui","Dionysios Georgiadis"],"pdf_url":"https://arxiv.org/pdf/2301.08379v1.pdf","comment":"11 Pages, 8 Figures,"},{"id":"http://arxiv.org/abs/2212.07398v2","updated":"2023-01-20T00:47:23Z","published":"2022-12-14T18:31:47Z","title":"Self-Play and Self-Describe: Policy Adaptation with Vision-Language\n  Foundation Models","summary":"  Recent progress on vision-language foundation models have brought significant\nadvancement to building general-purpose robots. By using the pre-trained models\nto encode the scene and instructions as inputs for decision making, the\ninstruction-conditioned policy can generalize across different objects and\ntasks. While this is encouraging, the policy still fails in most cases given an\nunseen task or environment. To adapt the policy to unseen tasks and\nenvironments, we explore a new paradigm on leveraging the pre-trained\nfoundation models with Self-PLAY and Self-Describe (SPLAYD). When deploying the\ntrained policy to a new task or a new environment, we first let the policy\nself-play with randomly generated instructions to record the demonstrations.\nWhile the execution could be wrong, we can use the pre-trained foundation\nmodels to accurately self-describe (i.e., re-label or classify) the\ndemonstrations. This automatically provides new pairs of\ndemonstration-instruction data for policy fine-tuning. We evaluate our method\non a broad range of experiments with the focus on generalization on unseen\nobjects, unseen tasks, unseen environments, and sim-to-real transfer. We show\nSPLAYD improves baselines by a large margin in all cases. Our project page is\navailable at https://geyuying.github.io/SPLAYD/\n","authors":["Yuying Ge","Annabella Macaluso","Li Erran Li","Ping Luo","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2212.07398v2.pdf","comment":"Project page: https://geyuying.github.io/SPLAYD/"},{"id":"http://arxiv.org/abs/2301.08375v1","updated":"2023-01-20T00:39:19Z","published":"2023-01-20T00:39:19Z","title":"Within-group fairness: A guidance for more sound between-group fairness","summary":"  As they have a vital effect on social decision-making, AI algorithms not only\nshould be accurate and but also should not pose unfairness against certain\nsensitive groups (e.g., non-white, women). Various specially designed AI\nalgorithms to ensure trained AI models to be fair between sensitive groups have\nbeen developed. In this paper, we raise a new issue that between-group fair AI\nmodels could treat individuals in a same sensitive group unfairly. We introduce\na new concept of fairness so-called within-group fairness which requires that\nAI models should be fair for those in a same sensitive group as well as those\nin different sensitive groups. We materialize the concept of within-group\nfairness by proposing corresponding mathematical definitions and developing\nlearning algorithms to control within-group fairness and between-group fairness\nsimultaneously. Numerical studies show that the proposed learning algorithms\nimprove within-group fairness without sacrificing accuracy as well as\nbetween-group fairness.\n","authors":["Sara Kim","Kyusang Yu","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2301.08375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08374v1","updated":"2023-01-20T00:38:15Z","published":"2023-01-20T00:38:15Z","title":"An Efficient Quadrature Sequence and Sparsifying Methodology for\n  Mean-Field Variational Inference","summary":"  This work proposes a quasirandom sequence of quadratures for high-dimensional\nmean-field variational inference and a related sparsifying methodology. Each\niterate of the sequence contains two evaluations points that combine to\ncorrectly integrate all univariate quadratic functions, as well as univariate\ncubics if the mean-field factors are symmetric. More importantly, averaging\nresults over short subsequences achieves periodic exactness on a much larger\nspace of multivariate polynomials of quadratic total degree. This framework is\ndevised by first considering stochastic blocked mean-field quadratures, which\nmay be useful in other contexts. By replacing pseudorandom sequences with\nquasirandom sequences, over half of all multivariate quadratic basis functions\nintegrate exactly with only 4 function evaluations, and the exactness dimension\nincreases for longer subsequences. Analysis shows how these efficient integrals\ncharacterize the dominant log-posterior contributions to mean-field variational\napproximations, including diagonal Hessian approximations, to support a robust\nsparsifying methodology in deep learning algorithms. A numerical demonstration\nof this approach on a simple Convolutional Neural Network for MNIST retains\nhigh test accuracy, 96.9%, while training over 98.9% of parameters to zero in\nonly 10 epochs, bearing potential to reduce both storage and energy\nrequirements for deep learning models.\n","authors":["Jed A. Duersch"],"pdf_url":"https://arxiv.org/pdf/2301.08374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.01814v3","updated":"2023-01-20T00:18:49Z","published":"2022-07-05T05:14:15Z","title":"Multimodal Frame-Scoring Transformer for Video Summarization","summary":"  As the number of video content has mushroomed in recent years, automatic\nvideo summarization has come useful when we want to just peek at the content of\nthe video. However, there are two underlying limitations in generic video\nsummarization task. First, most previous approaches read in just visual\nfeatures as input, leaving other modality features behind. Second, existing\ndatasets for generic video summarization are relatively insufficient to train a\ncaption generator used for extracting text information from a video and to\ntrain the multimodal feature extractors. To address these two problems, this\npaper proposes the Multimodal Frame-Scoring Transformer (MFST), a framework\nexploiting visual, text, and audio features and scoring a video with respect to\nframes. Our MFST framework first extracts each modality features\n(audio-visual-text) using pretrained encoders. Then, MFST trains the multimodal\nframe-scoring transformer that uses multimodal representation based on\nextracted features as inputs and predicts frame-level scores. Our extensive\nexperiments with previous models and ablation studies on TVSum and SumMe\ndatasets demonstrate the effectiveness and superiority of our proposed method\nby a large margin in both F1 score and Rank-based evaluation.\n","authors":["Jeiyoon Park","Kiho Kwoun","Chanhee Lee","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2207.01814v3.pdf","comment":"preprint"}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.08664v1","updated":"2023-01-20T16:30:44Z","published":"2023-01-20T16:30:44Z","title":"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","summary":"  The quality of the video stream is key to neural network-based video\nanalytics. However, low-quality video is inevitably collected by existing\nsurveillance systems because of poor quality cameras or over-compressed/pruned\nvideo streaming protocols, e.g., as a result of upstream bandwidth limit. To\naddress this issue, existing studies use quality enhancers (e.g., neural\nsuper-resolution) to improve the quality of videos (e.g., resolution) and\neventually ensure inference accuracy. Nevertheless, directly applying quality\nenhancers does not work in practice because it will introduce unacceptable\nlatency. In this paper, we present AccDecoder, a novel accelerated decoder for\nreal-time and neural-enhanced video analytics. AccDecoder can select a few\nframes adaptively via Deep Reinforcement Learning (DRL) to enhance the quality\nby neural super-resolution and then up-scale the unselected frames that\nreference them, which leads to 6-21% accuracy improvement. AccDecoder provides\nefficient inference capability via filtering important frames using DRL for\nDNN-based inference and reusing the results for the other frames via extracting\nthe reference relationship among frames and blocks, which results in a latency\nreduction of 20-80% than baselines.\n","authors":["Tingting Yuan","Liang Mi","Weijun Wang","Haipeng Dai","Xiaoming Fu"],"pdf_url":"https://arxiv.org/pdf/2301.08664v1.pdf","comment":"Accepted by 2023 IEEE INFOCOM"},{"id":"http://arxiv.org/abs/2211.16191v2","updated":"2023-01-20T13:56:39Z","published":"2022-11-28T14:58:15Z","title":"SgVA-CLIP: Semantic-guided Visual Adapting of Vision-Language Models for\n  Few-shot Image Classification","summary":"  Although significant progress has been made in few-shot learning, most of\nexisting few-shot image classification methods require supervised pre-training\non a large amount of samples of base classes, which limits their generalization\nability in real world application. Recently, large-scale Vision-Language\nPre-trained models (VLPs) have been gaining increasing attention in few-shot\nlearning because they can provide a new paradigm for transferable visual\nrepresentation learning with easily available text on the Web. However, the\nVLPs may neglect detailed visual information that is difficult to describe by\nlanguage sentences, but important for learning an effective classifier to\ndistinguish different images. To address the above problem, we propose a new\nframework, named Semantic-guided Visual Adapting (SgVA), which can effectively\nextend vision-language pre-trained models to produce discriminative adapted\nvisual features by comprehensively using an implicit knowledge distillation, a\nvision-specific contrastive loss, and a cross-modal contrastive loss. The\nimplicit knowledge distillation is designed to transfer the fine-grained\ncross-modal knowledge to guide the updating of the vision adapter.\nState-of-the-art results on 13 datasets demonstrate that the adapted visual\nfeatures can well complement the cross-modal features to improve few-shot image\nclassification.\n","authors":["Fang Peng","Xiaoshan Yang","Linhui Xiao","Yaowei Wang","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2211.16191v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08565v1","updated":"2023-01-20T13:26:36Z","published":"2023-01-20T13:26:36Z","title":"Developing a Framework for Heterotopias as Discursive Playgrounds: A\n  Comparative Analysis of Non-Immersive and Immersive Technologies","summary":"  The discursive space represents the reordering of knowledge gained through\naccumulation. In the digital age, multimedia has become the language of\ninformation, and the space for archival practices is provided by non-immersive\ntechnologies, resulting in the disappearance of several layers from discursive\nactivities. Heterotopias are unique, multilayered epistemic contexts that\nconnect other systems through the exchange of information. This paper describes\na process to create a framework for Virtual Reality, Mixed Reality, and\npersonal computer environments based on heterotopias to provide absent layers.\nThis study provides virtual museum space as an informational terrain that\ncontains a \"world within worlds\" and presents place production as a layer of\nheterotopia and the subject of discourse. Automation for the individual\nmultimedia content is provided via various sorting and grouping algorithms, and\nprocedural content generation algorithms such as Binary Space Partitioning,\nCellular Automata, Growth Algorithm, and Procedural Room Generation. Versions\nof the framework were comparatively evaluated through a user study involving 30\nparticipants, considering factors such as usability, technology acceptance, and\npresence. The results of the study show that the framework can serve diverse\ncontexts to construct multilayered digital habitats and is flexible for\nintegration into professional and daily life practices.\n","authors":["Elif Hilal Korkut","Elif Surer"],"pdf_url":"https://arxiv.org/pdf/2301.08565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08783v1","updated":"2023-01-20T19:46:23Z","published":"2023-01-20T19:46:23Z","title":"An Asynchronous Intensity Representation for Framed and Event Video\n  Sources","summary":"  Neuromorphic \"event\" cameras, designed to mimic the human vision system with\nasynchronous sensing, unlock a new realm of high-speed and high dynamic range\napplications. However, researchers often either revert to a framed\nrepresentation of event data for applications, or build bespoke applications\nfor a particular camera's event data type. To usher in the next era of video\nsystems, accommodate new event camera designs, and explore the benefits to\nasynchronous video in classical applications, we argue that there is a need for\nan asynchronous, source-agnostic video representation. In this paper, we\nintroduce a novel, asynchronous intensity representation for both framed and\nnon-framed data sources. We show that our representation can increase intensity\nprecision and greatly reduce the number of samples per pixel compared to\ngrid-based representations. With framed sources, we demonstrate that by\npermitting a small amount of loss through the temporal averaging of similar\npixel values, we can reduce our representational sample rate by more than half,\nwhile incurring a drop in VMAF quality score of only 4.5. We also demonstrate\nlower latency than the state-of-the-art method for fusing and transcoding\nframed and event camera data to an intensity representation, while maintaining\n$2000\\times$ the temporal resolution. We argue that our method provides the\ncomputational efficiency and temporal granularity necessary to build real-time\nintensity-based applications for event cameras.\n","authors":["Andrew C. Freeman","Montek Singh","Ketan Mayer-Patel"],"pdf_url":"https://arxiv.org/pdf/2301.08783v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2301.08752v1","updated":"2023-01-20T18:01:31Z","published":"2023-01-20T18:01:31Z","title":"Optimized learned entropy coding parameters for practical neural-based\n  image and video compression","summary":"  Neural-based image and video codecs are significantly more power-efficient\nwhen weights and activations are quantized to low-precision integers. While\nthere are general-purpose techniques for reducing quantization effects, large\nlosses can occur when specific entropy coding properties are not considered.\nThis work analyzes how entropy coding is affected by parameter quantizations,\nand provides a method to minimize losses. It is shown that, by using a certain\ntype of coding parameters to be learned, uniform quantization becomes\npractically optimal, also simplifying the minimization of code memory\nrequirements. The mathematical properties of the new representation are\npresented, and its effectiveness is demonstrated by coding experiments, showing\nthat good results can be obtained with precision as low as 4~bits per network\noutput, and practically no loss with 8~bits.\n","authors":["Amir Said","Reza Pourreza","Hoang Le"],"pdf_url":"https://arxiv.org/pdf/2301.08752v1.pdf","comment":"2022 IEEE International Conference on Image Processing (ICIP)"}]},"2023-01-23T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2204.04581v3","updated":"2023-01-23T18:57:42Z","published":"2022-04-10T02:33:00Z","title":"Augmenting Pre-trained Language Models with QA-Memory for Open-Domain\n  Question Answering","summary":"  Retrieval augmented language models have recently become the standard for\nknowledge intensive tasks. Rather than relying purely on latent semantics\nwithin the parameters of large neural models, these methods enlist a\nsemi-parametric memory to encode an index of knowledge for the model to\nretrieve over. Most prior work has employed text passages as the unit of\nknowledge, which has high coverage at the cost of interpretability,\ncontrollability, and efficiency. The opposite properties arise in other methods\nwhich have instead relied on knowledge base (KB) facts. At the same time, more\nrecent work has demonstrated the effectiveness of storing and retrieving from\nan index of Q-A pairs derived from text \\citep{lewis2021paq}. This approach\nyields a high coverage knowledge representation that maintains KB-like\nproperties due to its representations being more atomic units of information.\nIn this work we push this line of research further by proposing a\nquestion-answer augmented encoder-decoder model and accompanying pretraining\nstrategy. This yields an end-to-end system that not only outperforms prior QA\nretrieval methods on single-hop QA tasks but also enables compositional\nreasoning, as demonstrated by strong performance on two multi-hop QA datasets.\nTogether, these methods improve the ability to interpret and control the model\nwhile narrowing the performance gap with passage retrieval systems.\n","authors":["Wenhu Chen","Pat Verga","Michiel de Jong","John Wieting","William Cohen"],"pdf_url":"https://arxiv.org/pdf/2204.04581v3.pdf","comment":"Accepted by EACL 2023"},{"id":"http://arxiv.org/abs/2301.09626v1","updated":"2023-01-23T18:56:12Z","published":"2023-01-23T18:56:12Z","title":"Efficient Language Model Training through Cross-Lingual and Progressive\n  Transfer Learning","summary":"  Most Transformer language models are primarily pretrained on English text,\nlimiting their use for other languages. As the model sizes grow, the\nperformance gap between English and other languages with fewer compute and data\nresources increases even further. Consequently, more resource-efficient\ntraining methods are needed to bridge the gap for languages with fewer\nresources available. To address this problem, we introduce a cross-lingual and\nprogressive transfer learning approach, called CLP-Transfer, that transfers\nmodels from a source language, for which pretrained models are publicly\navailable, like English, to a new target language. As opposed to prior work,\nwhich focused on the cross-lingual transfer between two languages, we extend\nthe transfer to the model size. Given a pretrained model in a source language,\nwe aim for a same-sized model in a target language. Instead of training a model\nfrom scratch, we exploit a smaller model that is in the target language but\nrequires much fewer resources. Both small and source models are then used to\ninitialize the token embeddings of the larger model based on the overlapping\nvocabulary of the source and target language. All remaining weights are reused\nfrom the model in the source language. This approach outperforms the sole\ncross-lingual transfer and can save up to 80% of the training steps compared to\nthe random initialization.\n","authors":["Malte Ostendorff","Georg Rehm"],"pdf_url":"https://arxiv.org/pdf/2301.09626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06710v2","updated":"2023-01-23T18:51:00Z","published":"2022-10-13T04:08:24Z","title":"Large Language Models are few(1)-shot Table Reasoners","summary":"  Recent literature has shown that large language models (LLMs) are generally\nexcellent few-shot reasoners to solve text reasoning tasks. However, the\ncapability of LLMs on table reasoning tasks is yet to be explored. In this\npaper, we aim at understanding how well LLMs can perform table-related tasks\nwith few-shot in-context learning. Specifically, we evaluated LLMs on popular\ntable QA and fact verification datasets like WikiTableQuestion, FetaQA,\nTabFact, and FEVEROUS and found that LLMs are competent at complex reasoning\nover table structures, though these models are not pre-trained on any table\ncorpus. When combined with `chain of thoughts' prompting, LLMs can achieve very\nstrong performance with only a 1-shot demonstration, even on par with some SoTA\nmodels. We show that LLMs are even more competent at generating comprehensive\nlong-form answers on FetaQA than tuned T5-large. We further manually studied\nthe reasoning chains elicited from LLMs and found that these reasoning chains\nare highly consistent with the underlying semantic form. We believe that LLMs\ncan serve as a simple yet generic baseline for future research. The code and\ndata are released in https://github.com/wenhuchen/TableCoT.\n","authors":["Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2210.06710v2.pdf","comment":"Accepted to Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2205.12411v5","updated":"2023-01-23T18:21:02Z","published":"2022-05-24T23:43:02Z","title":"Linear Connectivity Reveals Generalization Strategies","summary":"  It is widely accepted in the mode connectivity literature that when two\nneural networks are trained similarly on the same data, they are connected by a\npath through parameter space over which test set accuracy is maintained. Under\nsome circumstances, including transfer learning from pretrained models, these\npaths are presumed to be linear. In contrast to existing results, we find that\namong text classifiers (trained on MNLI, QQP, and CoLA), some pairs of\nfinetuned models have large barriers of increasing loss on the linear paths\nbetween them. On each task, we find distinct clusters of models which are\nlinearly connected on the test loss surface, but are disconnected from models\noutside the cluster -- models that occupy separate basins on the surface. By\nmeasuring performance on specially-crafted diagnostic datasets, we find that\nthese clusters correspond to different generalization strategies: one cluster\nbehaves like a bag of words model under domain shift, while another cluster\nuses syntactic heuristics. Our work demonstrates how the geometry of the loss\nsurface can guide models towards different heuristic functions.\n","authors":["Jeevesh Juneja","Rachit Bansal","Kyunghyun Cho","João Sedoc","Naomi Saphra"],"pdf_url":"https://arxiv.org/pdf/2205.12411v5.pdf","comment":"Publushed as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.14024v2","updated":"2023-01-23T17:00:01Z","published":"2022-12-28T18:52:44Z","title":"Demonstrate-Search-Predict: Composing retrieval and language models for\n  knowledge-intensive NLP","summary":"  Retrieval-augmented in-context learning has emerged as a powerful approach\nfor addressing knowledge-intensive tasks using frozen language models (LM) and\nretrieval models (RM). Existing work has combined these in simple\n\"retrieve-then-read\" pipelines in which the RM retrieves passages that are\ninserted into the LM prompt. To begin to fully realize the potential of frozen\nLMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that\nrelies on passing natural language texts in sophisticated pipelines between an\nLM and an RM. DSP can express high-level programs that bootstrap pipeline-aware\ndemonstrations, search for relevant passages, and generate grounded\npredictions, systematically breaking down problems into small transformations\nthat the LM and RM can handle more reliably. We have written novel DSP programs\nfor answering questions in open-domain, multi-hop, and conversational settings,\nestablishing in early evaluations new state-of-the-art in-context learning\nresults and delivering 37-120%, 8-39%, and 80-290% relative gains against the\nvanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a\ncontemporaneous self-ask pipeline, respectively. We release DSP at\nhttps://github.com/stanfordnlp/dsp\n","authors":["Omar Khattab","Keshav Santhanam","Xiang Lisa Li","David Hall","Percy Liang","Christopher Potts","Matei Zaharia"],"pdf_url":"https://arxiv.org/pdf/2212.14024v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13439v2","updated":"2023-01-23T15:31:57Z","published":"2022-10-24T17:52:09Z","title":"Cascading Biases: Investigating the Effect of Heuristic Annotation\n  Strategies on Data and Models","summary":"  Cognitive psychologists have documented that humans use cognitive heuristics,\nor mental shortcuts, to make quick decisions while expending less effort. While\nperforming annotation work on crowdsourcing platforms, we hypothesize that such\nheuristic use among annotators cascades on to data quality and model\nrobustness. In this work, we study cognitive heuristic use in the context of\nannotating multiple-choice reading comprehension datasets. We propose tracking\nannotator heuristic traces, where we tangibly measure low-effort annotation\nstrategies that could indicate usage of various cognitive heuristics. We find\nevidence that annotators might be using multiple such heuristics, based on\ncorrelations with a battery of psychological tests. Importantly, heuristic use\namong annotators determines data quality along several dimensions: (1) known\nbiased models, such as partial input models, more easily solve examples\nauthored by annotators that rate highly on heuristic use, (2) models trained on\nannotators scoring highly on heuristic use don't generalize as well, and (3)\nheuristic-seeking annotators tend to create qualitatively less challenging\nexamples. Our findings suggest that tracking heuristic usage among annotators\ncan potentially help with collecting challenging datasets and diagnosing model\nbiases.\n","authors":["Chaitanya Malaviya","Sudeep Bhatia","Mark Yatskar"],"pdf_url":"https://arxiv.org/pdf/2210.13439v2.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2210.03765v2","updated":"2023-01-23T14:35:24Z","published":"2022-10-07T18:01:09Z","title":"Visualize Before You Write: Imagination-Guided Open-Ended Text\n  Generation","summary":"  Recent advances in text-to-image synthesis make it possible to visualize\nmachine imaginations for a given context. On the other hand, when generating\ntext, human writers are gifted at creative visualization, which enhances their\nwritings by forming imaginations as blueprints before putting down the stories\nin words. Inspired by such a cognitive process, we ask the natural question of\nwhether we can endow machines with the same ability to utilize visual\ninformation and construct a general picture of the context to guide text\ngeneration. In this work, we propose iNLG that uses machine-generated images to\nguide language models in open-ended text generation. The experiments and\nanalyses demonstrate the effectiveness of iNLG on open-ended text generation\ntasks, including text completion, story generation, and concept-to-text\ngeneration in both few-shot and full-data scenarios. Both automatic metrics and\nhuman evaluations verify that the text snippets generated by our iNLG are\ncoherent and informative while displaying minor degeneration.\n","authors":["Wanrong Zhu","An Yan","Yujie Lu","Wenda Xu","Xin Eric Wang","Miguel Eckstein","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2210.03765v2.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2301.09445v1","updated":"2023-01-23T14:08:34Z","published":"2023-01-23T14:08:34Z","title":"The Energy Worker Profiler from Technologies to Skills to Realize Energy\n  Efficiency in Manufacturing","summary":"  In recent years, the manufacturing sector has been responsible for nearly 55\npercent of total energy consumption, inducing a major impact on the global\necosystem. Although stricter regulations, restrictions on heavy manufacturing\nand technological advances are increasing its sustainability, zero-emission and\nfuel-efficient manufacturing is still considered a utopian target. In\nparallel,companies that have invested in digital innovation now need to align\ntheir internal competencies to maximize their return on investment. Moreover, a\nprimary feature of Industry 4.0 is the digitization of production processes,\nwhich offers the opportunity to optimize energy consumption. However, given the\nspeed with which innovation manifests itself, tools capable of measuring the\nimpact that technology is having on digital and green professions and skills\nare still being designed. In light of the above, in this article we present the\nWorker Profiler, a software designed to map the skills currently possessed by\nworkers, identifying misalignment with those they should ideally possess to\nmeet the renewed demands that digital innovation and environmental preservation\nimpose. The creation of the Worker Profiler consists of two steps: first, the\nauthors inferred the key technologies and skills for the area of interest,\nisolating those with markedly increasing patent trends and identifying green\nand digital enabling skills and occupations. Thus, the software was designed\nand implemented at the user-interface level. The output of the self-assessment\nis the definition of the missing digital and green skills and the job roles\nclosest to the starting one in terms of current skills; both the results enable\nthe definition of a customized retraining strategy. The tool has shown evidence\nof being user-friendly, effective in identifying skills gaps and easily\nadaptable to other contexts.\n","authors":["Silvia Fareri","Riccardo Apreda","Valentina Mulas","Ruben Alonso"],"pdf_url":"https://arxiv.org/pdf/2301.09445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02387v3","updated":"2023-01-23T13:42:33Z","published":"2022-01-07T10:22:08Z","title":"The Defeat of the Winograd Schema Challenge","summary":"  The Winograd Schema Challenge - a set of twin sentences involving pronoun\nreference disambiguation that seem to require the use of commonsense knowledge\n- was proposed by Hector Levesque in 2011. By 2019, a number of AI systems,\nbased on large pre-trained transformer-based language models and fine-tuned on\nthese kinds of problems, achieved better than 90% accuracy. In this paper, we\nreview the history of the Winograd Schema Challenge and discuss the lasting\ncontributions of the flurry of research that has taken place on the WSC in the\nlast decade. We discuss the significance of various datasets developed for WSC,\nand the research community's deeper understanding of the role of surrogate\ntasks in assessing the intelligence of an AI system.\n","authors":["Vid Kocijan","Ernest Davis","Thomas Lukasiewicz","Gary Marcus","Leora Morgenstern"],"pdf_url":"https://arxiv.org/pdf/2201.02387v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09412v1","updated":"2023-01-23T13:10:23Z","published":"2023-01-23T13:10:23Z","title":"Deep Learning Mental Health Dialogue System","summary":"  Mental health counseling remains a major challenge in modern society due to\ncost, stigma, fear, and unavailability. We posit that generative artificial\nintelligence (AI) models designed for mental health counseling could help\nimprove outcomes by lowering barriers to access. To this end, we have developed\na deep learning (DL) dialogue system called Serena. The system consists of a\ncore generative model and post-processing algorithms. The core generative model\nis a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of\ntranscripts of person-centered-therapy (PCT) sessions. The series of\npost-processing algorithms detects contradictions, improves coherency, and\nremoves repetitive answers. Serena is implemented and deployed on\n\\url{https://serena.chat}, which currently offers limited free services. While\nthe dialogue system is capable of responding in a qualitatively empathetic and\nengaging manner, occasionally it displays hallucination and long-term\nincoherence. Overall, we demonstrate that a deep learning mental health\ndialogue system has the potential to provide a low-cost and effective\ncomplement to traditional human counselors with less barriers to access.\n","authors":["Lennart Brocki","George C. Dyer","Anna Gładka","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2301.09412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10688v2","updated":"2023-01-23T11:29:44Z","published":"2022-11-19T13:04:53Z","title":"ReInform: Selecting paths with reinforcement learning for contextualized\n  link prediction","summary":"  We propose to use reinforcement learning to inform transformer-based\ncontextualized link prediction models by providing paths that are most useful\nfor predicting the correct answer. This is in contrast to previous approaches,\nthat either used reinforcement learning (RL) to directly search for the answer,\nor based their prediction on limited or randomly selected context. Our\nexperiments on WN18RR and FB15k-237 show that contextualized link prediction\nmodels consistently outperform RL-based answer search, and that additional\nimprovements (of up to 13.5% MRR) can be gained by combining RL with a link\nprediction model. The PyTorch implementation of the RL agent is available at\nhttps://github.com/marina-sp/reinform\n","authors":["Marina Speranskaya","Sameh Methias","Benjamin Roth"],"pdf_url":"https://arxiv.org/pdf/2211.10688v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09361v1","updated":"2023-01-23T10:58:18Z","published":"2023-01-23T10:58:18Z","title":"SMDDH: Singleton Mention detection using Deep Learning in Hindi Text","summary":"  Mention detection is an important component of coreference resolution system,\nwhere mentions such as name, nominal, and pronominals are identified. These\nmentions can be purely coreferential mentions or singleton mentions\n(non-coreferential mentions). Coreferential mentions are those mentions in a\ntext that refer to the same entities in a real world. Whereas, singleton\nmentions are mentioned only once in the text and do not participate in the\ncoreference as they are not mentioned again in the following text. Filtering of\nthese singleton mentions can substantially improve the performance of a\ncoreference resolution process. This paper proposes a singleton mention\ndetection module based on a fully connected network and a Convolutional neural\nnetwork for Hindi text. This model utilizes a few hand-crafted features and\ncontext information, and word embedding for words. The coreference annotated\nHindi dataset comprising of 3.6K sentences, and 78K tokens are used for the\ntask. In terms of Precision, Recall, and F-measure, the experimental findings\nobtained are excellent.\n","authors":["Kusum Lata","Pardeep Singh","Kamlesh Dutta"],"pdf_url":"https://arxiv.org/pdf/2301.09361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03551v3","updated":"2023-01-23T10:55:33Z","published":"2022-12-07T10:01:44Z","title":"Talking About Large Language Models","summary":"  Thanks to rapid progress in artificial intelligence, we have entered an era\nwhen technology and philosophy intersect in interesting ways. Sitting squarely\nat the centre of this intersection are large language models (LLMs). The more\nadept LLMs become at mimicking human language, the more vulnerable we become to\nanthropomorphism, to seeing the systems in which they are embedded as more\nhuman-like than they really are. This trend is amplified by the natural\ntendency to use philosophically loaded terms, such as \"knows\", \"believes\", and\n\"thinks\", when describing these systems. To mitigate this trend, this paper\nadvocates the practice of repeatedly stepping back to remind ourselves of how\nLLMs, and the systems of which they form a part, actually work. The hope is\nthat increased scientific precision will encourage more philosophical nuance in\nthe discourse around artificial intelligence, both within the field and in the\npublic sphere.\n","authors":["Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2212.03551v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.12235v3","updated":"2023-01-23T10:47:18Z","published":"2022-03-23T07:07:11Z","title":"Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions","summary":"  The syntactic categories of categorial grammar formalisms are structured\nunits made of smaller, indivisible primitives, bound together by the underlying\ngrammar's category formation rules. In the trending approach of constructive\nsupertagging, neural models are increasingly made aware of the internal\ncategory structure, which in turn enables them to more reliably predict rare\nand out-of-vocabulary categories, with significant implications for grammars\npreviously deemed too complex to find practical use. In this work, we revisit\nconstructive supertagging from a graph-theoretic perspective, and propose a\nframework based on heterogeneous dynamic graph convolutions aimed at exploiting\nthe distinctive structure of a supertagger's output space. We test our approach\non a number of categorial grammar datasets spanning different languages and\ngrammar formalisms, achieving substantial improvements over previous state of\nthe art scores. Code will be made available at\nhttps://github.com/konstantinosKokos/dynamic-graph-supertagging\n","authors":["Konstantinos Kogkalidis","Michael Moortgat"],"pdf_url":"https://arxiv.org/pdf/2203.12235v3.pdf","comment":"8 pages plus references, unpublished preprint v2: fixed small typos,\n  added appendix with a visualization of the decoding process; v3: improved\n  presentation, improved the decoding figure"},{"id":"http://arxiv.org/abs/2301.09350v1","updated":"2023-01-23T10:33:22Z","published":"2023-01-23T10:33:22Z","title":"Large-scale fine-grained semantic indexing of biomedical literature\n  based on weakly-supervised deep learning","summary":"  Semantic indexing of biomedical literature is usually done at the level of\nMeSH descriptors, representing topics of interest for the biomedical community.\nSeveral related but distinct biomedical concepts are often grouped together in\na single coarse-grained descriptor and are treated as a single topic for\nsemantic indexing. This study proposes a new method for the automated\nrefinement of subject annotations at the level of concepts, investigating deep\nlearning approaches. Lacking labelled data for this task, our method relies on\nweak supervision based on concept occurrence in the abstract of an article. The\nproposed approach is evaluated on an extended large-scale retrospective\nscenario, taking advantage of concepts that eventually become MeSH descriptors,\nfor which annotations become available in MEDLINE/PubMed. The results suggest\nthat concept occurrence is a strong heuristic for automated subject annotation\nrefinement and can be further enhanced when combined with dictionary-based\nheuristics. In addition, such heuristics can be useful as weak supervision for\ndeveloping deep learning models that can achieve further improvement in some\ncases.\n","authors":["Anastasios Nentidis","Thomas Chatzopoulos","Anastasia Krithara","Grigorios Tsoumakas","Georgios Paliouras"],"pdf_url":"https://arxiv.org/pdf/2301.09350v1.pdf","comment":"48 pages, 5 figures, 9 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2301.08006v2","updated":"2023-01-23T09:12:33Z","published":"2023-01-19T11:13:04Z","title":"Keyword Embeddings for Query Suggestion","summary":"  Nowadays, search engine users commonly rely on query suggestions to improve\ntheir initial inputs. Current systems are very good at recommending lexical\nadaptations or spelling corrections to users' queries. However, they often\nstruggle to suggest semantically related keywords given a user's query. The\nconstruction of a detailed query is crucial in some tasks, such as legal\nretrieval or academic search. In these scenarios, keyword suggestion methods\nare critical to guide the user during the query formulation. This paper\nproposes two novel models for the keyword suggestion task trained on scientific\nliterature. Our techniques adapt the architecture of Word2Vec and FastText to\ngenerate keyword embeddings by leveraging documents' keyword co-occurrence.\nAlong with these models, we also present a specially tailored negative sampling\napproach that exploits how keywords appear in academic publications. We devise\na ranking-based evaluation methodology following both known-item and ad-hoc\nsearch scenarios. Finally, we evaluate our proposals against the\nstate-of-the-art word and sentence embedding models showing considerable\nimprovements over the baselines for the tasks.\n","authors":["Jorge Gabín","M. Eduardo Ares","Javier Parapar"],"pdf_url":"https://arxiv.org/pdf/2301.08006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09295v1","updated":"2023-01-23T06:44:38Z","published":"2023-01-23T06:44:38Z","title":"Sensemaking About Contraceptive Methods Across Online Platforms","summary":"  Selecting a birth control method is a complex healthcare decision. While\nbirth control methods provide important benefits, they can also cause\nunpredictable side effects and be stigmatized, leading many people to seek\nadditional information online, where they can find reviews, advice, hypotheses,\nand experiences of other birth control users. However, the relationships\nbetween their healthcare concerns, sensemaking activities, and online settings\nare not well understood. We gather texts about birth control shared on Twitter,\nReddit, and WebMD -- platforms with different affordances, moderation, and\naudiences -- to study where and how birth control is discussed online. Using a\ncombination of topic modeling and hand annotation, we identify and characterize\nthe dominant sensemaking practices across these platforms, and we create\nlexicons to draw comparisons across birth control methods and side effects. We\nuse these to measure variations from survey reports of side effect experiences\nand method usage. Our findings characterize how online platforms are used to\nmake sense of difficult healthcare choices and highlight unmet needs of birth\ncontrol users.\n","authors":["LeAnn McDowall","Maria Antoniak","David Mimno"],"pdf_url":"https://arxiv.org/pdf/2301.09295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09279v1","updated":"2023-01-23T05:32:42Z","published":"2023-01-23T05:32:42Z","title":"StockEmotions: Discover Investor Emotions for Financial Sentiment\n  Analysis and Multivariate Time Series","summary":"  There has been growing interest in applying NLP techniques in the financial\ndomain, however, resources are extremely limited. This paper introduces\nStockEmotions, a new dataset for detecting emotions in the stock market that\nconsists of 10,000 English comments collected from StockTwits, a financial\nsocial media platform. Inspired by behavioral finance, it proposes 12\nfine-grained emotion classes that span the roller coaster of investor emotion.\nUnlike existing financial sentiment datasets, StockEmotions presents granular\nfeatures such as investor sentiment classes, fine-grained emotions, emojis, and\ntime series data. To demonstrate the usability of the dataset, we perform a\ndataset analysis and conduct experimental downstream tasks. For financial\nsentiment/emotion classification tasks, DistilBERT outperforms other baselines,\nand for multivariate time series forecasting, a Temporal Attention LSTM model\ncombining price index, text, and emotion features achieves the best performance\nthan using a single feature.\n","authors":["Jean Lee","Hoyoul Luis Youn","Josiah Poon","Soyeon Caren Han"],"pdf_url":"https://arxiv.org/pdf/2301.09279v1.pdf","comment":"Preprint for the AAAI-23 Bridge Program (AI for Financial Services)"},{"id":"http://arxiv.org/abs/2301.09244v1","updated":"2023-01-23T02:20:39Z","published":"2023-01-23T02:20:39Z","title":"Efficient Encoders for Streaming Sequence Tagging","summary":"  A naive application of state-of-the-art bidirectional encoders for streaming\nsequence tagging would require encoding each token from scratch for each new\ntoken in an incremental streaming input (like transcribed speech). The lack of\nre-usability of previous computation leads to a higher number of Floating Point\nOperations (or FLOPs) and higher number of unnecessary label flips. Increased\nFLOPs consequently lead to higher wall-clock time and increased label flipping\nleads to poorer streaming performance. In this work, we present a Hybrid\nEncoder with Adaptive Restart (HEAR) that addresses these issues while\nmaintaining the performance of bidirectional encoders over the offline (or\ncomplete) inputs while improving performance on streaming (or incomplete)\ninputs. HEAR has a Hybrid unidirectional-bidirectional encoder architecture to\nperform sequence tagging, along with an Adaptive Restart Module (ARM) to\nselectively guide the restart of bidirectional portion of the encoder. Across\nfour sequence tagging tasks, HEAR offers FLOP savings in streaming settings\nupto 71.1% and also outperforms bidirectional encoders for streaming\npredictions by upto +10% streaming exact match.\n","authors":["Ayush Kaushal","Aditya Gupta","Shyam Upadhyay","Manaal Faruqui"],"pdf_url":"https://arxiv.org/pdf/2301.09244v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2301.09237v1","updated":"2023-01-23T00:54:48Z","published":"2023-01-23T00:54:48Z","title":"Semantic-aware Contrastive Learning for Electroencephalography-to-Text\n  Generation with Curriculum Learning","summary":"  Electroencephalography-to-Text generation (EEG-to-Text), which aims to\ndirectly generate natural text from EEG signals has drawn increasing attention\nin recent years due to the enormous potential for Brain-computer interfaces\n(BCIs). However, the remarkable discrepancy between the subject-dependent EEG\nrepresentation and the semantic-dependent text representation poses a great\nchallenge to this task. To mitigate this challenge, we devise a Curriculum\nSemantic-aware Contrastive Learning strategy (C-SCL), which effectively\nre-calibrates the subject-dependent EEG representation to the\nsemantic-dependent EEG representation, thus reducing the discrepancy.\nSpecifically, our C-SCL pulls semantically similar EEG representations together\nwhile pushing apart dissimilar ones. Besides, in order to introduce more\nmeaningful contrastive pairs, we carefully employ curriculum learning to not\nonly craft meaningful contrastive pairs but also make the learning\nprogressively. We conduct extensive experiments on the ZuCo benchmark and our\nmethod combined with diverse models and architectures shows stable improvements\nacross three types of metrics while achieving the new state-of-the-art. Further\ninvestigation proves not only its superiority in both the single-subject and\nlow-resource settings but also its robust generalizability in the zero-shot\nsetting.\n","authors":["Xiachong Feng","Xiaocheng Feng","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2301.09237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09759v1","updated":"2023-01-23T23:43:24Z","published":"2023-01-23T23:43:24Z","title":"Topic Ontologies for Arguments","summary":"  Many computational argumentation tasks, like stance classification, are\ntopic-dependent: the effectiveness of approaches to these tasks significantly\ndepends on whether the approaches were trained on arguments from the same\ntopics as those they are tested on. So, which are these topics that researchers\ntrain approaches on? This paper contributes the first comprehensive survey of\ntopic coverage, assessing 45 argument corpora. For the assessment, we take the\nfirst step towards building an argument topic ontology, consulting three\ndiverse authoritative sources: the World Economic Forum, the Wikipedia list of\ncontroversial topics, and Debatepedia. Comparing the topic sets between the\nauthoritative sources and corpora, our analysis shows that the corpora\ntopics-which are mostly those frequently discussed in public online fora - are\ncovered well by the sources. However, other topics from the sources are less\nextensively covered by the corpora of today, revealing interesting future\ndirections for corpus construction.\n","authors":["Yamen Ajjour","Johannes Kiesel","Benno Stein","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2301.09759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09715v1","updated":"2023-01-23T20:43:26Z","published":"2023-01-23T20:43:26Z","title":"PRIMEQA: The Prime Repository for State-of-the-Art MultilingualQuestion\n  Answering Research and Development","summary":"  The field of Question Answering (QA) has made remarkable progress in recent\nyears, thanks to the advent of large pre-trained language models, newer\nrealistic benchmark datasets with leaderboards, and novel algorithms for key\ncomponents such as retrievers and readers. In this paper, we introduce PRIMEQA:\na one-stop and open-source QA repository with an aim to democratize QA\nre-search and facilitate easy replication of state-of-the-art (SOTA) QA\nmethods. PRIMEQA supports core QA functionalities like retrieval and reading\ncomprehension as well as auxiliary capabilities such as question generation.It\nhas been designed as an end-to-end toolkit for various use cases: building\nfront-end applications, replicating SOTA methods on pub-lic benchmarks, and\nexpanding pre-existing methods. PRIMEQA is available at :\nhttps://github.com/primeqa.\n","authors":["Avirup Sil","Jaydeep Sen","Bhavani Iyer","Martin Franz","Kshitij Fadnis","Mihaela Bornea","Sara Rosenthal","Scott McCarley","Rong Zhang","Vishwajeet Kumar","Yulong Li","Md Arafat Sultan","Riyaz Bhat","Radu Florian","Salim Roukos"],"pdf_url":"https://arxiv.org/pdf/2301.09715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09685v1","updated":"2023-01-23T19:26:34Z","published":"2023-01-23T19:26:34Z","title":"Noisy Parallel Data Alignment","summary":"  An ongoing challenge in current natural language processing is how its major\nadvancements tend to disproportionately favor resource-rich languages, leaving\na significant number of under-resourced languages behind. Due to the lack of\nresources required to train and evaluate models, most modern language\ntechnologies are either nonexistent or unreliable to process endangered, local,\nand non-standardized languages. Optical character recognition (OCR) is often\nused to convert endangered language documents into machine-readable data.\nHowever, such OCR output is typically noisy, and most word alignment models are\nnot built to work under such noisy conditions. In this work, we study the\nexisting word-level alignment models under noisy settings and aim to make them\nmore robust to noisy data. Our noise simulation and structural biasing method,\ntested on multiple language pairs, manages to reduce the alignment error rate\non a state-of-the-art neural-based alignment model up to 59.6%.\n","authors":["Ruoyu Xie","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2301.09685v1.pdf","comment":"Accepted for publication in EACL 2023"},{"id":"http://arxiv.org/abs/2301.09656v1","updated":"2023-01-23T19:00:02Z","published":"2023-01-23T19:00:02Z","title":"Selective Explanations: Leveraging Human Input to Align Explainable AI","summary":"  While a vast collection of explainable AI (XAI) algorithms have been\ndeveloped in recent years, they are often criticized for significant gaps with\nhow humans produce and consume explanations. As a result, current XAI\ntechniques are often found to be hard to use and lack effectiveness. In this\nwork, we attempt to close these gaps by making AI explanations selective -- a\nfundamental property of human explanations -- by selectively presenting a\nsubset from a large set of model reasons based on what aligns with the\nrecipient's preferences. We propose a general framework for generating\nselective explanations by leveraging human input on a small sample. This\nframework opens up a rich design space that accounts for different selectivity\ngoals, types of input, and more. As a showcase, we use a decision-support task\nto explore selective explanations based on what the decision-maker would\nconsider relevant to the decision task. We conducted two experimental studies\nto examine three out of a broader possible set of paradigms based on our\nproposed framework: in Study 1, we ask the participants to provide their own\ninput to generate selective explanations, with either open-ended or\ncritique-based input. In Study 2, we show participants selective explanations\nbased on input from a panel of similar users (annotators). Our experiments\ndemonstrate the promise of selective explanations in reducing over-reliance on\nAI and improving decision outcomes and subjective perceptions of the AI, but\nalso paint a nuanced picture that attributes some of these positive effects to\nthe opportunity to provide one's own input to augment AI explanations. Overall,\nour work proposes a novel XAI framework inspired by human communication\nbehaviors and demonstrates its potentials to encourage future work to better\nalign AI explanations with human production and consumption of explanations.\n","authors":["Vivian Lai","Yiming Zhang","Chacha Chen","Q. Vera Liao","Chenhao Tan"],"pdf_url":"https://arxiv.org/pdf/2301.09656v1.pdf","comment":"21 pages, 25 figures"},{"id":"http://arxiv.org/abs/2301.10165v1","updated":"2023-01-23T09:05:49Z","published":"2023-01-23T09:05:49Z","title":"Lexi: Self-Supervised Learning of the UI Language","summary":"  Humans can learn to operate the user interface (UI) of an application by\nreading an instruction manual or how-to guide. Along with text, these resources\ninclude visual content such as UI screenshots and images of application icons\nreferenced in the text. We explore how to leverage this data to learn generic\nvisio-linguistic representations of UI screens and their components. These\nrepresentations are useful in many real applications, such as accessibility,\nvoice navigation, and task automation. Prior UI representation models rely on\nUI metadata (UI trees and accessibility labels), which is often missing,\nincompletely defined, or not accessible. We avoid such a dependency, and\npropose Lexi, a pre-trained vision and language model designed to handle the\nunique features of UI screens, including their text richness and context\nsensitivity. To train Lexi we curate the UICaption dataset consisting of 114k\nUI images paired with descriptions of their functionality. We evaluate Lexi on\nfour tasks: UI action entailment, instruction-based UI image retrieval,\ngrounding referring expressions, and UI entity recognition.\n","authors":["Pratyay Banerjee","Shweti Mahajan","Kushal Arora","Chitta Baral","Oriana Riva"],"pdf_url":"https://arxiv.org/pdf/2301.10165v1.pdf","comment":"EMNLP (Findings) 2022"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.09637v1","updated":"2023-01-23T18:59:59Z","published":"2023-01-23T18:59:59Z","title":"InfiniCity: Infinite-Scale City Synthesis","summary":"  Toward infinite-scale 3D city synthesis, we propose a novel framework,\nInfiniCity, which constructs and renders an unconstrainedly large and\n3D-grounded environment from random noises. InfiniCity decomposes the seemingly\nimpractical task into three feasible modules, taking advantage of both 2D and\n3D data. First, an infinite-pixel image synthesis module generates\narbitrary-scale 2D maps from the bird's-eye view. Next, an octree-based voxel\ncompletion module lifts the generated 2D map to 3D octrees. Finally, a\nvoxel-based neural rendering module texturizes the voxels and renders 2D\nimages. InfiniCity can thus synthesize arbitrary-scale and traversable 3D city\nenvironments, and allow flexible and interactive editing from users. We\nquantitatively and qualitatively demonstrate the efficacy of the proposed\nframework. Project page: https://hubert0527.github.io/infinicity/\n","authors":["Chieh Hubert Lin","Hsin-Ying Lee","Willi Menapace","Menglei Chai","Aliaksandr Siarohin","Ming-Hsuan Yang","Sergey Tulyakov"],"pdf_url":"https://arxiv.org/pdf/2301.09637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13756v2","updated":"2023-01-23T18:59:54Z","published":"2022-11-24T18:59:01Z","title":"Contrastive pretraining for semantic segmentation is robust to noisy\n  positive pairs","summary":"  Domain-specific variants of contrastive learning can construct positive pairs\nfrom two distinct in-domain images, while traditional methods just augment the\nsame image twice. For example, we can form a positive pair from two satellite\nimages showing the same location at different times. Ideally, this teaches the\nmodel to ignore changes caused by seasons, weather conditions or image\nacquisition artifacts. However, unlike in traditional contrastive methods, this\ncan result in undesired positive pairs, since we form them without human\nsupervision. For example, a positive pair might consist of one image before a\ndisaster and one after. This could teach the model to ignore the differences\nbetween intact and damaged buildings, which might be what we want to detect in\nthe downstream task. Similar to false negative pairs, this could impede model\nperformance. Crucially, in this setting only parts of the images differ in\nrelevant ways, while other parts remain similar. Surprisingly, we find that\ndownstream semantic segmentation is either robust to such badly matched pairs\nor even benefits from them. The experiments are conducted on the remote sensing\ndataset xBD, and a synthetic segmentation dataset for which we have full\ncontrol over the pairing conditions. As a result, practitioners can use these\ndomain-specific contrastive methods without having to filter their positive\npairs beforehand, or might even be encouraged to purposefully include such\npairs in their pretraining dataset.\n","authors":["Sebastian Gerard","Josephine Sullivan"],"pdf_url":"https://arxiv.org/pdf/2211.13756v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. Compared to the previous version, large-scale changes\n  were made to make the paper easier to understand for people less familiar\n  with contrastive learning and to make it easier to follow certain arguments.\n  10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.09632v1","updated":"2023-01-23T18:59:25Z","published":"2023-01-23T18:59:25Z","title":"HexPlane: A Fast Representation for Dynamic Scenes","summary":"  Modeling and re-rendering dynamic 3D scenes is a challenging task in 3D\nvision. Prior approaches build on NeRF and rely on implicit representations.\nThis is slow since it requires many MLP evaluations, constraining real-world\napplications. We show that dynamic 3D scenes can be explicitly represented by\nsix planes of learned features, leading to an elegant solution we call\nHexPlane. A HexPlane computes features for points in spacetime by fusing\nvectors extracted from each plane, which is highly efficient. Pairing a\nHexPlane with a tiny MLP to regress output colors and training via volume\nrendering gives impressive results for novel view synthesis on dynamic scenes,\nmatching the image quality of prior work but reducing training time by more\nthan $100\\times$. Extensive ablations confirm our HexPlane design and show that\nit is robust to different feature fusion mechanisms, coordinate systems, and\ndecoding mechanisms. HexPlanes are a simple and effective solution for\nrepresenting 4D volumes, and we hope they can broadly contribute to modeling\nspacetime for dynamic 3D scenes.\n","authors":["Ang Cao","Justin Johnson"],"pdf_url":"https://arxiv.org/pdf/2301.09632v1.pdf","comment":"Project page: https://caoang327.github.io/HexPlane"},{"id":"http://arxiv.org/abs/2301.09629v1","updated":"2023-01-23T18:58:02Z","published":"2023-01-23T18:58:02Z","title":"LEGO-Net: Learning Regular Rearrangements of Objects in Rooms","summary":"  Humans universally dislike the task of cleaning up a messy room. If machines\nwere to help us with this task, they must understand human criteria for regular\narrangements, such as several types of symmetry, co-linearity or\nco-circularity, spacing uniformity in linear or circular patterns, and further\ninter-object relationships that relate to style and functionality. Previous\napproaches for this task relied on human input to explicitly specify goal\nstate, or synthesized scenes from scratch -- but such methods do not address\nthe rearrangement of existing messy scenes without providing a goal state. In\nthis paper, we present LEGO-Net, a data-driven transformer-based iterative\nmethod for learning regular rearrangement of objects in messy rooms. LEGO-Net\nis partly inspired by diffusion models -- it starts with an initial messy state\nand iteratively \"de-noises'' the position and orientation of objects to a\nregular state while reducing the distance traveled. Given randomly perturbed\nobject positions and orientations in an existing dataset of\nprofessionally-arranged scenes, our method is trained to recover a regular\nre-arrangement. Results demonstrate that our method is able to reliably\nrearrange room scenes and outperform other methods. We additionally propose a\nmetric for evaluating regularity in room arrangements using number-theoretic\nmachinery.\n","authors":["Qiuhong Anna Wei","Sijie Ding","Jeong Joon Park","Rahul Sajnani","Adrien Poulenard","Srinath Sridhar","Leonidas Guibas"],"pdf_url":"https://arxiv.org/pdf/2301.09629v1.pdf","comment":"Project page: https://ivl.cs.brown.edu/projects/lego-net"},{"id":"http://arxiv.org/abs/2206.08312v2","updated":"2023-01-23T18:49:47Z","published":"2022-06-16T17:17:44Z","title":"SoundSpaces 2.0: A Simulation Platform for Visual-Acoustic Learning","summary":"  We introduce SoundSpaces 2.0, a platform for on-the-fly geometry-based audio\nrendering for 3D environments. Given a 3D mesh of a real-world environment,\nSoundSpaces can generate highly realistic acoustics for arbitrary sounds\ncaptured from arbitrary microphone locations. Together with existing 3D visual\nassets, it supports an array of audio-visual research tasks, such as\naudio-visual navigation, mapping, source localization and separation, and\nacoustic matching. Compared to existing resources, SoundSpaces 2.0 has the\nadvantages of allowing continuous spatial sampling, generalization to novel\nenvironments, and configurable microphone and material properties. To our\nknowledge, this is the first geometry-based acoustic simulation that offers\nhigh fidelity and realism while also being fast enough to use for embodied\nlearning. We showcase the simulator's properties and benchmark its performance\nagainst real-world audio measurements. In addition, we demonstrate two\ndownstream tasks -- embodied navigation and far-field automatic speech\nrecognition -- and highlight sim2real performance for the latter. SoundSpaces\n2.0 is publicly available to facilitate wider research for perceptual systems\nthat can both see and hear.\n","authors":["Changan Chen","Carl Schissler","Sanchit Garg","Philip Kobernik","Alexander Clegg","Paul Calamia","Dhruv Batra","Philip W Robinson","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2206.08312v2.pdf","comment":"Camera-ready version. Website: https://soundspaces.org. Project page:\n  https://vision.cs.utexas.edu/projects/soundspaces2"},{"id":"http://arxiv.org/abs/2301.09624v1","updated":"2023-01-23T18:47:41Z","published":"2023-01-23T18:47:41Z","title":"Maximum Mean Discrepancy Kernels for Predictive and Prognostic Modeling\n  of Whole Slide Images","summary":"  How similar are two images? In computational pathology, where Whole Slide\nImages (WSIs) of digitally scanned tissue samples from patients can be\nmulti-gigapixels in size, determination of degree of similarity between two\nWSIs is a challenging task with a number of practical applications. In this\nwork, we explore a novel strategy based on kernelized Maximum Mean Discrepancy\n(MMD) analysis for determination of pairwise similarity between WSIs. The\nproposed approach works by calculating MMD between two WSIs using kernels over\ndeep features of image patches. This allows representation of an entire dataset\nof WSIs as a kernel matrix for WSI level clustering, weakly-supervised\nprediction of TP-53 mutation status in breast cancer patients from their\nroutine WSIs as well as survival analysis with state of the art prediction\nperformance. We believe that this work will open up further avenues for\napplication of WSI-level kernels for predictive and prognostic tasks in\ncomputational pathology.\n","authors":["Piotr Keller","Muhammad Dawood","Fayyaz ul Amir Afsar Minhas"],"pdf_url":"https://arxiv.org/pdf/2301.09624v1.pdf","comment":"* Joint first authorship Accepted: IEEE - ISBI 2023 International\n  Symposium on Biomedical Imaging"},{"id":"http://arxiv.org/abs/2301.09620v1","updated":"2023-01-23T18:40:21Z","published":"2023-01-23T18:40:21Z","title":"Tracking the industrial growth of modern China with high-resolution\n  panchromatic imagery: A sequential convolutional approach","summary":"  Due to insufficient or difficult to obtain data on development in\ninaccessible regions, remote sensing data is an important tool for interested\nstakeholders to collect information on economic growth. To date, no studies\nhave utilized deep learning to estimate industrial growth at the level of\nindividual sites. In this study, we harness high-resolution panchromatic\nimagery to estimate development over time at 419 industrial sites in the\nPeople's Republic of China using a multi-tier computer vision framework. We\npresent two methods for approximating development: (1) structural area coverage\nestimated through a Mask R-CNN segmentation algorithm, and (2) imputing\ndevelopment directly with visible & infrared radiance from the Visible Infrared\nImaging Radiometer Suite (VIIRS). Labels generated from these methods are\ncomparatively evaluated and tested. On a dataset of 2,078 50 cm resolution\nimages spanning 19 years, the results indicate that two dimensions of\nindustrial development can be estimated using high-resolution daytime imagery,\nincluding (a) the total square meters of industrial development (average error\nof 0.021 $\\textrm{km}^2$), and (b) the radiance of lights (average error of 9.8\n$\\mathrm{\\frac{nW}{cm^{2}sr}}$). Trend analysis of the techniques reveal\nestimates from a Mask R-CNN-labeled CNN-LSTM track ground truth measurements\nmost closely. The Mask R-CNN estimates positive growth at every site from the\noldest image to the most recent, with an average change of 4,084\n$\\textrm{m}^2$.\n","authors":["Ethan Brewer","Zhonghui Lv","Dan Runfola"],"pdf_url":"https://arxiv.org/pdf/2301.09620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09617v1","updated":"2023-01-23T18:33:38Z","published":"2023-01-23T18:33:38Z","title":"Fully transformer-based biomarker prediction from colorectal cancer\n  histology: a large-scale multicentric study","summary":"  Background: Deep learning (DL) can extract predictive and prognostic\nbiomarkers from routine pathology slides in colorectal cancer. For example, a\nDL test for the diagnosis of microsatellite instability (MSI) in CRC has been\napproved in 2022. Current approaches rely on convolutional neural networks\n(CNNs). Transformer networks are outperforming CNNs and are replacing them in\nmany applications, but have not been used for biomarker prediction in cancer at\na large scale. In addition, most DL approaches have been trained on small\npatient cohorts, which limits their clinical utility. Methods: In this study,\nwe developed a new fully transformer-based pipeline for end-to-end biomarker\nprediction from pathology slides. We combine a pre-trained transformer encoder\nand a transformer network for patch aggregation, capable of yielding single and\nmulti-target prediction at patient level. We train our pipeline on over 9,000\npatients from 10 colorectal cancer cohorts. Results: A fully transformer-based\napproach massively improves the performance, generalizability, data efficiency,\nand interpretability as compared with current state-of-the-art algorithms.\nAfter training on a large multicenter cohort, we achieve a sensitivity of 0.97\nwith a negative predictive value of 0.99 for MSI prediction on surgical\nresection specimens. We demonstrate for the first time that resection\nspecimen-only training reaches clinical-grade performance on endoscopic biopsy\ntissue, solving a long-standing diagnostic problem. Interpretation: A fully\ntransformer-based end-to-end pipeline trained on thousands of pathology slides\nyields clinical-grade performance for biomarker prediction on surgical\nresections and biopsies. Our new methods are freely available under an open\nsource license.\n","authors":["Sophia J. Wagner","Daniel Reisenbüchler","Nicholas P. West","Jan Moritz Niehues","Gregory Patrick Veldhuizen","Philip Quirke","Heike I. Grabsch","Piet A. van den Brandt","Gordon G. A. Hutchins","Susan D. Richman","Tanwei Yuan","Rupert Langer","Josien Christina Anna Jenniskens","Kelly Offermans","Wolfram Mueller","Richard Gray","Stephen B. Gruber","Joel K. Greenson","Gad Rennert","Joseph D. Bonner","Daniel Schmolze","Jacqueline A. James","Maurice B. Loughrey","Manuel Salto-Tellez","Hermann Brenner","Michael Hoffmeister","Daniel Truhn","Julia A. Schnabel","Melanie Boxberg","Tingying Peng","Jakob Nikolas Kather"],"pdf_url":"https://arxiv.org/pdf/2301.09617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09602v1","updated":"2023-01-23T18:06:35Z","published":"2023-01-23T18:06:35Z","title":"Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly\n  Segmentation","summary":"  We propose an incremental improvement to Fully Convolutional Data Description\n(FCDD), an adaptation of the one-class classification approach from anomaly\ndetection to image anomaly segmentation (a.k.a. anomaly localization). We\nanalyze its original loss function and propose a substitute that better\nresembles its predecessor, the Hypersphere Classifier (HSC). Both are compared\non the MVTec Anomaly Detection Dataset (MVTec-AD) -- training images are\nflawless objects/textures and the goal is to segment unseen defects -- showing\nthat consistent improvement is achieved by better designing the pixel-wise\nsupervision.\n","authors":["Joao P. C. Bertoldo","Santiago Velasco-Forero","Jesus Angulo","Etienne Decencière"],"pdf_url":"https://arxiv.org/pdf/2301.09602v1.pdf","comment":"Submitted to the 2023 IEEE International Conference on Image\n  Processing (ICIP 2023)"},{"id":"http://arxiv.org/abs/2301.09595v1","updated":"2023-01-23T17:51:39Z","published":"2023-01-23T17:51:39Z","title":"Zorro: the masked multimodal transformer","summary":"  Attention-based models are appealing for multimodal processing because inputs\nfrom multiple modalities can be concatenated and fed to a single backbone\nnetwork - thus requiring very little fusion engineering. The resulting\nrepresentations are however fully entangled throughout the network, which may\nnot always be desirable: in learning, contrastive audio-visual self-supervised\nlearning requires independent audio and visual features to operate, otherwise\nlearning collapses; in inference, evaluation of audio-visual models should be\npossible on benchmarks having just audio or just video. In this paper, we\nintroduce Zorro, a technique that uses masks to control how inputs from each\nmodality are routed inside Transformers, keeping some parts of the\nrepresentation modality-pure. We apply this technique to three popular\ntransformer-based architectures (ViT, Swin and HiP) and show that with\ncontrastive pre-training Zorro achieves state-of-the-art results on most\nrelevant benchmarks for multimodal tasks (AudioSet and VGGSound). Furthermore,\nthe resulting models are able to perform unimodal inference on both video and\naudio benchmarks such as Kinetics-400 or ESC-50.\n","authors":["Adrià Recasens","Jason Lin","Joāo Carreira","Drew Jaegle","Luyu Wang","Jean-baptiste Alayrac","Pauline Luc","Antoine Miech","Lucas Smaira","Ross Hemsley","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2301.09595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08730v2","updated":"2023-01-23T17:11:30Z","published":"2023-01-20T18:49:58Z","title":"Novel-View Acoustic Synthesis","summary":"  We introduce the novel-view acoustic synthesis (NVAS) task: given the sight\nand sound observed at a source viewpoint, can we synthesize the sound of that\nscene from an unseen target viewpoint? We propose a neural rendering approach:\nVisually-Guided Acoustic Synthesis (ViGAS) network that learns to synthesize\nthe sound of an arbitrary point in space by analyzing the input audio-visual\ncues. To benchmark this task, we collect two first-of-their-kind large-scale\nmulti-view audio-visual datasets, one synthetic and one real. We show that our\nmodel successfully reasons about the spatial cues and synthesizes faithful\naudio on both datasets. To our knowledge, this work represents the very first\nformulation, dataset, and approach to solve the novel-view acoustic synthesis\ntask, which has exciting potential applications ranging from AR/VR to art and\ndesign. Unlocked by this work, we believe that the future of novel-view\nsynthesis is in multi-modal learning from videos.\n","authors":["Changan Chen","Alexander Richard","Roman Shapovalov","Vamsi Krishna Ithapu","Natalia Neverova","Kristen Grauman","Andrea Vedaldi"],"pdf_url":"https://arxiv.org/pdf/2301.08730v2.pdf","comment":"Project page: https://vision.cs.utexas.edu/projects/nvas"},{"id":"http://arxiv.org/abs/2301.09544v1","updated":"2023-01-23T17:00:48Z","published":"2023-01-23T17:00:48Z","title":"Learning to View: Decision Transformers for Active Object Detection","summary":"  Active perception describes a broad class of techniques that couple planning\nand perception systems to move the robot in a way to give the robot more\ninformation about the environment. In most robotic systems, perception is\ntypically independent of motion planning. For example, traditional object\ndetection is passive: it operates only on the images it receives. However, we\nhave a chance to improve the results if we allow planning to consume detection\nsignals and move the robot to collect views that maximize the quality of the\nresults. In this paper, we use reinforcement learning (RL) methods to control\nthe robot in order to obtain images that maximize the detection quality.\nSpecifically, we propose using a Decision Transformer with online fine-tuning,\nwhich first optimizes the policy with a pre-collected expert dataset and then\nimproves the learned policy by exploring better solutions in the environment.\nWe evaluate the performance of proposed method on an interactive dataset\ncollected from an indoor scenario simulator. Experimental results demonstrate\nthat our method outperforms all baselines, including expert policy and pure\noffline RL methods. We also provide exhaustive analyses of the reward\ndistribution and observation space.\n","authors":["Wenhao Ding","Nathalie Majcherczyk","Mohit Deshpande","Xuewei Qi","Ding Zhao","Rajasimman Madhivanan","Arnie Sen"],"pdf_url":"https://arxiv.org/pdf/2301.09544v1.pdf","comment":"Accepted to ICRA 2023"},{"id":"http://arxiv.org/abs/2301.09542v1","updated":"2023-01-23T16:59:26Z","published":"2023-01-23T16:59:26Z","title":"Improving Presentation Attack Detection for ID Cards on Remote\n  Verification Systems","summary":"  In this paper, an updated two-stage, end-to-end Presentation Attack Detection\nmethod for remote biometric verification systems of ID cards, based on\nMobileNetV2, is presented. Several presentation attack species such as printed,\ndisplay, composite (based on cropped and spliced areas), plastic (PVC), and\nsynthetic ID card images using different capture sources are used. This\nproposal was developed using a database consisting of 190.000 real case Chilean\nID card images with the support of a third-party company. Also, a new framework\ncalled PyPAD, used to estimate multi-class metrics compliant with the ISO/IEC\n30107-3 standard was developed, and will be made available for research\npurposes. Our method is trained on two convolutional neural networks\nseparately, reaching BPCER\\textsubscript{100} scores on ID cards attacks of\n1.69\\% and 2.36\\% respectively. The two-stage method using both models together\ncan reach a BPCER\\textsubscript{100} score of 0.92\\%.\n","authors":["Sebastian Gonzalez","Juan Tapia"],"pdf_url":"https://arxiv.org/pdf/2301.09542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09525v1","updated":"2023-01-23T16:16:24Z","published":"2023-01-23T16:16:24Z","title":"DeepFEL: Deep Fastfood Ensemble Learning for Histopathology Image\n  Analysis","summary":"  Computational pathology tasks have some unique characterises such as\nmulti-gigapixel images, tedious and frequently uncertain annotations, and\nunavailability of large number of cases [13]. To address some of these issues,\nwe present Deep Fastfood Ensembles - a simple, fast and yet effective method\nfor combining deep features pooled from popular CNN models pre-trained on\ntotally different source domains (e.g., natural image objects) and projected\nonto diverse dimensions using random projections, the so-called Fastfood [11].\nThe final ensemble output is obtained by a consensus of simple individual\nclassifiers, each of which is trained on a different collection of random basis\nvectors. This offers extremely fast and yet effective solution, especially when\ntraining times and domain labels are of the essence. We demonstrate the\neffectiveness of the proposed deep fastfood ensemble learning as compared to\nthe state-of-the-art methods for three different tasks in histopathology image\nanalysis.\n","authors":["Nima Hatami"],"pdf_url":"https://arxiv.org/pdf/2301.09525v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2104.00669"},{"id":"http://arxiv.org/abs/2301.09522v1","updated":"2023-01-23T16:14:09Z","published":"2023-01-23T16:14:09Z","title":"Optimising Event-Driven Spiking Neural Network with Regularisation and\n  Cutoff","summary":"  Spiking neural networks (SNNs), a variant of artificial neural networks\n(ANNs) with the benefit of energy efficiency, have achieved the accuracy close\nto its ANN counterparts, on benchmark datasets such as CIFAR10/100 and\nImageNet. However, comparing with frame-based input (e.g., images), event-based\ninputs from e.g., Dynamic Vision Sensor (DVS) can make a better use of SNNs\nthanks to the SNNs' asynchronous working mechanism. In this paper, we\nstrengthen the marriage between SNNs and event-based inputs with a proposal to\nconsider anytime optimal inference SNNs, or AOI-SNNs, which can terminate\nanytime during the inference to achieve optimal inference result. Two novel\noptimisation techniques are presented to achieve AOI-SNNs: a regularisation and\na cutoff. The regularisation enables the training and construction of SNNs with\noptimised performance, and the cutoff technique optimises the inference of SNNs\non event-driven inputs. We conduct an extensive set of experiments on multiple\nbenchmark event-based datasets, including CIFAR10-DVS, N-Caltech101 and DVS128\nGesture. The experimental results demonstrate that our techniques are superior\nto the state-of-the-art with respect to the accuracy and latency.\n","authors":["Dengyu Wu","Gaojie Jin","Han Yu","Xinping Yi","Xiaowei Huang"],"pdf_url":"https://arxiv.org/pdf/2301.09522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09515v1","updated":"2023-01-23T16:05:45Z","published":"2023-01-23T16:05:45Z","title":"StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale\n  Text-to-Image Synthesis","summary":"  Text-to-image synthesis has recently seen significant progress thanks to\nlarge pretrained language models, large-scale training data, and the\nintroduction of scalable model families such as diffusion and autoregressive\nmodels. However, the best-performing models require iterative evaluation to\ngenerate a single sample. In contrast, generative adversarial networks (GANs)\nonly need a single forward pass. They are thus much faster, but they currently\nremain far behind the state-of-the-art in large-scale text-to-image synthesis.\nThis paper aims to identify the necessary steps to regain competitiveness. Our\nproposed model, StyleGAN-T, addresses the specific requirements of large-scale\ntext-to-image synthesis, such as large capacity, stable training on diverse\ndatasets, strong text alignment, and controllable variation vs. text alignment\ntradeoff. StyleGAN-T significantly improves over previous GANs and outperforms\ndistilled diffusion models - the previous state-of-the-art in fast\ntext-to-image synthesis - in terms of sample quality and speed.\n","authors":["Axel Sauer","Tero Karras","Samuli Laine","Andreas Geiger","Timo Aila"],"pdf_url":"https://arxiv.org/pdf/2301.09515v1.pdf","comment":"Project page: https://sites.google.com/view/stylegan-t/"},{"id":"http://arxiv.org/abs/2202.06924v2","updated":"2023-01-23T16:03:10Z","published":"2022-02-14T18:33:12Z","title":"Do Gradient Inversion Attacks Make Federated Learning Unsafe?","summary":"  Federated learning (FL) allows the collaborative training of AI models\nwithout needing to share raw data. This capability makes it especially\ninteresting for healthcare applications where patient and data privacy is of\nutmost concern. However, recent works on the inversion of deep neural networks\nfrom model gradients raised concerns about the security of FL in preventing the\nleakage of training data. In this work, we show that these attacks presented in\nthe literature are impractical in FL use-cases where the clients' training\ninvolves updating the Batch Normalization (BN) statistics and provide a new\nbaseline attack that works for such scenarios. Furthermore, we present new ways\nto measure and visualize potential data leakage in FL. Our work is a step\ntowards establishing reproducible methods of measuring data leakage in FL and\ncould help determine the optimal tradeoffs between privacy-preserving\ntechniques, such as differential privacy, and model accuracy based on\nquantifiable metrics.\n  Code is available at\nhttps://nvidia.github.io/NVFlare/research/quantifying-data-leakage.\n","authors":["Ali Hatamizadeh","Hongxu Yin","Pavlo Molchanov","Andriy Myronenko","Wenqi Li","Prerna Dogra","Andrew Feng","Mona G. Flores","Jan Kautz","Daguang Xu","Holger R. Roth"],"pdf_url":"https://arxiv.org/pdf/2202.06924v2.pdf","comment":"Revised version; Accepted to IEEE Transactions on Medical Imaging;\n  Improved and reformatted version of\n  https://www.researchsquare.com/article/rs-1147182/v2"},{"id":"http://arxiv.org/abs/2301.09506v1","updated":"2023-01-23T15:59:29Z","published":"2023-01-23T15:59:29Z","title":"OvarNet: Towards Open-vocabulary Object Attribute Recognition","summary":"  In this paper, we consider the problem of simultaneously detecting objects\nand inferring their visual attributes in an image, even for those with no\nmanual annotations provided at the training stage, resembling an\nopen-vocabulary scenario. To achieve this goal, we make the following\ncontributions: (i) we start with a naive two-stage approach for open-vocabulary\nobject detection and attribute classification, termed CLIP-Attr. The candidate\nobjects are first proposed with an offline RPN and later classified for\nsemantic category and attributes; (ii) we combine all available datasets and\ntrain with a federated strategy to finetune the CLIP model, aligning the visual\nrepresentation with attributes, additionally, we investigate the efficacy of\nleveraging freely available online image-caption pairs under weakly supervised\nlearning; (iii) in pursuit of efficiency, we train a Faster-RCNN type model\nend-to-end with knowledge distillation, that performs class-agnostic object\nproposals and classification on semantic categories and attributes with\nclassifiers generated from a text encoder; Finally, (iv) we conduct extensive\nexperiments on VAW, MS-COCO, LSA, and OVAD datasets, and show that recognition\nof semantic category and attributes is complementary for visual scene\nunderstanding, i.e., jointly training object detection and attributes\nprediction largely outperform existing approaches that treat the two tasks\nindependently, demonstrating strong generalization ability to novel attributes\nand categories.\n","authors":["Keyan Chen","Xiaolong Jiang","Yao Hu","Xu Tang","Yan Gao","Jianqi Chen","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2301.09506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04699v2","updated":"2023-01-23T15:59:20Z","published":"2022-09-10T15:48:28Z","title":"Explainable Image Quality Assessments in Teledermatological Photography","summary":"  Image quality is a crucial factor in the effectiveness and efficiency of\nteledermatological consultations. However, up to 50% of images sent by patients\nhave quality issues, thus increasing the time to diagnosis and treatment. An\nautomated, easily deployable, explainable method for assessing image quality is\nnecessary to improve the current teledermatological consultation flow. We\nintroduce ImageQX, a convolutional neural network for image quality assessment\nwith a learning mechanism for identifying the most common poor image quality\nexplanations: bad framing, bad lighting, blur, low resolution, and distance\nissues. ImageQX was trained on 26,635 photographs and validated on 9,874\nphotographs, each annotated with image quality labels and poor image quality\nexplanations by up to 12 board-certified dermatologists. The photographic\nimages were taken between 2017 and 2019 using a mobile skin disease tracking\napplication accessible worldwide. Our method achieves expert-level performance\nfor both image quality assessment and poor image quality explanation. For image\nquality assessment, ImageQX obtains a macro F1-score of 0.73 +- 0.01, which\nplaces it within standard deviation of the pairwise inter-rater F1-score of\n0.77 +- 0.07. For poor image quality explanations, our method obtains F1-scores\nof between 0.37 +- 0.01 and 0.70 +- 0.01, similar to the inter-rater pairwise\nF1-score of between 0.24 +- 0.15 and 0.83 +- 0.06. Moreover, with a size of\nonly 15 MB, ImageQX is easily deployable on mobile devices. With an image\nquality detection performance similar to that of dermatologists, incorporating\nImageQX into the teledermatology flow can enable a better, faster flow for\nremote consultations.\n","authors":["Raluca Jalaboi","Ole Winther","Alfiia Galimzianova"],"pdf_url":"https://arxiv.org/pdf/2209.04699v2.pdf","comment":"Accepted at the Telemedicine and eHealth Journal"},{"id":"http://arxiv.org/abs/2301.09498v1","updated":"2023-01-23T15:52:12Z","published":"2023-01-23T15:52:12Z","title":"Triplet Contrastive Learning for Unsupervised Vehicle Re-identification","summary":"  Part feature learning is a critical technology for finegrained semantic\nunderstanding in vehicle re-identification. However, recent unsupervised\nre-identification works exhibit serious gradient collapse issues when directly\nmodeling the part features and global features. To address this problem, in\nthis paper, we propose a novel Triplet Contrastive Learning framework (TCL)\nwhich leverages cluster features to bridge the part features and global\nfeatures. Specifically, TCL devises three memory banks to store the features\naccording to their attributes and proposes a proxy contrastive loss (PCL) to\nmake contrastive learning between adjacent memory banks, thus presenting the\nassociations between the part and global features as a transition of the\npartcluster and cluster-global associations. Since the cluster memory bank\ndeals with all the instance features, it can summarize them into a\ndiscriminative feature representation. To deeply exploit the instance\ninformation, TCL proposes two additional loss functions. For the inter-class\ninstance, a hybrid contrastive loss (HCL) re-defines the sample correlations by\napproaching the positive cluster features and leaving the all negative instance\nfeatures. For the intra-class instances, a weighted regularization cluster\ncontrastive loss (WRCCL) refines the pseudo labels by penalizing the mislabeled\nimages according to the instance similarity. Extensive experiments show that\nTCL outperforms many state-of-the-art unsupervised vehicle re-identification\napproaches. The code will be available at https://github.com/muzishen/TCL.\n","authors":["Fei Shen","Xiaoyu Du","Liyan Zhang","Jinhui Tang"],"pdf_url":"https://arxiv.org/pdf/2301.09498v1.pdf","comment":"Code: https://github.com/muzishen/TCL"},{"id":"http://arxiv.org/abs/2210.07903v2","updated":"2023-01-23T15:34:33Z","published":"2022-10-14T15:37:54Z","title":"Text Detection Forgot About Document OCR","summary":"  Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Yet OCR\nsystems still do not achieve 100% accuracy, requiring human corrections in\napplications where correct readout is essential. Advances in machine learning\nenabled even more challenging scenarios of text detection and recognition\n\"in-the-wild\" - such as detecting text on objects from photographs of complex\nscenes. While the state-of-the-art methods for in-the-wild text recognition are\ntypically evaluated on complex scenes, their performance in the domain of\ndocuments is typically not published, and a comprehensive comparison with\nmethods for document OCR is missing. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve competitive results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.\n","authors":["Krzysztof Olejniczak","Milan Šulc"],"pdf_url":"https://arxiv.org/pdf/2210.07903v2.pdf","comment":"Accepted to the 26th Computer Vision Winter Workshop (CVWW), 2023"},{"id":"http://arxiv.org/abs/2301.09489v1","updated":"2023-01-23T15:32:27Z","published":"2023-01-23T15:32:27Z","title":"Contracting Skeletal Kinematic Embeddings for Anomaly Detection","summary":"  Detecting the anomaly of human behavior is paramount to timely recognizing\nendangering situations, such as street fights or elderly falls. However,\nanomaly detection is complex, since anomalous events are rare and because it is\nan open set recognition task, i.e., what is anomalous at inference has not been\nobserved at training. We propose COSKAD, a novel model which encodes skeletal\nhuman motion by an efficient graph convolutional network and learns to COntract\nSKeletal kinematic embeddings onto a latent hypersphere of minimum volume for\nAnomaly Detection. We propose and analyze three latent space designs for\nCOSKAD: the commonly-adopted Euclidean, and the new spherical-radial and\nhyperbolic volumes. All three variants outperform the state-of-the-art,\nincluding video-based techniques, on the ShangaiTechCampus, the Avenue, and on\nthe most recent UBnormal dataset, for which we contribute novel skeleton\nannotations and the selection of human-related videos. The source code and\ndataset will be released upon acceptance.\n","authors":["Alessandro Flaborea","Guido Maria D'Amely di Melendugno","Stefano D'arrigo","Marco Aurelio Sterpa","Alessio Sampieri","Fabio Galasso"],"pdf_url":"https://arxiv.org/pdf/2301.09489v1.pdf","comment":"Submitted to Patter Recognition Journal"},{"id":"http://arxiv.org/abs/2202.06198v2","updated":"2023-01-23T14:50:26Z","published":"2022-02-13T04:09:21Z","title":"Data standardization for robust lip sync","summary":"  Lip sync is a fundamental audio-visual task. However, existing lip sync\nmethods fall short of being robust to the incredible diversity of videos taken\nin the wild, and the majority of the diversity is caused by compound\ndistracting factors that could degrade existing lip sync methods. To address\nthese issues, this paper proposes a data standardization pipeline that can\nproduce standardized expressive images while preserving lip motion information\nfrom the input and reducing the effects of compound distracting factors. Based\non recent advances in 3D face reconstruction, we first create a model that can\nconsistently disentangle expressions, with lip motion information embedded.\nThen, to reduce the effects of compound distracting factors on synthesized\nimages, we synthesize images with only expressions from the input,\nintentionally setting all other attributes at predefined values independent of\nthe input. Using synthesized images, existing lip sync methods improve their\ndata efficiency and robustness, and they achieve competitive performance for\nthe active speaker detection task.\n","authors":["Chun Wang"],"pdf_url":"https://arxiv.org/pdf/2202.06198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09461v1","updated":"2023-01-23T14:46:43Z","published":"2023-01-23T14:46:43Z","title":"Study on the identification limits of craniofacial superimposition","summary":"  Craniofacial Superimposition involves the superimposition of an image of a\nskull with a number of ante-mortem face images of an individual and the\nanalysis of their morphological correspondence. Despite being used for one\ncentury, it is not yet a mature and fully accepted technique due to the absence\nof solid scientific approaches, significant reliability studies, and\ninternational standards. In this paper we present a comprehensive\nexperimentation on the limitations of Craniofacial Superimposition as a\nforensic identification technique. The study involves different experiments\nover more than 1 Million comparisons performed by a landmark-based automatic\n3D/2D superimposition method. The total sample analyzed consists of 320\nsubjects and 29 craniofacial landmarks.\n","authors":["Óscar Ibáñez","Enrique Bermejo","Andrea Valsecchi"],"pdf_url":"https://arxiv.org/pdf/2301.09461v1.pdf","comment":"7 pages, 4 figures. To be submitted to Scientific Reports"},{"id":"http://arxiv.org/abs/2301.09460v1","updated":"2023-01-23T14:36:38Z","published":"2023-01-23T14:36:38Z","title":"HRVQA: A Visual Question Answering Benchmark for High-Resolution Aerial\n  Images","summary":"  Visual question answering (VQA) is an important and challenging multimodal\ntask in computer vision. Recently, a few efforts have been made to bring VQA\ntask to aerial images, due to its potential real-world applications in disaster\nmonitoring, urban planning, and digital earth product generation. However, not\nonly the huge variation in the appearance, scale and orientation of the\nconcepts in aerial images, but also the scarcity of the well-annotated datasets\nrestricts the development of VQA in this domain. In this paper, we introduce a\nnew dataset, HRVQA, which provides collected 53512 aerial images of 1024*1024\npixels and semi-automatically generated 1070240 QA pairs. To benchmark the\nunderstanding capability of VQA models for aerial images, we evaluate the\nrelevant methods on HRVQA. Moreover, we propose a novel model, GFTransformer,\nwith gated attention modules and a mutual fusion module. The experiments show\nthat the proposed dataset is quite challenging, especially the specific\nattribute related questions. Our method achieves superior performance in\ncomparison to the previous state-of-the-art approaches. The dataset and the\nsource code will be released at https://hrvqa.nl/.\n","authors":["Kun Li","George Vosselman","Michael Ying Yang"],"pdf_url":"https://arxiv.org/pdf/2301.09460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15769v2","updated":"2023-01-23T14:35:33Z","published":"2022-05-31T13:18:51Z","title":"Concept-level Debugging of Part-Prototype Networks","summary":"  Part-prototype Networks (ProtoPNets) are concept-based classifiers designed\nto achieve the same performance as black-box models without compromising\ntransparency. ProtoPNets compute predictions based on similarity to\nclass-specific part-prototypes learned to recognize parts of training examples,\nmaking it easy to faithfully determine what examples are responsible for any\ntarget prediction and why. However, like other models, they are prone to\npicking up confounders and shortcuts from the data, thus suffering from\ncompromised prediction accuracy and limited generalization. We propose\nProtoPDebug, an effective concept-level debugger for ProtoPNets in which a\nhuman supervisor, guided by the model's explanations, supplies feedback in the\nform of what part-prototypes must be forgotten or kept, and the model is\nfine-tuned to align with this supervision. Our experimental evaluation shows\nthat ProtoPDebug outperforms state-of-the-art debuggers for a fraction of the\nannotation cost. An online experiment with laypeople confirms the simplicity of\nthe feedback requested to the users and the effectiveness of the collected\nfeedback for learning confounder-free part-prototypes. ProtoPDebug is a\npromising tool for trustworthy interactive learning in critical applications,\nas suggested by a preliminary evaluation on a medical decision making task.\n","authors":["Andrea Bontempelli","Stefano Teso","Katya Tentori","Fausto Giunchiglia","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2205.15769v2.pdf","comment":"Accepted for publication at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.07502v2","updated":"2023-01-23T14:28:15Z","published":"2023-01-16T11:08:03Z","title":"Multimodal Side-Tuning for Document Classification","summary":"  In this paper, we propose to exploit the side-tuning framework for multimodal\ndocument classification. Side-tuning is a methodology for network adaptation\nrecently introduced to solve some of the problems related to previous\napproaches. Thanks to this technique it is actually possible to overcome model\nrigidity and catastrophic forgetting of transfer learning by fine-tuning. The\nproposed solution uses off-the-shelf deep learning architectures leveraging the\nside-tuning framework to combine a base model with a tandem of two side\nnetworks. We show that side-tuning can be successfully employed also when\ndifferent data sources are considered, e.g. text and images in document\nclassification. The experimental results show that this approach pushes further\nthe limit for document classification accuracy with respect to the state of the\nart.\n","authors":["Stefano Pio Zingaro","Giuseppe Lisanti","Maurizio Gabbrielli"],"pdf_url":"https://arxiv.org/pdf/2301.07502v2.pdf","comment":"2020 25th International Conference on Pattern Recognition (ICPR)"},{"id":"http://arxiv.org/abs/2301.09451v1","updated":"2023-01-23T14:20:01Z","published":"2023-01-23T14:20:01Z","title":"A Simple Recipe for Competitive Low-compute Self supervised Vision\n  Models","summary":"  Self-supervised methods in vision have been mostly focused on large\narchitectures as they seem to suffer from a significant performance drop for\nsmaller architectures. In this paper, we propose a simple self-supervised\ndistillation technique that can train high performance low-compute neural\nnetworks. Our main insight is that existing joint-embedding based SSL methods\ncan be repurposed for knowledge distillation from a large self-supervised\nteacher to a small student model. Thus, we call our method Replace one Branch\n(RoB) as it simply replaces one branch of the joint-embedding training with a\nlarge teacher model. RoB is widely applicable to a number of architectures such\nas small ResNets, MobileNets and ViT, and pretrained models such as DINO, SwAV\nor iBOT. When pretraining on the ImageNet dataset, RoB yields models that\ncompete with supervised knowledge distillation. When applied to MSN, RoB\nproduces students with strong semi-supervised capabilities. Finally, our best\nViT-Tiny models improve over prior SSL state-of-the-art on ImageNet by $2.3\\%$\nand are on par or better than a supervised distilled DeiT on five downstream\ntransfer tasks (iNaturalist, CIFAR, Clevr/Count, Clevr/Dist and Places). We\nhope RoB enables practical self-supervision at smaller scale.\n","authors":["Quentin Duval","Ishan Misra","Nicolas Ballas"],"pdf_url":"https://arxiv.org/pdf/2301.09451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09452v1","updated":"2023-01-23T14:20:01Z","published":"2023-01-23T14:20:01Z","title":"Fast and robust single particle reconstruction in 3D fluorescence\n  microscopy","summary":"  Single particle reconstruction has recently emerged in 3D fluorescence\nmicroscopy as a powerful technique to improve the axial resolution and the\ndegree of fluorescent labeling. It is based on the reconstruction of an average\nvolume of a biological particle from the acquisition multiple views with\nunknown poses. Current methods are limited either by template bias, restriction\nto 2D data, high computational cost or a lack of robustness to low fluorescent\nlabeling. In this work, we propose a single particle reconstruction method\ndedicated to convolutional models in 3D fluorescence microscopy that overcome\nthese issues. We address the joint reconstruction and estimation of the poses\nof the particles, which translates into a challenging non-convex optimization\nproblem. Our approach is based on a multilevel reformulation of this problem,\nand the development of efficient optimization techniques at each level. We\ndemonstrate on synthetic data that our method outperforms the standard\napproaches in terms of resolution and reconstruction error, while achieving a\nlow computational cost. We also perform successful reconstruction on real\ndatasets of centrioles to show the potential of our method in concrete\napplications.\n","authors":["Thibaut Eloy","Etienne Baudrier","Marine Laporte","Virginie Hamel","Paul Guichard","Denis Fortun"],"pdf_url":"https://arxiv.org/pdf/2301.09452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09431v1","updated":"2023-01-23T13:34:49Z","published":"2023-01-23T13:34:49Z","title":"Multi-domain stain normalization for digital pathology: A\n  cycle-consistent adversarial network for whole slide images","summary":"  The variation in histologic staining between different medical centers is one\nof the most profound challenges in the field of computer-aided diagnosis. The\nappearance disparity of pathological whole slide images causes algorithms to\nbecome less reliable, which in turn impedes the wide-spread applicability of\ndownstream tasks like cancer diagnosis. Furthermore, different stainings lead\nto biases in the training which in case of domain shifts negatively affect the\ntest performance. Therefore, in this paper we propose MultiStain-CycleGAN, a\nmulti-domain approach to stain normalization based on CycleGAN. Our\nmodifications to CycleGAN allow us to normalize images of different origins\nwithout retraining or using different models. We perform an extensive\nevaluation of our method using various metrics and compare it to commonly used\nmethods that are multi-domain capable. First, we evaluate how well our method\nfools a domain classifier that tries to assign a medical center to an image.\nThen, we test our normalization on the tumor classification performance of a\ndownstream classifier. Furthermore, we evaluate the image quality of the\nnormalized images using the Structural similarity index and the ability to\nreduce the domain shift using the Fr\\'echet inception distance. We show that\nour method proves to be multi-domain capable, provides the highest image\nquality among the compared methods, and can most reliably fool the domain\nclassifier while keeping the tumor classifier performance high. By reducing the\ndomain influence, biases in the data can be removed on the one hand and the\norigin of the whole slide image can be disguised on the other, thus enhancing\npatient data privacy.\n","authors":["Martin J. Hetz","Tabea-Clara Bucher","Titus J. Brinker"],"pdf_url":"https://arxiv.org/pdf/2301.09431v1.pdf","comment":"19 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2301.09430v1","updated":"2023-01-23T13:34:01Z","published":"2023-01-23T13:34:01Z","title":"RainDiffusion:When Unsupervised Learning Meets Diffusion Models for\n  Real-world Image Deraining","summary":"  What will happen when unsupervised learning meets diffusion models for\nreal-world image deraining? To answer it, we propose RainDiffusion, the first\nunsupervised image deraining paradigm based on diffusion models. Beyond the\ntraditional unsupervised wisdom of image deraining, RainDiffusion introduces\nstable training of unpaired real-world data instead of weakly adversarial\ntraining. RainDiffusion consists of two cooperative branches: Non-diffusive\nTranslation Branch (NTB) and Diffusive Translation Branch (DTB). NTB exploits a\ncycle-consistent architecture to bypass the difficulty in unpaired training of\nstandard diffusion models by generating initial clean/rainy image pairs. DTB\nleverages two conditional diffusion modules to progressively refine the desired\noutput with initial image pairs and diffusive generative prior, to obtain a\nbetter generalization ability of deraining and rain generation. Rain-Diffusion\nis a non adversarial training paradigm, serving as a new standard bar for\nreal-world image deraining. Extensive experiments confirm the superiority of\nour RainDiffusion over un/semi-supervised methods and show its competitive\nadvantages over fully-supervised ones.\n","authors":["Mingqiang Wei","Yiyang Shen","Yongzhen Wang","Haoran Xie","Fu Lee Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09430v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2204.07183v2","updated":"2023-01-23T12:50:38Z","published":"2022-04-14T18:31:59Z","title":"Interactive Object Segmentation in 3D Point Clouds","summary":"  We propose an interactive approach for 3D instance segmentation, where users\ncan iteratively collaborate with a deep learning model to segment objects in a\n3D point cloud directly. Current methods for 3D instance segmentation are\ngenerally trained in a fully-supervised fashion, which requires large amounts\nof costly training labels, and does not generalize well to classes unseen\nduring training. Few works have attempted to obtain 3D segmentation masks using\nhuman interactions. Existing methods rely on user feedback in the 2D image\ndomain. As a consequence, users are required to constantly switch between 2D\nimages and 3D representations, and custom architectures are employed to combine\nmultiple input modalities. Therefore, integration with existing standard 3D\nmodels is not straightforward. The core idea of this work is to enable users to\ninteract directly with 3D point clouds by clicking on desired 3D objects of\ninterest~(or their background) to interactively segment the scene in an\nopen-world setting. Specifically, our method does not require training data\nfrom any target domain, and can adapt to new environments where no appropriate\ntraining sets are available. Our system continuously adjusts the object\nsegmentation based on the user feedback and achieves accurate dense 3D\nsegmentation masks with minimal human effort (few clicks per object). Besides\nits potential for efficient labeling of large-scale and varied 3D datasets, our\napproach, where the user directly interacts with the 3D environment, enables\nnew applications in AR/VR and human-robot interaction.\n","authors":["Theodora Kontogianni","Ekin Celikkan","Siyu Tang","Konrad Schindler"],"pdf_url":"https://arxiv.org/pdf/2204.07183v2.pdf","comment":"2023 IEEE International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2301.09376v1","updated":"2023-01-23T11:45:27Z","published":"2023-01-23T11:45:27Z","title":"Crowd3D: Towards Hundreds of People Reconstruction from a Single Image","summary":"  Image-based multi-person reconstruction in wide-field large scenes is\ncritical for crowd analysis and security alert. However, existing methods\ncannot deal with large scenes containing hundreds of people, which encounter\nthe challenges of large number of people, large variations in human scale, and\ncomplex spatial distribution. In this paper, we propose Crowd3D, the first\nframework to reconstruct the 3D poses, shapes and locations of hundreds of\npeople with global consistency from a single large-scene image. The core of our\napproach is to convert the problem of complex crowd localization into pixel\nlocalization with the help of our newly defined concept, Human-scene Virtual\nInteraction Point (HVIP). To reconstruct the crowd with global consistency, we\npropose a progressive reconstruction network based on HVIP by pre-estimating a\nscene-level camera and a ground plane. To deal with a large number of persons\nand various human sizes, we also design an adaptive human-centric cropping\nscheme. Besides, we contribute a benchmark dataset, LargeCrowd, for crowd\nreconstruction in a large scene. Experimental results demonstrate the\neffectiveness of the proposed method. The code and datasets will be made\npublic.\n","authors":["Hao Wen","Jing Huang","Huili Cui","Haozhe Lin","YuKun Lai","Lu Fang","Kun Li"],"pdf_url":"https://arxiv.org/pdf/2301.09376v1.pdf","comment":"8 pages (not including reference)"},{"id":"http://arxiv.org/abs/2103.14675v6","updated":"2023-01-23T11:17:09Z","published":"2021-03-26T18:23:29Z","title":"Synthesis of Compositional Animations from Textual Descriptions","summary":"  \"How can we animate 3D-characters from a movie script or move robots by\nsimply telling them what we would like them to do?\" \"How unstructured and\ncomplex can we make a sentence and still generate plausible movements from it?\"\nThese are questions that need to be answered in the long-run, as the field is\nstill in its infancy. Inspired by these problems, we present a new technique\nfor generating compositional actions, which handles complex input sentences.\nOur output is a 3D pose sequence depicting the actions in the input sentence.\nWe propose a hierarchical two-stream sequential model to explore a finer\njoint-level mapping between natural language sentences and 3D pose sequences\ncorresponding to the given motion. We learn two manifold representations of the\nmotion -- one each for the upper body and the lower body movements. Our model\ncan generate plausible pose sequences for short sentences describing single\nactions as well as long compositional sentences describing multiple sequential\nand superimposed actions. We evaluate our proposed model on the publicly\navailable KIT Motion-Language Dataset containing 3D pose data with\nhuman-annotated sentences. Experimental results show that our model advances\nthe state-of-the-art on text-based motion synthesis in objective evaluations by\na margin of 50%. Qualitative evaluations based on a user study indicate that\nour synthesized motions are perceived to be the closest to the ground-truth\nmotion captures for both short and compositional sentences.\n","authors":["Anindita Ghosh","Noshaba Cheema","Cennet Oguz","Christian Theobalt","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2103.14675v6.pdf","comment":"13 pages, 6 figures, 3 tables. Proceedings of the IEEE/CVF\n  International Conference on Computer Vision (ICCV), 2021, pp. 1396-1406"},{"id":"http://arxiv.org/abs/2206.09372v2","updated":"2023-01-23T10:44:12Z","published":"2022-06-19T10:31:53Z","title":"mvHOTA: A multi-view higher order tracking accuracy metric to measure\n  spatial and temporal associations in multi-point detection","summary":"  Multi-point tracking is a challenging task that involves detecting points in\nthe scene and tracking them across a sequence of frames. Computing\ndetection-based measures like the F-measure on a frame-by-frame basis is not\nsufficient to assess the overall performance, as it does not interpret\nperformance in the temporal domain. The main evaluation metric available comes\nfrom Multi-object tracking (MOT) methods to benchmark performance on datasets\nsuch as KITTI with the recently proposed higher order tracking accuracy (HOTA)\nmetric, which is capable of providing a better description of the performance\nover metrics such as MOTA, DetA, and IDF1. While the HOTA metric takes into\naccount temporal associations, it does not provide a tailored means to analyse\nthe spatial associations of a dataset in a multi-camera setup. Moreover, there\nare differences in evaluating the detection task for points when compared to\nobjects (point distances vs. bounding box overlap). Therefore in this work, we\npropose a multi-view higher order tracking metric (mvHOTA) to determine the\naccuracy of multi-point (multi-instance and multi-class) tracking methods,\nwhile taking into account temporal and spatial associations.mvHOTA can be\ninterpreted as the geometric mean of detection, temporal, and spatial\nassociations, thereby providing equal weighting to each of the factors. We\ndemonstrate the use of this metric to evaluate the tracking performance on an\nendoscopic point detection dataset from a previously organised surgical data\nscience challenge. Furthermore, we compare with other adjusted MOT metrics for\nthis use-case, discuss the properties of mvHOTA, and show how the proposed\nmulti-view Association and the Occlusion index (OI) facilitate analysis of\nmethods with respect to handling of occlusions. The code is available at\nhttps://github.com/Cardio-AI/mvhota.\n","authors":["Lalith Sharan","Halvar Kelm","Gabriele Romano","Matthias Karck","Raffaele De Simone","Sandy Engelhardt"],"pdf_url":"https://arxiv.org/pdf/2206.09372v2.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.05489v2","updated":"2023-01-23T10:43:28Z","published":"2023-01-13T11:27:26Z","title":"Neural Image Compression with a Diffusion-Based Decoder","summary":"  Diffusion probabilistic models have recently achieved remarkable success in\ngenerating high quality image and video data. In this work, we build on this\nclass of generative models and introduce a method for lossy compression of high\nresolution images. The resulting codec, which we call DIffuson-based Residual\nAugmentation Codec (DIRAC),is the first neural codec to allow smooth traversal\nof the rate-distortion-perception tradeoff at test time, while obtaining\ncompetitive performance with GAN-based methods in perceptual quality.\nFurthermore, while sampling from diffusion probabilistic models is notoriously\nexpensive, we show that in the compression setting the number of steps can be\ndrastically reduced.\n","authors":["Noor Fathima Ghouse","Jens Petersen","Auke Wiggers","Tianlin Xu","Guillaume Sautière"],"pdf_url":"https://arxiv.org/pdf/2301.05489v2.pdf","comment":"v1: 26 pages, 13 figures v2: corrected typo in first author name in\n  arxiv metadata"},{"id":"http://arxiv.org/abs/2203.04908v2","updated":"2023-01-23T10:07:36Z","published":"2022-03-09T17:39:18Z","title":"Rethinking data-driven point spread function modeling with a\n  differentiable optical model","summary":"  In astronomy, upcoming space telescopes with wide-field optical instruments\nhave a spatially varying point spread function (PSF). Specific scientific goals\nrequire a high-fidelity estimation of the PSF at target positions where no\ndirect measurement of the PSF is provided. Even though observations of the PSF\nare available at some positions of the field of view (FOV), they are\nundersampled, noisy, and integrated into wavelength in the instrument's\npassband. PSF modeling represents a challenging ill-posed problem, as it\nrequires building a model from degraded observations that can infer a\nsuper-resolved PSF at any wavelength and position in the FOV. Our model, coined\nWaveDiff, proposes a paradigm shift in the data-driven modeling of the point\nspread function field of telescopes. We change the data-driven modeling space\nfrom the pixels to the wavefront by adding a differentiable optical forward\nmodel into the modeling framework. This change allows the transfer of\ncomplexity from the instrumental response into the forward model. The proposed\nmodel relies on stochastic gradient descent to estimate its parameters. Our\nframework paves the way to building powerful, physically motivated models that\ndo not require special calibration data. This paper demonstrates the WaveDiff\nmodel in a simplified setting of a space telescope. The proposed framework\nrepresents a performance breakthrough with respect to the existing\nstate-of-the-art data-driven approach. The pixel reconstruction errors decrease\n6-fold at observation resolution and 44-fold for a 3x super-resolution. The\nellipticity errors are reduced at least 20 times, and the size error is reduced\nmore than 250 times. By only using noisy broad-band in-focus observations, we\nsuccessfully capture the PSF chromatic variations due to diffraction. Code\navailable at https://github.com/tobias-liaudat/wf-psf.\n","authors":["Tobias Liaudat","Jean-Luc Starck","Martin Kilbinger","Pierre-Antoine Frugier"],"pdf_url":"https://arxiv.org/pdf/2203.04908v2.pdf","comment":"Submitted. Without appendix: 42 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2301.09339v1","updated":"2023-01-23T09:45:31Z","published":"2023-01-23T09:45:31Z","title":"Computer Vision for a Camel-Vehicle Collision Mitigation System","summary":"  As the population grows and more land is being used for urbanization,\necosystems are disrupted by our roads and cars. This expansion of\ninfrastructure cuts through wildlife territories, leading to many instances of\nWildlife-Vehicle Collision (WVC). These instances of WVC are a global issue\nthat is having a global socio-economic impact, resulting in billions of dollars\nin property damage and, at times, fatalities for vehicle occupants. In Saudi\nArabia, this issue is similar, with instances of Camel-Vehicle Collision (CVC)\nbeing particularly deadly due to the large size of camels, which results in a\n25% fatality rate [4]. The focus of this work is to test different object\ndetection models on the task of detecting camels on the road. The Deep Learning\n(DL) object detection models used in the experiments are: CenterNet,\nEfficientDet, Faster R-CNN, and SSD. Results of the experiments show that\nCenterNet performed the best in terms of accuracy and was the most efficient in\ntraining. In the future, the plan is to expand on this work by developing a\nsystem to make countryside roads safer.\n","authors":["Khalid Alnujaidi","Ghadah Alhabib"],"pdf_url":"https://arxiv.org/pdf/2301.09339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09338v1","updated":"2023-01-23T09:42:49Z","published":"2023-01-23T09:42:49Z","title":"Employing similarity to highlight differences: On the impact of\n  anatomical assumptions in chest X-ray registration methods","summary":"  To facilitate both the detection and the interpretation of findings in chest\nX-rays, comparison with a previous image of the same patient is very valuable\nto radiologists. Today, the most common approach for deep learning methods to\nautomatically inspect chest X-rays disregards the patient history and\nclassifies only single images as normal or abnormal. Nevertheless, several\nmethods for assisting in the task of comparison through image registration have\nbeen proposed in the past. However, as we illustrate, they tend to miss\nspecific types of pathological changes like cardiomegaly and effusion. Due to\nassumptions on fixed anatomical structures or their measurements of\nregistration quality they tend to produce unnaturally deformed warp fields\nimpacting visualization of the difference image between moving and fixed\nimages. To overcome these limitations, we are the first to use a new paradigm\nbased on individual rib pair segmentation for anatomy penalized registration,\nwhich proves a natural way to limit folding of the warp field, especially\nbeneficial for image pairs with large pathological changes. We show that it is\npossible to develop a deep learning powered solution that can visualize what\nother methods overlook on a large data set of paired public images, starting\nfrom less than 25 fully labeled and 50 partly labeled training images,\nemploying sequential instance memory segmentation with hole dropout, weak\nlabeling, coarse-to-fine refinement and Gaussian mixture model histogram\nmatching. We statistically evaluate the benefits of our method over the SOTA\nand highlight the limits of currently used metrics for registration of chest\nX-rays.\n","authors":["Astrid Berg","Eva Vandersmissen","Maria Wimmer","David Major","Theresa Neubauer","Dimitrios Lenis","Jeroen Cant","Annemiek Snoeckx","Katja Bühler"],"pdf_url":"https://arxiv.org/pdf/2301.09338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09322v1","updated":"2023-01-23T08:46:17Z","published":"2023-01-23T08:46:17Z","title":"Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19","summary":"  Cerebral Microbleeds (CMBs), typically captured as hypointensities from\nsusceptibility-weighted imaging (SWI), are particularly important for the study\nof dementia, cerebrovascular disease, and normal aging. Recent studies on\nCOVID-19 have shown an increase in CMBs of coronavirus cases. Automatic\ndetection of CMBs is challenging due to the small size and amount of CMBs\nmaking the classes highly imbalanced, lack of publicly available annotated\ndata, and similarity with CMB mimics such as calcifications, irons, and veins.\nHence, the existing deep learning methods are mostly trained on very limited\nresearch data and fail to generalize to unseen data with high variability and\ncannot be used in clinical setups. To this end, we propose an efficient 3D deep\nlearning framework that is actively trained on multi-domain data. Two public\ndatasets assigned for normal aging, stroke, and Alzheimer's disease analysis as\nwell as an in-house dataset for COVID-19 assessment are used to train and\nevaluate the models. The obtained results show that the proposed method is\nrobust to low-resolution images and achieves 78% recall and 80% precision on\nthe entire test set with an average false positive of 1.6 per scan.\n","authors":["Neus Rodeja Ferrer","Malini Vendela Sagar","Kiril Vadimovic Klein","Christina Kruuse","Mads Nielsen","Mostafa Mehdipour Ghazi"],"pdf_url":"https://arxiv.org/pdf/2301.09322v1.pdf","comment":"International Symposium on Biomedical Imaging (ISBI) 2023"},{"id":"http://arxiv.org/abs/2301.09318v1","updated":"2023-01-23T08:35:00Z","published":"2023-01-23T08:35:00Z","title":"Toward Foundation Models for Earth Monitoring: Generalizable Deep\n  Learning Models for Natural Hazard Segmentation","summary":"  Climate change results in an increased probability of extreme weather events\nthat put societies and businesses at risk on a global scale. Therefore, near\nreal-time mapping of natural hazards is an emerging priority for the support of\nnatural disaster relief, risk management, and informing governmental policy\ndecisions. Recent methods to achieve near real-time mapping increasingly\nleverage deep learning (DL). However, DL-based approaches are designed for one\nspecific task in a single geographic region based on specific frequency bands\nof satellite data. Therefore, DL models used to map specific natural hazards\nstruggle with their generalization to other types of natural hazards in unseen\nregions. In this work, we propose a methodology to significantly improve the\ngeneralizability of DL natural hazards mappers based on pre-training on a\nsuitable pre-task. Without access to any data from the target domain, we\ndemonstrate this improved generalizability across four U-Net architectures for\nthe segmentation of unseen natural hazards. Importantly, our method is\ninvariant to geographic differences and differences in the type of frequency\nbands of satellite data. By leveraging characteristics of unlabeled images from\nthe target domain that are publicly available, our approach is able to further\nimprove the generalization behavior without fine-tuning. Thereby, our approach\nsupports the development of foundation models for earth monitoring with the\nobjective of directly segmenting unseen natural hazards across novel geographic\nregions given different sources of satellite imagery.\n","authors":["Johannes Jakubik","Michal Muszynski","Michael Vössing","Niklas Kühl","Thomas Brunschwiler"],"pdf_url":"https://arxiv.org/pdf/2301.09318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09315v1","updated":"2023-01-23T08:24:33Z","published":"2023-01-23T08:24:33Z","title":"AI-Based Framework for Understanding Car Following Behaviors of Drivers\n  in A Naturalistic Driving Environment","summary":"  The most common type of accident on the road is a rear-end crash. These\ncrashes have a significant negative impact on traffic flow and are frequently\nfatal. To gain a more practical understanding of these scenarios, it is\nnecessary to accurately model car following behaviors that result in rear-end\ncrashes. Numerous studies have been carried out to model drivers' car-following\nbehaviors; however, the majority of these studies have relied on simulated\ndata, which may not accurately represent real-world incidents. Furthermore,\nmost studies are restricted to modeling the ego vehicle's acceleration, which\nis insufficient to explain the behavior of the ego vehicle. As a result, the\ncurrent study attempts to address these issues by developing an artificial\nintelligence framework for extracting features relevant to understanding driver\nbehavior in a naturalistic environment. Furthermore, the study modeled the\nacceleration of both the ego vehicle and the leading vehicle using extracted\ninformation from NDS videos. According to the study's findings, young people\nare more likely to be aggressive drivers than elderly people. In addition, when\nmodeling the ego vehicle's acceleration, it was discovered that the relative\nvelocity between the ego vehicle and the leading vehicle was more important\nthan the distance between the two vehicles.\n","authors":["Armstrong Aboah","Abdul Rashid Mussah","Yaw Adu-Gyamfi"],"pdf_url":"https://arxiv.org/pdf/2301.09315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09299v1","updated":"2023-01-23T07:00:04Z","published":"2023-01-23T07:00:04Z","title":"Self-Supervised Image Representation Learning: Transcending Masking with\n  Paired Image Overlay","summary":"  Self-supervised learning has become a popular approach in recent years for\nits ability to learn meaningful representations without the need for data\nannotation. This paper proposes a novel image augmentation technique,\noverlaying images, which has not been widely applied in self-supervised\nlearning. This method is designed to provide better guidance for the model to\nunderstand underlying information, resulting in more useful representations.\nThe proposed method is evaluated using contrastive learning, a widely used\nself-supervised learning method that has shown solid performance in downstream\ntasks. The results demonstrate the effectiveness of the proposed augmentation\ntechnique in improving the performance of self-supervised models.\n","authors":["Yinheng Li","Han Ding","Shaofei Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11541v2","updated":"2023-01-23T06:58:44Z","published":"2022-12-22T08:36:55Z","title":"Generative Colorization of Structured Mobile Web Pages","summary":"  Color is a critical design factor for web pages, affecting important factors\nsuch as viewer emotions and the overall trust and satisfaction of a website.\nEffective coloring requires design knowledge and expertise, but if this process\ncould be automated through data-driven modeling, efficient exploration and\nalternative workflows would be possible. However, this direction remains\nunderexplored due to the lack of a formalization of the web page colorization\nproblem, datasets, and evaluation protocols. In this work, we propose a new\ndataset consisting of e-commerce mobile web pages in a tractable format, which\nare created by simplifying the pages and extracting canonical color styles with\na common web browser. The web page colorization problem is then formalized as a\ntask of estimating plausible color styles for a given web page content with a\ngiven hierarchical structure of the elements. We present several\nTransformer-based methods that are adapted to this task by prepending\nstructural message passing to capture hierarchical relationships between\nelements. Experimental results, including a quantitative evaluation designed\nfor this task, demonstrate the advantages of our methods over statistical and\nimage colorization methods. The code is available at\nhttps://github.com/CyberAgentAILab/webcolor.\n","authors":["Kotaro Kikuchi","Naoto Inoue","Mayu Otani","Edgar Simo-Serra","Kota Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2212.11541v2.pdf","comment":"Accepted to WACV 2023"},{"id":"http://arxiv.org/abs/2301.09282v1","updated":"2023-01-23T05:58:26Z","published":"2023-01-23T05:58:26Z","title":"Classification of Luminal Subtypes in Full Mammogram Images Using\n  Transfer Learning","summary":"  Automatic identification of patients with luminal and non-luminal subtypes\nduring a routine mammography screening can support clinicians in streamlining\nbreast cancer therapy planning. Recent machine learning techniques have shown\npromising results in molecular subtype classification in mammography; however,\nthey are highly dependent on pixel-level annotations, handcrafted, and radiomic\nfeatures. In this work, we provide initial insights into the luminal subtype\nclassification in full mammogram images trained using only image-level labels.\nTransfer learning is applied from a breast abnormality classification task, to\nfinetune a ResNet-18-based luminal versus non-luminal subtype classification\ntask. We present and compare our results on the publicly available CMMD dataset\nand show that our approach significantly outperforms the baseline classifier by\nachieving a mean AUC score of 0.6688 and a mean F1 score of 0.6693 on the test\ndataset. The improvement over baseline is statistically significant, with a\np-value of p<0.0001.\n","authors":["Adarsh Bhandary Panambur","Prathmesh Madhu","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2301.09282v1.pdf","comment":"Submitted to IEEE ISBI 2023"},{"id":"http://arxiv.org/abs/2110.04070v3","updated":"2023-01-23T05:33:48Z","published":"2021-10-05T06:40:16Z","title":"Dataset Structural Index: Leveraging a machine's perspective towards\n  visual data","summary":"  With advances in vision and perception architectures, we have realized that\nworking with data is equally crucial, if not more, than the algorithms. Till\ntoday, we have trained machines based on our knowledge and perspective of the\nworld. The entire concept of Dataset Structural Index(DSI) revolves around\nunderstanding a machine`s perspective of the dataset. With DSI, I show two meta\nvalues with which we can get more information over a visual dataset and use it\nto optimize data, create better architectures, and have an ability to guess\nwhich model would work best. These two values are the Variety contribution\nratio and Similarity matrix. In the paper, I show many applications of DSI, one\nof which is how the same level of accuracy can be achieved with the same model\narchitectures trained over less amount of data.\n","authors":["Dishant Parikh"],"pdf_url":"https://arxiv.org/pdf/2110.04070v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09268v1","updated":"2023-01-23T04:34:25Z","published":"2023-01-23T04:34:25Z","title":"PCBDet: An Efficient Deep Neural Network Object Detection Architecture\n  for Automatic PCB Component Detection on the Edge","summary":"  There can be numerous electronic components on a given PCB, making the task\nof visual inspection to detect defects very time-consuming and prone to error,\nespecially at scale. There has thus been significant interest in automatic PCB\ncomponent detection, particularly leveraging deep learning. However, deep\nneural networks typically require high computational resources, possibly\nlimiting their feasibility in real-world use cases in manufacturing, which\noften involve high-volume and high-throughput detection with constrained edge\ncomputing resource availability. As a result of an exploration of efficient\ndeep neural network architectures for this use case, we introduce PCBDet, an\nattention condenser network design that provides state-of-the-art inference\nthroughput while achieving superior PCB component detection performance\ncompared to other state-of-the-art efficient architecture designs. Experimental\nresults show that PCBDet can achieve up to 2$\\times$ inference speed-up on an\nARM Cortex A72 processor when compared to an EfficientNet-based design while\nachieving $\\sim$2-4\\% higher mAP on the FICS-PCB benchmark dataset.\n","authors":["Brian Li","Steven Palayew","Francis Li","Saad Abbasi","Saeejith Nair","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2301.09268v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.09266v1","updated":"2023-01-23T04:31:03Z","published":"2023-01-23T04:31:03Z","title":"FInC Flow: Fast and Invertible $k \\times k$ Convolutions for Normalizing\n  Flows","summary":"  Invertible convolutions have been an essential element for building\nexpressive normalizing flow-based generative models since their introduction in\nGlow. Several attempts have been made to design invertible $k \\times k$\nconvolutions that are efficient in training and sampling passes. Though these\nattempts have improved the expressivity and sampling efficiency, they severely\nlagged behind Glow which used only $1 \\times 1$ convolutions in terms of\nsampling time. Also, many of the approaches mask a large number of parameters\nof the underlying convolution, resulting in lower expressivity on a fixed\nrun-time budget. We propose a $k \\times k$ convolutional layer and Deep\nNormalizing Flow architecture which i.) has a fast parallel inversion algorithm\nwith running time O$(n k^2)$ ($n$ is height and width of the input image and k\nis kernel size), ii.) masks the minimal amount of learnable parameters in a\nlayer. iii.) gives better forward pass and sampling times comparable to other\n$k \\times k$ convolution-based models on real-world benchmarks. We provide an\nimplementation of the proposed parallel algorithm for sampling using our\ninvertible convolutions on GPUs. Benchmarks on CIFAR-10, ImageNet, and CelebA\ndatasets show comparable performance to previous works regarding bits per\ndimension while significantly improving the sampling time.\n","authors":["Aditya Kallappa","Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2301.09266v1.pdf","comment":"accepted: VISAPP'23"},{"id":"http://arxiv.org/abs/2301.09264v1","updated":"2023-01-23T04:26:20Z","published":"2023-01-23T04:26:20Z","title":"Efficient Training Under Limited Resources","summary":"  Training time budget and size of the dataset are among the factors affecting\nthe performance of a Deep Neural Network (DNN). This paper shows that Neural\nArchitecture Search (NAS), Hyper Parameters Optimization (HPO), and Data\nAugmentation help DNNs perform much better while these two factors are limited.\nHowever, searching for an optimal architecture and the best hyperparameter\nvalues besides a good combination of data augmentation techniques under low\nresources requires many experiments. We present our approach to achieving such\na goal in three steps: reducing training epoch time by compressing the model\nwhile maintaining the performance compared to the original model, preventing\nmodel overfitting when the dataset is small, and performing the hyperparameter\ntuning. We used NOMAD, which is a blackbox optimization software based on a\nderivative-free algorithm to do NAS and HPO. Our work achieved an accuracy of\n86.0 % on a tiny subset of Mini-ImageNet at the ICLR 2021 Hardware Aware\nEfficient Training (HAET) Challenge and won second place in the competition.\nThe competition results can be found at haet2021.github.io/challenge and our\nsource code can be found at github.com/DouniaLakhmiri/ICLR\\_HAET2021.\n","authors":["Mahdi Zolnouri","Dounia Lakhmiri","Christophe Tribes","Eyyüb Sari","Sébastien Le Digabel"],"pdf_url":"https://arxiv.org/pdf/2301.09264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09257v1","updated":"2023-01-23T03:59:48Z","published":"2023-01-23T03:59:48Z","title":"Real-Time Simultaneous Localization and Mapping with LiDAR intensity","summary":"  We propose a novel real-time LiDAR intensity image-based simultaneous\nlocalization and mapping method , which addresses the geometry degeneracy\nproblem in unstructured environments. Traditional LiDAR-based front-end\nodometry mostly relies on geometric features such as points, lines and planes.\nA lack of these features in the environment can lead to the failure of the\nentire odometry system. To avoid this problem, we extract feature points from\nthe LiDAR-generated point cloud that match features identified in LiDAR\nintensity images. We then use the extracted feature points to perform scan\nregistration and estimate the robot ego-movement. For the back-end, we jointly\noptimize the distance between the corresponding feature points, and the point\nto plane distance for planes identified in the map. In addition, we use the\nfeatures extracted from intensity images to detect loop closure candidates from\nprevious scans and perform pose graph optimization. Our experiments show that\nour method can run in real time with high accuracy and works well with\nillumination changes, low-texture, and unstructured environments.\n","authors":["Wenqiang Du","Giovanni Beltrame"],"pdf_url":"https://arxiv.org/pdf/2301.09257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09255v1","updated":"2023-01-23T03:41:02Z","published":"2023-01-23T03:41:02Z","title":"Combined Use of Federated Learning and Image Encryption for\n  Privacy-Preserving Image Classification with Vision Transformer","summary":"  In recent years, privacy-preserving methods for deep learning have become an\nurgent problem. Accordingly, we propose the combined use of federated learning\n(FL) and encrypted images for privacy-preserving image classification under the\nuse of the vision transformer (ViT). The proposed method allows us not only to\ntrain models over multiple participants without directly sharing their raw data\nbut to also protect the privacy of test (query) images for the first time. In\naddition, it can also maintain the same accuracy as normally trained models. In\nan experiment, the proposed method was demonstrated to well work without any\nperformance degradation on the CIFAR-10 and CIFAR-100 datasets.\n","authors":["Teru Nagamori","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2301.09255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09254v1","updated":"2023-01-23T03:33:38Z","published":"2023-01-23T03:33:38Z","title":"Learning to Linearize Deep Neural Networks for Secure and Efficient\n  Private Inference","summary":"  The large number of ReLU non-linearity operations in existing deep neural\nnetworks makes them ill-suited for latency-efficient private inference (PI).\nExisting techniques to reduce ReLU operations often involve manual effort and\nsacrifice significant accuracy. In this paper, we first present a novel measure\nof non-linearity layers' ReLU sensitivity, enabling mitigation of the\ntime-consuming manual efforts in identifying the same. Based on this\nsensitivity, we then present SENet, a three-stage training method that for a\ngiven ReLU budget, automatically assigns per-layer ReLU counts, decides the\nReLU locations for each layer's activation map, and trains a model with\nsignificantly fewer ReLUs to potentially yield latency and communication\nefficient PI. Experimental evaluations with multiple models on various datasets\nshow SENet's superior performance both in terms of reduced ReLUs and improved\nclassification accuracy compared to existing alternatives. In particular, SENet\ncan yield models that require up to ~2x fewer ReLUs while yielding similar\naccuracy. For a similar ReLU budget SENet can yield models with ~2.32% improved\nclassification accuracy, evaluated on CIFAR-100.\n","authors":["Souvik Kundu","Shunlin Lu","Yuke Zhang","Jacqueline Liu","Peter A. Beerel"],"pdf_url":"https://arxiv.org/pdf/2301.09254v1.pdf","comment":"15 pages, 10 figures, 11 tables. Accepted as a conference paper at\n  ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09253v1","updated":"2023-01-23T03:32:57Z","published":"2023-01-23T03:32:57Z","title":"CircNet: Meshing 3D Point Clouds with Circumcenter Detection","summary":"  Reconstructing 3D point clouds into triangle meshes is a key problem in\ncomputational geometry and surface reconstruction. Point cloud triangulation\nsolves this problem by providing edge information to the input points. Since no\nvertex interpolation is involved, it is beneficial to preserve sharp details on\nthe surface. Taking advantage of learning-based techniques in triangulation,\nexisting methods enumerate the complete combinations of candidate triangles,\nwhich is both complex and inefficient. In this paper, we leverage the duality\nbetween a triangle and its circumcenter, and introduce a deep neural network\nthat detects the circumcenters to achieve point cloud triangulation.\nSpecifically, we introduce multiple anchor priors to divide the neighborhood\nspace of each point. The neural network then learns to predict the presences\nand locations of circumcenters under the guidance of those anchors. We extract\nthe triangles dual to the detected circumcenters to form a primitive mesh, from\nwhich an edge-manifold mesh is produced via simple post-processing. Unlike\nexisting learning-based triangulation methods, the proposed method bypasses an\nexhaustive enumeration of triangle combinations and local surface\nparameterization. We validate the efficiency, generalization, and robustness of\nour method on prominent datasets of both watertight and open surfaces. The code\nand trained models are provided at https://github.com/Ruitao-L/CircNet.\n","authors":["Huan Lei","Ruitao Leng","Liang Zheng","Hongdong Li"],"pdf_url":"https://arxiv.org/pdf/2301.09253v1.pdf","comment":"accepted to ICLR2023"},{"id":"http://arxiv.org/abs/2301.09249v1","updated":"2023-01-23T02:43:03Z","published":"2023-01-23T02:43:03Z","title":"Exploring Active 3D Object Detection from a Generalization Perspective","summary":"  To alleviate the high annotation cost in LiDAR-based 3D object detection,\nactive learning is a promising solution that learns to select only a small\nportion of unlabeled data to annotate, without compromising model performance.\nOur empirical study, however, suggests that mainstream uncertainty-based and\ndiversity-based active learning policies are not effective when applied in the\n3D detection task, as they fail to balance the trade-off between point cloud\ninformativeness and box-level annotation costs. To overcome this limitation, we\njointly investigate three novel criteria in our framework Crb for point cloud\nacquisition - label conciseness}, feature representativeness and geometric\nbalance, which hierarchically filters out the point clouds of redundant 3D\nbounding box labels, latent features and geometric characteristics (e.g., point\ncloud density) from the unlabeled sample pool and greedily selects informative\nones with fewer objects to annotate. Our theoretical analysis demonstrates that\nthe proposed criteria align the marginal distributions of the selected subset\nand the prior distributions of the unseen test set, and minimizes the upper\nbound of the generalization error. To validate the effectiveness and\napplicability of \\textsc{Crb}, we conduct extensive experiments on the two\nbenchmark 3D object detection datasets of KITTI and Waymo and examine both\none-stage (\\textit{i.e.}, \\textsc{Second}) and two-stage 3D detectors (i.e.,\nPv-rcnn). Experiments evidence that the proposed approach outperforms existing\nactive learning strategies and achieves fully supervised performance requiring\n$1\\%$ and $8\\%$ annotations of bounding boxes and point clouds, respectively.\nSource code: https://github.com/Luoyadan/CRB-active-3Ddet.\n","authors":["Yadan Luo","Zhuoxiao Chen","Zijian Wang","Xin Yu","Zi Huang","Mahsa Baktashmotlagh"],"pdf_url":"https://arxiv.org/pdf/2301.09249v1.pdf","comment":"To appear in ICLR 2023"},{"id":"http://arxiv.org/abs/2301.07650v2","updated":"2023-01-23T02:11:45Z","published":"2023-01-18T16:52:40Z","title":"Facial Thermal and Blood Perfusion Patterns of Human Emotions:\n  Proof-of-Concept","summary":"  In this work, a preliminary study of proof-of-concept was conducted to\nevaluate the performance of the thermographic and blood perfusion data when\nemotions of positive and negative valence are applied, where the blood\nperfusion data are obtained from the thermographic data. The images were\nobtained for baseline, positive, and negative valence according to the protocol\nof the Geneva Affective Picture Database. Absolute and percentage differences\nof average values of the data between the valences and the baseline were\ncalculated for different regions of interest (forehead, periorbital eyes,\ncheeks, nose and upper lips). For negative valence, a decrease in temperature\nand blood perfusion was observed in the regions of interest, and the effect was\ngreater on the left side than on the right side. In positive valence, the\ntemperature and blood perfusion increased in some cases, showing a complex\npattern. The temperature and perfusion of the nose was reduced for both\nvalences, which is indicative of the arousal dimension. The blood perfusion\nimages were found to be greater contrast; the percentage differences in the\nblood perfusion images are greater than those obtained in thermographic images.\nMoreover, the blood perfusion images, and vasomotor answer are consistent,\ntherefore, they can be a better biomarker than thermographic analysis in\nidentifying emotions.\n","authors":["Victor H. Aristizabal-Tique","Marcela Henao-Perez","Diana Carolina Lopez-Medina","Renato Zambrano-Cruz","Gloria Diaz-Londoñod"],"pdf_url":"https://arxiv.org/pdf/2301.07650v2.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.08365v2","updated":"2023-01-23T22:51:47Z","published":"2023-01-20T00:05:18Z","title":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction","summary":"  $\\textbf{Purpose:}$ The MRI $k$-space acquisition is time consuming.\nTraditional techniques aim to acquire accelerated data, which in conjunction\nwith recent DL methods, aid in producing high-fidelity images in truncated\ntimes. Conventionally, subsampling the $k$-space is performed by utilizing\nCartesian-rectilinear trajectories, which even with the use of DL, provide\nimprecise reconstructions, though, a plethora of non-rectilinear or\nnon-Cartesian trajectories can be implemented in modern MRI scanners. This work\ninvestigates the effect of the $k$-space subsampling scheme on the quality of\nreconstructed accelerated MRI measurements produced by trained DL models.\n  $\\textbf{Methods:}$ The RecurrentVarNet was used as the DL-based\nMRI-reconstruction architecture. Cartesian fully-sampled multi-coil $k$-space\nmeasurements from three datasets with different accelerations were\nretrospectively subsampled using eight distinct subsampling schemes (four\nCartesian-rectilinear, two Cartesian non-rectilinear, two non-Cartesian).\nExperiments were conducted in two frameworks: Scheme-specific, where a distinct\nmodel was trained and evaluated for each dataset-subsampling scheme pair, and\nmulti-scheme, where for each dataset a single model was trained on data\nrandomly subsampled by any of the eight schemes and evaluated on data\nsubsampled by all schemes.\n  $\\textbf{Results:}$ In the scheme-specific setting RecurrentVarNets trained\nand evaluated on non-rectilinearly subsampled data demonstrated superior\nperformance especially for high accelerations, whilst in the multi-scheme\nsetting, reconstruction performance on rectilinearly subsampled data improved\nwhen compared to the scheme-specific experiments.\n  $\\textbf{Conclusion:}$ Training DL-based MRI reconstruction algorithms on\nnon-rectilinearly subsampled measurements can produce more faithful\nreconstructions.\n","authors":["George Yiasemis","Clara I. Sánchez","Jan-Jakob Sonke","Jonas Teuwen"],"pdf_url":"https://arxiv.org/pdf/2301.08365v2.pdf","comment":"25 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2301.09733v1","updated":"2023-01-23T21:54:01Z","published":"2023-01-23T21:54:01Z","title":"Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling\n  using Real-time Thermography","summary":"  We present a novel thermodynamic parameter estimation framework for\nenergy-based surgery on live tissue, with direct applications to tissue\ncharacterization during electrosurgery. This framework addresses the problem of\nestimating tissue-specific thermodynamics in real-time, which would enable\naccurate prediction of thermal damage impact to the tissue and damage-conscious\nplanning of electrosurgical procedures. Our approach provides basic\nthermodynamic information such as thermal diffusivity, and also allows for\nobtaining the thermal relaxation time and a model of the heat source, yielding\nin real-time a controlled hyperbolic thermodynamics model. The latter accounts\nfor the finite thermal propagation time necessary for modeling of the\nelectrosurgical action, in which the probe motion speed often surpasses the\nspeed of thermal propagation in the tissue operated on. Our approach relies\nsolely on thermographer feedback and a knowledge of the power level and\nposition of the electrosurgical pencil, imposing only very minor adjustments to\nnormal electrosurgery to obtain a high-fidelity model of the tissue-probe\ninteraction. Our method is minimally invasive and can be performed in situ. We\napply our method first to simulated data based on porcine muscle tissue to\nverify its accuracy and then to in vivo liver tissue, and compare the results\nwith those from the literature. This comparison shows that parameterizing the\nMaxwell--Cattaneo model through the framework proposed yields a noticeably\nhigher fidelity real-time adaptable representation of the thermodynamic tissue\nresponse to the electrosurgical impact than currently available. A discussion\non the differences between the live and the dead tissue thermodynamics is also\nprovided.\n","authors":["Hamza El-Kebir","Junren Ran","Yongseok Lee","Leonardo P. Chamorro","Martin Ostoja-Starzewski","Richard Berlin","Gabriela M. Aguiluz Cornejo","Enrico Benedetti","Pier C. Giulianotti","Joseph Bentsman"],"pdf_url":"https://arxiv.org/pdf/2301.09733v1.pdf","comment":"Accepted for publication in the IEEE Transactions on Biomedical\n  Engineering. Research reported in this publication was supported by the\n  National Institute of Biomedical Imaging and Bioengineering of the National\n  Institutes of Health under award number R01EB029766"},{"id":"http://arxiv.org/abs/2301.09724v1","updated":"2023-01-23T21:25:24Z","published":"2023-01-23T21:25:24Z","title":"Long-tail Detection with Effective Class-Margins","summary":"  Large-scale object detection and instance segmentation face a severe data\nimbalance. The finer-grained object classes become, the less frequent they\nappear in our datasets. However, at test-time, we expect a detector that\nperforms well for all classes and not just the most frequent ones. In this\npaper, we provide a theoretical understanding of the long-trail detection\nproblem. We show how the commonly used mean average precision evaluation metric\non an unknown test set is bound by a margin-based binary classification error\non a long-tailed object detection training set. We optimize margin-based binary\nclassification error with a novel surrogate objective called \\textbf{Effective\nClass-Margin Loss} (ECM). The ECM loss is simple, theoretically well-motivated,\nand outperforms other heuristic counterparts on LVIS v1 benchmark over a wide\nrange of architecture and detectors. Code is available at\n\\url{https://github.com/janghyuncho/ECM-Loss}.\n","authors":["Jang Hyun Cho","Philipp Krähenbühl"],"pdf_url":"https://arxiv.org/pdf/2301.09724v1.pdf","comment":"ECCV 2022 Oral. Code is available at\n  https://github.com/janghyuncho/ECM-Loss"},{"id":"http://arxiv.org/abs/2301.09702v1","updated":"2023-01-23T20:11:24Z","published":"2023-01-23T20:11:24Z","title":"Illumination Variation Correction Using Image Synthesis For Unsupervised\n  Domain Adaptive Person Re-Identification","summary":"  Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to\nlearn identity information from labeled images in source domains and apply it\nto unlabeled images in a target domain. One major issue with many unsupervised\nre-identification methods is that they do not perform well relative to large\ndomain variations such as illumination, viewpoint, and occlusions. In this\npaper, we propose a Synthesis Model Bank (SMB) to deal with illumination\nvariation in unsupervised person re-ID. The proposed SMB consists of several\nconvolutional neural networks (CNN) for feature extraction and Mahalanobis\nmatrices for distance metrics. They are trained using synthetic data with\ndifferent illumination conditions such that their synergistic effect makes the\nSMB robust against illumination variation. To better quantify the illumination\nintensity and improve the quality of synthetic images, we introduce a new 3D\nvirtual-human dataset for GAN-based image synthesis. From our experiments, the\nproposed SMB outperforms other synthesis methods on several re-ID benchmarks.\n","authors":["Jiaqi Guo","Amy R. Reibman","Edward J. Delp"],"pdf_url":"https://arxiv.org/pdf/2301.09702v1.pdf","comment":"10 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2210.10605v3","updated":"2023-01-23T19:56:55Z","published":"2022-10-19T14:51:44Z","title":"Provably Convergent Plug & Play Linearized ADMM, applied to Deblurring\n  Spatially Varying Kernels","summary":"  Plug & Play methods combine proximal algorithms with denoiser priors to solve\ninverse problems. These methods rely on the computability of the proximal\noperator of the data fidelity term. In this paper, we propose a Plug & Play\nframework based on linearized ADMM that allows us to bypass the computation of\nintractable proximal operators. We demonstrate the convergence of the algorithm\nand provide results on restoration tasks such as super-resolution and\ndeblurring with non-uniform blur.\n","authors":["Charles Laroche","Andrés Almansa","Eva Coupeté","Matias Tassano"],"pdf_url":"https://arxiv.org/pdf/2210.10605v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17106v2","updated":"2023-01-23T19:52:02Z","published":"2022-10-31T07:27:01Z","title":"Intelligent Painter: Picture Composition With Resampling Diffusion Model","summary":"  Have you ever thought that you can be an intelligent painter? This means that\nyou can paint a picture with a few expected objects in mind, or with a\ndesirable scene. This is different from normal inpainting approaches for which\nthe location of specific objects cannot be determined. In this paper, we\npresent an intelligent painter that generate a person's imaginary scene in one\ngo, given explicit hints. We propose a resampling strategy for Denoising\nDiffusion Probabilistic Model (DDPM) to intelligently compose unconditional\nharmonized pictures according to the input subjects at specific locations. By\nexploiting the diffusion property, we resample efficiently to produce realistic\npictures. Experimental results show that our resampling method favors the\nsemantic meaning of the generated output efficiently and generates less blurry\noutput. Quantitative analysis of image quality assessment shows that our method\nproduces higher perceptual quality images compared with the state-of-the-art\nmethods.\n","authors":["Wing-Fung Ku","Wan-Chi Siu","Xi Cheng","H. Anthony Chan"],"pdf_url":"https://arxiv.org/pdf/2210.17106v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09667v1","updated":"2023-01-23T19:09:36Z","published":"2023-01-23T19:09:36Z","title":"Improving Performance of Object Detection using the Mechanisms of Visual\n  Recognition in Humans","summary":"  Object recognition systems are usually trained and evaluated on high\nresolution images. However, in real world applications, it is common that the\nimages have low resolutions or have small sizes. In this study, we first track\nthe performance of the state-of-the-art deep object recognition network,\nFaster- RCNN, as a function of image resolution. The results reveals negative\neffects of low resolution images on recognition performance. They also show\nthat different spatial frequencies convey different information about the\nobjects in recognition process. It means multi-resolution recognition system\ncan provides better insight into optimal selection of features that results in\nbetter recognition of objects. This is similar to the mechanisms of the human\nvisual systems that are able to implement multi-scale representation of a\nvisual scene simultaneously. Then, we propose a multi-resolution object\nrecognition framework rather than a single-resolution network. The proposed\nframework is evaluated on the PASCAL VOC2007 database. The experimental results\nshow the performance of our adapted multi-resolution Faster-RCNN framework\noutperforms the single-resolution Faster-RCNN on input images with various\nresolutions with an increase in the mean Average Precision (mAP) of 9.14%\nacross all resolutions and 1.2% on the full-spectrum images. Furthermore, the\nproposed model yields robustness of the performance over a wide range of\nspatial frequencies.\n","authors":["Amir Ghasemi","Fatemeh Mottaghian","Akram Bayat"],"pdf_url":"https://arxiv.org/pdf/2301.09667v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10018v1","updated":"2023-01-23T13:44:15Z","published":"2023-01-23T13:44:15Z","title":"GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical\n  Flow Learning","summary":"  Existing homography and optical flow methods are erroneous in challenging\nscenes, such as fog, rain, night, and snow because the basic assumptions such\nas brightness and gradient constancy are broken. To address this issue, we\npresent an unsupervised learning approach that fuses gyroscope into homography\nand optical flow learning. Specifically, we first convert gyroscope readings\ninto motion fields named gyro field. Second, we design a self-guided fusion\nmodule (SGF) to fuse the background motion extracted from the gyro field with\nthe optical flow and guide the network to focus on motion details. Meanwhile,\nwe propose a homography decoder module (HD) to combine gyro field and\nintermediate results of SGF to produce the homography. To the best of our\nknowledge, this is the first deep learning framework that fuses gyroscope data\nand image content for both deep homography and optical flow learning. To\nvalidate our method, we propose a new dataset that covers regular and\nchallenging scenes. Experiments show that our method outperforms the\nstate-of-the-art methods in both regular and challenging scenes.\n","authors":["Haipeng Li","Kunming Luo","Bing Zeng","Shuaicheng Liu"],"pdf_url":"https://arxiv.org/pdf/2301.10018v1.pdf","comment":"12 pages. arXiv admin note: substantial text overlap with\n  arXiv:2103.13725"},{"id":"http://arxiv.org/abs/2202.06174v2","updated":"2023-01-23T01:58:50Z","published":"2022-02-13T01:19:41Z","title":"Source-Free Progressive Graph Learning for Open-Set Domain Adaptation","summary":"  Open-set domain adaptation (OSDA) has gained considerable attention in many\nvisual recognition tasks. However, most existing OSDA approaches are limited\ndue to three main reasons, including: (1) the lack of essential theoretical\nanalysis of generalization bound, (2) the reliance on the coexistence of source\nand target data during adaptation, and (3) failing to accurately estimate the\nuncertainty of model predictions. We propose a Progressive Graph Learning (PGL)\nframework that decomposes the target hypothesis space into the shared and\nunknown subspaces, and then progressively pseudo-labels the most confident\nknown samples from the target domain for hypothesis adaptation. Moreover, we\ntackle a more realistic source-free open-set domain adaptation (SF-OSDA)\nsetting that makes no assumption about the coexistence of source and target\ndomains, and introduce a balanced pseudo-labeling (BP-L) strategy in a\ntwo-stage framework, namely SF-PGL. Different from PGL that applies a\nclass-agnostic constant threshold for all target samples for pseudo-labeling,\nthe SF-PGL model uniformly selects the most confident target instances from\neach category at a fixed ratio. The confidence thresholds in each class are\nregarded as the 'uncertainty' of learning the semantic information, which are\nthen used to weigh the classification loss in the adaptation step. We conducted\nunsupervised and semi-supervised OSDA and SF-OSDA experiments on the benchmark\nimage classification and action recognition datasets. Additionally, we find\nthat balanced pseudo-labeling plays a significant role in improving\ncalibration, which makes the trained model less prone to over-confident or\nunder-confident predictions on the target data. Source code is available at\nhttps://github.com/Luoyadan/SF-PGL.\n","authors":["Yadan Luo","Zijian Wang","Zhuoxiao Chen","Zi Huang","Mahsa Baktashmotlagh"],"pdf_url":"https://arxiv.org/pdf/2202.06174v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2006.12087"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.14024v2","updated":"2023-01-23T17:00:01Z","published":"2022-12-28T18:52:44Z","title":"Demonstrate-Search-Predict: Composing retrieval and language models for\n  knowledge-intensive NLP","summary":"  Retrieval-augmented in-context learning has emerged as a powerful approach\nfor addressing knowledge-intensive tasks using frozen language models (LM) and\nretrieval models (RM). Existing work has combined these in simple\n\"retrieve-then-read\" pipelines in which the RM retrieves passages that are\ninserted into the LM prompt. To begin to fully realize the potential of frozen\nLMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that\nrelies on passing natural language texts in sophisticated pipelines between an\nLM and an RM. DSP can express high-level programs that bootstrap pipeline-aware\ndemonstrations, search for relevant passages, and generate grounded\npredictions, systematically breaking down problems into small transformations\nthat the LM and RM can handle more reliably. We have written novel DSP programs\nfor answering questions in open-domain, multi-hop, and conversational settings,\nestablishing in early evaluations new state-of-the-art in-context learning\nresults and delivering 37-120%, 8-39%, and 80-290% relative gains against the\nvanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a\ncontemporaneous self-ask pipeline, respectively. We release DSP at\nhttps://github.com/stanfordnlp/dsp\n","authors":["Omar Khattab","Keshav Santhanam","Xiang Lisa Li","David Hall","Percy Liang","Christopher Potts","Matei Zaharia"],"pdf_url":"https://arxiv.org/pdf/2212.14024v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08006v2","updated":"2023-01-23T09:12:33Z","published":"2023-01-19T11:13:04Z","title":"Keyword Embeddings for Query Suggestion","summary":"  Nowadays, search engine users commonly rely on query suggestions to improve\ntheir initial inputs. Current systems are very good at recommending lexical\nadaptations or spelling corrections to users' queries. However, they often\nstruggle to suggest semantically related keywords given a user's query. The\nconstruction of a detailed query is crucial in some tasks, such as legal\nretrieval or academic search. In these scenarios, keyword suggestion methods\nare critical to guide the user during the query formulation. This paper\nproposes two novel models for the keyword suggestion task trained on scientific\nliterature. Our techniques adapt the architecture of Word2Vec and FastText to\ngenerate keyword embeddings by leveraging documents' keyword co-occurrence.\nAlong with these models, we also present a specially tailored negative sampling\napproach that exploits how keywords appear in academic publications. We devise\na ranking-based evaluation methodology following both known-item and ad-hoc\nsearch scenarios. Finally, we evaluate our proposals against the\nstate-of-the-art word and sentence embedding models showing considerable\nimprovements over the baselines for the tasks.\n","authors":["Jorge Gabín","M. Eduardo Ares","Javier Parapar"],"pdf_url":"https://arxiv.org/pdf/2301.08006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09728v1","updated":"2023-01-23T21:41:25Z","published":"2023-01-23T21:41:25Z","title":"Injecting the BM25 Score as Text Improves BERT-Based Re-rankers","summary":"  In this paper we propose a novel approach for combining first-stage lexical\nretrieval models and Transformer-based re-rankers: we inject the relevance\nscore of the lexical model as a token in the middle of the input of the\ncross-encoder re-ranker. It was shown in prior work that interpolation between\nthe relevance score of lexical and BERT-based re-rankers may not consistently\nresult in higher effectiveness. Our idea is motivated by the finding that BERT\nmodels can capture numeric information. We compare several representations of\nthe BM25 score and inject them as text in the input of four different\ncross-encoders. We additionally analyze the effect for different query types,\nand investigate the effectiveness of our method for capturing exact matching\nrelevance. Evaluation on the MSMARCO Passage collection and the TREC DL\ncollections shows that the proposed method significantly improves over all\ncross-encoder re-rankers as well as the common interpolation methods. We show\nthat the improvement is consistent for all query types. We also find an\nimprovement in exact matching capabilities over both BM25 and the\ncross-encoders. Our findings indicate that cross-encoder re-rankers can\nefficiently be improved without additional computational burden and extra steps\nin the pipeline by explicitly adding the output of the first-stage ranker to\nthe model input, and this effect is robust for different models and query\ntypes.\n","authors":["Arian Askari","Amin Abolghasemi","Gabriella Pasi","Wessel Kraaij","Suzan Verberne"],"pdf_url":"https://arxiv.org/pdf/2301.09728v1.pdf","comment":"Accepted at ECIR 2023"},{"id":"http://arxiv.org/abs/2301.09715v1","updated":"2023-01-23T20:43:26Z","published":"2023-01-23T20:43:26Z","title":"PRIMEQA: The Prime Repository for State-of-the-Art MultilingualQuestion\n  Answering Research and Development","summary":"  The field of Question Answering (QA) has made remarkable progress in recent\nyears, thanks to the advent of large pre-trained language models, newer\nrealistic benchmark datasets with leaderboards, and novel algorithms for key\ncomponents such as retrievers and readers. In this paper, we introduce PRIMEQA:\na one-stop and open-source QA repository with an aim to democratize QA\nre-search and facilitate easy replication of state-of-the-art (SOTA) QA\nmethods. PRIMEQA supports core QA functionalities like retrieval and reading\ncomprehension as well as auxiliary capabilities such as question generation.It\nhas been designed as an end-to-end toolkit for various use cases: building\nfront-end applications, replicating SOTA methods on pub-lic benchmarks, and\nexpanding pre-existing methods. PRIMEQA is available at :\nhttps://github.com/primeqa.\n","authors":["Avirup Sil","Jaydeep Sen","Bhavani Iyer","Martin Franz","Kshitij Fadnis","Mihaela Bornea","Sara Rosenthal","Scott McCarley","Rong Zhang","Vishwajeet Kumar","Yulong Li","Md Arafat Sultan","Riyaz Bhat","Radu Florian","Salim Roukos"],"pdf_url":"https://arxiv.org/pdf/2301.09715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06257v3","updated":"2023-01-23T19:10:13Z","published":"2022-09-13T18:31:23Z","title":"A computational framework for physics-informed symbolic regression with\n  straightforward integration of domain knowledge","summary":"  Discovering a meaningful symbolic expression that explains experimental data\nis a fundamental challenge in many scientific fields. We present a novel,\nopen-source computational framework called Scientist-Machine Equation Detector\n(SciMED), which integrates scientific discipline wisdom in a\nscientist-in-the-loop approach, with state-of-the-art symbolic regression (SR)\nmethods. SciMED combines a wrapper selection method, that is based on a genetic\nalgorithm, with automatic machine learning and two levels of SR methods. We\ntest SciMED on five configurations of a settling sphere, with and without\naerodynamic non-linear drag force, and with excessive noise in the\nmeasurements. We show that SciMED is sufficiently robust to discover the\ncorrect physically meaningful symbolic expressions from the data, and\ndemonstrate how the integration of domain knowledge enhances its performance.\nOur results indicate better performance on these tasks than the\nstate-of-the-art SR software packages , even in cases where no knowledge is\nintegrated. Moreover, we demonstrate how SciMED can alert the user about\npossible missing features, unlike the majority of current SR systems.\n","authors":["Liron Simon Keren","Alex Liberzon","Teddy Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2209.06257v3.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.09637v1","updated":"2023-01-23T18:59:59Z","published":"2023-01-23T18:59:59Z","title":"InfiniCity: Infinite-Scale City Synthesis","summary":"  Toward infinite-scale 3D city synthesis, we propose a novel framework,\nInfiniCity, which constructs and renders an unconstrainedly large and\n3D-grounded environment from random noises. InfiniCity decomposes the seemingly\nimpractical task into three feasible modules, taking advantage of both 2D and\n3D data. First, an infinite-pixel image synthesis module generates\narbitrary-scale 2D maps from the bird's-eye view. Next, an octree-based voxel\ncompletion module lifts the generated 2D map to 3D octrees. Finally, a\nvoxel-based neural rendering module texturizes the voxels and renders 2D\nimages. InfiniCity can thus synthesize arbitrary-scale and traversable 3D city\nenvironments, and allow flexible and interactive editing from users. We\nquantitatively and qualitatively demonstrate the efficacy of the proposed\nframework. Project page: https://hubert0527.github.io/infinicity/\n","authors":["Chieh Hubert Lin","Hsin-Ying Lee","Willi Menapace","Menglei Chai","Aliaksandr Siarohin","Ming-Hsuan Yang","Sergey Tulyakov"],"pdf_url":"https://arxiv.org/pdf/2301.09637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09633v1","updated":"2023-01-23T18:59:28Z","published":"2023-01-23T18:59:28Z","title":"Prediction-Powered Inference","summary":"  We introduce prediction-powered inference $\\unicode{x2013}$ a framework for\nperforming valid statistical inference when an experimental data set is\nsupplemented with predictions from a machine-learning system such as AlphaFold.\nOur framework yields provably valid conclusions without making any assumptions\non the machine-learning algorithm that supplies the predictions. Higher\naccuracy of the predictions translates to smaller confidence intervals,\npermitting more powerful inference. Prediction-powered inference yields simple\nalgorithms for computing valid confidence intervals for statistical objects\nsuch as means, quantiles, and linear and logistic regression coefficients. We\ndemonstrate the benefits of prediction-powered inference with data sets from\nproteomics, genomics, electronic voting, remote sensing, census analysis, and\necology.\n","authors":["Anastasios N. Angelopoulos","Stephen Bates","Clara Fannjiang","Michael I. Jordan","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2301.09633v1.pdf","comment":"Code is available at\n  https://github.com/aangelopoulos/prediction-powered-inference"},{"id":"http://arxiv.org/abs/2301.09631v1","updated":"2023-01-23T18:59:01Z","published":"2023-01-23T18:59:01Z","title":"Feature construction using explanations of individual predictions","summary":"  Feature construction can contribute to comprehensibility and performance of\nmachine learning models. Unfortunately, it usually requires exhaustive search\nin the attribute space or time-consuming human involvement to generate\nmeaningful features. We propose a novel heuristic approach for reducing the\nsearch space based on aggregation of instance-based explanations of predictive\nmodels. The proposed Explainable Feature Construction (EFC) methodology\nidentifies groups of co-occurring attributes exposed by popular explanation\nmethods, such as IME and SHAP. We empirically show that reducing the search to\nthese groups significantly reduces the time of feature construction using\nlogical, relational, Cartesian, numerical, and threshold num-of-N and X-of-N\nconstructive operators. An analysis on 10 transparent synthetic datasets shows\nthat EFC effectively identifies informative groups of attributes and constructs\nrelevant features. Using 30 real-world classification datasets, we show\nsignificant improvements in classification accuracy for several classifiers and\ndemonstrate the feasibility of the proposed feature construction even for large\ndatasets. Finally, EFC generated interpretable features on a real-world problem\nfrom the financial industry, which were confirmed by a domain expert.\n","authors":["Boštjan Vouk","Matej Guid","Marko Robnik-Šikonja"],"pdf_url":"https://arxiv.org/pdf/2301.09631v1.pdf","comment":"54 pages, 10 figures, 22 tables"},{"id":"http://arxiv.org/abs/2204.04581v3","updated":"2023-01-23T18:57:42Z","published":"2022-04-10T02:33:00Z","title":"Augmenting Pre-trained Language Models with QA-Memory for Open-Domain\n  Question Answering","summary":"  Retrieval augmented language models have recently become the standard for\nknowledge intensive tasks. Rather than relying purely on latent semantics\nwithin the parameters of large neural models, these methods enlist a\nsemi-parametric memory to encode an index of knowledge for the model to\nretrieve over. Most prior work has employed text passages as the unit of\nknowledge, which has high coverage at the cost of interpretability,\ncontrollability, and efficiency. The opposite properties arise in other methods\nwhich have instead relied on knowledge base (KB) facts. At the same time, more\nrecent work has demonstrated the effectiveness of storing and retrieving from\nan index of Q-A pairs derived from text \\citep{lewis2021paq}. This approach\nyields a high coverage knowledge representation that maintains KB-like\nproperties due to its representations being more atomic units of information.\nIn this work we push this line of research further by proposing a\nquestion-answer augmented encoder-decoder model and accompanying pretraining\nstrategy. This yields an end-to-end system that not only outperforms prior QA\nretrieval methods on single-hop QA tasks but also enables compositional\nreasoning, as demonstrated by strong performance on two multi-hop QA datasets.\nTogether, these methods improve the ability to interpret and control the model\nwhile narrowing the performance gap with passage retrieval systems.\n","authors":["Wenhu Chen","Pat Verga","Michiel de Jong","John Wieting","William Cohen"],"pdf_url":"https://arxiv.org/pdf/2204.04581v3.pdf","comment":"Accepted by EACL 2023"},{"id":"http://arxiv.org/abs/2301.09627v1","updated":"2023-01-23T18:57:16Z","published":"2023-01-23T18:57:16Z","title":"The Impossibility of Parallelizing Boosting","summary":"  The aim of boosting is to convert a sequence of weak learners into a strong\nlearner. At their heart, these methods are fully sequential. In this paper, we\ninvestigate the possibility of parallelizing boosting. Our main contribution is\na strong negative result, implying that significant parallelization of boosting\nrequires an exponential blow-up in the total computing resources needed for\ntraining.\n","authors":["Amin Karbasi","Kasper Green Larsen"],"pdf_url":"https://arxiv.org/pdf/2301.09627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09624v1","updated":"2023-01-23T18:47:41Z","published":"2023-01-23T18:47:41Z","title":"Maximum Mean Discrepancy Kernels for Predictive and Prognostic Modeling\n  of Whole Slide Images","summary":"  How similar are two images? In computational pathology, where Whole Slide\nImages (WSIs) of digitally scanned tissue samples from patients can be\nmulti-gigapixels in size, determination of degree of similarity between two\nWSIs is a challenging task with a number of practical applications. In this\nwork, we explore a novel strategy based on kernelized Maximum Mean Discrepancy\n(MMD) analysis for determination of pairwise similarity between WSIs. The\nproposed approach works by calculating MMD between two WSIs using kernels over\ndeep features of image patches. This allows representation of an entire dataset\nof WSIs as a kernel matrix for WSI level clustering, weakly-supervised\nprediction of TP-53 mutation status in breast cancer patients from their\nroutine WSIs as well as survival analysis with state of the art prediction\nperformance. We believe that this work will open up further avenues for\napplication of WSI-level kernels for predictive and prognostic tasks in\ncomputational pathology.\n","authors":["Piotr Keller","Muhammad Dawood","Fayyaz ul Amir Afsar Minhas"],"pdf_url":"https://arxiv.org/pdf/2301.09624v1.pdf","comment":"* Joint first authorship Accepted: IEEE - ISBI 2023 International\n  Symposium on Biomedical Imaging"},{"id":"http://arxiv.org/abs/2205.12411v5","updated":"2023-01-23T18:21:02Z","published":"2022-05-24T23:43:02Z","title":"Linear Connectivity Reveals Generalization Strategies","summary":"  It is widely accepted in the mode connectivity literature that when two\nneural networks are trained similarly on the same data, they are connected by a\npath through parameter space over which test set accuracy is maintained. Under\nsome circumstances, including transfer learning from pretrained models, these\npaths are presumed to be linear. In contrast to existing results, we find that\namong text classifiers (trained on MNLI, QQP, and CoLA), some pairs of\nfinetuned models have large barriers of increasing loss on the linear paths\nbetween them. On each task, we find distinct clusters of models which are\nlinearly connected on the test loss surface, but are disconnected from models\noutside the cluster -- models that occupy separate basins on the surface. By\nmeasuring performance on specially-crafted diagnostic datasets, we find that\nthese clusters correspond to different generalization strategies: one cluster\nbehaves like a bag of words model under domain shift, while another cluster\nuses syntactic heuristics. Our work demonstrates how the geometry of the loss\nsurface can guide models towards different heuristic functions.\n","authors":["Jeevesh Juneja","Rachit Bansal","Kyunghyun Cho","João Sedoc","Naomi Saphra"],"pdf_url":"https://arxiv.org/pdf/2205.12411v5.pdf","comment":"Publushed as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09611v1","updated":"2023-01-23T18:14:32Z","published":"2023-01-23T18:14:32Z","title":"Explaining Deep Learning Hidden Neuron Activations using Concept\n  Induction","summary":"  One of the current key challenges in Explainable AI is in correctly\ninterpreting activations of hidden neurons. It seems evident that accurate\ninterpretations thereof would provide insights into the question what a deep\nlearning system has internally \\emph{detected} as relevant on the input, thus\nlifting some of the black box character of deep learning systems.\n  The state of the art on this front indicates that hidden node activations\nappear to be interpretable in a way that makes sense to humans, at least in\nsome cases. Yet, systematic automated methods that would be able to first\nhypothesize an interpretation of hidden neuron activations, and then verify it,\nare mostly missing.\n  In this paper, we provide such a method and demonstrate that it provides\nmeaningful interpretations. It is based on using large-scale background\nknowledge -- a class hierarchy of approx. 2 million classes curated from the\nWikipedia Concept Hierarchy -- together with a symbolic reasoning approach\ncalled \\emph{concept induction} based on description logics that was originally\ndeveloped for applications in the Semantic Web field.\n  Our results show that we can automatically attach meaningful labels from the\nbackground knowledge to individual neurons in the dense layer of a\nConvolutional Neural Network through a hypothesis and verification process.\n","authors":["Abhilekha Dalal","Md Kamruzzaman Sarker","Adrita Barua","Pascal Hitzler"],"pdf_url":"https://arxiv.org/pdf/2301.09611v1.pdf","comment":"Submitted to IJCAI-23"},{"id":"http://arxiv.org/abs/2301.09604v1","updated":"2023-01-23T18:10:22Z","published":"2023-01-23T18:10:22Z","title":"FedExP: Speeding up Federated Averaging Via Extrapolation","summary":"  Federated Averaging (FedAvg) remains the most popular algorithm for Federated\nLearning (FL) optimization due to its simple implementation, stateless nature,\nand privacy guarantees combined with secure aggregation. Recent work has sought\nto generalize the vanilla averaging in FedAvg to a generalized gradient descent\nstep by treating client updates as pseudo-gradients and using a server step\nsize. While the use of a server step size has been shown to provide performance\nimprovement theoretically, the practical benefit of the server step size has\nnot been seen in most existing works. In this work, we present FedExP, a method\nto adaptively determine the server step size in FL based on dynamically varying\npseudo-gradients throughout the FL process. We begin by considering the\noverparameterized convex regime, where we reveal an interesting similarity\nbetween FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then\nshow how FedExP can be motivated as a novel extension to the extrapolation\nmechanism that is used to speed up POCS. Our theoretical analysis later also\ndiscusses the implications of FedExP in underparameterized and non-convex\nsettings. Experimental results show that FedExP consistently converges faster\nthan FedAvg and competing baselines on a range of realistic FL datasets.\n","authors":["Divyansh Jhunjhunwala","Shiqiang Wang","Gauri Joshi"],"pdf_url":"https://arxiv.org/pdf/2301.09604v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2210.05394v2","updated":"2023-01-23T18:10:19Z","published":"2022-10-11T12:13:21Z","title":"Computationally-efficient initialisation of GPs: The generalised\n  variogram method","summary":"  We present a computationally-efficient strategy to find the hyperparameters\nof a Gaussian process (GP) avoiding the computation of the likelihood function.\nThe found hyperparameters can then be used directly for regression or passed as\ninitial conditions to maximum-likelihood (ML) training. Motivated by the fact\nthat training a GP via ML is equivalent (on average) to minimising the\nKL-divergence between the true and learnt model, we set to explore different\nmetrics/divergences among GPs that are computationally inexpensive and provide\nestimates close to those of ML. In particular, we identify the GP\nhyperparameters by projecting the empirical covariance or (Fourier) power\nspectrum onto a parametric family, thus proposing and studying various measures\nof discrepancy operating on the temporal or frequency domains. Our contribution\nextends the Variogram method developed by the geostatistics literature and,\naccordingly, it is referred to as the Generalised Variogram method (GVM). In\naddition to the theoretical presentation of GVM, we provide experimental\nvalidation in terms of accuracy, consistency with ML and computational\ncomplexity for different kernels using synthetic and real-world data.\n","authors":["Felipe Tobar","Elsa Cazelles","Taco de Wolff"],"pdf_url":"https://arxiv.org/pdf/2210.05394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.12210v7","updated":"2023-01-23T17:58:01Z","published":"2021-11-24T00:45:27Z","title":"From Kepler to Newton: Explainable AI for Science","summary":"  The Observation--Hypothesis--Prediction--Experimentation loop paradigm for\nscientific research has been practiced by researchers for years towards\nscientific discoveries. However, with data explosion in both mega-scale and\nmilli-scale scientific research, it has been sometimes very difficult to\nmanually analyze the data and propose new hypotheses to drive the cycle for\nscientific discovery. In this paper, we discuss the role of Explainable AI in\nscientific discovery process by demonstrating an Explainable AI-based paradigm\nfor science discovery. The key is to use Explainable AI to help derive data or\nmodel interpretations, hypotheses, as well as scientific discoveries or\ninsights. We show how computational and data-intensive methodology -- together\nwith experimental and theoretical methodology -- can be seamlessly integrated\nfor scientific research. To demonstrate the AI-based science discovery process,\nand to pay our respect to some of the greatest minds in human history, we show\nhow Kepler's laws of planetary motion and Newton's law of universal gravitation\ncan be rediscovered by (Explainable) AI based on Tycho Brahe's astronomical\nobservation data, whose works were leading the scientific revolution in the\n16-17th century. This work also highlights the important role of Explainable AI\n(as compared to Blackbox AI) in science discovery to help humans prevent or\nbetter prepare for the possible technological singularity that may happen in\nthe future, since science is not only about the know how, but also the know\nwhy. Presentation of the work is available at\nhttps://slideslive.com/38986142/from-kepler-to-newton-explainable-ai-for-science-discovery.\n","authors":["Zelong Li","Jianchao Ji","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2111.12210v7.pdf","comment":"Accepted by ICML-AI4Science 2022"},{"id":"http://arxiv.org/abs/2206.03477v2","updated":"2023-01-23T17:30:05Z","published":"2022-06-07T17:52:46Z","title":"Short Blocklength Wiretap Channel Codes via Deep Learning: Design and\n  Performance Evaluation","summary":"  We design short blocklength codes for the Gaussian wiretap channel under\ninformation-theoretic security guarantees. Our approach consists in decoupling\nthe reliability and secrecy constraints in our code design. Specifically, we\nhandle the reliability constraint via an autoencoder, and handle the secrecy\nconstraint with hash functions. For blocklengths smaller than or equal to 128,\nwe evaluate through simulations the probability of error at the legitimate\nreceiver and the leakage at the eavesdropper for our code construction. This\nleakage is defined as the mutual information between the confidential message\nand the eavesdropper's channel observations, and is empirically measured via a\nneural network-based mutual information estimator. Our simulation results\nprovide examples of codes with positive secrecy rates that outperform the best\nknown achievable secrecy rates obtained non-constructively for the Gaussian\nwiretap channel. Additionally, we show that our code design is suitable for the\ncompound and arbitrarily varying Gaussian wiretap channels, for which the\nchannel statistics are not perfectly known but only known to belong to a\npre-specified uncertainty set. These models not only capture uncertainty\nrelated to channel statistics estimation, but also scenarios where the\neavesdropper jams the legitimate transmission or influences its own channel\nstatistics by changing its location.\n","authors":["Vidhi Rana","Remi A. Chou"],"pdf_url":"https://arxiv.org/pdf/2206.03477v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09573v1","updated":"2023-01-23T17:29:26Z","published":"2023-01-23T17:29:26Z","title":"Huber-Robust Confidence Sequences","summary":"  Confidence sequences are confidence intervals that can be sequentially\ntracked, and are valid at arbitrary data-dependent stopping times. This paper\npresents confidence sequences for a univariate mean of an unknown distribution\nwith a known upper bound on the p-th central moment (p > 1), but allowing for\n(at most) {\\epsilon} fraction of arbitrary distribution corruption, as in\nHuber's contamination model. We do this by designing new robust exponential\nsupermartingales, and show that the resulting confidence sequences attain the\noptimal width achieved in the nonsequential setting. Perhaps surprisingly, the\nconstant margin between our sequential result and the lower bound is smaller\nthan even fixed-time robust confidence intervals based on the trimmed mean, for\nexample. Since confidence sequences are a common tool used within A/B/n testing\nand bandits, these results open the door to sequential experimentation that is\nrobust to outliers and adversarial corruptions.\n","authors":["Hongjian Wang","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2301.09573v1.pdf","comment":"26th International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2023)"},{"id":"http://arxiv.org/abs/2301.09559v1","updated":"2023-01-23T17:20:25Z","published":"2023-01-23T17:20:25Z","title":"SpArX: Sparse Argumentative Explanations for Neural Networks","summary":"  Neural networks (NNs) have various applications in AI, but explaining their\ndecision process remains challenging. Existing approaches often focus on\nexplaining how changing individual inputs affects NNs' outputs. However, an\nexplanation that is consistent with the input-output behaviour of an NN is not\nnecessarily faithful to the actual mechanics thereof. In this paper, we exploit\nrelationships between multi-layer perceptrons (MLPs) and quantitative\nargumentation frameworks (QAFs) to create argumentative explanations for the\nmechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining\nas much of the original mechanics as possible. It then translates the sparse\nMLP into an equivalent QAF to shed light on the underlying decision process of\nthe MLP, producing global and/or local explanations. We demonstrate\nexperimentally that SpArX can give more faithful explanations than existing\napproaches, while simultaneously providing deeper insights into the actual\nreasoning process of MLPs.\n","authors":["Hamed Ayoobi","Nico Potyka","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2301.09559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09554v1","updated":"2023-01-23T17:16:21Z","published":"2023-01-23T17:16:21Z","title":"Deep Learning Meets Sparse Regularization: A Signal Processing\n  Perspective","summary":"  Deep learning has been widely successful in practice and most\nstate-of-the-art machine learning methods are based on neural networks.\nLacking, however, is a rigorous mathematical theory that adequately explains\nthe amazing performance of deep neural networks. In this article, we present a\nrelatively new mathematical framework that provides the beginning of a deeper\nunderstanding of deep learning. This framework precisely characterizes the\nfunctional properties of neural networks that are trained to fit to data. The\nkey mathematical tools which support this framework include transform-domain\nsparse regularization, the Radon transform of computed tomography, and\napproximation theory, which are all techniques deeply rooted in signal\nprocessing. This framework explains the effect of weight decay regularization\nin neural network training, the use of skip connections and low-rank weight\nmatrices in network architectures, the role of sparsity in neural networks, and\nexplains why neural networks can perform well in high-dimensional problems.\n","authors":["Rahul Parhi","Robert D. Nowak"],"pdf_url":"https://arxiv.org/pdf/2301.09554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09545v1","updated":"2023-01-23T17:03:54Z","published":"2023-01-23T17:03:54Z","title":"The Entoptic Field Camera as Metaphor-Driven Research-through-Design\n  with AI Technologies","summary":"  Artificial intelligence (AI) technologies are widely deployed in smartphone\nphotography; and prompt-based image synthesis models have rapidly become\ncommonplace. In this paper, we describe a Research-through-Design (RtD) project\nwhich explores this shift in the means and modes of image production via the\ncreation and use of the Entoptic Field Camera. Entoptic phenomena usually refer\nto perceptions of floaters or bright blue dots stemming from the physiological\ninterplay of the eye and brain. We use the term entoptic as a metaphor to\ninvestigate how the material interplay of data and models in AI technologies\nshapes human experiences of reality. Through our case study using first-person\ndesign and a field study, we offer implications for critical, reflective,\nmore-than-human and ludic design to engage AI technologies; the\nconceptualisation of an RtD research space which contributes to AI literacy\ndiscourses; and outline a research trajectory concerning materiality and design\naffordances of AI technologies.\n","authors":["Jesse Josua Benjamin","Heidi Biggs","Arne Berger","Julija Rukanskaitė","Michael Heidt","Nick Merrill","James Pierce","Joseph Lindley"],"pdf_url":"https://arxiv.org/pdf/2301.09545v1.pdf","comment":"To be published in Proceedings of the 2023 CHI Conference on Human\n  Factors in Computing Systems (CHI '23), April 23--28, 2023, Hamburg, Germany"},{"id":"http://arxiv.org/abs/2111.04003v2","updated":"2023-01-23T16:52:59Z","published":"2021-11-07T04:58:40Z","title":"Predictive Model for Gross Community Production Rate of Coral Reefs\n  using Ensemble Learning Methodologies","summary":"  Coral reefs play a vital role in maintaining the ecological balance of the\nmarine ecosystem. Various marine organisms depend on coral reefs for their\nexistence and their natural processes. Coral reefs provide the necessary\nhabitat for reproduction and growth for various exotic species of the marine\necosystem. In this article, we discuss the most important parameters which\ninfluence the lifecycle of coral and coral reefs such as ocean acidification,\ndeoxygenation and other physical parameters such as flow rate and surface area.\nOcean acidification depends on the amount of dissolved Carbon dioxide (CO2).\nThis is due to the release of H+ ions upon the reaction of the dissolved CO2\ngases with the calcium carbonate compounds in the ocean. Deoxygenation is\nanother problem that leads to hypoxia which is characterized by a lesser amount\nof dissolved oxygen in water than the required amount for the existence of\nmarine organisms. In this article, we highlight the importance of physical\nparameters such as flow rate which influence gas exchange, heat dissipation,\nbleaching sensitivity, nutrient supply, feeding, waste and sediment removal,\ngrowth and reproduction. In this paper, we also bring out these important\nparameters and propose an ensemble machine learning-based model for analyzing\nthese parameters and provide better rates that can help us to understand and\nsuitably improve the ocean composition which in turn can eminently improve the\nsustainability of the marine ecosystem, mainly the coral reefs\n","authors":["Umanandini S","Rishivardhan M","Aouthithiye Barathwaj SR Y","Jasline Augusta J","Shrirang Sapate","Reenasree S","Vigneash M"],"pdf_url":"https://arxiv.org/pdf/2111.04003v2.pdf","comment":"8 pages, 18 figures"},{"id":"http://arxiv.org/abs/2208.12212v2","updated":"2023-01-23T16:50:51Z","published":"2022-08-25T17:02:37Z","title":"Sustaining Fairness via Incremental Learning","summary":"  Machine learning systems are often deployed for making critical decisions\nlike credit lending, hiring, etc. While making decisions, such systems often\nencode the user's demographic information (like gender, age) in their\nintermediate representations. This can lead to decisions that are biased\ntowards specific demographics. Prior work has focused on debiasing intermediate\nrepresentations to ensure fair decisions. However, these approaches fail to\nremain fair with changes in the task or demographic distribution. To ensure\nfairness in the wild, it is important for a system to adapt to such changes as\nit accesses new data in an incremental fashion. In this work, we propose to\naddress this issue by introducing the problem of learning fair representations\nin an incremental learning setting. To this end, we present Fairness-aware\nIncremental Representation Learning (FaIRL), a representation learning system\nthat can sustain fairness while incrementally learning new tasks. FaIRL is able\nto achieve fairness and learn new tasks by controlling the rate-distortion\nfunction of the learned representations. Our empirical evaluations show that\nFaIRL is able to make fair decisions while achieving high performance on the\ntarget task, outperforming several baselines.\n","authors":["Somnath Basu Roy Chowdhury","Snigdha Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2208.12212v2.pdf","comment":"Accepted at AAAI 2023"},{"id":"http://arxiv.org/abs/2301.09525v1","updated":"2023-01-23T16:16:24Z","published":"2023-01-23T16:16:24Z","title":"DeepFEL: Deep Fastfood Ensemble Learning for Histopathology Image\n  Analysis","summary":"  Computational pathology tasks have some unique characterises such as\nmulti-gigapixel images, tedious and frequently uncertain annotations, and\nunavailability of large number of cases [13]. To address some of these issues,\nwe present Deep Fastfood Ensembles - a simple, fast and yet effective method\nfor combining deep features pooled from popular CNN models pre-trained on\ntotally different source domains (e.g., natural image objects) and projected\nonto diverse dimensions using random projections, the so-called Fastfood [11].\nThe final ensemble output is obtained by a consensus of simple individual\nclassifiers, each of which is trained on a different collection of random basis\nvectors. This offers extremely fast and yet effective solution, especially when\ntraining times and domain labels are of the essence. We demonstrate the\neffectiveness of the proposed deep fastfood ensemble learning as compared to\nthe state-of-the-art methods for three different tasks in histopathology image\nanalysis.\n","authors":["Nima Hatami"],"pdf_url":"https://arxiv.org/pdf/2301.09525v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2104.00669"},{"id":"http://arxiv.org/abs/2301.09521v1","updated":"2023-01-23T16:12:18Z","published":"2023-01-23T16:12:18Z","title":"WDC Products: A Multi-Dimensional Entity Matching Benchmark","summary":"  The difficulty of an entity matching task depends on a combination of\nmultiple factors such as the amount of corner-case pairs, the fraction of\nentities in the test set that have not been seen during training, and the size\nof the development set. Current entity matching benchmarks usually represent\nsingle points in the space along such dimensions or they provide for the\nevaluation of matching methods along a single dimension, for instance the\namount of training data. This paper presents WDC Products, an entity matching\nbenchmark which provides for the systematic evaluation of matching systems\nalong combinations of three dimensions while relying on real-word data. The\nthree dimensions are (i) amount of corner-cases (ii) generalization to unseen\nentities, and (iii) development set size. Generalization to unseen entities is\na dimension not covered by any of the existing benchmarks yet but is crucial\nfor evaluating the robustness of entity matching systems. WDC Products is based\non heterogeneous product data from thousands of e-shops which mark-up products\noffers using schema.org annotations. Instead of learning how to match entity\npairs, entity matching can also be formulated as a multi-class classification\ntask that requires the matcher to recognize individual entities. WDC Products\nis the first benchmark that provides a pair-wise and a multi-class formulation\nof the same tasks and thus allows to directly compare the two alternatives. We\nevaluate WDC Products using several state-of-the-art matching systems,\nincluding Ditto, HierGAT, and R-SupCon. The evaluation shows that all matching\nsystems struggle with unseen entities to varying degrees. It also shows that\nsome systems are more training data efficient than others.\n","authors":["Ralph Peeters","Reng Chiz Der","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2301.09521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09519v1","updated":"2023-01-23T16:07:57Z","published":"2023-01-23T16:07:57Z","title":"A New Approach to Learning Linear Dynamical Systems","summary":"  Linear dynamical systems are the foundational statistical model upon which\ncontrol theory is built. Both the celebrated Kalman filter and the linear\nquadratic regulator require knowledge of the system dynamics to provide\nanalytic guarantees. Naturally, learning the dynamics of a linear dynamical\nsystem from linear measurements has been intensively studied since Rudolph\nKalman's pioneering work in the 1960's. Towards these ends, we provide the\nfirst polynomial time algorithm for learning a linear dynamical system from a\npolynomial length trajectory up to polynomial error in the system parameters\nunder essentially minimal assumptions: observability, controllability, and\nmarginal stability. Our algorithm is built on a method of moments estimator to\ndirectly estimate Markov parameters from which the dynamics can be extracted.\nFurthermore, we provide statistical lower bounds when our observability and\ncontrollability assumptions are violated.\n","authors":["Ainesh Bakshi","Allen Liu","Ankur Moitra","Morris Yau"],"pdf_url":"https://arxiv.org/pdf/2301.09519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09517v1","updated":"2023-01-23T16:05:56Z","published":"2023-01-23T16:05:56Z","title":"Sampling-based Nyström Approximation and Kernel Quadrature","summary":"  We analyze the Nystr\\\"om approximation of a positive definite kernel\nassociated with a probability measure. We first prove an improved error bound\nfor the conventional Nystr\\\"om approximation with i.i.d. sampling and\nsingular-value decomposition in the continuous regime; the proof techniques are\nborrowed from statistical learning theory. We further introduce a refined\nselection of subspaces in Nystr\\\"om approximation with theoretical guarantees\nthat is applicable to non-i.i.d. landmark points. Finally, we discuss their\napplication to convex kernel quadrature and give novel theoretical guarantees\nas well as numerical observations.\n","authors":["Satoshi Hayakawa","Harald Oberhauser","Terry Lyons"],"pdf_url":"https://arxiv.org/pdf/2301.09517v1.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2301.09515v1","updated":"2023-01-23T16:05:45Z","published":"2023-01-23T16:05:45Z","title":"StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale\n  Text-to-Image Synthesis","summary":"  Text-to-image synthesis has recently seen significant progress thanks to\nlarge pretrained language models, large-scale training data, and the\nintroduction of scalable model families such as diffusion and autoregressive\nmodels. However, the best-performing models require iterative evaluation to\ngenerate a single sample. In contrast, generative adversarial networks (GANs)\nonly need a single forward pass. They are thus much faster, but they currently\nremain far behind the state-of-the-art in large-scale text-to-image synthesis.\nThis paper aims to identify the necessary steps to regain competitiveness. Our\nproposed model, StyleGAN-T, addresses the specific requirements of large-scale\ntext-to-image synthesis, such as large capacity, stable training on diverse\ndatasets, strong text alignment, and controllable variation vs. text alignment\ntradeoff. StyleGAN-T significantly improves over previous GANs and outperforms\ndistilled diffusion models - the previous state-of-the-art in fast\ntext-to-image synthesis - in terms of sample quality and speed.\n","authors":["Axel Sauer","Tero Karras","Samuli Laine","Andreas Geiger","Timo Aila"],"pdf_url":"https://arxiv.org/pdf/2301.09515v1.pdf","comment":"Project page: https://sites.google.com/view/stylegan-t/"},{"id":"http://arxiv.org/abs/2202.06924v2","updated":"2023-01-23T16:03:10Z","published":"2022-02-14T18:33:12Z","title":"Do Gradient Inversion Attacks Make Federated Learning Unsafe?","summary":"  Federated learning (FL) allows the collaborative training of AI models\nwithout needing to share raw data. This capability makes it especially\ninteresting for healthcare applications where patient and data privacy is of\nutmost concern. However, recent works on the inversion of deep neural networks\nfrom model gradients raised concerns about the security of FL in preventing the\nleakage of training data. In this work, we show that these attacks presented in\nthe literature are impractical in FL use-cases where the clients' training\ninvolves updating the Batch Normalization (BN) statistics and provide a new\nbaseline attack that works for such scenarios. Furthermore, we present new ways\nto measure and visualize potential data leakage in FL. Our work is a step\ntowards establishing reproducible methods of measuring data leakage in FL and\ncould help determine the optimal tradeoffs between privacy-preserving\ntechniques, such as differential privacy, and model accuracy based on\nquantifiable metrics.\n  Code is available at\nhttps://nvidia.github.io/NVFlare/research/quantifying-data-leakage.\n","authors":["Ali Hatamizadeh","Hongxu Yin","Pavlo Molchanov","Andriy Myronenko","Wenqi Li","Prerna Dogra","Andrew Feng","Mona G. Flores","Jan Kautz","Daguang Xu","Holger R. Roth"],"pdf_url":"https://arxiv.org/pdf/2202.06924v2.pdf","comment":"Revised version; Accepted to IEEE Transactions on Medical Imaging;\n  Improved and reformatted version of\n  https://www.researchsquare.com/article/rs-1147182/v2"},{"id":"http://arxiv.org/abs/2301.09511v1","updated":"2023-01-23T16:02:54Z","published":"2023-01-23T16:02:54Z","title":"On the Convergence of the Gradient Descent Method with Stochastic\n  Fixed-point Rounding Errors under the Polyak-Lojasiewicz Inequality","summary":"  When training neural networks with low-precision computation, rounding errors\noften cause stagnation or are detrimental to the convergence of the optimizers;\nin this paper we study the influence of rounding errors on the convergence of\nthe gradient descent method for problems satisfying the Polyak-Lojasiewicz\ninequality. Within this context, we show that, in contrast, biased stochastic\nrounding errors may be beneficial since choosing a proper rounding strategy\neliminates the vanishing gradient problem and forces the rounding bias in a\ndescent direction. Furthermore, we obtain a bound on the convergence rate that\nis stricter than the one achieved by unbiased stochastic rounding. The\ntheoretical analysis is validated by comparing the performances of various\nrounding strategies when optimizing several examples using low-precision\nfixed-point number formats.\n","authors":["Lu Xia","Michiel E. Hochstenbach","Stefano Massei"],"pdf_url":"https://arxiv.org/pdf/2301.09511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09508v1","updated":"2023-01-23T16:01:30Z","published":"2023-01-23T16:01:30Z","title":"BayBFed: Bayesian Backdoor Defense for Federated Learning","summary":"  Federated learning (FL) allows participants to jointly train a machine\nlearning model without sharing their private data with others. However, FL is\nvulnerable to poisoning attacks such as backdoor attacks. Consequently, a\nvariety of defenses have recently been proposed, which have primarily utilized\nintermediary states of the global model (i.e., logits) or distance of the local\nmodels (i.e., L2-norm) from the global model to detect malicious backdoors.\nHowever, as these approaches directly operate on client updates, their\neffectiveness depends on factors such as clients' data distribution or the\nadversary's attack strategies. In this paper, we introduce a novel and more\ngeneric backdoor defense framework, called BayBFed, which proposes to utilize\nprobability distributions over client updates to detect malicious updates in\nFL: it computes a probabilistic measure over the clients' updates to keep track\nof any adjustments made in the updates, and uses a novel detection algorithm\nthat can leverage this probabilistic measure to efficiently detect and filter\nout malicious updates. Thus, it overcomes the shortcomings of previous\napproaches that arise due to the direct usage of client updates; as our\nprobabilistic measure will include all aspects of the local client training\nstrategies. BayBFed utilizes two Bayesian Non-Parametric extensions: (i) a\nHierarchical Beta-Bernoulli process to draw a probabilistic measure given the\nclients' updates, and (ii) an adaptation of the Chinese Restaurant Process\n(CRP), referred by us as CRP-Jensen, which leverages this probabilistic measure\nto detect and filter out malicious updates. We extensively evaluate our defense\napproach on five benchmark datasets: CIFAR10, Reddit, IoT intrusion detection,\nMNIST, and FMNIST, and show that it can effectively detect and eliminate\nmalicious updates in FL without deteriorating the benign performance of the\nglobal model.\n","authors":["Kavita Kumari","Phillip Rieger","Hossein Fereidooni","Murtuza Jadliwala","Ahmad-Reza Sadeghi"],"pdf_url":"https://arxiv.org/pdf/2301.09508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09507v1","updated":"2023-01-23T16:01:26Z","published":"2023-01-23T16:01:26Z","title":"Characterizing Polarization in Social Networks using the Signed\n  Relational Latent Distance Model","summary":"  Graph representation learning has become a prominent tool for the\ncharacterization and understanding of the structure of networks in general and\nsocial networks in particular. Typically, these representation learning\napproaches embed the networks into a low-dimensional space in which the role of\neach individual can be characterized in terms of their latent position. A major\ncurrent concern in social networks is the emergence of polarization and filter\nbubbles promoting a mindset of \"us-versus-them\" that may be defined by extreme\npositions believed to ultimately lead to political violence and the erosion of\ndemocracy. Such polarized networks are typically characterized in terms of\nsigned links reflecting likes and dislikes. We propose the latent Signed\nrelational Latent dIstance Model (SLIM) utilizing for the first time the\nSkellam distribution as a likelihood function for signed networks and extend\nthe modeling to the characterization of distinct extreme positions by\nconstraining the embedding space to polytopes. On four real social signed\nnetworks of polarization, we demonstrate that the model extracts\nlow-dimensional characterizations that well predict friendships and animosity\nwhile providing interpretable visualizations defined by extreme positions when\nendowing the model with an embedding space restricted to polytopes.\n","authors":["Nikolaos Nakis","Abdulkadir Çelikkanat","Louis Boucherie","Christian Djurhuus","Felix Burmester","Daniel Mathias Holmelund","Monika Frolcová","Morten Mørup"],"pdf_url":"https://arxiv.org/pdf/2301.09507v1.pdf","comment":"Preprint version - Accepted for the proceedings of the 26th\n  International Conference on Artificial Intelligence and Statistics (AISTATS)\n  2023"},{"id":"http://arxiv.org/abs/2209.04699v2","updated":"2023-01-23T15:59:20Z","published":"2022-09-10T15:48:28Z","title":"Explainable Image Quality Assessments in Teledermatological Photography","summary":"  Image quality is a crucial factor in the effectiveness and efficiency of\nteledermatological consultations. However, up to 50% of images sent by patients\nhave quality issues, thus increasing the time to diagnosis and treatment. An\nautomated, easily deployable, explainable method for assessing image quality is\nnecessary to improve the current teledermatological consultation flow. We\nintroduce ImageQX, a convolutional neural network for image quality assessment\nwith a learning mechanism for identifying the most common poor image quality\nexplanations: bad framing, bad lighting, blur, low resolution, and distance\nissues. ImageQX was trained on 26,635 photographs and validated on 9,874\nphotographs, each annotated with image quality labels and poor image quality\nexplanations by up to 12 board-certified dermatologists. The photographic\nimages were taken between 2017 and 2019 using a mobile skin disease tracking\napplication accessible worldwide. Our method achieves expert-level performance\nfor both image quality assessment and poor image quality explanation. For image\nquality assessment, ImageQX obtains a macro F1-score of 0.73 +- 0.01, which\nplaces it within standard deviation of the pairwise inter-rater F1-score of\n0.77 +- 0.07. For poor image quality explanations, our method obtains F1-scores\nof between 0.37 +- 0.01 and 0.70 +- 0.01, similar to the inter-rater pairwise\nF1-score of between 0.24 +- 0.15 and 0.83 +- 0.06. Moreover, with a size of\nonly 15 MB, ImageQX is easily deployable on mobile devices. With an image\nquality detection performance similar to that of dermatologists, incorporating\nImageQX into the teledermatology flow can enable a better, faster flow for\nremote consultations.\n","authors":["Raluca Jalaboi","Ole Winther","Alfiia Galimzianova"],"pdf_url":"https://arxiv.org/pdf/2209.04699v2.pdf","comment":"Accepted at the Telemedicine and eHealth Journal"},{"id":"http://arxiv.org/abs/2301.09505v1","updated":"2023-01-23T15:58:59Z","published":"2023-01-23T15:58:59Z","title":"Rethinking the Expressive Power of GNNs via Graph Biconnectivity","summary":"  Designing expressive Graph Neural Networks (GNNs) is a central topic in\nlearning graph-structured data. While numerous approaches have been proposed to\nimprove GNNs in terms of the Weisfeiler-Lehman (WL) test, generally there is\nstill a lack of deep understanding of what additional power they can\nsystematically and provably gain. In this paper, we take a fundamentally\ndifferent perspective to study the expressive power of GNNs beyond the WL test.\nSpecifically, we introduce a novel class of expressivity metrics via graph\nbiconnectivity and highlight their importance in both theory and practice. As\nbiconnectivity can be easily calculated using simple algorithms that have\nlinear computational costs, it is natural to expect that popular GNNs can learn\nit easily as well. However, after a thorough review of prior GNN architectures,\nwe surprisingly find that most of them are not expressive for any of these\nmetrics. The only exception is the ESAN framework (Bevilacqua et al., 2022),\nfor which we give a theoretical justification of its power. We proceed to\nintroduce a principled and more efficient approach, called the Generalized\nDistance Weisfeiler-Lehman (GD-WL), which is provably expressive for all\nbiconnectivity metrics. Practically, we show GD-WL can be implemented by a\nTransformer-like architecture that preserves expressiveness and enjoys full\nparallelizability. A set of experiments on both synthetic and real datasets\ndemonstrates that our approach can consistently outperform prior GNN\narchitectures.\n","authors":["Bohang Zhang","Shengjie Luo","Liwei Wang","Di He"],"pdf_url":"https://arxiv.org/pdf/2301.09505v1.pdf","comment":"ICLR 2023 notable top-5%; 58 pages, 11 figures"},{"id":"http://arxiv.org/abs/2301.09500v1","updated":"2023-01-23T15:53:06Z","published":"2023-01-23T15:53:06Z","title":"Federated Sufficient Dimension Reduction Through High-Dimensional Sparse\n  Sliced Inverse Regression","summary":"  Federated learning has become a popular tool in the big data era nowadays. It\ntrains a centralized model based on data from different clients while keeping\ndata decentralized. In this paper, we propose a federated sparse sliced inverse\nregression algorithm for the first time. Our method can simultaneously estimate\nthe central dimension reduction subspace and perform variable selection in a\nfederated setting. We transform this federated high-dimensional sparse sliced\ninverse regression problem into a convex optimization problem by constructing\nthe covariance matrix safely and losslessly. We then use a linearized\nalternating direction method of multipliers algorithm to estimate the central\nsubspace. We also give approaches of Bayesian information criterion and\nhold-out validation to ascertain the dimension of the central subspace and the\nhyper-parameter of the algorithm. We establish an upper bound of the\nstatistical error rate of our estimator under the heterogeneous setting. We\ndemonstrate the effectiveness of our method through simulations and real world\napplications.\n","authors":["Wenquan Cui","Yue Zhao","Jianjun Xu","Haoyang Cheng"],"pdf_url":"https://arxiv.org/pdf/2301.09500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09496v1","updated":"2023-01-23T15:48:02Z","published":"2023-01-23T15:48:02Z","title":"ECGAN: Self-supervised generative adversarial network for\n  electrocardiography","summary":"  High-quality synthetic data can support the development of effective\npredictive models for biomedical tasks, especially in rare diseases or when\nsubject to compelling privacy constraints. These limitations, for instance,\nnegatively impact open access to electrocardiography datasets about\narrhythmias. This work introduces a self-supervised approach to the generation\nof synthetic electrocardiography time series which is shown to promote\nmorphological plausibility. Our model (ECGAN) allows conditioning the\ngenerative process for specific rhythm abnormalities, enhancing synchronization\nand diversity across samples with respect to literature models. A dedicated\nsample quality assessment framework is also defined, leveraging arrhythmia\nclassifiers. The empirical results highlight a substantial improvement against\nstate-of-the-art generative models for sequences and audio synthesis.\n","authors":["Lorenzo Simone","Davide Bacciu"],"pdf_url":"https://arxiv.org/pdf/2301.09496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09490v1","updated":"2023-01-23T15:38:58Z","published":"2023-01-23T15:38:58Z","title":"Speeding Up BatchBALD: A k-BALD Family of Approximations for Active\n  Learning","summary":"  Active learning is a powerful method for training machine learning models\nwith limited labeled data. One commonly used technique for active learning is\nBatchBALD, which uses Bayesian neural networks to find the most informative\npoints to label in a pool set. However, BatchBALD can be very slow to compute,\nespecially for larger datasets. In this paper, we propose a new approximation,\nk-BALD, which uses k-wise mutual information terms to approximate BatchBALD,\nmaking it much less expensive to compute. Results on the MNIST dataset show\nthat k-BALD is significantly faster than BatchBALD while maintaining similar\nperformance. Additionally, we also propose a dynamic approach for choosing k\nbased on the quality of the approximation, making it more efficient for larger\ndatasets.\n","authors":["Andreas Kirsch"],"pdf_url":"https://arxiv.org/pdf/2301.09490v1.pdf","comment":"5 pages, workshop preprint"},{"id":"http://arxiv.org/abs/2204.07261v3","updated":"2023-01-23T15:36:30Z","published":"2022-04-14T22:50:28Z","title":"Convergence and Implicit Regularization Properties of Gradient Descent\n  for Deep Residual Networks","summary":"  We prove linear convergence of gradient descent to a global optimum for the\ntraining of deep residual networks with constant layer width and smooth\nactivation function. We show that if the trained weights, as a function of the\nlayer index, admit a scaling limit as the depth increases, then the limit has\nfinite $p-$variation with $p=2$. Proofs are based on non-asymptotic estimates\nfor the loss function and for norms of the network weights along the gradient\ndescent path. We illustrate the relevance of our theoretical results to\npractical settings using detailed numerical experiments on supervised learning\nproblems.\n","authors":["Rama Cont","Alain Rossier","RenYuan Xu"],"pdf_url":"https://arxiv.org/pdf/2204.07261v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09485v1","updated":"2023-01-23T15:30:01Z","published":"2023-01-23T15:30:01Z","title":"Ordinal Regression for Difficulty Estimation of StepMania Levels","summary":"  StepMania is a popular open-source clone of a rhythm-based video game. As is\ncommon in popular games, there is a large number of community-designed levels.\nIt is often difficult for players and level authors to determine the difficulty\nlevel of such community contributions. In this work, we formalize and analyze\nthe difficulty prediction task on StepMania levels as an ordinal regression\n(OR) task. We standardize a more extensive and diverse selection of this data\nresulting in five data sets, two of which are extensions of previous work. We\nevaluate many competitive OR and non-OR models, demonstrating that neural\nnetwork-based models significantly outperform the state of the art and that\nStepMania-level data makes for an excellent test bed for deep OR models. We\nconclude with a user experiment showing our trained models' superiority over\nhuman labeling.\n","authors":["Billy Joe Franks","Benjamin Dinkelmann","Sophie Fellenz","Marius Kloft"],"pdf_url":"https://arxiv.org/pdf/2301.09485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09483v1","updated":"2023-01-23T15:25:58Z","published":"2023-01-23T15:25:58Z","title":"An iterative multi-fidelity approach for model order reduction of\n  multi-dimensional input parametric PDE systems","summary":"  We propose a parametric sampling strategy for the reduction of large-scale\nPDE systems with multidimensional input parametric spaces by leveraging models\nof different fidelity. The design of this methodology allows a user to\nadaptively sample points ad hoc from a discrete training set with no prior\nrequirement of error estimators. It is achieved by exploiting low-fidelity\nmodels throughout the parametric space to sample points using an efficient\nsampling strategy, and at the sampled parametric points, high-fidelity models\nare evaluated to recover the reduced basis functions. The low-fidelity models\nare then adapted with the reduced order models ( ROMs) built by projection onto\nthe subspace spanned by the recovered basis functions. The process continues\nuntil the low-fidelity model can represent the high-fidelity model adequately\nfor all the parameters in the parametric space. Since the proposed methodology\nleverages the use of low-fidelity models to assimilate the solution database,\nit significantly reduces the computational cost in the offline stage. The\nhighlight of this article is to present the construction of the initial\nlow-fidelity model, and a sampling strategy based on the discrete empirical\ninterpolation method (DEIM). We test this approach on a 2D steady-state heat\nconduction problem for two different input parameters and make a qualitative\ncomparison with the classical greedy reduced basis method (RBM), and further\ntest on a 9-dimensional parametric non-coercive elliptic problem and analyze\nthe computational performance based on different tuning of greedy selection of\npoints.\n","authors":["Manisha Chetry","Domenico Borzacchiello","Lucas Lestandi","Luisa Rocha Da Silva"],"pdf_url":"https://arxiv.org/pdf/2301.09483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09479v1","updated":"2023-01-23T15:22:42Z","published":"2023-01-23T15:22:42Z","title":"Modality-Agnostic Variational Compression of Implicit Neural\n  Representations","summary":"  We introduce a modality-agnostic neural data compression algorithm based on a\nfunctional view of data and parameterised as an Implicit Neural Representation\n(INR). Bridging the gap between latent coding and sparsity, we obtain compact\nlatent representations which are non-linearly mapped to a soft gating mechanism\ncapable of specialising a shared INR base network to each data item through\nsubnetwork selection. After obtaining a dataset of such compact latent\nrepresentations, we directly optimise the rate/distortion trade-off in this\nmodality-agnostic space using non-linear transform coding. We term this method\nVariational Compression of Implicit Neural Representation (VC-INR) and show\nboth improved performance given the same representational capacity pre\nquantisation while also outperforming previous quantisation schemes used for\nother INR-based techniques. Our experiments demonstrate strong results over a\nlarge set of diverse data modalities using the same algorithm without any\nmodality-specific inductive biases. We show results on images, climate data, 3D\nshapes and scenes as well as audio and video, introducing VC-INR as the first\nINR-based method to outperform codecs as well-known and diverse as JPEG 2000,\nMP3 and AVC/HEVC on their respective modalities.\n","authors":["Jonathan Richard Schwarz","Jihoon Tack","Yee Whye Teh","Jaeho Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2301.09479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10906v2","updated":"2023-01-23T15:19:32Z","published":"2022-11-20T08:48:34Z","title":"Learning from Long-Tailed Noisy Data with Sample Selection and Balanced\n  Loss","summary":"  The success of deep learning depends on large-scale and well-curated training\ndata, while data in real-world applications are commonly long-tailed and noisy.\nMany methods have been proposed to deal with long-tailed data or noisy data,\nwhile a few methods are developed to tackle long-tailed noisy data. To solve\nthis, we propose a robust method for learning from long-tailed noisy data with\nsample selection and balanced loss. Specifically, we separate the noisy\ntraining data into clean labeled set and unlabeled set with sample selection,\nand train the deep neural network in a semi-supervised manner with a balanced\nloss based on model bias. Extensive experiments on benchmarks demonstrate that\nour method outperforms existing state-of-the-art methods.\n","authors":["Lefan Zhang","Zhang-Hao Tian","Wujun Zhou","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2211.10906v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09474v1","updated":"2023-01-23T15:18:54Z","published":"2023-01-23T15:18:54Z","title":"DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained\n  Diffusion","summary":"  Real-world data generation often involves complex inter-dependencies among\ninstances, violating the IID-data hypothesis of standard learning paradigms and\nposing a challenge for uncovering the geometric structures for learning desired\ninstance representations. To this end, we introduce an energy constrained\ndiffusion model which encodes a batch of instances from a dataset into\nevolutionary states that progressively incorporate other instances' information\nby their interactions. The diffusion process is constrained by descent criteria\nw.r.t.~a principled energy function that characterizes the global consistency\nof instance representations over latent structures. We provide rigorous theory\nthat implies closed-form optimal estimates for the pairwise diffusion strength\namong arbitrary instance pairs, which gives rise to a new class of neural\nencoders, dubbed as DIFFormer (diffusion-based Transformers), with two\ninstantiations: a simple version with linear complexity for prohibitive\ninstance numbers, and an advanced version for learning complex structures.\nExperiments highlight the wide applicability of our model as a general-purpose\nencoder backbone with superior performance in various tasks, such as node\nclassification on large graphs, semi-supervised image/text classification, and\nspatial-temporal dynamics prediction.\n","authors":["Qitian Wu","Chenxiao Yang","Wentao Zhao","Yixuan He","David Wipf","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2301.09474v1.pdf","comment":"Accepted by International Conference on Learning Representations\n  (ICLR 2023)"},{"id":"http://arxiv.org/abs/2201.12825v3","updated":"2023-01-23T15:04:57Z","published":"2022-01-30T14:14:15Z","title":"Autoencoding Hyperbolic Representation for Adversarial Generation","summary":"  With the recent advance of geometric deep learning, neural networks have been\nextensively used for data in non-Euclidean domains. In particular, hyperbolic\nneural networks have proved successful in processing hierarchical information\nof data. However, many hyperbolic neural networks are numerically unstable\nduring training, which precludes using complex architectures. This crucial\nproblem makes it difficult to build hyperbolic generative models for real and\ncomplex data. In this work, we propose a hyperbolic generative network in which\nwe design novel architecture and layers to improve stability in training. Our\nproposed network contains three parts: first, a hyperbolic autoencoder (AE)\nthat produces hyperbolic embedding for input data; second, a hyperbolic\ngenerative adversarial network (GAN) for generating the hyperbolic latent\nembedding of the AE from simple noise; third, a generator that inherits the\ndecoder from the AE and the generator from the GAN. We call this network the\nhyperbolic AE-GAN, or HAEGAN for short. The architecture of HAEGAN fosters\nexpressive representation in the hyperbolic space, and the specific design of\nlayers ensures numerical stability. Experiments show that HAEGAN is able to\ngenerate complex data with state-of-the-art structure-related performance.\n","authors":["Eric Qu","Dongmian Zou"],"pdf_url":"https://arxiv.org/pdf/2201.12825v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15769v2","updated":"2023-01-23T14:35:33Z","published":"2022-05-31T13:18:51Z","title":"Concept-level Debugging of Part-Prototype Networks","summary":"  Part-prototype Networks (ProtoPNets) are concept-based classifiers designed\nto achieve the same performance as black-box models without compromising\ntransparency. ProtoPNets compute predictions based on similarity to\nclass-specific part-prototypes learned to recognize parts of training examples,\nmaking it easy to faithfully determine what examples are responsible for any\ntarget prediction and why. However, like other models, they are prone to\npicking up confounders and shortcuts from the data, thus suffering from\ncompromised prediction accuracy and limited generalization. We propose\nProtoPDebug, an effective concept-level debugger for ProtoPNets in which a\nhuman supervisor, guided by the model's explanations, supplies feedback in the\nform of what part-prototypes must be forgotten or kept, and the model is\nfine-tuned to align with this supervision. Our experimental evaluation shows\nthat ProtoPDebug outperforms state-of-the-art debuggers for a fraction of the\nannotation cost. An online experiment with laypeople confirms the simplicity of\nthe feedback requested to the users and the effectiveness of the collected\nfeedback for learning confounder-free part-prototypes. ProtoPDebug is a\npromising tool for trustworthy interactive learning in critical applications,\nas suggested by a preliminary evaluation on a medical decision making task.\n","authors":["Andrea Bontempelli","Stefano Teso","Katya Tentori","Fausto Giunchiglia","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2205.15769v2.pdf","comment":"Accepted for publication at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.07502v2","updated":"2023-01-23T14:28:15Z","published":"2023-01-16T11:08:03Z","title":"Multimodal Side-Tuning for Document Classification","summary":"  In this paper, we propose to exploit the side-tuning framework for multimodal\ndocument classification. Side-tuning is a methodology for network adaptation\nrecently introduced to solve some of the problems related to previous\napproaches. Thanks to this technique it is actually possible to overcome model\nrigidity and catastrophic forgetting of transfer learning by fine-tuning. The\nproposed solution uses off-the-shelf deep learning architectures leveraging the\nside-tuning framework to combine a base model with a tandem of two side\nnetworks. We show that side-tuning can be successfully employed also when\ndifferent data sources are considered, e.g. text and images in document\nclassification. The experimental results show that this approach pushes further\nthe limit for document classification accuracy with respect to the state of the\nart.\n","authors":["Stefano Pio Zingaro","Giuseppe Lisanti","Maurizio Gabbrielli"],"pdf_url":"https://arxiv.org/pdf/2301.07502v2.pdf","comment":"2020 25th International Conference on Pattern Recognition (ICPR)"},{"id":"http://arxiv.org/abs/2204.12965v4","updated":"2023-01-23T14:25:58Z","published":"2022-04-27T14:25:07Z","title":"Particle algorithms for maximum likelihood training of latent variable\n  models","summary":"  (Neal and Hinton, 1998) recast maximum likelihood estimation of any given\nlatent variable model as the minimization of a free energy functional $F$, and\nthe EM algorithm as coordinate descent applied to $F$. Here, we explore\nalternative ways to optimize the functional. In particular, we identify various\ngradient flows associated with $F$ and show that their limits coincide with\n$F$'s stationary points. By discretizing the flows, we obtain practical\nparticle-based algorithms for maximum likelihood estimation in broad classes of\nlatent variable models. The novel algorithms scale to high-dimensional settings\nand perform well in numerical experiments.\n","authors":["Juan Kuntz","Jen Ning Lim","Adam M. Johansen"],"pdf_url":"https://arxiv.org/pdf/2204.12965v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02596v3","updated":"2023-01-23T14:25:32Z","published":"2022-01-07T18:39:33Z","title":"Explainable deep learning for insights in El Niño and river flows","summary":"  The El Ni\\~no Southern Oscillation (ENSO) is a semi-periodic fluctuation in\nsea surface temperature (SST) over the tropical central and eastern Pacific\nOcean that influences interannual variability in regional hydrology across the\nworld through long-range dependence or teleconnections. Recent research has\ndemonstrated the value of Deep Learning (DL) methods for improving ENSO\nprediction as well as Complex Networks (CN) for understanding teleconnections.\nHowever, gaps in predictive understanding of ENSO-driven river flows include\nthe black box nature of DL, the use of simple ENSO indices to describe a\ncomplex phenomenon and translating DL-based ENSO predictions to river flow\npredictions. Here we show that eXplainable DL (XDL) methods, based on saliency\nmaps, can extract interpretable predictive information contained in global SST\nand discover SST information regions and dependence structures relevant for\nriver flows which, in tandem with climate network constructions, enable\nimproved predictive understanding. Our results reveal additional information\ncontent in global SST beyond ENSO indices, develop understanding of how SSTs\ninfluence river flows, and generate improved river flow prediction, including\nuncertainty estimation. Observations, reanalysis data, and earth system model\nsimulations are used to demonstrate the value of the XDL-CN based methods for\nfuture interannual and decadal scale climate projections.\n","authors":["Yumin Liu","Kate Duffy","Jennifer G. Dy","Auroop R. Ganguly"],"pdf_url":"https://arxiv.org/pdf/2201.02596v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09454v1","updated":"2023-01-23T14:24:35Z","published":"2023-01-23T14:24:35Z","title":"Modeling Non-deterministic Human Behaviors in Discrete Food Choices","summary":"  We establish a non-deterministic model that predicts a user's food\npreferences from their demographic information. Our simulator is based on\nNHANES dataset and domain expert knowledge in the form of established\nbehavioral studies. Our model can be used to generate an arbitrary amount of\nsynthetic datapoints that are similar in distribution to the original dataset\nand align with behavioral science expectations. Such a simulator can be used in\na variety of machine learning tasks and especially in applications requiring\nhuman behavior prediction.\n","authors":["Andrew Starnes","Anton Dereventsov","E. Susanne Blazek","Folasade Phillips"],"pdf_url":"https://arxiv.org/pdf/2301.09454v1.pdf","comment":"6 pages, 4 figures, published in 2022 IEEE International Conference\n  on Data Mining Workshops (ICDMW)"},{"id":"http://arxiv.org/abs/2301.09451v1","updated":"2023-01-23T14:20:01Z","published":"2023-01-23T14:20:01Z","title":"A Simple Recipe for Competitive Low-compute Self supervised Vision\n  Models","summary":"  Self-supervised methods in vision have been mostly focused on large\narchitectures as they seem to suffer from a significant performance drop for\nsmaller architectures. In this paper, we propose a simple self-supervised\ndistillation technique that can train high performance low-compute neural\nnetworks. Our main insight is that existing joint-embedding based SSL methods\ncan be repurposed for knowledge distillation from a large self-supervised\nteacher to a small student model. Thus, we call our method Replace one Branch\n(RoB) as it simply replaces one branch of the joint-embedding training with a\nlarge teacher model. RoB is widely applicable to a number of architectures such\nas small ResNets, MobileNets and ViT, and pretrained models such as DINO, SwAV\nor iBOT. When pretraining on the ImageNet dataset, RoB yields models that\ncompete with supervised knowledge distillation. When applied to MSN, RoB\nproduces students with strong semi-supervised capabilities. Finally, our best\nViT-Tiny models improve over prior SSL state-of-the-art on ImageNet by $2.3\\%$\nand are on par or better than a supervised distilled DeiT on five downstream\ntransfer tasks (iNaturalist, CIFAR, Clevr/Count, Clevr/Dist and Places). We\nhope RoB enables practical self-supervision at smaller scale.\n","authors":["Quentin Duval","Ishan Misra","Nicolas Ballas"],"pdf_url":"https://arxiv.org/pdf/2301.09451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00974v2","updated":"2023-01-23T13:49:16Z","published":"2022-10-03T14:42:48Z","title":"Dealing with Unknown Variances in Best-Arm Identification","summary":"  The problem of identifying the best arm among a collection of items having\nGaussian rewards distribution is well understood when the variances are known.\nDespite its practical relevance for many applications, few works studied it for\nunknown variances. In this paper we introduce and analyze two approaches to\ndeal with unknown variances, either by plugging in the empirical variance or by\nadapting the transportation costs. In order to calibrate our two stopping\nrules, we derive new time-uniform concentration inequalities, which are of\nindependent interest. Then, we illustrate the theoretical and empirical\nperformances of our two sampling rule wrappers on Track-and-Stop and on a Top\nTwo algorithm. Moreover, by quantifying the impact on the sample complexity of\nnot knowing the variances, we reveal that it is rather small.\n","authors":["Marc Jourdan","Rémy Degenne","Emilie Kaufmann"],"pdf_url":"https://arxiv.org/pdf/2210.00974v2.pdf","comment":"73 pages, 5 figures, 3 tables. To be published in the 34th\n  International Conference on Algorithmic Learning Theory, Singapore, 2023"},{"id":"http://arxiv.org/abs/2208.03066v2","updated":"2023-01-23T13:34:15Z","published":"2022-08-05T09:51:18Z","title":"Tailoring to the Tails: Risk Measures for Fine-Grained Tail Sensitivity","summary":"  Expected risk minimization (ERM) is at the core of many machine learning\nsystems. This means that the risk inherent in a loss distribution is summarized\nusing a single number - its average. In this paper, we propose a general\napproach to construct risk measures which exhibit a desired tail sensitivity\nand may replace the expectation operator in ERM. Our method relies on the\nspecification of a reference distribution with a desired tail behaviour, which\nis in a one-to-one correspondence to a coherent upper probability. Any risk\nmeasure, which is compatible with this upper probability, displays a tail\nsensitivity which is finely tuned to the reference distribution. As a concrete\nexample, we focus on divergence risk measures based on f-divergence ambiguity\nsets, which are a widespread tool used to foster distributional robustness of\nmachine learning systems. For instance, we show how ambiguity sets based on the\nKullback-Leibler divergence are intricately tied to the class of subexponential\nrandom variables. We elaborate the connection of divergence risk measures and\nrearrangement invariant Banach norms.\n","authors":["Christian Fröhlich","Robert C. Williamson"],"pdf_url":"https://arxiv.org/pdf/2208.03066v2.pdf","comment":"Made multiple minor edits"},{"id":"http://arxiv.org/abs/2301.09428v1","updated":"2023-01-23T13:30:40Z","published":"2023-01-23T13:30:40Z","title":"Explaining the effects of non-convergent sampling in the training of\n  Energy-Based Models","summary":"  In this paper, we quantify the impact of using non-convergent Markov chains\nto train Energy-Based models (EBMs). In particular, we show analytically that\nEBMs trained with non-persistent short runs to estimate the gradient can\nperfectly reproduce a set of empirical statistics of the data, not at the level\nof the equilibrium measure, but through a precise dynamical process. Our\nresults provide a first-principles explanation for the observations of recent\nworks proposing the strategy of using short runs starting from random initial\nconditions as an efficient way to generate high-quality samples in EBMs, and\nlay the groundwork for using EBMs as diffusion models. After explaining this\neffect in generic EBMs, we analyze two solvable models in which the effect of\nthe non-convergent sampling in the trained parameters can be described in\ndetail. Finally, we test these predictions numerically on the Boltzmann\nmachine.\n","authors":["Elisabeth Agoritsas","Giovanni Catania","Aurélien Decelle","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2301.09428v1.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2203.01228v2","updated":"2023-01-23T13:07:40Z","published":"2022-03-02T16:45:19Z","title":"Estimating average causal effects from patient trajectories","summary":"  In medical practice, treatments are selected based on the expected causal\neffects on patient outcomes. Here, the gold standard for estimating causal\neffects are randomized controlled trials; however, such trials are costly and\nsometimes even unethical. Instead, medical practice is increasingly interested\nin estimating causal effects among patient (sub)groups from electronic health\nrecords, that is, observational data. In this paper, we aim at estimating the\naverage causal effect (ACE) from observational data (patient trajectories) that\nare collected over time. For this, we propose DeepACE: an end-to-end deep\nlearning model. DeepACE leverages the iterative G-computation formula to adjust\nfor the bias induced by time-varying confounders. Moreover, we develop a novel\nsequential targeting procedure which ensures that DeepACE has favorable\ntheoretical properties, i.e., is doubly robust and asymptotically efficient. To\nthe best of our knowledge, this is the first work that proposes an end-to-end\ndeep learning model tailored for estimating time-varying ACEs. We compare\nDeepACE in an extensive number of experiments, confirming that it achieves\nstate-of-the-art performance. We further provide a case study for patients\nsuffering from low back pain to demonstrate that DeepACE generates important\nand meaningful findings for clinical practice. Our work enables practitioners\nto develop effective treatment recommendations based on population effects.\n","authors":["Dennis Frauen","Tobias Hatt","Valentyn Melnychuk","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2203.01228v2.pdf","comment":"Accepted at AAAI 2023"},{"id":"http://arxiv.org/abs/2211.07816v4","updated":"2023-01-23T12:49:42Z","published":"2022-11-15T00:40:55Z","title":"Quantifying the Impact of Label Noise on Federated Learning","summary":"  Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets. While existing studies focus on FL algorithm development to tackle\ndata heterogeneity across clients, the important issue of data quality (e.g.,\nlabel noise) in FL is overlooked. This paper aims to fill this gap by providing\na quantitative study on the impact of label noise on FL. We derive an upper\nbound for the generalization error that is linear in the clients' label noise\nlevel. Then we conduct experiments on MNIST and CIFAR-10 datasets using various\nFL algorithms. Our empirical results show that the global model accuracy\nlinearly decreases as the noise level increases, which is consistent with our\ntheoretical analysis. We further find that label noise slows down the\nconvergence of FL training, and the global model tends to overfit when the\nnoise level is high.\n","authors":["Shuqi Ke","Chao Huang","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2211.07816v4.pdf","comment":"Accepted by The AAAI 2023 Workshop on Representation Learning for\n  Responsible Human-Centric AI"},{"id":"http://arxiv.org/abs/2206.12832v3","updated":"2023-01-23T12:16:23Z","published":"2022-06-26T09:42:39Z","title":"Prediction Errors for Penalized Regressions based on Generalized\n  Approximate Message Passing","summary":"  We discuss the prediction accuracy of assumed statistical models in terms of\nprediction errors for the generalized linear model and penalized maximum\nlikelihood methods. We derive the forms of estimators for the prediction\nerrors, such as $C_p$ criterion, information criteria, and leave-one-out cross\nvalidation (LOOCV) error, using the generalized approximate message passing\n(GAMP) algorithm and replica method. These estimators coincide with each other\nwhen the number of model parameters is sufficiently small; however, there is a\ndiscrepancy between them in particular in the parameter region where the number\nof model parameters is larger than the data dimension. In this paper, we review\nthe prediction errors and corresponding estimators, and discuss their\ndifferences. In the framework of GAMP, we show that the information criteria\ncan be expressed by using the variance of the estimates. Further, we\ndemonstrate how to approach LOOCV error from the information criteria by\nutilizing the expression provided by GAMP.\n","authors":["Ayaka Sakata"],"pdf_url":"https://arxiv.org/pdf/2206.12832v3.pdf","comment":"73 pages, 13 figures, accepted Journal of Physics A"},{"id":"http://arxiv.org/abs/2301.09387v1","updated":"2023-01-23T12:12:33Z","published":"2023-01-23T12:12:33Z","title":"LSTM and CNN application for core-collapse supernova search in\n  gravitational wave real data","summary":"  $Context.$ Core-collapse supernovae (CCSNe) are expected to emit\ngravitational wave signals that could be detected by current and future\ngeneration interferometers within the Milky Way and nearby galaxies. The\nstochastic nature of the signal arising from CCSNe requires alternative\ndetection methods to matched filtering. $Aims.$ We aim to show the potential of\nmachine learning (ML) for multi-label classification of different CCSNe\nsimulated signals and noise transients using real data. We compared the\nperformance of 1D and 2D convolutional neural networks (CNNs) on single and\nmultiple detector data. For the first time, we tested multi-label\nclassification also with long short-term memory (LSTM) networks. $Methods.$ We\napplied a search and classification procedure for CCSNe signals, using an event\ntrigger generator, the Wavelet Detection Filter (WDF), coupled with ML. We used\ntime series and time-frequency representations of the data as inputs to the ML\nmodels. To compute classification accuracies, we simultaneously injected, at\ndetectable distance of 1\\,kpc, CCSN waveforms, obtained from recent\nhydrodynamical simulations of neutrino-driven core-collapse, onto\ninterferometer noise from the O2 LIGO and Virgo science run. $Results.$ We\ncompared the performance of the three models on single detector data. We then\nmerged the output of the models for single detector classification of noise and\nastrophysical transients, obtaining overall accuracies for LIGO ($\\sim99\\%$)\nand ($\\sim80\\%$) for Virgo. We extended our analysis to the multi-detector case\nusing triggers coincident among the three ITFs and achieved an accuracy of\n$\\sim98\\%$.\n","authors":["Alberto Iess","Elena Cuoco","Filip Morawski","Constantina Nicolaou","Ofer Lahav"],"pdf_url":"https://arxiv.org/pdf/2301.09387v1.pdf","comment":"10 pages, 13 figures. Accepted by A&A journal"},{"id":"http://arxiv.org/abs/2211.13960v5","updated":"2023-01-23T11:57:41Z","published":"2022-11-25T09:08:11Z","title":"The European AI Liability Directives -- Critique of a Half-Hearted\n  Approach and Lessons for the Future","summary":"  As ChatGPT et al. conquer the world, the optimal liability framework for AI\nsystems remains an unsolved problem across the globe. In a much-anticipated\nmove, the European Commission advanced two proposals outlining the European\napproach to AI liability in September 2022: a novel AI Liability Directive and\na revision of the Product Liability Directive. They constitute the final\ncornerstone of EU AI regulation. Crucially, the liability proposals and the EU\nAI Act are inherently intertwined: the latter does not contain any individual\nrights of affected persons, and the former lack specific, substantive rules on\nAI development and deployment. Taken together, these acts may well trigger a\nBrussels Effect in AI regulation, with significant consequences for the US and\nbeyond.\n  This paper makes three novel contributions. First, it examines in detail the\nCommission proposals and shows that, while making steps in the right direction,\nthey ultimately represent a half-hearted approach: if enacted as foreseen, AI\nliability in the EU will primarily rest on disclosure of evidence mechanisms\nand a set of narrowly defined presumptions concerning fault, defectiveness and\ncausality. Hence, second, the article suggests amendments, which are collected\nin an Annex at the end of the paper. Third, based on an analysis of the key\nrisks AI poses, the final part of the paper maps out a road for the future of\nAI liability and regulation, in the EU and beyond. This includes: a\ncomprehensive framework for AI liability; provisions to support innovation; an\nextension to non-discrimination/algorithmic fairness, as well as explainable\nAI; and sustainability. I propose to jump-start sustainable AI regulation via\nsustainability impact assessments in the AI Act and sustainable design defects\nin the liability regime. In this way, the law may help spur not only fair AI\nand XAI, but potentially also sustainable AI (SAI).\n","authors":["Philipp Hacker"],"pdf_url":"https://arxiv.org/pdf/2211.13960v5.pdf","comment":"under peer-review; contains 3 Tables"},{"id":"http://arxiv.org/abs/2301.09381v1","updated":"2023-01-23T11:50:57Z","published":"2023-01-23T11:50:57Z","title":"A Structural Approach to the Design of Domain Specific Neural Network\n  Architectures","summary":"  This is a master's thesis concerning the theoretical ideas of geometric deep\nlearning. Geometric deep learning aims to provide a structured characterization\nof neural network architectures, specifically focused on the ideas of\ninvariance and equivariance of data with respect to given transformations.\n  This thesis aims to provide a theoretical evaluation of geometric deep\nlearning, compiling theoretical results that characterize the properties of\ninvariant neural networks with respect to learning performance.\n","authors":["Gerrit Nolte"],"pdf_url":"https://arxiv.org/pdf/2301.09381v1.pdf","comment":"94 pages and 16 Figures Upload of my Master's thesis. Not peer\n  reviewed and potentially contains errors"},{"id":"http://arxiv.org/abs/2109.12679v3","updated":"2023-01-23T11:46:44Z","published":"2021-09-26T19:04:57Z","title":"Be More Active! Understanding the Differences between Mean and Sampled\n  Representations of Variational Autoencoders","summary":"  The ability of Variational Autoencoders to learn disentangled representations\nhas made them appealing for practical applications. However, their mean\nrepresentations, which are generally used for downstream tasks, have recently\nbeen shown to be more correlated than their sampled counterpart, on which\ndisentanglement is usually measured. In this paper, we refine this observation\nthrough the lens of selective posterior collapse, which states that only a\nsubset of the learned representations, the active variables, is encoding useful\ninformation while the rest (the passive variables) is discarded. We first\nextend the existing definition to multiple data examples and show that active\nvariables are equally disentangled in mean and sampled representations. Based\non this extension and the pre-trained models from disentanglement lib, we then\nisolate the passive variables and show that they are responsible for the\ndiscrepancies between mean and sampled representations. Specifically, passive\nvariables exhibit high correlation scores with other variables in mean\nrepresentations while being fully uncorrelated in sampled ones. We thus\nconclude that despite what their higher correlation might suggest, mean\nrepresentations are still good candidates for downstream tasks applications.\nHowever, it may be beneficial to remove their passive variables, especially\nwhen used with models sensitive to correlated features.\n","authors":["Lisa Bonheme","Marek Grzes"],"pdf_url":"https://arxiv.org/pdf/2109.12679v3.pdf","comment":"the main paper of 20 pages plus an appendix; 29 pages in total"},{"id":"http://arxiv.org/abs/2103.14675v6","updated":"2023-01-23T11:17:09Z","published":"2021-03-26T18:23:29Z","title":"Synthesis of Compositional Animations from Textual Descriptions","summary":"  \"How can we animate 3D-characters from a movie script or move robots by\nsimply telling them what we would like them to do?\" \"How unstructured and\ncomplex can we make a sentence and still generate plausible movements from it?\"\nThese are questions that need to be answered in the long-run, as the field is\nstill in its infancy. Inspired by these problems, we present a new technique\nfor generating compositional actions, which handles complex input sentences.\nOur output is a 3D pose sequence depicting the actions in the input sentence.\nWe propose a hierarchical two-stream sequential model to explore a finer\njoint-level mapping between natural language sentences and 3D pose sequences\ncorresponding to the given motion. We learn two manifold representations of the\nmotion -- one each for the upper body and the lower body movements. Our model\ncan generate plausible pose sequences for short sentences describing single\nactions as well as long compositional sentences describing multiple sequential\nand superimposed actions. We evaluate our proposed model on the publicly\navailable KIT Motion-Language Dataset containing 3D pose data with\nhuman-annotated sentences. Experimental results show that our model advances\nthe state-of-the-art on text-based motion synthesis in objective evaluations by\na margin of 50%. Qualitative evaluations based on a user study indicate that\nour synthesized motions are perceived to be the closest to the ground-truth\nmotion captures for both short and compositional sentences.\n","authors":["Anindita Ghosh","Noshaba Cheema","Cennet Oguz","Christian Theobalt","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2103.14675v6.pdf","comment":"13 pages, 6 figures, 3 tables. Proceedings of the IEEE/CVF\n  International Conference on Computer Vision (ICCV), 2021, pp. 1396-1406"},{"id":"http://arxiv.org/abs/2301.09362v1","updated":"2023-01-23T10:58:45Z","published":"2023-01-23T10:58:45Z","title":"A Comprehensive Survey on Heart Sound Analysis in the Deep Learning Era","summary":"  Heart sound auscultation has been demonstrated to be beneficial in clinical\nusage for early screening of cardiovascular diseases. Due to the high\nrequirement of well-trained professionals for auscultation, automatic\nauscultation benefiting from signal processing and machine learning can help\nauxiliary diagnosis and reduce the burdens of training professional clinicians.\nNevertheless, classic machine learning is limited to performance improvement in\nthe era of big data. Deep learning has achieved better performance than classic\nmachine learning in many research fields, as it employs more complex model\narchitectures with stronger capability of extracting effective representations.\nDeep learning has been successfully applied to heart sound analysis in the past\nyears. As most review works about heart sound analysis were given before 2017,\nthe present survey is the first to work on a comprehensive overview to\nsummarise papers on heart sound analysis with deep learning in the past six\nyears 2017--2022. We introduce both classic machine learning and deep learning\nfor comparison, and further offer insights about the advances and future\nresearch directions in deep learning for heart sound analysis.\n","authors":["Zhao Ren","Yi Chang","Thanh Tam Nguyen","Yang Tan","Kun Qian","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2301.09362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09361v1","updated":"2023-01-23T10:58:18Z","published":"2023-01-23T10:58:18Z","title":"SMDDH: Singleton Mention detection using Deep Learning in Hindi Text","summary":"  Mention detection is an important component of coreference resolution system,\nwhere mentions such as name, nominal, and pronominals are identified. These\nmentions can be purely coreferential mentions or singleton mentions\n(non-coreferential mentions). Coreferential mentions are those mentions in a\ntext that refer to the same entities in a real world. Whereas, singleton\nmentions are mentioned only once in the text and do not participate in the\ncoreference as they are not mentioned again in the following text. Filtering of\nthese singleton mentions can substantially improve the performance of a\ncoreference resolution process. This paper proposes a singleton mention\ndetection module based on a fully connected network and a Convolutional neural\nnetwork for Hindi text. This model utilizes a few hand-crafted features and\ncontext information, and word embedding for words. The coreference annotated\nHindi dataset comprising of 3.6K sentences, and 78K tokens are used for the\ntask. In terms of Precision, Recall, and F-measure, the experimental findings\nobtained are excellent.\n","authors":["Kusum Lata","Pardeep Singh","Kamlesh Dutta"],"pdf_url":"https://arxiv.org/pdf/2301.09361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09357v1","updated":"2023-01-23T10:56:12Z","published":"2023-01-23T10:56:12Z","title":"Accelerating Fair Federated Learning: Adaptive Federated Adam","summary":"  Federated learning is a distributed and privacy-preserving approach to train\na statistical model collaboratively from decentralized data of different\nparties. However, when datasets of participants are not independent and\nidentically distributed (non-IID), models trained by naive federated algorithms\nmay be biased towards certain participants, and model performance across\nparticipants is non-uniform. This is known as the fairness problem in federated\nlearning. In this paper, we formulate fairness-controlled federated learning as\na dynamical multi-objective optimization problem to ensure fair performance\nacross all participants. To solve the problem efficiently, we study the\nconvergence and bias of Adam as the server optimizer in federated learning, and\npropose Adaptive Federated Adam (AdaFedAdam) to accelerate fair federated\nlearning with alleviated bias. We validated the effectiveness, Pareto\noptimality and robustness of AdaFedAdam in numerical experiments and show that\nAdaFedAdam outperforms existing algorithms, providing better convergence and\nfairness properties of the federated scheme.\n","authors":["Li Ju","Tianru Zhang","Salman Toor","Andreas Hellander"],"pdf_url":"https://arxiv.org/pdf/2301.09357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03551v3","updated":"2023-01-23T10:55:33Z","published":"2022-12-07T10:01:44Z","title":"Talking About Large Language Models","summary":"  Thanks to rapid progress in artificial intelligence, we have entered an era\nwhen technology and philosophy intersect in interesting ways. Sitting squarely\nat the centre of this intersection are large language models (LLMs). The more\nadept LLMs become at mimicking human language, the more vulnerable we become to\nanthropomorphism, to seeing the systems in which they are embedded as more\nhuman-like than they really are. This trend is amplified by the natural\ntendency to use philosophically loaded terms, such as \"knows\", \"believes\", and\n\"thinks\", when describing these systems. To mitigate this trend, this paper\nadvocates the practice of repeatedly stepping back to remind ourselves of how\nLLMs, and the systems of which they form a part, actually work. The hope is\nthat increased scientific precision will encourage more philosophical nuance in\nthe discourse around artificial intelligence, both within the field and in the\npublic sphere.\n","authors":["Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2212.03551v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.12235v3","updated":"2023-01-23T10:47:18Z","published":"2022-03-23T07:07:11Z","title":"Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions","summary":"  The syntactic categories of categorial grammar formalisms are structured\nunits made of smaller, indivisible primitives, bound together by the underlying\ngrammar's category formation rules. In the trending approach of constructive\nsupertagging, neural models are increasingly made aware of the internal\ncategory structure, which in turn enables them to more reliably predict rare\nand out-of-vocabulary categories, with significant implications for grammars\npreviously deemed too complex to find practical use. In this work, we revisit\nconstructive supertagging from a graph-theoretic perspective, and propose a\nframework based on heterogeneous dynamic graph convolutions aimed at exploiting\nthe distinctive structure of a supertagger's output space. We test our approach\non a number of categorial grammar datasets spanning different languages and\ngrammar formalisms, achieving substantial improvements over previous state of\nthe art scores. Code will be made available at\nhttps://github.com/konstantinosKokos/dynamic-graph-supertagging\n","authors":["Konstantinos Kogkalidis","Michael Moortgat"],"pdf_url":"https://arxiv.org/pdf/2203.12235v3.pdf","comment":"8 pages plus references, unpublished preprint v2: fixed small typos,\n  added appendix with a visualization of the decoding process; v3: improved\n  presentation, improved the decoding figure"},{"id":"http://arxiv.org/abs/2301.09350v1","updated":"2023-01-23T10:33:22Z","published":"2023-01-23T10:33:22Z","title":"Large-scale fine-grained semantic indexing of biomedical literature\n  based on weakly-supervised deep learning","summary":"  Semantic indexing of biomedical literature is usually done at the level of\nMeSH descriptors, representing topics of interest for the biomedical community.\nSeveral related but distinct biomedical concepts are often grouped together in\na single coarse-grained descriptor and are treated as a single topic for\nsemantic indexing. This study proposes a new method for the automated\nrefinement of subject annotations at the level of concepts, investigating deep\nlearning approaches. Lacking labelled data for this task, our method relies on\nweak supervision based on concept occurrence in the abstract of an article. The\nproposed approach is evaluated on an extended large-scale retrospective\nscenario, taking advantage of concepts that eventually become MeSH descriptors,\nfor which annotations become available in MEDLINE/PubMed. The results suggest\nthat concept occurrence is a strong heuristic for automated subject annotation\nrefinement and can be further enhanced when combined with dictionary-based\nheuristics. In addition, such heuristics can be useful as weak supervision for\ndeveloping deep learning models that can achieve further improvement in some\ncases.\n","authors":["Anastasios Nentidis","Thomas Chatzopoulos","Anastasia Krithara","Grigorios Tsoumakas","Georgios Paliouras"],"pdf_url":"https://arxiv.org/pdf/2301.09350v1.pdf","comment":"48 pages, 5 figures, 9 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2204.09405v2","updated":"2023-01-23T10:06:00Z","published":"2022-04-20T11:55:17Z","title":"Continuous-time identification of dynamic state-space models by deep\n  subspace encoding","summary":"  Continuous-time (CT) modeling has proven to provide improved sample\nefficiency and interpretability in learning the dynamical behavior of physical\nsystems compared to discrete-time (DT) models. However, even with numerous\nrecent developments, the CT nonlinear state-space (NL-SS) model identification\nproblem remains to be solved in full, considering common experimental aspects\nsuch as the presence of external inputs, measurement noise, latent states, and\ngeneral robustness. This paper presents a novel estimation method that\naddresses all these aspects and that can obtain state-of-the-art results on\nmultiple benchmarks with compact fully connected neural networks capturing the\nCT dynamics. The proposed estimation method called the subspace encoder\napproach (SUBNET) ascertains these results by efficiently approximating the\ncomplete simulation loss by evaluating short simulations on subsections of the\ndata, by using an encoder function to estimate the initial state for each\nsubsection and a novel state-derivative normalization to ensure stability and\ngood numerical conditioning of the training process. We prove that the use of\nsubsections increases cost function smoothness together with the necessary\nrequirements for the existence of the encoder function and we show that the\nproposed state-derivative normalization is essential for reliable estimation of\nCT NL-SS models.\n","authors":["Gerben I. Beintema","Maarten Schoukens","Roland Tóth"],"pdf_url":"https://arxiv.org/pdf/2204.09405v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2206.02660v4","updated":"2023-01-23T10:03:23Z","published":"2022-06-06T14:57:25Z","title":"Pseudo-Hamiltonian Neural Networks with State-Dependent External Forces","summary":"  Hybrid machine learning based on Hamiltonian formulations has recently been\nsuccessfully demonstrated for simple mechanical systems, both energy conserving\nand not energy conserving. We introduce a pseudo-Hamiltonian formulation that\nis a generalization of the Hamiltonian formulation via the port-Hamiltonian\nformulation, and show that pseudo-Hamiltonian neural network models can be used\nto learn external forces acting on a system. We argue that this property is\nparticularly useful when the external forces are state dependent, in which case\nit is the pseudo-Hamiltonian structure that facilitates the separation of\ninternal and external forces. Numerical results are provided for a forced and\ndamped mass-spring system and a tank system of higher complexity, and a\nsymmetric fourth-order integration scheme is introduced for improved training\non sparse and noisy data.\n","authors":["Sølve Eidnes","Alexander J. Stasik","Camilla Sterud","Eivind Bøhn","Signe Riemer-Sørensen"],"pdf_url":"https://arxiv.org/pdf/2206.02660v4.pdf","comment":"23 pages, 13 figures; v4: slight title change, expanded on\n  methodology for more clarity, updated plots"},{"id":"http://arxiv.org/abs/2301.07568v2","updated":"2023-01-23T09:54:01Z","published":"2023-01-18T14:39:34Z","title":"Beating the Best: Improving on AlphaFold2 at Protein Structure\n  Prediction","summary":"  The goal of Protein Structure Prediction (PSP) problem is to predict a\nprotein's 3D structure (confirmation) from its amino acid sequence. The problem\nhas been a 'holy grail' of science since the Noble prize-winning work of\nAnfinsen demonstrated that protein conformation was determined by sequence. A\nrecent and important step towards this goal was the development of AlphaFold2,\ncurrently the best PSP method. AlphaFold2 is probably the highest profile\napplication of AI to science. Both AlphaFold2 and RoseTTAFold (another\nimpressive PSP method) have been published and placed in the public domain\n(code & models). Stacking is a form of ensemble machine learning ML in which\nmultiple baseline models are first learnt, then a meta-model is learnt using\nthe outputs of the baseline level model to form a model that outperforms the\nbase models. Stacking has been successful in many applications. We developed\nthe ARStack PSP method by stacking AlphaFold2 and RoseTTAFold. ARStack\nsignificantly outperforms AlphaFold2. We rigorously demonstrate this using two\nsets of non-homologous proteins, and a test set of protein structures published\nafter that of AlphaFold2 and RoseTTAFold. As more high quality prediction\nmethods are published it is likely that ensemble methods will increasingly\noutperform any single method.\n","authors":["Abbi Abdel-Rehim","Oghenejokpeme Orhobor","Hang Lou","Hao Ni","Ross D. King"],"pdf_url":"https://arxiv.org/pdf/2301.07568v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2301.09322v1","updated":"2023-01-23T08:46:17Z","published":"2023-01-23T08:46:17Z","title":"Deep Learning-Based Assessment of Cerebral Microbleeds in COVID-19","summary":"  Cerebral Microbleeds (CMBs), typically captured as hypointensities from\nsusceptibility-weighted imaging (SWI), are particularly important for the study\nof dementia, cerebrovascular disease, and normal aging. Recent studies on\nCOVID-19 have shown an increase in CMBs of coronavirus cases. Automatic\ndetection of CMBs is challenging due to the small size and amount of CMBs\nmaking the classes highly imbalanced, lack of publicly available annotated\ndata, and similarity with CMB mimics such as calcifications, irons, and veins.\nHence, the existing deep learning methods are mostly trained on very limited\nresearch data and fail to generalize to unseen data with high variability and\ncannot be used in clinical setups. To this end, we propose an efficient 3D deep\nlearning framework that is actively trained on multi-domain data. Two public\ndatasets assigned for normal aging, stroke, and Alzheimer's disease analysis as\nwell as an in-house dataset for COVID-19 assessment are used to train and\nevaluate the models. The obtained results show that the proposed method is\nrobust to low-resolution images and achieves 78% recall and 80% precision on\nthe entire test set with an average false positive of 1.6 per scan.\n","authors":["Neus Rodeja Ferrer","Malini Vendela Sagar","Kiril Vadimovic Klein","Christina Kruuse","Mads Nielsen","Mostafa Mehdipour Ghazi"],"pdf_url":"https://arxiv.org/pdf/2301.09322v1.pdf","comment":"International Symposium on Biomedical Imaging (ISBI) 2023"},{"id":"http://arxiv.org/abs/2301.09320v1","updated":"2023-01-23T08:41:46Z","published":"2023-01-23T08:41:46Z","title":"A Framework for Evaluating the Impact of Food Security Scenarios","summary":"  This study proposes an approach for predicting the impacts of scenarios on\nfood security and demonstrates its application in a case study. The approach\ninvolves two main steps: (1) scenario definition, in which the end user\nspecifies the assumptions and impacts of the scenario using a scenario\ntemplate, and (2) scenario evaluation, in which a Vector Autoregression (VAR)\nmodel is used in combination with Monte Carlo simulation to generate\npredictions for the impacts of the scenario based on the defined assumptions\nand impacts. The case study is based on a proprietary time series food security\ndatabase created using data from the Food and Agriculture Organization of the\nUnited Nations (FAOSTAT), the World Bank, and the United States Department of\nAgriculture (USDA). The database contains a wide range of data on various\nindicators of food security, such as production, trade, consumption, prices,\navailability, access, and nutritional value. The results show that the proposed\napproach can be used to predict the potential impacts of scenarios on food\nsecurity and that the proprietary time series food security database can be\nused to support this approach. The study provides specific insights on how this\napproach can inform decision-making processes related to food security such as\nfood prices and availability in the case study region.\n","authors":["Rachid Belmeskine","Abed Benaichouche"],"pdf_url":"https://arxiv.org/pdf/2301.09320v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.02494v3","updated":"2023-01-23T08:35:28Z","published":"2023-01-06T13:12:59Z","title":"Adaptive Pattern Extraction Multi-Task Learning for Multi-Step\n  Conversion Estimations","summary":"  Multi-task learning (MTL) has been successfully used in many real-world\napplications, which aims to simultaneously solve multiple tasks with a single\nmodel. The general idea of multi-task learning is designing kinds of global\nparameter sharing mechanism and task-specific feature extractor to improve the\nperformance of all tasks. However, challenge still remains in balancing the\ntrade-off of various tasks since model performance is sensitive to the\nrelationships between them. Less correlated or even conflict tasks will\ndeteriorate the performance by introducing unhelpful or negative information.\nTherefore, it is important to efficiently exploit and learn fine-grained\nfeature representation corresponding to each task. In this paper, we propose an\nAdaptive Pattern Extraction Multi-task (APEM) framework, which is adaptive and\nflexible for large-scale industrial application. APEM is able to fully utilize\nthe feature information by learning the interactions between the input feature\nfields and extracted corresponding tasks-specific information. We first\nintroduce a DeepAuto Group Transformer module to automatically and efficiently\nenhance the feature expressivity with a modified set attention mechanism and a\nSqueeze-and-Excitation operation. Second, explicit Pattern Selector is\nintroduced to further enable selectively feature representation learning by\nadaptive task-indicator vectors. Empirical evaluations show that APEM\noutperforms the state-of-the-art MTL methods on public and real-world financial\nservices datasets. More importantly, we explore the online performance of APEM\nin a real industrial-level recommendation scenario.\n","authors":["Xuewen Tao","Mingming Ha","Xiaobo Guo","Qiongxu Ma","Hongwei Cheng","Wenfang Lin"],"pdf_url":"https://arxiv.org/pdf/2301.02494v3.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.09318v1","updated":"2023-01-23T08:35:00Z","published":"2023-01-23T08:35:00Z","title":"Toward Foundation Models for Earth Monitoring: Generalizable Deep\n  Learning Models for Natural Hazard Segmentation","summary":"  Climate change results in an increased probability of extreme weather events\nthat put societies and businesses at risk on a global scale. Therefore, near\nreal-time mapping of natural hazards is an emerging priority for the support of\nnatural disaster relief, risk management, and informing governmental policy\ndecisions. Recent methods to achieve near real-time mapping increasingly\nleverage deep learning (DL). However, DL-based approaches are designed for one\nspecific task in a single geographic region based on specific frequency bands\nof satellite data. Therefore, DL models used to map specific natural hazards\nstruggle with their generalization to other types of natural hazards in unseen\nregions. In this work, we propose a methodology to significantly improve the\ngeneralizability of DL natural hazards mappers based on pre-training on a\nsuitable pre-task. Without access to any data from the target domain, we\ndemonstrate this improved generalizability across four U-Net architectures for\nthe segmentation of unseen natural hazards. Importantly, our method is\ninvariant to geographic differences and differences in the type of frequency\nbands of satellite data. By leveraging characteristics of unlabeled images from\nthe target domain that are publicly available, our approach is able to further\nimprove the generalization behavior without fine-tuning. Thereby, our approach\nsupports the development of foundation models for earth monitoring with the\nobjective of directly segmenting unseen natural hazards across novel geographic\nregions given different sources of satellite imagery.\n","authors":["Johannes Jakubik","Michal Muszynski","Michael Vössing","Niklas Kühl","Thomas Brunschwiler"],"pdf_url":"https://arxiv.org/pdf/2301.09318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09317v1","updated":"2023-01-23T08:26:28Z","published":"2023-01-23T08:26:28Z","title":"A Survey on Actionable Knowledge","summary":"  Actionable Knowledge Discovery (AKD) is a crucial aspect of data mining that\nis gaining popularity and being applied in a wide range of domains. This is\nbecause AKD can extract valuable insights and information, also known as\nknowledge, from large datasets. The goal of this paper is to examine different\nresearch studies that focus on various domains and have different objectives.\nThe paper will review and discuss the methods used in these studies in detail.\nAKD is a process of identifying and extracting actionable insights from data,\nwhich can be used to make informed decisions and improve business outcomes. It\nis a powerful tool for uncovering patterns and trends in data that can be used\nfor various applications such as customer relationship management, marketing,\nand fraud detection. The research studies reviewed in this paper will explore\ndifferent techniques and approaches for AKD in different domains, such as\nhealthcare, finance, and telecommunications. The paper will provide a thorough\nanalysis of the current state of AKD in the field and will review the main\nmethods used by various research studies. Additionally, the paper will evaluate\nthe advantages and disadvantages of each method and will discuss any novel or\nnew solutions presented in the field. Overall, this paper aims to provide a\ncomprehensive overview of the methods and techniques used in AKD and the impact\nthey have on different domains.\n","authors":["Sayed Erfan Arefin"],"pdf_url":"https://arxiv.org/pdf/2301.09317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09312v1","updated":"2023-01-23T08:15:09Z","published":"2023-01-23T08:15:09Z","title":"Enabling Hard Constraints in Differentiable Neural Network and\n  Accelerator Co-Exploration","summary":"  Co-exploration of an optimal neural architecture and its hardware accelerator\nis an approach of rising interest which addresses the computational cost\nproblem, especially in low-profile systems. The large co-exploration space is\noften handled by adopting the idea of differentiable neural architecture\nsearch. However, despite the superior search efficiency of the differentiable\nco-exploration, it faces a critical challenge of not being able to\nsystematically satisfy hard constraints such as frame rate. To handle the hard\nconstraint problem of differentiable co-exploration, we propose HDX, which\nsearches for hard-constrained solutions without compromising the global design\nobjectives. By manipulating the gradients in the interest of the given hard\nconstraint, high-quality solutions satisfying the constraint can be obtained.\n","authors":["Deokki Hong","Kanghyun Choi","Hye Yoon Lee","Joonsang Yu","Noseong Park","Youngsok Kim","Jinho Lee"],"pdf_url":"https://arxiv.org/pdf/2301.09312v1.pdf","comment":"publisehd at DAC'22"},{"id":"http://arxiv.org/abs/2301.09308v1","updated":"2023-01-23T08:08:10Z","published":"2023-01-23T08:08:10Z","title":"On the Expressive Power of Geometric Graph Neural Networks","summary":"  The expressive power of Graph Neural Networks (GNNs) has been studied\nextensively through the Weisfeiler-Leman (WL) graph isomorphism test. However,\nstandard GNNs and the WL framework are inapplicable for geometric graphs\nembedded in Euclidean space, such as biomolecules, materials, and other\nphysical systems. In this work, we propose a geometric version of the WL test\n(GWL) for discriminating geometric graphs while respecting the underlying\nphysical symmetries: permutations, rotation, reflection, and translation. We\nuse GWL to characterise the expressive power of geometric GNNs that are\ninvariant or equivariant to physical symmetries in terms of distinguishing\ngeometric graphs. GWL unpacks how key design choices influence geometric GNN\nexpressivity: (1) Invariant layers have limited expressivity as they cannot\ndistinguish one-hop identical geometric graphs; (2) Equivariant layers\ndistinguish a larger class of graphs by propagating geometric information\nbeyond local neighbourhoods; (3) Higher order tensors and scalarisation enable\nmaximally powerful geometric GNNs; and (4) GWL's discrimination-based\nperspective is equivalent to universal approximation. Synthetic experiments\nsupplementing our results are available at\nhttps://github.com/chaitjo/geometric-gnn-dojo\n","authors":["Chaitanya K. Joshi","Cristian Bodnar","Simon V. Mathis","Taco Cohen","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2301.09308v1.pdf","comment":"NeurIPS 2022 Workshop on Symmetry and Geometry in Neural\n  Representations"},{"id":"http://arxiv.org/abs/2301.09305v1","updated":"2023-01-23T07:51:25Z","published":"2023-01-23T07:51:25Z","title":"Practical Adversarial Attacks Against AI-Driven Power Allocation in a\n  Distributed MIMO Network","summary":"  In distributed multiple-input multiple-output (D-MIMO) networks, power\ncontrol is crucial to optimize the spectral efficiencies of users and max-min\nfairness (MMF) power control is a commonly used strategy as it satisfies\nuniform quality-of-service to all users. The optimal solution of MMF power\ncontrol requires high complexity operations and hence deep neural network based\nartificial intelligence (AI) solutions are proposed to decrease the complexity.\nAlthough quite accurate models can be achieved by using AI, these models have\nsome intrinsic vulnerabilities against adversarial attacks where carefully\ncrafted perturbations are applied to the input of the AI model. In this work,\nwe show that threats against the target AI model which might be originated from\nmalicious users or radio units can substantially decrease the network\nperformance by applying a successful adversarial sample, even in the most\nconstrained circumstances. We also demonstrate that the risk associated with\nthese kinds of adversarial attacks is higher than the conventional attack\nthreats. Detailed simulations reveal the effectiveness of adversarial attacks\nand the necessity of smart defense techniques.\n","authors":["Ömer Faruk Tuna","Fehmi Emre Kadan","Leyli Karaçay"],"pdf_url":"https://arxiv.org/pdf/2301.09305v1.pdf","comment":"6 pages, 10 figures, accepted for presentation in International\n  Conference on Communications (ICC) 2023 in Communication and Information\n  System Security Symposium"},{"id":"http://arxiv.org/abs/2301.09300v1","updated":"2023-01-23T07:15:43Z","published":"2023-01-23T07:15:43Z","title":"A Tale of Two Latent Flows: Learning Latent Space Normalizing Flow with\n  Short-run Langevin Flow for Approximate Inference","summary":"  We study a normalizing flow in the latent space of a top-down generator\nmodel, in which the normalizing flow model plays the role of the informative\nprior model of the generator. We propose to jointly learn the latent space\nnormalizing flow prior model and the top-down generator model by a Markov chain\nMonte Carlo (MCMC)-based maximum likelihood algorithm, where a short-run\nLangevin sampling from the intractable posterior distribution is performed to\ninfer the latent variables for each observed example, so that the parameters of\nthe normalizing flow prior and the generator can be updated with the inferred\nlatent variables. We show that, under the scenario of non-convergent short-run\nMCMC, the finite step Langevin dynamics is a flow-like approximate inference\nmodel and the learning objective actually follows the perturbation of the\nmaximum likelihood estimation (MLE). We further point out that the learning\nframework seeks to (i) match the latent space normalizing flow and the\naggregated posterior produced by the short-run Langevin flow, and (ii) bias the\nmodel from MLE such that the short-run Langevin flow inference is close to the\ntrue posterior. Empirical results of extensive experiments validate the\neffectiveness of the proposed latent space normalizing flow model in the tasks\nof image generation, image reconstruction, anomaly detection, supervised image\ninpainting and unsupervised image recovery.\n","authors":["Jianwen Xie","Yaxuan Zhu","Yifei Xu","Dingcheng Li","Ping Li"],"pdf_url":"https://arxiv.org/pdf/2301.09300v1.pdf","comment":"The Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI)\n  2023"},{"id":"http://arxiv.org/abs/2301.09299v1","updated":"2023-01-23T07:00:04Z","published":"2023-01-23T07:00:04Z","title":"Self-Supervised Image Representation Learning: Transcending Masking with\n  Paired Image Overlay","summary":"  Self-supervised learning has become a popular approach in recent years for\nits ability to learn meaningful representations without the need for data\nannotation. This paper proposes a novel image augmentation technique,\noverlaying images, which has not been widely applied in self-supervised\nlearning. This method is designed to provide better guidance for the model to\nunderstand underlying information, resulting in more useful representations.\nThe proposed method is evaluated using contrastive learning, a widely used\nself-supervised learning method that has shown solid performance in downstream\ntasks. The results demonstrate the effectiveness of the proposed augmentation\ntechnique in improving the performance of self-supervised models.\n","authors":["Yinheng Li","Han Ding","Shaofei Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01295v2","updated":"2023-01-23T06:50:05Z","published":"2022-10-04T00:46:49Z","title":"Max-Quantile Grouped Infinite-Arm Bandits","summary":"  In this paper, we consider a bandit problem in which there are a number of\ngroups each consisting of infinitely many arms. Whenever a new arm is requested\nfrom a given group, its mean reward is drawn from an unknown reservoir\ndistribution (different for each group), and the uncertainty in the arm's mean\nreward can only be reduced via subsequent pulls of the arm. The goal is to\nidentify the infinite-arm group whose reservoir distribution has the highest\n$(1-\\alpha)$-quantile (e.g., median if $\\alpha = \\frac{1}{2}$), using as few\ntotal arm pulls as possible. We introduce a two-step algorithm that first\nrequests a fixed number of arms from each group and then runs a finite-arm\ngrouped max-quantile bandit algorithm. We characterize both the\ninstance-dependent and worst-case regret, and provide a matching lower bound\nfor the latter, while discussing various strengths, weaknesses, algorithmic\nimprovements, and potential lower bounds associated with our instance-dependent\nupper bounds.\n","authors":["Ivan Lau","Yan Hao Ling","Mayank Shrivastava","Jonathan Scarlett"],"pdf_url":"https://arxiv.org/pdf/2210.01295v2.pdf","comment":"ALT 2023"},{"id":"http://arxiv.org/abs/2212.12749v2","updated":"2023-01-23T06:43:39Z","published":"2022-12-24T15:17:42Z","title":"Deep Latent State Space Models for Time-Series Generation","summary":"  Methods based on ordinary differential equations (ODEs) are widely used to\nbuild generative models of time-series. In addition to high computational\noverhead due to explicitly computing hidden states recurrence, existing\nODE-based models fall short in learning sequence data with sharp transitions -\ncommon in many real-world systems - due to numerical challenges during\noptimization. In this work, we propose LS4, a generative model for sequences\nwith latent variables evolving according to a state space ODE to increase\nmodeling capacity. Inspired by recent deep state space models (S4), we achieve\nspeedups by leveraging a convolutional representation of LS4 which bypasses the\nexplicit evaluation of hidden states. We show that LS4 significantly\noutperforms previous continuous-time generative models in terms of marginal\ndistribution, classification, and prediction scores on real-world datasets in\nthe Monash Forecasting Repository, and is capable of modeling highly stochastic\ndata with sharp temporal transitions. LS4 sets state-of-the-art for\ncontinuous-time latent generative models, with significant improvement of mean\nsquared error and tighter variational lower bounds on irregularly-sampled\ndatasets, while also being x100 faster than other baselines on long sequences.\n","authors":["Linqi Zhou","Michael Poli","Winnie Xu","Stefano Massaroli","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2212.12749v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.12328v6","updated":"2023-01-23T06:30:59Z","published":"2021-10-24T01:43:12Z","title":"Improving Spectral Clustering Using Spectrum-Preserving Node Aggregation","summary":"  Spectral clustering is one of the most popular clustering methods. However,\nthe high computational cost due to the involved eigen-decomposition procedure\ncan immediately hinder its applications in large-scale tasks. In this paper we\nuse spectrum-preserving node reduction to accelerate eigen-decomposition and\ngenerate concise representations of data sets. Specifically, we create a small\nnumber of pseudonodes based on spectral similarity. Then, standard spectral\nclustering algorithm is performed on the smaller node set. Finally, each data\npoint in the original data set is assigned to the cluster as its representative\npseudo-node. The proposed framework run in nearly-linear time. Meanwhile, the\nclustering accuracy can be significantly improved by mining concise\nrepresentations. The experimental results show dramatically improved clustering\nperformance when compared with state-of-the-art methods.\n","authors":["Yongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2110.12328v6.pdf","comment":"Accepted at ICPR 2022"},{"id":"http://arxiv.org/abs/2301.09282v1","updated":"2023-01-23T05:58:26Z","published":"2023-01-23T05:58:26Z","title":"Classification of Luminal Subtypes in Full Mammogram Images Using\n  Transfer Learning","summary":"  Automatic identification of patients with luminal and non-luminal subtypes\nduring a routine mammography screening can support clinicians in streamlining\nbreast cancer therapy planning. Recent machine learning techniques have shown\npromising results in molecular subtype classification in mammography; however,\nthey are highly dependent on pixel-level annotations, handcrafted, and radiomic\nfeatures. In this work, we provide initial insights into the luminal subtype\nclassification in full mammogram images trained using only image-level labels.\nTransfer learning is applied from a breast abnormality classification task, to\nfinetune a ResNet-18-based luminal versus non-luminal subtype classification\ntask. We present and compare our results on the publicly available CMMD dataset\nand show that our approach significantly outperforms the baseline classifier by\nachieving a mean AUC score of 0.6688 and a mean F1 score of 0.6693 on the test\ndataset. The improvement over baseline is statistically significant, with a\np-value of p<0.0001.\n","authors":["Adarsh Bhandary Panambur","Prathmesh Madhu","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2301.09282v1.pdf","comment":"Submitted to IEEE ISBI 2023"},{"id":"http://arxiv.org/abs/2110.04070v3","updated":"2023-01-23T05:33:48Z","published":"2021-10-05T06:40:16Z","title":"Dataset Structural Index: Leveraging a machine's perspective towards\n  visual data","summary":"  With advances in vision and perception architectures, we have realized that\nworking with data is equally crucial, if not more, than the algorithms. Till\ntoday, we have trained machines based on our knowledge and perspective of the\nworld. The entire concept of Dataset Structural Index(DSI) revolves around\nunderstanding a machine`s perspective of the dataset. With DSI, I show two meta\nvalues with which we can get more information over a visual dataset and use it\nto optimize data, create better architectures, and have an ability to guess\nwhich model would work best. These two values are the Variety contribution\nratio and Similarity matrix. In the paper, I show many applications of DSI, one\nof which is how the same level of accuracy can be achieved with the same model\narchitectures trained over less amount of data.\n","authors":["Dishant Parikh"],"pdf_url":"https://arxiv.org/pdf/2110.04070v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09279v1","updated":"2023-01-23T05:32:42Z","published":"2023-01-23T05:32:42Z","title":"StockEmotions: Discover Investor Emotions for Financial Sentiment\n  Analysis and Multivariate Time Series","summary":"  There has been growing interest in applying NLP techniques in the financial\ndomain, however, resources are extremely limited. This paper introduces\nStockEmotions, a new dataset for detecting emotions in the stock market that\nconsists of 10,000 English comments collected from StockTwits, a financial\nsocial media platform. Inspired by behavioral finance, it proposes 12\nfine-grained emotion classes that span the roller coaster of investor emotion.\nUnlike existing financial sentiment datasets, StockEmotions presents granular\nfeatures such as investor sentiment classes, fine-grained emotions, emojis, and\ntime series data. To demonstrate the usability of the dataset, we perform a\ndataset analysis and conduct experimental downstream tasks. For financial\nsentiment/emotion classification tasks, DistilBERT outperforms other baselines,\nand for multivariate time series forecasting, a Temporal Attention LSTM model\ncombining price index, text, and emotion features achieves the best performance\nthan using a single feature.\n","authors":["Jean Lee","Hoyoul Luis Youn","Josiah Poon","Soyeon Caren Han"],"pdf_url":"https://arxiv.org/pdf/2301.09279v1.pdf","comment":"Preprint for the AAAI-23 Bridge Program (AI for Financial Services)"},{"id":"http://arxiv.org/abs/2301.09269v1","updated":"2023-01-23T04:40:01Z","published":"2023-01-23T04:40:01Z","title":"M22: A Communication-Efficient Algorithm for Federated Learning Inspired\n  by Rate-Distortion","summary":"  In federated learning (FL), the communication constraint between the remote\nlearners and the Parameter Server (PS) is a crucial bottleneck. For this\nreason, model updates must be compressed so as to minimize the loss in accuracy\nresulting from the communication constraint. This paper proposes ``\\emph{${\\bf\nM}$-magnitude weighted $L_{\\bf 2}$ distortion + $\\bf 2$ degrees of freedom''}\n(M22) algorithm, a rate-distortion inspired approach to gradient compression\nfor federated training of deep neural networks (DNNs). In particular, we\npropose a family of distortion measures between the original gradient and the\nreconstruction we referred to as ``$M$-magnitude weighted $L_2$'' distortion,\nand we assume that gradient updates follow an i.i.d. distribution --\ngeneralized normal or Weibull, which have two degrees of freedom. In both the\ndistortion measure and the gradient, there is one free parameter for each that\ncan be fitted as a function of the iteration number. Given a choice of gradient\ndistribution and distortion measure, we design the quantizer minimizing the\nexpected distortion in gradient reconstruction. To measure the gradient\ncompression performance under a communication constraint, we define the\n\\emph{per-bit accuracy} as the optimal improvement in accuracy that one bit of\ncommunication brings to the centralized model over the training period. Using\nthis performance measure, we systematically benchmark the choice of gradient\ndistribution and distortion measure. We provide substantial insights on the\nrole of these choices and argue that significant performance improvements can\nbe attained using such a rate-distortion inspired compressor.\n","authors":["Yangyi Liu","Stefano Rini","Sadaf Salehkalaibar","Jun Chen"],"pdf_url":"https://arxiv.org/pdf/2301.09269v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.02812"},{"id":"http://arxiv.org/abs/2301.09266v1","updated":"2023-01-23T04:31:03Z","published":"2023-01-23T04:31:03Z","title":"FInC Flow: Fast and Invertible $k \\times k$ Convolutions for Normalizing\n  Flows","summary":"  Invertible convolutions have been an essential element for building\nexpressive normalizing flow-based generative models since their introduction in\nGlow. Several attempts have been made to design invertible $k \\times k$\nconvolutions that are efficient in training and sampling passes. Though these\nattempts have improved the expressivity and sampling efficiency, they severely\nlagged behind Glow which used only $1 \\times 1$ convolutions in terms of\nsampling time. Also, many of the approaches mask a large number of parameters\nof the underlying convolution, resulting in lower expressivity on a fixed\nrun-time budget. We propose a $k \\times k$ convolutional layer and Deep\nNormalizing Flow architecture which i.) has a fast parallel inversion algorithm\nwith running time O$(n k^2)$ ($n$ is height and width of the input image and k\nis kernel size), ii.) masks the minimal amount of learnable parameters in a\nlayer. iii.) gives better forward pass and sampling times comparable to other\n$k \\times k$ convolution-based models on real-world benchmarks. We provide an\nimplementation of the proposed parallel algorithm for sampling using our\ninvertible convolutions on GPUs. Benchmarks on CIFAR-10, ImageNet, and CelebA\ndatasets show comparable performance to previous works regarding bits per\ndimension while significantly improving the sampling time.\n","authors":["Aditya Kallappa","Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2301.09266v1.pdf","comment":"accepted: VISAPP'23"},{"id":"http://arxiv.org/abs/2301.09264v1","updated":"2023-01-23T04:26:20Z","published":"2023-01-23T04:26:20Z","title":"Efficient Training Under Limited Resources","summary":"  Training time budget and size of the dataset are among the factors affecting\nthe performance of a Deep Neural Network (DNN). This paper shows that Neural\nArchitecture Search (NAS), Hyper Parameters Optimization (HPO), and Data\nAugmentation help DNNs perform much better while these two factors are limited.\nHowever, searching for an optimal architecture and the best hyperparameter\nvalues besides a good combination of data augmentation techniques under low\nresources requires many experiments. We present our approach to achieving such\na goal in three steps: reducing training epoch time by compressing the model\nwhile maintaining the performance compared to the original model, preventing\nmodel overfitting when the dataset is small, and performing the hyperparameter\ntuning. We used NOMAD, which is a blackbox optimization software based on a\nderivative-free algorithm to do NAS and HPO. Our work achieved an accuracy of\n86.0 % on a tiny subset of Mini-ImageNet at the ICLR 2021 Hardware Aware\nEfficient Training (HAET) Challenge and won second place in the competition.\nThe competition results can be found at haet2021.github.io/challenge and our\nsource code can be found at github.com/DouniaLakhmiri/ICLR\\_HAET2021.\n","authors":["Mahdi Zolnouri","Dounia Lakhmiri","Christophe Tribes","Eyyüb Sari","Sébastien Le Digabel"],"pdf_url":"https://arxiv.org/pdf/2301.09264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09262v1","updated":"2023-01-23T04:24:26Z","published":"2023-01-23T04:24:26Z","title":"MEMO : Accelerating Transformers with Memoization on Big Memory Systems","summary":"  Transformers gain popularity because of their superior prediction accuracy\nand inference throughput. However, the transformer is computation-intensive,\ncausing a long inference time. The existing work to accelerate transformer\ninferences has limitations because of the changes to transformer architectures\nor the need for specialized hardware. In this paper, we identify the\nopportunities of using memoization to accelerate the attention mechanism in\ntransformers without the above limitation. Built upon a unique observation that\nthere is a rich similarity in attention computation across inference sequences,\nwe build an attention database upon the emerging big memory system. We\nintroduce the embedding technique to find semantically similar inputs to\nidentify computation similarity. We also introduce a series of techniques such\nas memory mapping and selective memoization to avoid memory copy and\nunnecessary overhead. We enable 21% performance improvement on average (up to\n68%) with the TB-scale attention database and with ignorable loss in inference\naccuracy.\n","authors":["Yuan Feng","Hyeran Jeon","Filip Blagojevic","Cyril Guyot","Qing Li","Dong Li"],"pdf_url":"https://arxiv.org/pdf/2301.09262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09255v1","updated":"2023-01-23T03:41:02Z","published":"2023-01-23T03:41:02Z","title":"Combined Use of Federated Learning and Image Encryption for\n  Privacy-Preserving Image Classification with Vision Transformer","summary":"  In recent years, privacy-preserving methods for deep learning have become an\nurgent problem. Accordingly, we propose the combined use of federated learning\n(FL) and encrypted images for privacy-preserving image classification under the\nuse of the vision transformer (ViT). The proposed method allows us not only to\ntrain models over multiple participants without directly sharing their raw data\nbut to also protect the privacy of test (query) images for the first time. In\naddition, it can also maintain the same accuracy as normally trained models. In\nan experiment, the proposed method was demonstrated to well work without any\nperformance degradation on the CIFAR-10 and CIFAR-100 datasets.\n","authors":["Teru Nagamori","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2301.09255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09254v1","updated":"2023-01-23T03:33:38Z","published":"2023-01-23T03:33:38Z","title":"Learning to Linearize Deep Neural Networks for Secure and Efficient\n  Private Inference","summary":"  The large number of ReLU non-linearity operations in existing deep neural\nnetworks makes them ill-suited for latency-efficient private inference (PI).\nExisting techniques to reduce ReLU operations often involve manual effort and\nsacrifice significant accuracy. In this paper, we first present a novel measure\nof non-linearity layers' ReLU sensitivity, enabling mitigation of the\ntime-consuming manual efforts in identifying the same. Based on this\nsensitivity, we then present SENet, a three-stage training method that for a\ngiven ReLU budget, automatically assigns per-layer ReLU counts, decides the\nReLU locations for each layer's activation map, and trains a model with\nsignificantly fewer ReLUs to potentially yield latency and communication\nefficient PI. Experimental evaluations with multiple models on various datasets\nshow SENet's superior performance both in terms of reduced ReLUs and improved\nclassification accuracy compared to existing alternatives. In particular, SENet\ncan yield models that require up to ~2x fewer ReLUs while yielding similar\naccuracy. For a similar ReLU budget SENet can yield models with ~2.32% improved\nclassification accuracy, evaluated on CIFAR-100.\n","authors":["Souvik Kundu","Shunlin Lu","Yuke Zhang","Jacqueline Liu","Peter A. Beerel"],"pdf_url":"https://arxiv.org/pdf/2301.09254v1.pdf","comment":"15 pages, 10 figures, 11 tables. Accepted as a conference paper at\n  ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09251v1","updated":"2023-01-23T03:11:06Z","published":"2023-01-23T03:11:06Z","title":"Congested Bandits: Optimal Routing via Short-term Resets","summary":"  For traffic routing platforms, the choice of which route to recommend to a\nuser depends on the congestion on these routes -- indeed, an individual's\nutility depends on the number of people using the recommended route at that\ninstance. Motivated by this, we introduce the problem of Congested Bandits\nwhere each arm's reward is allowed to depend on the number of times it was\nplayed in the past $\\Delta$ timesteps. This dependence on past history of\nactions leads to a dynamical system where an algorithm's present choices also\naffect its future pay-offs, and requires an algorithm to plan for this. We\nstudy the congestion aware formulation in the multi-armed bandit (MAB) setup\nand in the contextual bandit setup with linear rewards. For the multi-armed\nsetup, we propose a UCB style algorithm and show that its policy regret scales\nas $\\tilde{O}(\\sqrt{K \\Delta T})$. For the linear contextual bandit setup, our\nalgorithm, based on an iterative least squares planner, achieves policy regret\n$\\tilde{O}(\\sqrt{dT} + \\Delta)$. From an experimental standpoint, we\ncorroborate the no-regret properties of our algorithms via a simulation study.\n","authors":["Pranjal Awasthi","Kush Bhatia","Sreenivas Gollapudi","Kostas Kollias"],"pdf_url":"https://arxiv.org/pdf/2301.09251v1.pdf","comment":"Published at ICML 2022"},{"id":"http://arxiv.org/abs/2109.14099v2","updated":"2023-01-23T02:31:02Z","published":"2021-09-28T23:29:31Z","title":"An Explainable-AI approach for Diagnosis of COVID-19 using MALDI-ToF\n  Mass Spectrometry","summary":"  The severe acute respiratory syndrome coronavirus type-2 (SARS-CoV-2) caused\na global pandemic and imposed immense effects on the global economy. Accurate,\ncost-effective, and quick tests have proven substantial in identifying infected\npeople and mitigating the spread. Recently, multiple alternative platforms for\ntesting coronavirus disease 2019 (COVID-19) have been published that show high\nagreement with current gold standard real-time polymerase chain reaction\n(RT-PCR) results. These new methods do away with nasopharyngeal (NP) swabs,\neliminate the need for complicated reagents, and reduce the burden on RT-PCR\ntest reagent supply. In the present work, we have designed an artificial\nintelligence-based (AI) testing method to provide confidence in the results.\nCurrent AI applications to COVID-19 studies often lack a biological foundation\nin the decision-making process, and our AI approach is one of the earliest to\nleverage explainable-AI (X-AI) algorithms for COVID-19 diagnosis using mass\nspectrometry. Here, we have employed X-AI to explain the decision-making\nprocess on a local (per-sample) and global (all samples) basis underscored by\nbiologically relevant features. We evaluated our technique with data extracted\nfrom human gargle samples and achieved a testing accuracy of 94.44%. Such\ntechniques would strengthen the relationship between AI and clinical\ndiagnostics by providing biomedical researchers and healthcare workers with\ntrustworthy and, most importantly, explainable test results.\n","authors":["Venkata Devesh Reddy Seethi","Zane LaCasse","Prajkta Chivte","Joshua Bland","Shrihari S. Kadkol","Elizabeth R. Gaillard","Pratool Bharti","Hamed Alhoori"],"pdf_url":"https://arxiv.org/pdf/2109.14099v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09245v1","updated":"2023-01-23T02:23:45Z","published":"2023-01-23T02:23:45Z","title":"Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural\n  Networks","summary":"  Throughout history, the development of artificial intelligence, particularly\nartificial neural networks, has been open to and constantly inspired by the\nincreasingly deepened understanding of the brain, such as the inspiration of\nneocognitron, which is the pioneering work of convolutional neural networks.\nPer the motives of the emerging field: NeuroAI, a great amount of neuroscience\nknowledge can help catalyze the next generation of AI by endowing a network\nwith more powerful capabilities. As we know, the human brain has numerous\nmorphologically and functionally different neurons, while artificial neural\nnetworks are almost exclusively built on a single neuron type. In the human\nbrain, neuronal diversity is an enabling factor for all kinds of biological\nintelligent behaviors. Since an artificial network is a miniature of the human\nbrain, introducing neuronal diversity should be valuable in terms of addressing\nthose essential problems of artificial networks such as efficiency,\ninterpretability, and memory. In this Primer, we first discuss the\npreliminaries of biological neuronal diversity and the characteristics of\ninformation transmission and processing in a biological neuron. Then, we review\nstudies of designing new neurons for artificial networks. Next, we discuss what\ngains can neuronal diversity bring into artificial networks and exemplary\napplications in several important fields. Lastly, we discuss the challenges and\nfuture directions of neuronal diversity to explore the potential of NeuroAI.\n","authors":["Feng-Lei Fan","Yingxin Li","Hanchuan Peng","Tieyong Zeng","Fei Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05778v3","updated":"2023-01-23T02:21:51Z","published":"2022-06-12T16:14:16Z","title":"Learning-Based Data Storage [Vision] (Technical Report)","summary":"  Deep neural network (DNN) and its variants have been extensively used for a\nwide spectrum of real applications such as image classification, face/speech\nrecognition, fraud detection, and so on. In addition to many important machine\nlearning tasks, as artificial networks emulating the way brain cells function,\nDNNs also show the capability of storing non-linear relationships between input\nand output data, which exhibits the potential of storing data via DNNs. We\nenvision a new paradigm of data storage, \"DNN-as-a-Database\", where data are\nencoded in well-trained machine learning models. Compared with conventional\ndata storage that directly records data in raw formats, learning-based\nstructures (e.g., DNN) can implicitly encode data pairs of inputs and outputs\nand compute/materialize actual output data of different resolutions only if\ninput data are provided. This new paradigm can greatly enhance the data\nsecurity by allowing flexible data privacy settings on different levels,\nachieve low space consumption and fast computation with the acceleration of new\nhardware (e.g., Diffractive Neural Network and AI chips), and can be\ngeneralized to distributed DNN-based storage/computing. In this paper, we\npropose this novel concept of learning-based data storage, which utilizes a\nlearning structure called learning-based memory unit (LMU), to store, organize,\nand retrieve data. As a case study, we use DNNs as the engine in the LMU, and\nstudy the data capacity and accuracy of the DNN-based data storage. Our\npreliminary experimental results show the feasibility of the learning-based\ndata storage by achieving high (100%) accuracy of the DNN storage. We explore\nand design effective solutions to utilize the DNN-based data storage to manage\nand query relational tables. We discuss how to generalize our solutions to\nother data types (e.g., graphs) and environments such as distributed DNN\nstorage/computing.\n","authors":["Xiang Lian","Xiaofei Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.05778v3.pdf","comment":"14 pages, 16 figures"},{"id":"http://arxiv.org/abs/2208.02810v3","updated":"2023-01-23T01:51:01Z","published":"2022-08-04T17:58:37Z","title":"Analyzing Data-Centric Properties for Graph Contrastive Learning","summary":"  Recent analyses of self-supervised learning (SSL) find the following\ndata-centric properties to be critical for learning good representations:\ninvariance to task-irrelevant semantics, separability of classes in some latent\nspace, and recoverability of labels from augmented samples. However, given\ntheir discrete, non-Euclidean nature, graph datasets and graph SSL methods are\nunlikely to satisfy these properties. This raises the question: how do graph\nSSL methods, such as contrastive learning (CL), work well? To systematically\nprobe this question, we perform a generalization analysis for CL when using\ngeneric graph augmentations (GGAs), with a focus on data-centric properties.\nOur analysis yields formal insights into the limitations of GGAs and the\nnecessity of task-relevant augmentations. As we empirically show, GGAs do not\ninduce task-relevant invariances on common benchmark datasets, leading to only\nmarginal gains over naive, untrained baselines. Our theory motivates a\nsynthetic data generation process that enables control over task-relevant\ninformation and boasts pre-defined optimal augmentations. This flexible\nbenchmark helps us identify yet unrecognized limitations in advanced\naugmentation techniques (e.g., automated methods). Overall, our work rigorously\ncontextualizes, both empirically and theoretically, the effects of data-centric\nproperties on augmentation strategies and learning paradigms for graph SSL.\n","authors":["Puja Trivedi","Ekdeep Singh Lubana","Mark Heimann","Danai Koutra","Jayaraman J. Thiagarajan"],"pdf_url":"https://arxiv.org/pdf/2208.02810v3.pdf","comment":"Accepted to NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.09235v1","updated":"2023-01-23T00:44:05Z","published":"2023-01-23T00:44:05Z","title":"Learning Reservoir Dynamics with Temporal Self-Modulation","summary":"  Reservoir computing (RC) can efficiently process time-series data by\ntransferring the input signal to randomly connected recurrent neural networks\n(RNNs), which are referred to as a reservoir. The high-dimensional\nrepresentation of time-series data in the reservoir significantly simplifies\nsubsequent learning tasks. Although this simple architecture allows fast\nlearning and facile physical implementation, the learning performance is\ninferior to that of other state-of-the-art RNN models. In this paper, to\nimprove the learning ability of RC, we propose self-modulated RC (SM-RC), which\nextends RC by adding a self-modulation mechanism. The self-modulation mechanism\nis realized with two gating variables: an input gate and a reservoir gate. The\ninput gate modulates the input signal, and the reservoir gate modulates the\ndynamical properties of the reservoir. We demonstrated that SM-RC can perform\nattention tasks where input information is retained or discarded depending on\nthe input signal. We also found that a chaotic state emerged as a result of\nlearning in SM-RC. This indicates that self-modulation mechanisms provide RC\nwith qualitatively different information-processing capabilities. Furthermore,\nSM-RC outperformed RC in NARMA and Lorentz model tasks. In particular, SM-RC\nachieved a higher prediction accuracy than RC with a reservoir 10 times larger\nin the Lorentz model tasks. Because the SM-RC architecture only requires two\nadditional gates, it is physically implementable as RC, providing a new\ndirection for realizing edge AI.\n","authors":["Yusuke Sakemi","Sou Nobukawa","Toshitaka Matsuki","Takashi Morie","Kazuyuki Aihara"],"pdf_url":"https://arxiv.org/pdf/2301.09235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09232v1","updated":"2023-01-23T00:22:37Z","published":"2023-01-23T00:22:37Z","title":"Optimising complexity of CNN models for resource constrained devices:\n  QRS detection case study","summary":"  Traditional DL models are complex and resource hungry and thus, care needs to\nbe taken in designing Internet of (medical) things (IoT, or IoMT) applications\nbalancing efficiency-complexity trade-off. Recent IoT solutions tend to avoid\nusing deep-learning methods due to such complexities, and rather classical\nfilter-based methods are commonly used. We hypothesize that a shallow CNN model\ncan offer satisfactory level of performance in combination by leveraging other\nessential solution-components, such as post-processing that is suitable for\nresource constrained environment. In an IoMT application context, QRS-detection\nand R-peak localisation from ECG signal as a case study, the complexities of\nCNN models and post-processing were varied to identify a set of combinations\nsuitable for a range of target resource-limited environments. To the best of\nour knowledge, finding a deploy-able configuration, by incrementally increasing\nthe CNN model complexity, as required to match the target's resource capacity,\nand leveraging the strength of post-processing, is the first of its kind. The\nresults show that a shallow 2-layer CNN with a suitable post-processing can\nachieve $>$90\\% F1-score, and the scores continue to improving for 8-32 layer\nCNNs, which can be used to profile target constraint environment. The outcome\nshows that it is possible to design an optimal DL solution with known target\nperformance characteristics and resource (computing capacity, and memory)\nconstraints.\n","authors":["Ahsan Habib","Chandan Karmakar","John Yearwood"],"pdf_url":"https://arxiv.org/pdf/2301.09232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09231v1","updated":"2023-01-23T00:17:52Z","published":"2023-01-23T00:17:52Z","title":"GP-NAS-ensemble: a model for NAS Performance Prediction","summary":"  It is of great significance to estimate the performance of a given model\narchitecture without training in the application of Neural Architecture Search\n(NAS) as it may take a lot of time to evaluate the performance of an\narchitecture. In this paper, a novel NAS framework called GP-NAS-ensemble is\nproposed to predict the performance of a neural network architecture with a\nsmall training dataset. We make several improvements on the GP-NAS model to\nmake it share the advantage of ensemble learning methods. Our method ranks\nsecond in the CVPR2022 second lightweight NAS challenge performance prediction\ntrack.\n","authors":["Kunlong Chen","Liu Yang","Yitian Chen","Kunjin Chen","Yidan Xu","Lujun Li"],"pdf_url":"https://arxiv.org/pdf/2301.09231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.11489v2","updated":"2023-01-23T23:55:16Z","published":"2020-06-20T04:17:13Z","title":"Federated Learning Meets Multi-objective Optimization","summary":"  Federated learning has emerged as a promising, massively distributed way to\ntrain a joint deep model over large amounts of edge devices while keeping\nprivate user data strictly on device. In this work, motivated from ensuring\nfairness among users and robustness against malicious adversaries, we formulate\nfederated learning as multi-objective optimization and propose a new algorithm\nFedMGDA+ that is guaranteed to converge to Pareto stationary solutions.\nFedMGDA+ is simple to implement, has fewer hyperparameters to tune, and\nrefrains from sacrificing the performance of any participating user. We\nestablish the convergence properties of FedMGDA+ and point out its connections\nto existing approaches. Extensive experiments on a variety of datasets confirm\nthat FedMGDA+ compares favorably against state-of-the-art.\n","authors":["Zeou Hu","Kiarash Shaloudegi","Guojun Zhang","Yaoliang Yu"],"pdf_url":"https://arxiv.org/pdf/2006.11489v2.pdf","comment":"Accepted at IEEE Transactions on Network Science and Engineering 2022"},{"id":"http://arxiv.org/abs/2301.08110v2","updated":"2023-01-23T23:30:02Z","published":"2023-01-19T15:01:00Z","title":"AtMan: Understanding Transformer Predictions Through Memory Efficient\n  Attention Manipulation","summary":"  Generative transformer models have become increasingly complex, with large\nnumbers of parameters and the ability to process multiple input modalities.\nCurrent methods for explaining their predictions are resource-intensive. Most\ncrucially, they require prohibitively large amounts of extra memory, since they\nrely on backpropagation which allocates almost twice as much GPU memory as the\nforward pass. This makes it difficult, if not impossible, to use them in\nproduction. We present AtMan that provides explanations of generative\ntransformer models at almost no extra cost. Specifically, AtMan is a\nmodality-agnostic perturbation method that manipulates the attention mechanisms\nof transformers to produce relevance maps for the input with respect to the\noutput prediction. Instead of using backpropagation, AtMan applies a\nparallelizable token-based search method based on cosine similarity\nneighborhood in the embedding space. Our exhaustive experiments on text and\nimage-text benchmarks demonstrate that AtMan outperforms current\nstate-of-the-art gradient-based methods on several metrics while being\ncomputationally efficient. As such, AtMan is suitable for use in large model\ninference deployments.\n","authors":["Mayukh Deb","Björn Deiseroth","Samuel Weinbach","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2301.08110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09756v1","updated":"2023-01-23T23:27:22Z","published":"2023-01-23T23:27:22Z","title":"Earthquake Magnitude and b value prediction model using Extreme Learning\n  Machine","summary":"  Earthquake prediction has been a challenging research area for many decades,\nwhere the future occurrence of this highly uncertain calamity is predicted. In\nthis paper, several parametric and non-parametric features were calculated,\nwhere the non-parametric features were calculated using the parametric\nfeatures. $8$ seismic features were calculated using Gutenberg-Richter law, the\ntotal recurrence, and the seismic energy release. Additionally, criterions such\nas Maximum Relevance and Maximum Redundancy were applied to choose the\npertinent features. These features along with others were used as input for an\nExtreme Learning Machine (ELM) Regression Model. Magnitude and time data of $5$\ndecades from the Assam-Guwahati region were used to create this model for\nmagnitude prediction. The Testing Accuracy and Testing Speed were computed\ntaking the Root Mean Squared Error (RMSE) as the parameter for evaluating the\nmode. As confirmed by the results, ELM shows better scalability with much\nfaster training and testing speed (up to a thousand times faster) than\ntraditional Support Vector Machines. The testing RMSE came out to be around\n$0.097$. To further test the model's robustness -- magnitude-time data from\nCalifornia was used to calculate the seismic indicators which were then fed\ninto an ELM and then tested on the Assam-Guwahati region. The model proves to\nbe robust and can be implemented in early warning systems as it continues to be\na major part of Disaster Response and management.\n","authors":["Gunbir Singh Baveja","Jaspreet Singh"],"pdf_url":"https://arxiv.org/pdf/2301.09756v1.pdf","comment":"11 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2210.14891v5","updated":"2023-01-23T23:25:14Z","published":"2022-10-26T17:45:01Z","title":"Broken Neural Scaling Laws","summary":"  We present a smoothly broken power law functional form that accurately models\nand extrapolates the scaling behaviors of deep neural networks (i.e. how the\nevaluation metric of interest varies as the amount of compute used for\ntraining, number of model parameters, training dataset size, or upstream\nperformance varies) for various architectures and for each of various tasks\nwithin a large and diverse set of upstream and downstream tasks, in zero-shot,\nprompted, and fine-tuned settings. This set includes large-scale vision,\nlanguage, audio, video, diffusion generative modeling, multimodal learning,\ncontrastive learning, AI alignment, robotics, arithmetic,\nunsupervised/self-supervised learning, and reinforcement learning (single agent\nand multi-agent). When compared to other functional forms for neural scaling\nbehavior, this functional form yields extrapolations of scaling behavior that\nare considerably more accurate on this set. Moreover, this functional form\naccurately models and extrapolates scaling behavior that other functional forms\nare incapable of expressing such as the non-monotonic transitions present in\nthe scaling behavior of phenomena such as double descent and the delayed, sharp\ninflection points present in the scaling behavior of tasks such as arithmetic.\nLastly, we use this functional form to glean insights about the limit of the\npredictability of scaling behavior. Code is available at\nhttps://github.com/ethancaballero/broken_neural_scaling_laws\n","authors":["Ethan Caballero","Kshitij Gupta","Irina Rish","David Krueger"],"pdf_url":"https://arxiv.org/pdf/2210.14891v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09753v1","updated":"2023-01-23T22:54:34Z","published":"2023-01-23T22:54:34Z","title":"Towards Modular Machine Learning Solution Development: Benefits and\n  Trade-offs","summary":"  Machine learning technologies have demonstrated immense capabilities in\nvarious domains. They play a key role in the success of modern businesses.\nHowever, adoption of machine learning technologies has a lot of untouched\npotential. Cost of developing custom machine learning solutions that solve\nunique business problems is a major inhibitor to far-reaching adoption of\nmachine learning technologies. We recognize that the monolithic nature\nprevalent in today's machine learning applications stands in the way of\nefficient and cost effective customized machine learning solution development.\nIn this work we explore the benefits of modular machine learning solutions and\ndiscuss how modular machine learning solutions can overcome some of the major\nsolution engineering limitations of monolithic machine learning solutions. We\nanalyze the trade-offs between modular and monolithic machine learning\nsolutions through three deep learning problems; one text based and the two\nimage based. Our experimental results show that modular machine learning\nsolutions have a promising potential to reap the solution engineering\nadvantages of modularity while gaining performance and data advantages in a way\nthe monolithic machine learning solutions do not permit.\n","authors":["Samiyuru Menik","Lakshmish Ramaswamy"],"pdf_url":"https://arxiv.org/pdf/2301.09753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.10369v2","updated":"2023-01-23T22:16:54Z","published":"2020-12-18T17:19:31Z","title":"Upper and Lower Bounds on the Performance of Kernel PCA","summary":"  Principal Component Analysis (PCA) is a popular method for dimension\nreduction and has attracted an unfailing interest for decades. More recently,\nkernel PCA (KPCA) has emerged as an extension of PCA but, despite its use in\npractice, a sound theoretical understanding of KPCA is missing. We contribute\nseveral lower and upper bounds on the efficiency of KPCA, involving the\nempirical eigenvalues of the kernel Gram matrix and new quantities involving a\nnotion of variance. These bounds show how much information is captured by KPCA\non average and contribute a better theoretical understanding of its efficiency.\nWe demonstrate that fast convergence rates are achievable for a widely used\nclass of kernels and we highlight the importance of some desirable properties\nof datasets to ensure KPCA efficiency.\n","authors":["Maxime Haddouche","Benjamin Guedj","John Shawe-Taylor"],"pdf_url":"https://arxiv.org/pdf/2012.10369v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2301.09742v1","updated":"2023-01-23T22:11:37Z","published":"2023-01-23T22:11:37Z","title":"Topological Understanding of Neural Networks, a survey","summary":"  We look at the internal structure of neural networks which is usually treated\nas a black box. The easiest and the most comprehensible thing to do is to look\nat a binary classification and try to understand the approach a neural network\ntakes. We review the significance of different activation functions, types of\nnetwork architectures associated to them, and some empirical data. We find some\ninteresting observations and a possibility to build upon the ideas to verify\nthe process for real datasets. We suggest some possible experiments to look\nforward to in three different directions.\n","authors":["Tushar Pandey"],"pdf_url":"https://arxiv.org/pdf/2301.09742v1.pdf","comment":"Literature Review"},{"id":"http://arxiv.org/abs/2301.09740v1","updated":"2023-01-23T22:10:40Z","published":"2023-01-23T22:10:40Z","title":"DODEM: DOuble DEfense Mechanism Against Adversarial Attacks Towards\n  Secure Industrial Internet of Things Analytics","summary":"  Industrial Internet of Things (I-IoT) is a collaboration of devices, sensors,\nand networking equipment to monitor and collect data from industrial\noperations. Machine learning (ML) methods use this data to make high-level\ndecisions with minimal human intervention. Data-driven predictive maintenance\n(PDM) is a crucial ML-based I-IoT application to find an optimal maintenance\nschedule for industrial assets. The performance of these ML methods can\nseriously be threatened by adversarial attacks where an adversary crafts\nperturbed data and sends it to the ML model to deteriorate its prediction\nperformance. The models should be able to stay robust against these attacks\nwhere robustness is measured by how much perturbation in input data affects\nmodel performance. Hence, there is a need for effective defense mechanisms that\ncan protect these models against adversarial attacks. In this work, we propose\na double defense mechanism to detect and mitigate adversarial attacks in I-IoT\nenvironments. We first detect if there is an adversarial attack on a given\nsample using novelty detection algorithms. Then, based on the outcome of our\nalgorithm, marking an instance as attack or normal, we select adversarial\nretraining or standard training to provide a secondary defense layer. If there\nis an attack, adversarial retraining provides a more robust model, while we\napply standard training for regular samples. Since we may not know if an attack\nwill take place, our adaptive mechanism allows us to consider irregular changes\nin data. The results show that our double defense strategy is highly efficient\nwhere we can improve model robustness by up to 64.6% and 52% compared to\nstandard and adversarial retraining, respectively.\n","authors":["Onat Gungor","Tajana Rosing","Baris Aksanli"],"pdf_url":"https://arxiv.org/pdf/2301.09740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.01666v3","updated":"2023-01-23T21:58:36Z","published":"2022-02-03T16:28:04Z","title":"Proportional Fairness in Federated Learning","summary":"  With the increasingly broad deployment of federated learning (FL) systems in\nthe real world, it is critical but challenging to ensure fairness in FL, i.e.\nreasonably satisfactory performances for each of the numerous diverse clients.\nIn this work, we introduce and study a new fairness notion in FL, called\nproportional fairness (PF), which is based on the relative change of each\nclient's performance. From its connection with the bargaining games, we propose\nPropFair, a novel and easy-to-implement algorithm for finding proportionally\nfair solutions in FL and study its convergence properties. Through extensive\nexperiments on vision and language datasets, we demonstrate that PropFair can\napproximately find PF solutions, and it achieves a good balance between the\naverage performances of all clients and of the worst 10% clients.\n","authors":["Guojun Zhang","Saber Malekmohammadi","Xi Chen","Yaoliang Yu"],"pdf_url":"https://arxiv.org/pdf/2202.01666v3.pdf","comment":"Accepted at TMLR 2023"},{"id":"http://arxiv.org/abs/2301.09734v1","updated":"2023-01-23T21:54:25Z","published":"2023-01-23T21:54:25Z","title":"Topological Structure is Predictive of Deep Neural Network Success in\n  Learning","summary":"  Machine learning has become a fundamental tool in modern science, yet its\nlimitations are still not fully understood. Using a simple children's game, we\nshow that the topological structure of the underlying training data can have a\ndramatic effect on the ability of a deep neural network (DNN) classifier to\nlearn to classify data. We then take insights obtained from this toy model and\napply them to two physical data sets (one from particle physics and one from\nacoustics), which are known to be amenable to classification by DNN's. We show\nthat the simplicity in their topological structure explains the majority of the\nDNN's ability to operate on these data sets by showing that fully interpretable\ntopological classifiers are able to perform nearly as well as their DNN\ncounterparts.\n","authors":["Christopher Griffin","Trevor Karn","Benjamin Apple"],"pdf_url":"https://arxiv.org/pdf/2301.09734v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.09732v1","updated":"2023-01-23T21:49:28Z","published":"2023-01-23T21:49:28Z","title":"Backdoor Attacks in Peer-to-Peer Federated Learning","summary":"  We study backdoor attacks in peer-to-peer federated learning systems on\ndifferent graph topologies and datasets. We show that only 5% attacker nodes\nare sufficient to perform a backdoor attack with 42% attack success without\ndecreasing the accuracy on clean data by more than 2%. We also demonstrate that\nthe attack can be amplified by the attacker crashing a small number of nodes.\nWe evaluate defenses proposed in the context of centralized federated learning\nand show they are ineffective in peer-to-peer settings. Finally, we propose a\ndefense that mitigates the attacks by applying different clipping norms to the\nmodel updates received from peers and local model trained by a node.\n","authors":["Gokberk Yar","Cristina Nita-Rotaru","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2301.09732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09729v1","updated":"2023-01-23T21:45:00Z","published":"2023-01-23T21:45:00Z","title":"Long-term stable Electromyography classification using Canonical\n  Correlation Analysis","summary":"  Discrimination of hand gestures based on the decoding of surface\nelectromyography (sEMG) signals is a well-establish approach for controlling\nprosthetic devices and for Human-Machine Interfaces (HMI). However, despite the\npromising results achieved by this approach in well-controlled experimental\nconditions, its deployment in long-term real-world application scenarios is\nstill hindered by several challenges. One of the most critical challenges is\nmaintaining high EMG data classification performance across multiple days\nwithout retraining the decoding system. The drop in performance is mostly due\nto the high EMG variability caused by electrodes shift, muscle artifacts,\nfatigue, user adaptation, or skin-electrode interfacing issues. Here we propose\na novel statistical method based on canonical correlation analysis (CCA) that\nstabilizes EMG classification performance across multiple days for long-term\ncontrol of prosthetic devices. We show how CCA can dramatically decrease the\nperformance drop of standard classifiers observed across days, by maximizing\nthe correlation among multiple-day acquisition data sets. Our results show how\nthe performance of a classifier trained on EMG data acquired only of the first\nday of the experiment maintains 90% relative accuracy across multiple days,\ncompensating for the EMG data variability that occurs over long-term periods,\nusing the CCA transformation on data obtained from a small number of gestures.\nThis approach eliminates the need for large data sets and multiple or periodic\ntraining sessions, which currently hamper the usability of conventional pattern\nrecognition based approaches\n","authors":["Elisa Donati","Simone Benatti","Enea Ceolini","Giacomo Indiveri"],"pdf_url":"https://arxiv.org/pdf/2301.09729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03299v6","updated":"2023-01-23T21:44:39Z","published":"2022-09-07T16:59:03Z","title":"Multimodal learning with graphs","summary":"  Artificial intelligence for graphs has achieved remarkable success in\nmodeling complex systems, ranging from dynamic networks in biology to\ninteracting particle systems in physics. However, the increasingly\nheterogeneous graph datasets call for multimodal methods that can combine\ndifferent inductive biases: the set of assumptions that algorithms use to make\npredictions for inputs they have not encountered during training. Learning on\nmultimodal datasets presents fundamental challenges because the inductive\nbiases can vary by data modality and graphs might not be explicitly given in\nthe input. To address these challenges, multimodal graph AI methods combine\ndifferent modalities while leveraging cross-modal dependencies using graphs.\nDiverse datasets are combined using graphs and fed into sophisticated\nmultimodal architectures, specified as image-intensive, knowledge-grounded and\nlanguage-intensive models. Using this categorization, we introduce a blueprint\nfor multimodal graph learning, use it to study existing methods and provide\nguidelines to design new models.\n","authors":["Yasha Ektefaie","George Dasoulas","Ayush Noori","Maha Farhat","Marinka Zitnik"],"pdf_url":"https://arxiv.org/pdf/2209.03299v6.pdf","comment":"27 pages, 5 figures, 2 boxes"},{"id":"http://arxiv.org/abs/2301.09724v1","updated":"2023-01-23T21:25:24Z","published":"2023-01-23T21:25:24Z","title":"Long-tail Detection with Effective Class-Margins","summary":"  Large-scale object detection and instance segmentation face a severe data\nimbalance. The finer-grained object classes become, the less frequent they\nappear in our datasets. However, at test-time, we expect a detector that\nperforms well for all classes and not just the most frequent ones. In this\npaper, we provide a theoretical understanding of the long-trail detection\nproblem. We show how the commonly used mean average precision evaluation metric\non an unknown test set is bound by a margin-based binary classification error\non a long-tailed object detection training set. We optimize margin-based binary\nclassification error with a novel surrogate objective called \\textbf{Effective\nClass-Margin Loss} (ECM). The ECM loss is simple, theoretically well-motivated,\nand outperforms other heuristic counterparts on LVIS v1 benchmark over a wide\nrange of architecture and detectors. Code is available at\n\\url{https://github.com/janghyuncho/ECM-Loss}.\n","authors":["Jang Hyun Cho","Philipp Krähenbühl"],"pdf_url":"https://arxiv.org/pdf/2301.09724v1.pdf","comment":"ECCV 2022 Oral. Code is available at\n  https://github.com/janghyuncho/ECM-Loss"},{"id":"http://arxiv.org/abs/2202.05255v3","updated":"2023-01-23T20:52:00Z","published":"2022-02-10T18:57:17Z","title":"Topogivity: A Machine-Learned Chemical Rule for Discovering Topological\n  Materials","summary":"  Topological materials present unconventional electronic properties that make\nthem attractive for both basic science and next-generation technological\napplications. The majority of currently known topological materials have been\ndiscovered using methods that involve symmetry-based analysis of the quantum\nwavefunction. Here we use machine learning to develop a simple-to-use heuristic\nchemical rule that diagnoses with a high accuracy whether a material is\ntopological using only its chemical formula. This heuristic rule is based on a\nnotion that we term topogivity, a machine-learned numerical value for each\nelement that loosely captures its tendency to form topological materials. We\nnext implement a high-throughput procedure for discovering topological\nmaterials based on the heuristic topogivity-rule prediction followed by ab\ninitio validation. This way, we discover new topological materials that are not\ndiagnosable using symmetry indicators, including several that may be promising\nfor experimental observation.\n","authors":["Andrew Ma","Yang Zhang","Thomas Christensen","Hoi Chun Po","Li Jing","Liang Fu","Marin Soljačić"],"pdf_url":"https://arxiv.org/pdf/2202.05255v3.pdf","comment":"Main text: 6 pages, 3 figures; supplementary materials: 43 pages, 62\n  figures, 5 tables"},{"id":"http://arxiv.org/abs/2111.04597v2","updated":"2023-01-23T20:46:51Z","published":"2021-11-08T16:09:39Z","title":"Neyman-Pearson Multi-class Classification via Cost-sensitive Learning","summary":"  Most existing classification methods aim to minimize the overall\nmisclassification error rate. However, in applications, different types of\nerrors can have different consequences. Two popular paradigms have been\ndeveloped to account for this asymmetry issue: the Neyman-Pearson (NP) paradigm\nand the cost-sensitive (CS) paradigm. Compared to the CS paradigm, the NP\nparadigm does not require a specification of costs. Most previous works on the\nNP paradigm focused on the binary case. In this work, we study the multi-class\nNP problem by connecting it to the CS problem and propose two algorithms. We\nextend the NP oracle inequalities and consistency from the binary case to the\nmulti-class case, showing that our two algorithms enjoy these properties under\ncertain conditions. The simulation and real data studies demonstrate the\neffectiveness of our algorithms. To our knowledge, this is the first work to\nsolve the multi-class NP problem via cost-sensitive learning techniques with\ntheoretical guarantees. The proposed algorithms are implemented in the R\npackage npcs on CRAN.\n","authors":["Ye Tian","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2111.04597v2.pdf","comment":"53 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.09715v1","updated":"2023-01-23T20:43:26Z","published":"2023-01-23T20:43:26Z","title":"PRIMEQA: The Prime Repository for State-of-the-Art MultilingualQuestion\n  Answering Research and Development","summary":"  The field of Question Answering (QA) has made remarkable progress in recent\nyears, thanks to the advent of large pre-trained language models, newer\nrealistic benchmark datasets with leaderboards, and novel algorithms for key\ncomponents such as retrievers and readers. In this paper, we introduce PRIMEQA:\na one-stop and open-source QA repository with an aim to democratize QA\nre-search and facilitate easy replication of state-of-the-art (SOTA) QA\nmethods. PRIMEQA supports core QA functionalities like retrieval and reading\ncomprehension as well as auxiliary capabilities such as question generation.It\nhas been designed as an end-to-end toolkit for various use cases: building\nfront-end applications, replicating SOTA methods on pub-lic benchmarks, and\nexpanding pre-existing methods. PRIMEQA is available at :\nhttps://github.com/primeqa.\n","authors":["Avirup Sil","Jaydeep Sen","Bhavani Iyer","Martin Franz","Kshitij Fadnis","Mihaela Bornea","Sara Rosenthal","Scott McCarley","Rong Zhang","Vishwajeet Kumar","Yulong Li","Md Arafat Sultan","Riyaz Bhat","Radu Florian","Salim Roukos"],"pdf_url":"https://arxiv.org/pdf/2301.09715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09709v1","updated":"2023-01-23T20:32:41Z","published":"2023-01-23T20:32:41Z","title":"On The Convergence Of Policy Iteration-Based Reinforcement Learning With\n  Monte Carlo Policy Evaluation","summary":"  A common technique in reinforcement learning is to evaluate the value\nfunction from Monte Carlo simulations of a given policy, and use the estimated\nvalue function to obtain a new policy which is greedy with respect to the\nestimated value function. A well-known longstanding open problem in this\ncontext is to prove the convergence of such a scheme when the value function of\na policy is estimated from data collected from a single sample path obtained\nfrom implementing the policy (see page 99 of [Sutton and Barto, 2018], page 8\nof [Tsitsiklis, 2002]). We present a solution to the open problem by showing\nthat a first-visit version of such a policy iteration scheme indeed converges\nto the optimal policy provided that the policy improvement step uses lookahead\n[Silver et al., 2016, Mnih et al., 2016, Silver et al., 2017b] rather than a\nsimple greedy policy improvement. We provide results both for the original open\nproblem in the tabular setting and also present extensions to the function\napproximation setting, where we show that the policy resulting from the\nalgorithm performs close to the optimal policy within a function approximation\nerror.\n","authors":["Anna Winnicki","R. Srikant"],"pdf_url":"https://arxiv.org/pdf/2301.09709v1.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2301.09703v1","updated":"2023-01-23T20:23:35Z","published":"2023-01-23T20:23:35Z","title":"Two-Stage Learning For the Flexible Job Shop Scheduling Problem","summary":"  The Flexible Job-shop Scheduling Problem (FJSP) is an important combinatorial\noptimization problem that arises in manufacturing and service settings. FJSP is\ncomposed of two subproblems, an assignment problem that assigns tasks to\nmachines, and a scheduling problem that determines the starting times of tasks\non their chosen machines. Solving FJSP instances of realistic size and\ncomposition is an ongoing challenge even under simplified, deterministic\nassumptions. Motivated by the inevitable randomness and uncertainties in supply\nchains, manufacturing, and service operations, this paper investigates the\npotential of using a deep learning framework to generate fast and accurate\napproximations for FJSP. In particular, this paper proposes a two-stage\nlearning framework 2SLFJSP that explicitly models the hierarchical nature of\nFJSP decisions, uses a confidence-aware branching scheme to generate\nappropriate instances for the scheduling stage from the assignment predictions\nand leverages a novel symmetry-breaking formulation to improve learnability.\n2SL-FJSP is evaluated on instances from the FJSP benchmark library. Results\nshow that 2SL-FJSP can generate high-quality solutions in milliseconds,\noutperforming a state-of-the-art reinforcement learning approach recently\nproposed in the literature, and other heuristics commonly used in practice.\n","authors":["Wenbo Chen","Reem Khir","Pascal Van Hentenryck"],"pdf_url":"https://arxiv.org/pdf/2301.09703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09702v1","updated":"2023-01-23T20:11:24Z","published":"2023-01-23T20:11:24Z","title":"Illumination Variation Correction Using Image Synthesis For Unsupervised\n  Domain Adaptive Person Re-Identification","summary":"  Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to\nlearn identity information from labeled images in source domains and apply it\nto unlabeled images in a target domain. One major issue with many unsupervised\nre-identification methods is that they do not perform well relative to large\ndomain variations such as illumination, viewpoint, and occlusions. In this\npaper, we propose a Synthesis Model Bank (SMB) to deal with illumination\nvariation in unsupervised person re-ID. The proposed SMB consists of several\nconvolutional neural networks (CNN) for feature extraction and Mahalanobis\nmatrices for distance metrics. They are trained using synthetic data with\ndifferent illumination conditions such that their synergistic effect makes the\nSMB robust against illumination variation. To better quantify the illumination\nintensity and improve the quality of synthetic images, we introduce a new 3D\nvirtual-human dataset for GAN-based image synthesis. From our experiments, the\nproposed SMB outperforms other synthesis methods on several re-ID benchmarks.\n","authors":["Jiaqi Guo","Amy R. Reibman","Edward J. Delp"],"pdf_url":"https://arxiv.org/pdf/2301.09702v1.pdf","comment":"10 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2301.09696v1","updated":"2023-01-23T19:57:58Z","published":"2023-01-23T19:57:58Z","title":"Optimizing the Noise in Self-Supervised Learning: from Importance\n  Sampling to Noise-Contrastive Estimation","summary":"  Self-supervised learning is an increasingly popular approach to unsupervised\nlearning, achieving state-of-the-art results. A prevalent approach consists in\ncontrasting data points and noise points within a classification task: this\nrequires a good noise distribution which is notoriously hard to specify. While\na comprehensive theory is missing, it is widely assumed that the optimal noise\ndistribution should in practice be made equal to the data distribution, as in\nGenerative Adversarial Networks (GANs). We here empirically and theoretically\nchallenge this assumption. We turn to Noise-Contrastive Estimation (NCE) which\ngrounds this self-supervised task as an estimation problem of an energy-based\nmodel of the data. This ties the optimality of the noise distribution to the\nsample efficiency of the estimator, which is rigorously defined as its\nasymptotic variance, or mean-squared error. In the special case where the\nnormalization constant only is unknown, we show that NCE recovers a family of\nImportance Sampling estimators for which the optimal noise is indeed equal to\nthe data distribution. However, in the general case where the energy is also\nunknown, we prove that the optimal noise density is the data density multiplied\nby a correction term based on the Fisher score. In particular, the optimal\nnoise distribution is different from the data distribution, and is even from a\ndifferent family. Nevertheless, we soberly conclude that the optimal noise may\nbe hard to sample from, and the gain in efficiency can be modest compared to\nchoosing the noise distribution equal to the data's.\n","authors":["Omar Chehab","Alexandre Gramfort","Aapo Hyvarinen"],"pdf_url":"https://arxiv.org/pdf/2301.09696v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.01110"},{"id":"http://arxiv.org/abs/2301.09689v1","updated":"2023-01-23T19:35:59Z","published":"2023-01-23T19:35:59Z","title":"Graph Neural Networks for Decentralized Multi-Agent Perimeter Defense","summary":"  In this work, we study the problem of decentralized multi-agent perimeter\ndefense that asks for computing actions for defenders with local perceptions\nand communications to maximize the capture of intruders. One major challenge\nfor practical implementations is to make perimeter defense strategies scalable\nfor large-scale problem instances. To this end, we leverage graph neural\nnetworks (GNNs) to develop an imitation learning framework that learns a\nmapping from defenders' local perceptions and their communication graph to\ntheir actions. The proposed GNN-based learning network is trained by imitating\na centralized expert algorithm such that the learned actions are close to that\ngenerated by the expert algorithm. We demonstrate that our proposed network\nperforms closer to the expert algorithm and is superior to other baseline\nalgorithms by capturing more intruders. Our GNN-based network is trained at a\nsmall scale and can be generalized to large-scale cases. We run perimeter\ndefense games in scenarios with different team sizes and configurations to\ndemonstrate the performance of the learned network.\n","authors":["Elijah S. Lee","Lifeng Zhou","Alejandro Ribeiro","Vijay Kumar"],"pdf_url":"https://arxiv.org/pdf/2301.09689v1.pdf","comment":"20 pages, 10 figures. Published in Frontiers in Control Engineering\n  2023. arXiv admin note: substantial text overlap with arXiv:2211.01757"},{"id":"http://arxiv.org/abs/2301.09685v1","updated":"2023-01-23T19:26:34Z","published":"2023-01-23T19:26:34Z","title":"Noisy Parallel Data Alignment","summary":"  An ongoing challenge in current natural language processing is how its major\nadvancements tend to disproportionately favor resource-rich languages, leaving\na significant number of under-resourced languages behind. Due to the lack of\nresources required to train and evaluate models, most modern language\ntechnologies are either nonexistent or unreliable to process endangered, local,\nand non-standardized languages. Optical character recognition (OCR) is often\nused to convert endangered language documents into machine-readable data.\nHowever, such OCR output is typically noisy, and most word alignment models are\nnot built to work under such noisy conditions. In this work, we study the\nexisting word-level alignment models under noisy settings and aim to make them\nmore robust to noisy data. Our noise simulation and structural biasing method,\ntested on multiple language pairs, manages to reduce the alignment error rate\non a state-of-the-art neural-based alignment model up to 59.6%.\n","authors":["Ruoyu Xie","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2301.09685v1.pdf","comment":"Accepted for publication in EACL 2023"},{"id":"http://arxiv.org/abs/2301.09680v1","updated":"2023-01-23T19:23:10Z","published":"2023-01-23T19:23:10Z","title":"Quantum Heavy-tailed Bandits","summary":"  In this paper, we study multi-armed bandits (MAB) and stochastic linear\nbandits (SLB) with heavy-tailed rewards and quantum reward oracle. Unlike the\nprevious work on quantum bandits that assumes bounded/sub-Gaussian\ndistributions for rewards, here we investigate the quantum bandits problem\nunder a weaker assumption that the distributions of rewards only have bounded\n$(1+v)$-th moment for some $v\\in (0,1]$. In order to achieve regret\nimprovements for heavy-tailed bandits, we first propose a new quantum mean\nestimator for heavy-tailed distributions, which is based on the Quantum Monte\nCarlo Mean Estimator and achieves a quadratic improvement of estimation error\ncompared to the classical one. Based on our quantum mean estimator, we focus on\nquantum heavy-tailed MAB and SLB and propose quantum algorithms based on the\nUpper Confidence Bound (UCB) framework for both problems with\n$\\Tilde{O}(T^{\\frac{1-v}{1+v}})$ regrets, polynomially improving the dependence\nin terms of $T$ as compared to classical (near) optimal regrets of\n$\\Tilde{O}(T^{\\frac{1}{1+v}})$, where $T$ is the number of rounds. Finally,\nexperiments also support our theoretical results and show the effectiveness of\nour proposed methods.\n","authors":["Yulian Wu","Chaowen Guan","Vaneet Aggarwal","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09680v1.pdf","comment":"Online learning; Quantum machine learning"},{"id":"http://arxiv.org/abs/2009.01797v3","updated":"2023-01-23T19:18:29Z","published":"2020-09-03T16:56:36Z","title":"A Wholistic View of Continual Learning with Deep Neural Networks:\n  Forgotten Lessons and the Bridge to Active and Open World Learning","summary":"  Current deep learning methods are regarded as favorable if they empirically\nperform well on dedicated test sets. This mentality is seamlessly reflected in\nthe resurfacing area of continual learning, where consecutively arriving data\nis investigated. The core challenge is framed as protecting previously acquired\nrepresentations from being catastrophically forgotten. However, comparison of\nindividual methods is nevertheless performed in isolation from the real world\nby monitoring accumulated benchmark test set performance. The closed world\nassumption remains predominant, i.e. models are evaluated on data that is\nguaranteed to originate from the same distribution as used for training. This\nposes a massive challenge as neural networks are well known to provide\noverconfident false predictions on unknown and corrupted instances. In this\nwork we critically survey the literature and argue that notable lessons from\nopen set recognition, identifying unknown examples outside of the observed set,\nand the adjacent field of active learning, querying data to maximize the\nexpected performance gain, are frequently overlooked in the deep learning era.\nHence, we propose a consolidated view to bridge continual learning, active\nlearning and open set recognition in deep neural networks. Finally, the\nestablished synergies are supported empirically, showing joint improvement in\nalleviating catastrophic forgetting, querying data, selecting task orders,\nwhile exhibiting robust open world application.\n","authors":["Martin Mundt","Yongwon Hong","Iuliia Pliushch","Visvanathan Ramesh"],"pdf_url":"https://arxiv.org/pdf/2009.01797v3.pdf","comment":"Accepted for publication at Neural Networks in open-access form.\n  Final version available at: https://doi.org/10.1016/j.neunet.2023.01.014"},{"id":"http://arxiv.org/abs/2102.11598v3","updated":"2023-01-23T19:14:32Z","published":"2021-02-23T10:19:04Z","title":"Gradient-adjusted Incremental Target Propagation Provides Effective\n  Credit Assignment in Deep Neural Networks","summary":"  Many of the recent advances in the field of artificial intelligence have been\nfueled by the highly successful backpropagation of error (BP) algorithm, which\nefficiently solves the credit assignment problem in artificial neural networks.\nHowever, it is unlikely that BP is implemented in its usual form within\nbiological neural networks, because of its reliance on non-local information in\npropagating error gradients. Since biological neural networks are capable of\nhighly efficient learning and responses from BP trained models can be related\nto neural responses, it seems reasonable that a biologically viable\napproximation of BP underlies synaptic plasticity in the brain.\nGradient-adjusted incremental target propagation (GAIT-prop or GP for short)\nhas recently been derived directly from BP and has been shown to successfully\ntrain networks in a more biologically plausible manner. However, so far, GP has\nonly been shown to work on relatively low-dimensional problems, such as\nhandwritten-digit recognition. This work addresses some of the scaling issues\nin GP and shows it to perform effective multi-layer credit assignment in deeper\nnetworks and on the much more challenging ImageNet dataset.\n","authors":["Sander Dalm","Nasir Ahmad","Luca Ambrogioni","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2102.11598v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09671v1","updated":"2023-01-23T19:11:43Z","published":"2023-01-23T19:11:43Z","title":"Flexible conditional density estimation for time series","summary":"  This paper introduces FlexCodeTS, a new conditional density estimator for\ntime series. FlexCodeTS is a flexible nonparametric conditional density\nestimator, which can be based on an arbitrary regression method. It is shown\nthat FlexCodeTS inherits the rate of convergence of the chosen regression\nmethod. Hence, FlexCodeTS can adapt its convergence by employing the regression\nmethod that best fits the structure of data. From an empirical perspective,\nFlexCodeTS is compared to NNKCDE and GARCH in both simulated and real data.\nFlexCodeTS is shown to generally obtain the best performance among the selected\nmethods according to either the CDE loss or the pinball loss.\n","authors":["Gustavo Grivol","Rafael Izbicki","Alex A. Okuno","Rafael B. Stern"],"pdf_url":"https://arxiv.org/pdf/2301.09671v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2209.06257v3","updated":"2023-01-23T19:10:13Z","published":"2022-09-13T18:31:23Z","title":"A computational framework for physics-informed symbolic regression with\n  straightforward integration of domain knowledge","summary":"  Discovering a meaningful symbolic expression that explains experimental data\nis a fundamental challenge in many scientific fields. We present a novel,\nopen-source computational framework called Scientist-Machine Equation Detector\n(SciMED), which integrates scientific discipline wisdom in a\nscientist-in-the-loop approach, with state-of-the-art symbolic regression (SR)\nmethods. SciMED combines a wrapper selection method, that is based on a genetic\nalgorithm, with automatic machine learning and two levels of SR methods. We\ntest SciMED on five configurations of a settling sphere, with and without\naerodynamic non-linear drag force, and with excessive noise in the\nmeasurements. We show that SciMED is sufficiently robust to discover the\ncorrect physically meaningful symbolic expressions from the data, and\ndemonstrate how the integration of domain knowledge enhances its performance.\nOur results indicate better performance on these tasks than the\nstate-of-the-art SR software packages , even in cases where no knowledge is\nintegrated. Moreover, we demonstrate how SciMED can alert the user about\npossible missing features, unlike the majority of current SR systems.\n","authors":["Liron Simon Keren","Alex Liberzon","Teddy Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2209.06257v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10952v2","updated":"2023-01-23T19:07:39Z","published":"2022-10-20T01:55:59Z","title":"Autoencoded sparse Bayesian in-IRT factorization, calibration, and\n  amortized inference for the Work Disability Functional Assessment Battery","summary":"  The Work Disability Functional Assessment Battery (WD-FAB) is a\nmultidimensional item response theory (IRT) instrument designed for assessing\nwork-related mental and physical function based on responses to an item bank.\nIn prior iterations it was developed using traditional means -- linear\nfactorization and null hypothesis statistical testing for item\npartitioning/selection, and finally, posthoc calibration of disjoint\nunidimensional IRT models. As a result, the WD-FAB, like many other IRT\ninstruments, is a posthoc model. Its item partitioning, based on exploratory\nfactor analysis, is blind to the final nonlinear IRT model and is not performed\nin a manner consistent with goodness of fit to the final model. In this\nmanuscript, we develop a Bayesian hierarchical model for self-consistently\nperforming the following simultaneous tasks: scale factorization, item\nselection, parameter identification, and response scoring. This method uses\nsparsity-based shrinkage to obviate the linear factorization and null\nhypothesis statistical tests that are usually required for developing\nmultidimensional IRT models, so that item partitioning is consistent with the\nultimate nonlinear factor model. We also analogize our multidimensional IRT\nmodel to probabilistic autoencoders, specifying an encoder function that\namortizes the inference of ability parameters from item responses. The encoder\nfunction is equivalent to the \"VBE\" step in a stochastic variational Bayesian\nexpectation maximization (VBEM) procedure that we use for approxiamte Bayesian\ninference on the entire model. We use the method on a sample of WD-FAB item\nresponses and compare the resulting item discriminations to those obtained\nusing the traditional posthoc method.\n","authors":["Joshua C. Chang","Carson C. Chow","Julia Porcino"],"pdf_url":"https://arxiv.org/pdf/2210.10952v2.pdf","comment":"Accepted to AISTATS 2023 and the AAAI 2023 AI for Social Good\n  workshop"},{"id":"http://arxiv.org/abs/2301.09656v1","updated":"2023-01-23T19:00:02Z","published":"2023-01-23T19:00:02Z","title":"Selective Explanations: Leveraging Human Input to Align Explainable AI","summary":"  While a vast collection of explainable AI (XAI) algorithms have been\ndeveloped in recent years, they are often criticized for significant gaps with\nhow humans produce and consume explanations. As a result, current XAI\ntechniques are often found to be hard to use and lack effectiveness. In this\nwork, we attempt to close these gaps by making AI explanations selective -- a\nfundamental property of human explanations -- by selectively presenting a\nsubset from a large set of model reasons based on what aligns with the\nrecipient's preferences. We propose a general framework for generating\nselective explanations by leveraging human input on a small sample. This\nframework opens up a rich design space that accounts for different selectivity\ngoals, types of input, and more. As a showcase, we use a decision-support task\nto explore selective explanations based on what the decision-maker would\nconsider relevant to the decision task. We conducted two experimental studies\nto examine three out of a broader possible set of paradigms based on our\nproposed framework: in Study 1, we ask the participants to provide their own\ninput to generate selective explanations, with either open-ended or\ncritique-based input. In Study 2, we show participants selective explanations\nbased on input from a panel of similar users (annotators). Our experiments\ndemonstrate the promise of selective explanations in reducing over-reliance on\nAI and improving decision outcomes and subjective perceptions of the AI, but\nalso paint a nuanced picture that attributes some of these positive effects to\nthe opportunity to provide one's own input to augment AI explanations. Overall,\nour work proposes a novel XAI framework inspired by human communication\nbehaviors and demonstrates its potentials to encourage future work to better\nalign AI explanations with human production and consumption of explanations.\n","authors":["Vivian Lai","Yiming Zhang","Chacha Chen","Q. Vera Liao","Chenhao Tan"],"pdf_url":"https://arxiv.org/pdf/2301.09656v1.pdf","comment":"21 pages, 25 figures"},{"id":"http://arxiv.org/abs/2301.09620v1","updated":"2023-01-23T18:40:21Z","published":"2023-01-23T18:40:21Z","title":"Tracking the industrial growth of modern China with high-resolution\n  panchromatic imagery: A sequential convolutional approach","summary":"  Due to insufficient or difficult to obtain data on development in\ninaccessible regions, remote sensing data is an important tool for interested\nstakeholders to collect information on economic growth. To date, no studies\nhave utilized deep learning to estimate industrial growth at the level of\nindividual sites. In this study, we harness high-resolution panchromatic\nimagery to estimate development over time at 419 industrial sites in the\nPeople's Republic of China using a multi-tier computer vision framework. We\npresent two methods for approximating development: (1) structural area coverage\nestimated through a Mask R-CNN segmentation algorithm, and (2) imputing\ndevelopment directly with visible & infrared radiance from the Visible Infrared\nImaging Radiometer Suite (VIIRS). Labels generated from these methods are\ncomparatively evaluated and tested. On a dataset of 2,078 50 cm resolution\nimages spanning 19 years, the results indicate that two dimensions of\nindustrial development can be estimated using high-resolution daytime imagery,\nincluding (a) the total square meters of industrial development (average error\nof 0.021 $\\textrm{km}^2$), and (b) the radiance of lights (average error of 9.8\n$\\mathrm{\\frac{nW}{cm^{2}sr}}$). Trend analysis of the techniques reveal\nestimates from a Mask R-CNN-labeled CNN-LSTM track ground truth measurements\nmost closely. The Mask R-CNN estimates positive growth at every site from the\noldest image to the most recent, with an average change of 4,084\n$\\textrm{m}^2$.\n","authors":["Ethan Brewer","Zhonghui Lv","Dan Runfola"],"pdf_url":"https://arxiv.org/pdf/2301.09620v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2206.08312v2","updated":"2023-01-23T18:49:47Z","published":"2022-06-16T17:17:44Z","title":"SoundSpaces 2.0: A Simulation Platform for Visual-Acoustic Learning","summary":"  We introduce SoundSpaces 2.0, a platform for on-the-fly geometry-based audio\nrendering for 3D environments. Given a 3D mesh of a real-world environment,\nSoundSpaces can generate highly realistic acoustics for arbitrary sounds\ncaptured from arbitrary microphone locations. Together with existing 3D visual\nassets, it supports an array of audio-visual research tasks, such as\naudio-visual navigation, mapping, source localization and separation, and\nacoustic matching. Compared to existing resources, SoundSpaces 2.0 has the\nadvantages of allowing continuous spatial sampling, generalization to novel\nenvironments, and configurable microphone and material properties. To our\nknowledge, this is the first geometry-based acoustic simulation that offers\nhigh fidelity and realism while also being fast enough to use for embodied\nlearning. We showcase the simulator's properties and benchmark its performance\nagainst real-world audio measurements. In addition, we demonstrate two\ndownstream tasks -- embodied navigation and far-field automatic speech\nrecognition -- and highlight sim2real performance for the latter. SoundSpaces\n2.0 is publicly available to facilitate wider research for perceptual systems\nthat can both see and hear.\n","authors":["Changan Chen","Carl Schissler","Sanchit Garg","Philip Kobernik","Alexander Clegg","Paul Calamia","Dhruv Batra","Philip W Robinson","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2206.08312v2.pdf","comment":"Camera-ready version. Website: https://soundspaces.org. Project page:\n  https://vision.cs.utexas.edu/projects/soundspaces2"},{"id":"http://arxiv.org/abs/2301.09492v1","updated":"2023-01-23T15:40:47Z","published":"2023-01-23T15:40:47Z","title":"Understanding Context to Capture when Reconstructing Meaningful Spaces\n  for Remote Instruction and Connecting in XR","summary":"  Recent technological advances are enabling HCI researchers to explore\ninteraction possibilities for remote XR collaboration using high-fidelity\nreconstructions of physical activity spaces. However, creating these\nreconstructions often lacks user involvement with an overt focus on capturing\nsensory context that does not necessarily augment an informal social\nexperience. This work seeks to understand social context that can be important\nfor reconstruction to enable XR applications for informal instructional\nscenarios. Our study involved the evaluation of an XR remote guidance prototype\nby 8 intergenerational groups of closely related gardeners using\nreconstructions of personally meaningful spaces in their gardens. Our findings\ncontextualize physical objects and areas with various motivations related to\ngardening and detail perceptions of XR that might affect the use of\nreconstructions for remote interaction. We discuss implications for user\ninvolvement to create reconstructions that better translate real-world\nexperience, encourage reflection, incorporate privacy considerations, and\npreserve shared experiences with XR as a medium for informal intergenerational\nactivities.\n","authors":["Hanuma Teja Maddali","Amanda Lazar"],"pdf_url":"https://arxiv.org/pdf/2301.09492v1.pdf","comment":"26 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2212.11541v2","updated":"2023-01-23T06:58:44Z","published":"2022-12-22T08:36:55Z","title":"Generative Colorization of Structured Mobile Web Pages","summary":"  Color is a critical design factor for web pages, affecting important factors\nsuch as viewer emotions and the overall trust and satisfaction of a website.\nEffective coloring requires design knowledge and expertise, but if this process\ncould be automated through data-driven modeling, efficient exploration and\nalternative workflows would be possible. However, this direction remains\nunderexplored due to the lack of a formalization of the web page colorization\nproblem, datasets, and evaluation protocols. In this work, we propose a new\ndataset consisting of e-commerce mobile web pages in a tractable format, which\nare created by simplifying the pages and extracting canonical color styles with\na common web browser. The web page colorization problem is then formalized as a\ntask of estimating plausible color styles for a given web page content with a\ngiven hierarchical structure of the elements. We present several\nTransformer-based methods that are adapted to this task by prepending\nstructural message passing to capture hierarchical relationships between\nelements. Experimental results, including a quantitative evaluation designed\nfor this task, demonstrate the advantages of our methods over statistical and\nimage colorization methods. The code is available at\nhttps://github.com/CyberAgentAILab/webcolor.\n","authors":["Kotaro Kikuchi","Naoto Inoue","Mayu Otani","Edgar Simo-Serra","Kota Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2212.11541v2.pdf","comment":"Accepted to WACV 2023"}]},"2023-01-22T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.09211v1","updated":"2023-01-22T21:47:26Z","published":"2023-01-22T21:47:26Z","title":"An Empirical Study of Metrics to Measure Representational Harms in\n  Pre-Trained Language Models","summary":"  Large-scale Pre-Trained Language Models (PTLMs) capture knowledge from\nmassive human-written data which contains latent societal biases and toxic\ncontents. In this paper, we leverage the primary task of PTLMs, i.e., language\nmodeling, and propose a new metric to quantify manifested implicit\nrepresentational harms in PTLMs towards 13 marginalized demographics. Using\nthis metric, we conducted an empirical analysis of 24 widely used PTLMs. Our\nanalysis provides insights into the correlation between the proposed metric in\nthis work and other related metrics for representational harm. We observe that\nour metric correlates with most of the gender-specific metrics in the\nliterature. Through extensive experiments, we explore the connections between\nPTLMs architectures and representational harms across two dimensions: depth and\nwidth of the networks. We found that prioritizing depth over width, mitigates\nrepresentational harms in some PTLMs. Our code and data can be found at\nhttps://github.com/microsoft/SafeNLP.\n","authors":["Saghar Hosseini","Hamid Palangi","Ahmed Hassan Awadallah"],"pdf_url":"https://arxiv.org/pdf/2301.09211v1.pdf","comment":"17 pages,"},{"id":"http://arxiv.org/abs/2301.09209v1","updated":"2023-01-22T21:30:12Z","published":"2023-01-22T21:30:12Z","title":"Summarize the Past to Predict the Future: Natural Language Descriptions\n  of Context Boost Multimodal Object Interaction","summary":"  We study the task of object interaction anticipation in egocentric videos.\nSuccessful prediction of future actions and objects requires an understanding\nof the spatio-temporal context formed by past actions and object relationships.\nWe propose TransFusion, a multimodal transformer-based architecture, that\neffectively makes use of the representational power of language by summarizing\npast actions concisely. TransFusion leverages pre-trained image captioning\nmodels and summarizes the caption, focusing on past actions and objects. This\naction context together with a single input frame is processed by a multimodal\nfusion module to forecast the next object interactions. Our model enables more\nefficient end-to-end learning by replacing dense video features with language\nrepresentations, allowing us to benefit from knowledge encoded in large\npre-trained models. Experiments on Ego4D and EPIC-KITCHENS-100 show the\neffectiveness of our multimodal fusion model and the benefits of using\nlanguage-based context summaries. Our method outperforms state-of-the-art\napproaches by 40.4% in overall mAP on the Ego4D test set. We show the\ngenerality of TransFusion via experiments on EPIC-KITCHENS-100. Video and code\nare available at: https://eth-ait.github.io/transfusion-proj/.\n","authors":["Razvan-George Pasca","Alexey Gavryushin","Yen-Ling Kuo","Otmar Hilliges","Xi Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11081v3","updated":"2023-01-22T19:08:58Z","published":"2022-05-23T06:54:56Z","title":"BanglaNLG and BanglaT5: Benchmarks and Resources for Evaluating\n  Low-Resource Natural Language Generation in Bangla","summary":"  This work presents BanglaNLG, a comprehensive benchmark for evaluating\nnatural language generation (NLG) models in Bangla, a widely spoken yet\nlow-resource language. We aggregate six challenging conditional text generation\ntasks under the BanglaNLG benchmark, introducing a new dataset on dialogue\ngeneration in the process. Then, using a clean corpus of 27.5 GB of Bangla\ndata, we pretrain BanglaT5, a sequence-to-sequence Transformer model for\nBangla. BanglaT5 achieves state-of-the-art performance in all of these tasks,\noutperforming several multilingual models by up to 9% absolute gain and 32%\nrelative gain. We are making the new dataset, the BanglaT5 language model, and\na leaderboard publicly available at https://github.com/csebuetnlp/BanglaNLG in\nthe hope of advancing future research and evaluation on Bangla NLG.\n","authors":["Abhik Bhattacharjee","Tahmid Hasan","Wasi Uddin Ahmad","Rifat Shahriyar"],"pdf_url":"https://arxiv.org/pdf/2205.11081v3.pdf","comment":"Accepted at the Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2301.09175v1","updated":"2023-01-22T18:22:55Z","published":"2023-01-22T18:22:55Z","title":"Ensemble Transfer Learning for Multilingual Coreference Resolution","summary":"  Entity coreference resolution is an important research problem with many\napplications, including information extraction and question answering.\nCoreference resolution for English has been studied extensively. However, there\nis relatively little work for other languages. A problem that frequently occurs\nwhen working with a non-English language is the scarcity of annotated training\ndata. To overcome this challenge, we design a simple but effective\nensemble-based framework that combines various transfer learning (TL)\ntechniques. We first train several models using different TL methods. Then,\nduring inference, we compute the unweighted average scores of the models'\npredictions to extract the final set of predicted clusters. Furthermore, we\nalso propose a low-cost TL method that bootstraps coreference resolution models\nby utilizing Wikipedia anchor texts. Leveraging the idea that the coreferential\nlinks naturally exist between anchor texts pointing to the same article, our\nmethod builds a sizeable distantly-supervised dataset for the target language\nthat consists of tens of thousands of documents. We can pre-train a model on\nthe pseudo-labeled dataset before finetuning it on the final target dataset.\nExperimental results on two benchmark datasets, OntoNotes and SemEval, confirm\nthe effectiveness of our methods. Our best ensembles consistently outperform\nthe baseline approach of simple training by up to 7.68% in the F1 score. These\nensembles also achieve new state-of-the-art results for three languages:\nArabic, Dutch, and Spanish.\n","authors":["Tuan Manh Lai","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2301.09175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09169v1","updated":"2023-01-22T17:41:29Z","published":"2023-01-22T17:41:29Z","title":"Representing Interlingual Meaning in Lexical Databases","summary":"  In today's multilingual lexical databases, the majority of the world's\nlanguages are under-represented. Beyond a mere issue of resource\nincompleteness, we show that existing lexical databases have structural\nlimitations that result in a reduced expressivity on culturally-specific words\nand in mapping them across languages. In particular, the lexical meaning space\nof dominant languages, such as English, is represented more accurately while\nlinguistically or culturally diverse languages are mapped in an approximate\nmanner. Our paper assesses state-of-the-art multilingual lexical databases and\nevaluates their strengths and limitations with respect to their expressivity on\nlexical phenomena of linguistic diversity.\n","authors":["Fausto Giunchiglia","Gabor Bella","Nandu Chandran Nair","Yang Chi","Hao Xu"],"pdf_url":"https://arxiv.org/pdf/2301.09169v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.04993v2","updated":"2023-01-22T15:05:58Z","published":"2022-07-11T16:36:14Z","title":"Embedding Recycling for Language Models","summary":"  Real-world applications of neural language models often involve running many\ndifferent models over the same corpus. The high computational cost of these\nruns has led to interest in techniques that can reuse the contextualized\nembeddings produced in previous runs to speed training and inference of future\nones. We refer to this approach as embedding recycling (ER). While multiple ER\ntechniques have been proposed, their practical effectiveness is still unknown\nbecause existing evaluations consider very few models and do not adequately\naccount for overhead costs. We perform an extensive evaluation of ER across\neight different models (17 to 900 million parameters) and fourteen tasks in\nEnglish. We show how a simple ER technique that caches activations from an\nintermediate layer of a pretrained model, and learns task-specific adapters on\nthe later layers, is broadly effective. For the best-performing baseline in our\nexperiments (DeBERTa-v2 XL), adding a precomputed cache results in a >90%\nspeedup during training and 87-91% speedup for inference, with negligible\nimpact on accuracy. Our analysis reveals important areas of future work.\n","authors":["Jon Saad-Falcon","Amanpreet Singh","Luca Soldaini","Mike D'Arcy","Arman Cohan","Doug Downey"],"pdf_url":"https://arxiv.org/pdf/2207.04993v2.pdf","comment":"EACL Findings 2023"},{"id":"http://arxiv.org/abs/2204.06092v2","updated":"2023-01-22T14:25:40Z","published":"2022-04-12T21:58:44Z","title":"ASQA: Factoid Questions Meet Long-Form Answers","summary":"  An abundance of datasets and availability of reliable evaluation metrics have\nresulted in strong progress in factoid question answering (QA). This progress,\nhowever, does not easily transfer to the task of long-form QA, where the goal\nis to answer questions that require in-depth explanations. The hurdles include\n(i) a lack of high-quality data, and (ii) the absence of a well-defined notion\nof the answer's quality. In this work, we address these problems by (i)\nreleasing a novel dataset and a task that we call ASQA (Answer Summaries for\nQuestions which are Ambiguous); and (ii) proposing a reliable metric for\nmeasuring performance on ASQA. Our task focuses on factoid questions that are\nambiguous, that is, have different correct answers depending on interpretation.\nAnswers to ambiguous questions should synthesize factual information from\nmultiple sources into a long-form summary that resolves the ambiguity. In\ncontrast to existing long-form QA tasks (such as ELI5), ASQA admits a clear\nnotion of correctness: a user faced with a good summary should be able to\nanswer different interpretations of the original ambiguous question. We use\nthis notion of correctness to define an automated metric of performance for\nASQA. Our analysis demonstrates an agreement between this metric and human\njudgments, and reveals a considerable gap between human performance and strong\nbaselines.\n","authors":["Ivan Stelmakh","Yi Luan","Bhuwan Dhingra","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2204.06092v2.pdf","comment":"A minor bug in computing the ROUGE score was fixed. The fix **did\n  not** result in any changes in observations and conclusions"},{"id":"http://arxiv.org/abs/2206.10658v3","updated":"2023-01-22T14:07:11Z","published":"2022-06-21T18:16:31Z","title":"Questions Are All You Need to Train a Dense Passage Retriever","summary":"  We introduce ART, a new corpus-level autoencoding approach for training dense\nretrieval models that does not require any labeled training data. Dense\nretrieval is a central challenge for open-domain tasks, such as Open QA, where\nstate-of-the-art methods typically require large supervised datasets with\ncustom hard-negative mining and denoising of positive examples. ART, in\ncontrast, only requires access to unpaired inputs and outputs (e.g. questions\nand potential answer documents). It uses a new document-retrieval autoencoding\nscheme, where (1) an input question is used to retrieve a set of evidence\ndocuments, and (2) the documents are then used to compute the probability of\nreconstructing the original question. Training for retrieval based on question\nreconstruction enables effective unsupervised learning of both document and\nquestion encoders, which can be later incorporated into complete Open QA\nsystems without any further finetuning. Extensive experiments demonstrate that\nART obtains state-of-the-art results on multiple QA retrieval benchmarks with\nonly generic initialization from a pre-trained language model, removing the\nneed for labeled data and task-specific losses.\n","authors":["Devendra Singh Sachan","Mike Lewis","Dani Yogatama","Luke Zettlemoyer","Joelle Pineau","Manzil Zaheer"],"pdf_url":"https://arxiv.org/pdf/2206.10658v3.pdf","comment":"Accepted to TACL, pre MIT Press publication version"},{"id":"http://arxiv.org/abs/2112.01922v3","updated":"2023-01-22T12:54:40Z","published":"2021-12-03T14:05:52Z","title":"MetaQA: Combining Expert Agents for Multi-Skill Question Answering","summary":"  The recent explosion of question answering (QA) datasets and models has\nincreased the interest in the generalization of models across multiple domains\nand formats by either training on multiple datasets or by combining multiple\nmodels. Despite the promising results of multi-dataset models, some domains or\nQA formats may require specific architectures, and thus the adaptability of\nthese models might be limited. In addition, current approaches for combining\nmodels disregard cues such as question-answer compatibility. In this work, we\npropose to combine expert agents with a novel, flexible, and training-efficient\narchitecture that considers questions, answer predictions, and\nanswer-prediction confidence scores to select the best answer among a list of\nanswer candidates. Through quantitative and qualitative experiments we show\nthat our model i) creates a collaboration between agents that outperforms\nprevious multi-agent and multi-dataset approaches in both in-domain and\nout-of-domain scenarios, ii) is highly data-efficient to train, and iii) can be\nadapted to any QA format. We release our code and a dataset of answer\npredictions from expert agents for 16 QA datasets to foster future developments\nof multi-agent systems on https://github.com/UKPLab/MetaQA.\n","authors":["Haritz Puerto","Gözde Gül Şahin","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2112.01922v3.pdf","comment":"Accepted at EACL 2023"},{"id":"http://arxiv.org/abs/2301.09112v1","updated":"2023-01-22T12:29:03Z","published":"2023-01-22T12:29:03Z","title":"Differentially Private Natural Language Models: Recent Advances and\n  Future Directions","summary":"  Recent developments in deep learning have led to great success in various\nnatural language processing (NLP) tasks. However, these applications may\ninvolve data that contain sensitive information. Therefore, how to achieve good\nperformance while also protect privacy of sensitive data is a crucial challenge\nin NLP. To preserve privacy, Differential Privacy (DP), which can prevent\nreconstruction attacks and protect against potential side knowledge, is\nbecoming a de facto technique for private data analysis. In recent years, NLP\nin DP models (DP-NLP) has been studied from different perspectives, which\ndeserves a comprehensive review. In this paper, we provide the first systematic\nreview of recent advances on DP deep learning models in NLP. In particular, we\nfirst discuss some differences and additional challenges of DP-NLP compared\nwith the standard DP deep learning. Then we investigate some existing work on\nDP-NLP and present its recent developments from two aspects: gradient\nperturbation based methods and embedding vector perturbation based methods. We\nalso discuss some challenges and future directions of this topic.\n","authors":["Lijie Hu","Ivan Habernal","Lei Shen","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09099v1","updated":"2023-01-22T10:41:58Z","published":"2023-01-22T10:41:58Z","title":"Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a\n  Case Study","summary":"  Several high-resource Text to Speech (TTS) systems currently produce natural,\nwell-established human-like speech. In contrast, low-resource languages,\nincluding Arabic, have very limited TTS systems due to the lack of resources.\nWe propose a fully unsupervised method for building TTS, including automatic\ndata selection and pre-training/fine-tuning strategies for TTS training, using\nbroadcast news as a case study. We show how careful selection of data, yet\nsmaller amounts, can improve the efficiency of TTS system in generating more\nnatural speech than a system trained on a bigger dataset. We adopt to propose\ndifferent approaches for the: 1) data: we applied automatic annotations using\nDNSMOS, automatic vowelization, and automatic speech recognition (ASR) for\nfixing transcriptions' errors; 2) model: we used transfer learning from\nhigh-resource language in TTS model and fine-tuned it with one hour broadcast\nrecording then we used this model to guide a FastSpeech2-based Conformer model\nfor duration. Our objective evaluation shows 3.9% character error rate (CER),\nwhile the groundtruth has 1.3% CER. As for the subjective evaluation, where 1\nis bad and 5 is excellent, our FastSpeech2-based Conformer model achieved a\nmean opinion score (MOS) of 4.4 for intelligibility and 4.2 for naturalness,\nwhere many annotators recognized the voice of the broadcaster, which proves the\neffectiveness of our proposed unsupervised method.\n","authors":["Massa Baali","Tomoki Hayashi","Hamdy Mubarak","Soumi Maiti","Shinji Watanabe","Wassim El-Hajj","Ahmed Ali"],"pdf_url":"https://arxiv.org/pdf/2301.09099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00522v2","updated":"2023-01-22T07:24:56Z","published":"2022-11-01T15:12:34Z","title":"TrimTail: Low-Latency Streaming ASR with Simple but Effective\n  Spectrogram-Level Length Penalty","summary":"  In this paper, we present TrimTail, a simple but effective emission\nregularization method to improve the latency of streaming ASR models. The core\nidea of TrimTail is to apply length penalty (i.e., by trimming trailing frames,\nsee Fig. 1-(b)) directly on the spectrogram of input utterances, which does not\nrequire any alignment. We demonstrate that TrimTail is computationally cheap\nand can be applied online and optimized with any training loss or any model\narchitecture on any dataset without any extra effort by applying it on various\nend-to-end streaming ASR networks either trained with CTC loss [1] or\nTransducer loss [2]. We achieve 100 $\\sim$ 200ms latency reduction with equal\nor even better accuracy on both Aishell-1 and Librispeech. Moreover, by using\nTrimTail, we can achieve a 400ms algorithmic improvement of User Sensitive\nDelay (USD) with an accuracy loss of less than 0.2.\n","authors":["Xingchen Song","Di Wu","Zhiyong Wu","Binbin Zhang","Yuekai Zhang","Zhendong Peng","Wenpeng Li","Fuping Pan","Changbao Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.00522v2.pdf","comment":"submitted to ICASSP 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2210.09520v4","updated":"2023-01-22T22:33:38Z","published":"2022-10-18T01:14:02Z","title":"Using Language to Extend to Unseen Domains","summary":"  It is expensive to collect training data for every possible domain that a\nvision model may encounter when deployed. We instead consider how simply\nverbalizing the training domain (e.g. \"photos of birds\") as well as domains we\nwant to extend to but do not have data for (e.g. \"paintings of birds\") can\nimprove robustness. Using a multimodal model with a joint image and language\nembedding space, our method LADS learns a transformation of the image\nembeddings from the training domain to each unseen test domain, while\npreserving task relevant information. Without using any images from the unseen\ntest domain, we show that over the extended domain containing both training and\nunseen test domains, LADS outperforms standard fine-tuning and ensemble\napproaches over a suite of four benchmarks targeting domain adaptation and\ndataset bias.\n","authors":["Lisa Dunlap","Clara Mohri","Devin Guillory","Han Zhang","Trevor Darrell","Joseph E. Gonzalez","Aditi Raghunathan","Anja Rohrbach"],"pdf_url":"https://arxiv.org/pdf/2210.09520v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09219v1","updated":"2023-01-22T22:14:25Z","published":"2023-01-22T22:14:25Z","title":"Applied Deep Learning to Identify and Localize Polyps from Endoscopic\n  Images","summary":"  Deep learning based neural networks have gained popularity for a variety of\nbiomedical imaging applications. In the last few years several works have shown\nthe use of these methods for colon cancer detection and the early results have\nbeen promising. These methods can potentially be utilized to assist doctor's\nand may help in identifying the number of lesions or abnormalities in a\ndiagnosis session. From our literature survey we found out that there is a lack\nof publicly available labeled data. Thus, as part of this work, we have aimed\nat open sourcing a dataset which contains annotations of polyps and ulcers.\nThis is the first dataset that's coming from India containing polyp and ulcer\nimages. The dataset can be used for detection and classification tasks. We also\nevaluated our dataset with several popular deep learning object detection\nmodels that's trained on large publicly available datasets and found out\nempirically that the model trained on one dataset works well on our dataset\nthat has data being captured in a different acquisition device.\n","authors":["Chandana Raju","Sumedh Vilas Datar","Kushala Hari","Kavin Vijay","Suma Ningappa"],"pdf_url":"https://arxiv.org/pdf/2301.09219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09213v1","updated":"2023-01-22T21:59:38Z","published":"2023-01-22T21:59:38Z","title":"FRAME: Fast and Robust Autonomous 3D point cloud Map-merging for\n  Egocentric multi-robot exploration","summary":"  This article presents a 3D point cloud map-merging framework for egocentric\nheterogeneous multi-robot exploration, based on overlap detection and\nalignment, that is independent of a manual initial guess or prior knowledge of\nthe robots' poses. The novel proposed solution utilizes state-of-the-art place\nrecognition learned descriptors, that through the framework's main pipeline,\noffer a fast and robust region overlap estimation, hence eliminating the need\nfor the time-consuming global feature extraction and feature matching process\nthat is typically used in 3D map integration. The region overlap estimation\nprovides a homogeneous rigid transform that is applied as an initial condition\nin the point cloud registration algorithm Fast-GICP, which provides the final\nand refined alignment. The efficacy of the proposed framework is experimentally\nevaluated based on multiple field multi-robot exploration missions in\nunderground environments, where both ground and aerial robots are deployed,\nwith different sensor configurations.\n","authors":["Nikolaos Stathoulopoulos","Anton Koval","Ali-akbar Agha-mohammadi","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2301.09213v1.pdf","comment":"to be published"},{"id":"http://arxiv.org/abs/2301.09209v1","updated":"2023-01-22T21:30:12Z","published":"2023-01-22T21:30:12Z","title":"Summarize the Past to Predict the Future: Natural Language Descriptions\n  of Context Boost Multimodal Object Interaction","summary":"  We study the task of object interaction anticipation in egocentric videos.\nSuccessful prediction of future actions and objects requires an understanding\nof the spatio-temporal context formed by past actions and object relationships.\nWe propose TransFusion, a multimodal transformer-based architecture, that\neffectively makes use of the representational power of language by summarizing\npast actions concisely. TransFusion leverages pre-trained image captioning\nmodels and summarizes the caption, focusing on past actions and objects. This\naction context together with a single input frame is processed by a multimodal\nfusion module to forecast the next object interactions. Our model enables more\nefficient end-to-end learning by replacing dense video features with language\nrepresentations, allowing us to benefit from knowledge encoded in large\npre-trained models. Experiments on Ego4D and EPIC-KITCHENS-100 show the\neffectiveness of our multimodal fusion model and the benefits of using\nlanguage-based context summaries. Our method outperforms state-of-the-art\napproaches by 40.4% in overall mAP on the Ego4D test set. We show the\ngenerality of TransFusion via experiments on EPIC-KITCHENS-100. Video and code\nare available at: https://eth-ait.github.io/transfusion-proj/.\n","authors":["Razvan-George Pasca","Alexey Gavryushin","Yen-Ling Kuo","Otmar Hilliges","Xi Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09190v1","updated":"2023-01-22T19:51:22Z","published":"2023-01-22T19:51:22Z","title":"Apples and Oranges? Assessing Image Quality over Content Recognition","summary":"  Image recognition and quality assessment are two important viewing tasks,\nwhile potentially following different visual mechanisms. This paper\ninvestigates if the two tasks can be performed in a multitask learning manner.\nA sequential spatial-channel attention module is proposed to simulate the\nvisual attention and contrast sensitivity mechanisms that are crucial for\ncontent recognition and quality assessment. Spatial attention is shared between\ncontent recognition and quality assessment, while channel attention is solely\nfor quality assessment. Such attention module is integrated into Transformer to\nbuild a uniform model for the two viewing tasks. The experimental results have\ndemonstrated that the proposed uniform model can achieve promising performance\nfor both quality assessment and content recognition tasks.\n","authors":["Junyong You"],"pdf_url":"https://arxiv.org/pdf/2301.09190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.13798v5","updated":"2023-01-22T18:34:16Z","published":"2022-07-27T21:18:58Z","title":"Look at Adjacent Frames: Video Anomaly Detection without Offline\n  Training","summary":"  We propose a solution to detect anomalous events in videos without the need\nto train a model offline. Specifically, our solution is based on a\nrandomly-initialized multilayer perceptron that is optimized online to\nreconstruct video frames, pixel-by-pixel, from their frequency information.\nBased on the information shifts between adjacent frames, an incremental learner\nis used to update parameters of the multilayer perceptron after observing each\nframe, thus allowing to detect anomalous events along the video stream.\nTraditional solutions that require no offline training are limited to operating\non videos with only a few abnormal frames. Our solution breaks this limit and\nachieves strong performance on benchmark datasets.\n","authors":["Yuqi Ouyang","Guodong Shen","Victor Sanchez"],"pdf_url":"https://arxiv.org/pdf/2207.13798v5.pdf","comment":"Accepted in ECCV 2022 RWS"},{"id":"http://arxiv.org/abs/2301.09174v1","updated":"2023-01-22T18:18:20Z","published":"2023-01-22T18:18:20Z","title":"MATT: Multimodal Attention Level Estimation for e-learning Platforms","summary":"  This work presents a new multimodal system for remote attention level\nestimation based on multimodal face analysis. Our multimodal approach uses\ndifferent parameters and signals obtained from the behavior and physiological\nprocesses that have been related to modeling cognitive load such as faces\ngestures (e.g., blink rate, facial actions units) and user actions (e.g., head\npose, distance to the camera). The multimodal system uses the following modules\nbased on Convolutional Neural Networks (CNNs): Eye blink detection, head pose\nestimation, facial landmark detection, and facial expression features. First,\nwe individually evaluate the proposed modules in the task of estimating the\nstudent's attention level captured during online e-learning sessions. For that\nwe trained binary classifiers (high or low attention) based on Support Vector\nMachines (SVM) for each module. Secondly, we find out to what extent multimodal\nscore level fusion improves the attention level estimation. The mEBAL database\nis used in the experimental framework, a public multi-modal database for\nattention level estimation obtained in an e-learning environment that contains\ndata from 38 users while conducting several e-learning tasks of variable\ndifficulty (creating changes in student cognitive loads).\n","authors":["Roberto Daza","Luis F. Gomez","Aythami Morales","Julian Fierrez","Ruben Tolosana","Ruth Cobos","Javier Ortega-Garcia"],"pdf_url":"https://arxiv.org/pdf/2301.09174v1.pdf","comment":"Preprint of the paper presented to the Workshop on Artificial\n  Intelligence for Education (AI4EDU) of AAAI 2023"},{"id":"http://arxiv.org/abs/2301.09164v1","updated":"2023-01-22T17:12:58Z","published":"2023-01-22T17:12:58Z","title":"Unifying Synergies between Self-supervised Learning and Dynamic\n  Computation","summary":"  Self-supervised learning (SSL) approaches have made major strides forward by\nemulating the performance of their supervised counterparts on several computer\nvision benchmarks. This, however, comes at a cost of substantially larger model\nsizes, and computationally expensive training strategies, which eventually lead\nto larger inference times making it impractical for resource constrained\nindustrial settings. Techniques like knowledge distillation (KD), dynamic\ncomputation (DC), and pruning are often used to obtain a lightweight\nsub-network, which usually involves multiple epochs of fine-tuning of a large\npre-trained model, making it more computationally challenging.\n  In this work we propose a novel perspective on the interplay between SSL and\nDC paradigms that can be leveraged to simultaneously learn a dense and gated\n(sparse/lightweight) sub-network from scratch offering a good\naccuracy-efficiency trade-off, and therefore yielding a generic and\nmulti-purpose architecture for application specific industrial settings. Our\nstudy overall conveys a constructive message: exhaustive experiments on several\nimage classification benchmarks: CIFAR-10, STL-10, CIFAR-100, and ImageNet-100,\ndemonstrates that the proposed training strategy provides a dense and\ncorresponding sparse sub-network that achieves comparable (on-par) performance\ncompared with the vanilla self-supervised setting, but at a significant\nreduction in computation in terms of FLOPs under a range of target budgets.\n","authors":["Tarun Krishna","Ayush K Rai","Alexandru Drimbarean","Alan F Smeaton","Kevin McGuinness","Noel E O'Connor"],"pdf_url":"https://arxiv.org/pdf/2301.09164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14258v2","updated":"2023-01-22T16:14:32Z","published":"2022-12-29T11:05:47Z","title":"HIER: Metric Learning Beyond Class Labels via Hierarchical\n  Regularization","summary":"  Supervision for metric learning has long been given in the form of\nequivalence between human-labeled classes. Although this type of supervision\nhas been a basis of metric learning for decades, we argue that it hinders\nfurther advances of the field. In this regard, we propose a new regularization\nmethod, dubbed HIER, to discover the latent semantic hierarchy of training\ndata, and to deploy the hierarchy to provide richer and more fine-grained\nsupervision than inter-class separability induced by common metric learning\nlosses. HIER achieved this goal with no annotation for the semantic hierarchy\nbut by learning hierarchical proxies in hyperbolic spaces. The hierarchical\nproxies are learnable parameters, and each of them is trained to serve as an\nancestor of a group of data or other proxies to approximate the semantic\nhierarchy among them. HIER deals with the proxies along with data in hyperbolic\nspace since geometric properties of the space are well-suited to represent\ntheir hierarchical structure. The efficacy of HIER was evaluated on four\nstandard benchmarks, where it consistently improved performance of conventional\nmethods when integrated with them, and consequently achieved the best records,\nsurpassing even the existing hyperbolic metric learning technique, in almost\nall settings.\n","authors":["Sungyeon Kim","Boseung Jeong","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2212.14258v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11696v2","updated":"2023-01-22T13:53:42Z","published":"2022-12-22T13:37:59Z","title":"Reversible Column Networks","summary":"  We propose a new neural network design paradigm Reversible Column Network\n(RevCol). The main body of RevCol is composed of multiple copies of\nsubnetworks, named columns respectively, between which multi-level reversible\nconnections are employed. Such architectural scheme attributes RevCol very\ndifferent behavior from conventional networks: during forward propagation,\nfeatures in RevCol are learned to be gradually disentangled when passing\nthrough each column, whose total information is maintained rather than\ncompressed or discarded as other network does. Our experiments suggest that\nCNN-style RevCol models can achieve very competitive performances on multiple\ncomputer vision tasks such as image classification, object detection and\nsemantic segmentation, especially with large parameter budget and large\ndataset. For example, after ImageNet-22K pre-training, RevCol-XL obtains 88.2%\nImageNet-1K accuracy. Given more pre-training data, our largest model RevCol-H\nreaches 90.0% on ImageNet-1K, 63.8% APbox on COCO detection minival set, 61.0%\nmIoU on ADE20k segmentation. To our knowledge, it is the best COCO detection\nand ADE20k segmentation result among pure (static) CNN models. Moreover, as a\ngeneral macro architecture fashion, RevCol can also be introduced into\ntransformers or other neural networks, which is demonstrated to improve the\nperformances in both computer vision and NLP tasks. We release code and models\nat https://github.com/megvii-research/RevCol\n","authors":["Yuxuan Cai","Yizhuang Zhou","Qi Han","Jianjian Sun","Xiangwen Kong","Jun Li","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11696v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09123v1","updated":"2023-01-22T13:27:12Z","published":"2023-01-22T13:27:12Z","title":"Face Generation from Textual Features using Conditionally Trained Inputs\n  to Generative Adversarial Networks","summary":"  Generative Networks have proved to be extremely effective in image\nrestoration and reconstruction in the past few years. Generating faces from\ntextual descriptions is one such application where the power of generative\nalgorithms can be used. The task of generating faces can be useful for a number\nof applications such as finding missing persons, identifying criminals, etc.\nThis paper discusses a novel approach to generating human faces given a textual\ndescription regarding the facial features. We use the power of state of the art\nnatural language processing models to convert face descriptions into learnable\nlatent vectors which are then fed to a generative adversarial network which\ngenerates faces corresponding to those features. While this paper focuses on\nhigh level descriptions of faces only, the same approach can be tailored to\ngenerate any image based on fine grained textual features.\n","authors":["Sandeep Shinde","Tejas Pradhan","Aniket Ghorpade","Mihir Tale"],"pdf_url":"https://arxiv.org/pdf/2301.09123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14613v7","updated":"2023-01-22T13:12:48Z","published":"2022-12-30T09:40:09Z","title":"Delving into Semantic Scale Imbalance","summary":"  Model bias triggered by long-tailed data has been widely studied. However,\nmeasure based on the number of samples cannot explicate three phenomena\nsimultaneously: (1) Given enough data, the classification performance gain is\nmarginal with additional samples. (2) Classification performance decays\nprecipitously as the number of training samples decreases when there is\ninsufficient data. (3) Model trained on sample-balanced datasets still has\ndifferent biases for different classes. In this work, we define and quantify\nthe semantic scale of classes, which is used to measure the feature diversity\nof classes. It is exciting to find experimentally that there is a marginal\neffect of semantic scale, which perfectly describes the first two phenomena.\nFurther, the quantitative measurement of semantic scale imbalance is proposed,\nwhich can accurately reflect model bias on multiple datasets, even on\nsample-balanced data, revealing a novel perspective for the study of class\nimbalance. Due to the prevalence of semantic scale imbalance, we propose\nsemantic-scale-balanced learning, including a general loss improvement scheme\nand a dynamic re-weighting training framework that overcomes the challenge of\ncalculating semantic scales in real-time during iterations. Comprehensive\nexperiments show that dynamic semantic-scale-balanced learning consistently\nenables the model to perform superiorly on large-scale long-tailed and\nnon-long-tailed natural and medical datasets, which is a good starting point\nfor mitigating the prevalent but unnoticed model bias.\n","authors":["Yanbiao Ma","Licheng Jiao","Fang Liu","Yuxin Li","Shuyuan Yang","Xu Liu"],"pdf_url":"https://arxiv.org/pdf/2212.14613v7.pdf","comment":"47 pages, 26 figures, 12 tables, Published as a conference paper at\n  ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09121v1","updated":"2023-01-22T13:10:05Z","published":"2023-01-22T13:10:05Z","title":"Learning Open-vocabulary Semantic Segmentation Models From Natural\n  Language Supervision","summary":"  In this paper, we consider the problem of open-vocabulary semantic\nsegmentation (OVS), which aims to segment objects of arbitrary classes instead\nof pre-defined, closed-set categories. The main contributions are as follows:\nFirst, we propose a transformer-based model for OVS, termed as OVSegmentor,\nwhich only exploits web-crawled image-text pairs for pre-training without using\nany mask annotations. OVSegmentor assembles the image pixels into a set of\nlearnable group tokens via a slot-attention based binding module, and aligns\nthe group tokens to the corresponding caption embedding. Second, we propose two\nproxy tasks for training, namely masked entity completion and cross-image mask\nconsistency. The former aims to infer all masked entities in the caption given\nthe group tokens, that enables the model to learn fine-grained alignment\nbetween visual groups and text entities. The latter enforces consistent mask\npredictions between images that contain shared entities, which encourages the\nmodel to learn visual invariance. Third, we construct CC4M dataset for\npre-training by filtering CC12M with frequently appeared entities, which\nsignificantly improves training efficiency. Fourth, we perform zero-shot\ntransfer on three benchmark datasets, PASCAL VOC 2012, PASCAL Context, and COCO\nObject. Our model achieves superior segmentation results over the\nstate-of-the-art method by using only 3\\% data (4M vs 134M) for pre-training.\nCode and pre-trained models will be released for future research.\n","authors":["Jilan Xu","Junlin Hou","Yuejie Zhang","Rui Feng","Yi Wang","Yu Qiao","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2301.09121v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09120v1","updated":"2023-01-22T13:07:24Z","published":"2023-01-22T13:07:24Z","title":"Causality-based Dual-Contrastive Learning Framework for Domain\n  Generalization","summary":"  Domain Generalization (DG) is essentially a sub-branch of out-of-distribution\ngeneralization, which trains models from multiple source domains and\ngeneralizes to unseen target domains. Recently, some domain generalization\nalgorithms have emerged, but most of them were designed with non-transferable\ncomplex architecture. Additionally, contrastive learning has become a promising\nsolution for simplicity and efficiency in DG. However, existing contrastive\nlearning neglected domain shifts that caused severe model confusions. In this\npaper, we propose a Dual-Contrastive Learning (DCL) module on feature and\nprototype contrast. Moreover, we design a novel Causal Fusion Attention (CFA)\nmodule to fuse diverse views of a single image to attain prototype.\nFurthermore, we introduce a Similarity-based Hard-pair Mining (SHM) strategy to\nleverage information on diversity shift. Extensive experiments show that our\nmethod outperforms state-of-the-art algorithms on three DG datasets. The\nproposed algorithm can also serve as a plug-and-play module without usage of\ndomain labels.\n","authors":["Zining Chen","Weiqiu Wang","Zhicheng Zhao","Aidong Men"],"pdf_url":"https://arxiv.org/pdf/2301.09120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09091v1","updated":"2023-01-22T10:17:02Z","published":"2023-01-22T10:17:02Z","title":"BallGAN: 3D-aware Image Synthesis with a Spherical Background","summary":"  3D-aware GANs aim to synthesize realistic 3D scenes such that they can be\nrendered in arbitrary perspectives to produce images. Although previous methods\nproduce realistic images, they suffer from unstable training or degenerate\nsolutions where the 3D geometry is unnatural. We hypothesize that the 3D\ngeometry is underdetermined due to the insufficient constraint, i.e., being\nclassified as real image to the discriminator is not enough. To solve this\nproblem, we propose to approximate the background as a spherical surface and\nrepresent a scene as a union of the foreground placed in the sphere and the\nthin spherical background. It reduces the degree of freedom in the background\nfield. Accordingly, we modify the volume rendering equation and incorporate\ndedicated constraints to design a novel 3D-aware GAN framework named BallGAN.\nBallGAN has multiple advantages as follows. 1) It produces more reasonable 3D\ngeometry; the images of a scene across different viewpoints have better\nphotometric consistency and fidelity than the state-of-the-art methods. 2) The\ntraining becomes much more stable. 3) The foreground can be separately rendered\non top of different arbitrary backgrounds.\n","authors":["Minjung Shin","Yunji Seo","Jeongmin Bae","Young Sun Choi","Hyunsu Kim","Hyeran Byun","Youngjung Uh"],"pdf_url":"https://arxiv.org/pdf/2301.09091v1.pdf","comment":"Project Page: https://minjung-s.github.io/ballgan"},{"id":"http://arxiv.org/abs/2209.12202v6","updated":"2023-01-22T10:16:42Z","published":"2022-09-25T11:48:09Z","title":"Multimodal Exponentially Modified Gaussian Oscillators","summary":"  Acoustic modeling serves audio processing tasks such as de-noising, data\nreconstruction, model-based testing and classification. Previous work dealt\nwith signal parameterization of wave envelopes either by multiple Gaussian\ndistributions or a single asymmetric Gaussian curve, which both fall short in\nrepresenting super-imposed echoes sufficiently well. This study presents a\nthree-stage Multimodal Exponentially Modified Gaussian (MEMG) model with an\noptional oscillating term that regards captured echoes as a superposition of\nunivariate probability distributions in the temporal domain. With this,\nsynthetic ultrasound signals suffering from artifacts can be fully recovered,\nwhich is backed by quantitative assessment. Real data experimentation is\ncarried out to demonstrate the classification capability of the acquired\nfeatures with object reflections being detected at different points in time.\nThe code is available at https://github.com/hahnec/multimodal_emg.\n","authors":["Christopher Hahne"],"pdf_url":"https://arxiv.org/pdf/2209.12202v6.pdf","comment":"IEEE International Ultrasonic Symposium 2022"},{"id":"http://arxiv.org/abs/2301.09077v1","updated":"2023-01-22T08:26:58Z","published":"2023-01-22T08:26:58Z","title":"Bidirectional Propagation for Cross-Modal 3D Object Detection","summary":"  Recent works have revealed the superiority of feature-level fusion for\ncross-modal 3D object detection, where fine-grained feature propagation from 2D\nimage pixels to 3D LiDAR points has been widely adopted for performance\nimprovement. Still, the potential of heterogeneous feature propagation between\n2D and 3D domains has not been fully explored. In this paper, in contrast to\nexisting pixel-to-point feature propagation, we investigate an opposite\npoint-to-pixel direction, allowing point-wise features to flow inversely into\nthe 2D image branch. Thus, when jointly optimizing the 2D and 3D streams, the\ngradients back-propagated from the 2D image branch can boost the representation\nability of the 3D backbone network working on LiDAR point clouds. Then,\ncombining pixel-to-point and point-to-pixel information flow mechanisms, we\nconstruct an bidirectional feature propagation framework, dubbed BiProDet. In\naddition to the architectural design, we also propose normalized local\ncoordinates map estimation, a new 2D auxiliary task for the training of the 2D\nimage branch, which facilitates learning local spatial-aware features from the\nimage modality and implicitly enhances the overall 3D detection performance.\nExtensive experiments and ablation studies validate the effectiveness of our\nmethod. Notably, we rank $\\mathbf{1^{\\mathrm{st}}}$ on the highly competitive\nKITTI benchmark on the cyclist class by the time of submission. The source code\nis available at https://github.com/Eaphan/BiProDet.\n","authors":["Yifan Zhang","Qijian Zhang","Junhui Hou","Yixuan Yuan","Guoliang Xing"],"pdf_url":"https://arxiv.org/pdf/2301.09077v1.pdf","comment":"Accepted by ICLR2023. Code is avaliable at\n  https://github.com/Eaphan/BiProDet"},{"id":"http://arxiv.org/abs/2301.09071v1","updated":"2023-01-22T08:02:23Z","published":"2023-01-22T08:02:23Z","title":"Variational Cross-Graph Reasoning and Adaptive Structured Semantics\n  Learning for Compositional Temporal Grounding","summary":"  Temporal grounding is the task of locating a specific segment from an\nuntrimmed video according to a query sentence. This task has achieved\nsignificant momentum in the computer vision community as it enables activity\ngrounding beyond pre-defined activity classes by utilizing the semantic\ndiversity of natural language descriptions. The semantic diversity is rooted in\nthe principle of compositionality in linguistics, where novel semantics can be\nsystematically described by combining known words in novel ways (compositional\ngeneralization). However, existing temporal grounding datasets are not\ncarefully designed to evaluate the compositional generalizability. To\nsystematically benchmark the compositional generalizability of temporal\ngrounding models, we introduce a new Compositional Temporal Grounding task and\nconstruct two new dataset splits, i.e., Charades-CG and ActivityNet-CG. When\nevaluating the state-of-the-art methods on our new dataset splits, we\nempirically find that they fail to generalize to queries with novel\ncombinations of seen words. We argue that the inherent structured semantics\ninside the videos and language is the crucial factor to achieve compositional\ngeneralization. Based on this insight, we propose a variational cross-graph\nreasoning framework that explicitly decomposes video and language into\nhierarchical semantic graphs, respectively, and learns fine-grained semantic\ncorrespondence between the two graphs. Furthermore, we introduce a novel\nadaptive structured semantics learning approach to derive the\nstructure-informed and domain-generalizable graph representations, which\nfacilitate the fine-grained semantic correspondence reasoning between the two\ngraphs. Extensive experiments validate the superior compositional\ngeneralizability of our approach.\n","authors":["Juncheng Li","Siliang Tang","Linchao Zhu","Wenqiao Zhang","Yi Yang","Tat-Seng Chua","Fei Wu","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2301.09071v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2203.13049"},{"id":"http://arxiv.org/abs/2301.09063v1","updated":"2023-01-22T06:23:53Z","published":"2023-01-22T06:23:53Z","title":"DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for\n  Improved Siamese Tracking","summary":"  Tracking tasks based on deep neural networks have greatly improved with the\nemergence of Siamese trackers. However, the appearance of targets often changes\nduring tracking, which can reduce the robustness of the tracker when facing\nchallenges such as aspect ratio change, occlusion, and scale variation. In\naddition, cluttered backgrounds can lead to multiple high response points in\nthe response map, leading to incorrect target positioning. In this paper, we\nintroduce two transformer-based modules to improve Siamese tracking called\nDASTSiam: the spatio-temporal (ST) fusion module and the Discriminative\nAugmentation (DA) module. The ST module uses cross-attention based accumulation\nof historical cues to improve robustness against object appearance changes,\nwhile the DA module associates semantic information between the template and\nsearch region to improve target discrimination. Moreover, Modifying the label\nassignment of anchors also improves the reliability of the object location. Our\nmodules can be used with all Siamese trackers and show improved performance on\nseveral public datasets through comparative and ablation experiments.\n","authors":["Yucheng Huang","Eksan Firkat","Ziwang Xiao","Jihong Zhu","Askar Hamdulla"],"pdf_url":"https://arxiv.org/pdf/2301.09063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09060v1","updated":"2023-01-22T05:26:08Z","published":"2023-01-22T05:26:08Z","title":"3D Reconstruction of Non-cooperative Resident Space Objects using\n  Instant NGP-accelerated NeRF and D-NeRF","summary":"  The proliferation of non-cooperative resident space objects (RSOs) in orbit\nhas spurred the demand for active space debris removal, on-orbit servicing\n(OOS), classification, and functionality identification of these RSOs. Recent\nadvances in computer vision have enabled high-definition 3D modeling of objects\nbased on a set of 2D images captured from different viewing angles. This work\nadapts Instant NeRF and D-NeRF, variations of the neural radiance field (NeRF)\nalgorithm to the problem of mapping RSOs in orbit for the purposes of\nfunctionality identification and assisting with OOS. The algorithms are\nevaluated for 3D reconstruction quality and hardware requirements using\ndatasets of images of a spacecraft mock-up taken under two different lighting\nand motion conditions at the Orbital Robotic Interaction, On-Orbit Servicing\nand Navigation (ORION) Laboratory at Florida Institute of Technology. Instant\nNeRF is shown to learn high-fidelity 3D models with a computational cost that\ncould feasibly be trained on on-board computers.\n","authors":["Trupti Mahendrakar","Basilio Caruso","Van Minh Nguyen","Ryan T. White","Todd Steffen"],"pdf_url":"https://arxiv.org/pdf/2301.09060v1.pdf","comment":"Presented at AAS/AIAA Spaceflight Mechanics Conference 2023, 14\n  pages, 10 figures, 2 tables"},{"id":"http://arxiv.org/abs/2301.09059v1","updated":"2023-01-22T05:22:11Z","published":"2023-01-22T05:22:11Z","title":"Autonomous Rendezvous with Non-cooperative Target Objects with Swarm\n  Chasers and Observers","summary":"  Space debris is on the rise due to the increasing demand for spacecraft for\ncom-munication, navigation, and other applications. The Space Surveillance\nNetwork (SSN) tracks over 27,000 large pieces of debris and estimates the\nnumber of small, un-trackable fragments at over 1,00,000. To control the growth\nof debris, the for-mation of further debris must be reduced. Some solutions\ninclude deorbiting larger non-cooperative resident space objects (RSOs) or\nservicing satellites in or-bit. Both require rendezvous with RSOs, and the\nscale of the problem calls for autonomous missions. This paper introduces the\nMultipurpose Autonomous Ren-dezvous Vision-Integrated Navigation system\n(MARVIN) developed and tested at the ORION Facility at Florida Institution of\nTechnology. MARVIN consists of two sub-systems: a machine vision-aided\nnavigation system and an artificial po-tential field (APF) guidance algorithm\nwhich work together to command a swarm of chasers to safely rendezvous with the\nRSO. We present the MARVIN architec-ture and hardware-in-the-loop experiments\ndemonstrating autonomous, collabo-rative swarm satellite operations\nsuccessfully guiding three drones to rendezvous with a physical mockup of a\nnon-cooperative satellite in motion.\n","authors":["Trupti Mahendrakar","Steven Holmberg","Andrew Ekblad","Emma Conti","Ryan T. White","Markus Wilde","Isaac Silver"],"pdf_url":"https://arxiv.org/pdf/2301.09059v1.pdf","comment":"Presented at AAS/AIAA Spaceflight Mechanics Meeting 2023, 17 pages, 9\n  figures, 3 tables"},{"id":"http://arxiv.org/abs/2301.09056v1","updated":"2023-01-22T04:53:38Z","published":"2023-01-22T04:53:38Z","title":"Performance Study of YOLOv5 and Faster R-CNN for Autonomous Navigation\n  around Non-Cooperative Targets","summary":"  Autonomous navigation and path-planning around non-cooperative space objects\nis an enabling technology for on-orbit servicing and space debris removal\nsystems. The navigation task includes the determination of target object\nmotion, the identification of target object features suitable for grasping, and\nthe identification of collision hazards and other keep-out zones. Given this\nknowledge, chaser spacecraft can be guided towards capture locations without\ndamaging the target object or without unduly the operations of a servicing\ntarget by covering up solar arrays or communication antennas. One way to\nautonomously achieve target identification, characterization and feature\nrecognition is by use of artificial intelligence algorithms. This paper\ndiscusses how the combination of cameras and machine learning algorithms can\nachieve the relative navigation task. The performance of two deep\nlearning-based object detection algorithms, Faster Region-based Convolutional\nNeural Networks (R-CNN) and You Only Look Once (YOLOv5), is tested using\nexperimental data obtained in formation flight simulations in the ORION Lab at\nFlorida Institute of Technology. The simulation scenarios vary the yaw motion\nof the target object, the chaser approach trajectory, and the lighting\nconditions in order to test the algorithms in a wide range of realistic and\nperformance limiting situations. The data analyzed include the mean average\nprecision metrics in order to compare the performance of the object detectors.\nThe paper discusses the path to implementing the feature recognition algorithms\nand towards integrating them into the spacecraft Guidance Navigation and\nControl system.\n","authors":["Trupti Mahendrakar","Andrew Ekblad","Nathan Fischer","Ryan T. White","Markus Wilde","Brian Kish","Isaac Silver"],"pdf_url":"https://arxiv.org/pdf/2301.09056v1.pdf","comment":"12 pages, 10 figures, 9 tables, IEEE Aerospace Conference 2022"},{"id":"http://arxiv.org/abs/2301.09055v1","updated":"2023-01-22T04:49:04Z","published":"2023-01-22T04:49:04Z","title":"Resource-constrained FPGA Design for Satellite Component Feature\n  Extraction","summary":"  The effective use of computer vision and machine learning for on-orbit\napplications has been hampered by limited computing capabilities, and therefore\nlimited performance. While embedded systems utilizing ARM processors have been\nshown to meet acceptable but low performance standards, the recent availability\nof larger space-grade field programmable gate arrays (FPGAs) show potential to\nexceed the performance of microcomputer systems. This work proposes use of\nneural network-based object detection algorithm that can be deployed on a\ncomparably resource-constrained FPGA to automatically detect components of\nnon-cooperative, satellites on orbit. Hardware-in-the-loop experiments were\nperformed on the ORION Maneuver Kinematics Simulator at Florida Tech to compare\nthe performance of the new model deployed on a small, resource-constrained FPGA\nto an equivalent algorithm on a microcomputer system. Results show the FPGA\nimplementation increases the throughput and decreases latency while maintaining\ncomparable accuracy. These findings suggest future missions should consider\ndeploying computer vision algorithms on space-grade FPGAs.\n","authors":["Andrew Ekblad","Trupti Mahendrakar","Ryan T. White","Markus Wilde","Isaac Silver","Brooke Wheeler"],"pdf_url":"https://arxiv.org/pdf/2301.09055v1.pdf","comment":"9 pages, 7 figures, 4 tables, Accepted at IEEE Aerospace Conference\n  2023"},{"id":"http://arxiv.org/abs/2301.09045v1","updated":"2023-01-22T03:14:31Z","published":"2023-01-22T03:14:31Z","title":"Champion Solution for the WSDM2023 Toloka VQA Challenge","summary":"  In this report, we present our champion solution to the WSDM2023 Toloka\nVisual Question Answering (VQA) Challenge. Different from the common VQA and\nvisual grounding (VG) tasks, this challenge involves a more complex scenario,\ni.e. inferring and locating the object implicitly specified by the given\ninterrogative question. For this task, we leverage ViT-Adapter, a\npre-training-free adapter network, to adapt multi-modal pre-trained\nUni-Perceiver for better cross-modal localization. Our method ranks first on\nthe leaderboard, achieving 77.5 and 76.347 IoU on public and private test sets,\nrespectively. It shows that ViT-Adapter is also an effective paradigm for\nadapting the unified perception model to vision-language downstream tasks. Code\nand models will be released at\nhttps://github.com/czczup/ViT-Adapter/tree/main/wsdm2023.\n","authors":["Shengyi Gao","Zhe Chen","Guo Chen","Wenhai Wang","Tong Lu"],"pdf_url":"https://arxiv.org/pdf/2301.09045v1.pdf","comment":"Technical report in WSDM Cup 2023"},{"id":"http://arxiv.org/abs/2204.10704v2","updated":"2023-01-22T01:49:00Z","published":"2022-04-22T13:49:52Z","title":"SUES-200: A Multi-height Multi-scene Cross-view Image Benchmark Across\n  Drone and Satellite","summary":"  Cross-view image matching aims to match images of the same target scene\nacquired from different platforms. With the rapid development of drone\ntechnology, cross-view matching by neural network models has been a widely\naccepted choice for drone position or navigation. However, existing public\ndatasets do not include images obtained by drones at different heights, and the\ntypes of scenes are relatively homogeneous, which yields issues in assessing a\nmodel's capability to adapt to complex and changing scenes. In this end, we\npresent a new cross-view dataset called SUES-200 to address these issues.\nSUES-200 contains 24120 images acquired by the drone at four different heights\nand corresponding satellite view images of the same target scene. To the best\nof our knowledge, SUES-200 is the first public dataset that considers the\ndifferences generated in aerial photography captured by drones flying at\ndifferent heights. In addition, we developed an evaluation for efficient\ntraining, testing and evaluation of cross-view matching models, under which we\ncomprehensively analyze the performance of nine architectures. Then, we propose\na robust baseline model for use with SUES-200. Experimental results show that\nSUES-200 can help the model to learn highly discriminative features of the\nheight of the drone.\n","authors":["Runzhe Zhu","Ling Yin","Mingze Yang","Fei Wu","Yuncheng Yang","Wenbo Hu"],"pdf_url":"https://arxiv.org/pdf/2204.10704v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.09210v1","updated":"2023-01-22T21:44:25Z","published":"2023-01-22T21:44:25Z","title":"Debiasing the Cloze Task in Sequential Recommendation with Bidirectional\n  Transformers","summary":"  Bidirectional Transformer architectures are state-of-the-art sequential\nrecommendation models that use a bi-directional representation capacity based\non the Cloze task, a.k.a. Masked Language Modeling. The latter aims to predict\nrandomly masked items within the sequence. Because they assume that the true\ninteracted item is the most relevant one, an exposure bias results, where\nnon-interacted items with low exposure propensities are assumed to be\nirrelevant. The most common approach to mitigating exposure bias in\nrecommendation has been Inverse Propensity Scoring (IPS), which consists of\ndown-weighting the interacted predictions in the loss function in proportion to\ntheir propensities of exposure, yielding a theoretically unbiased learning. In\nthis work, we argue and prove that IPS does not extend to sequential\nrecommendation because it fails to account for the temporal nature of the\nproblem. We then propose a novel propensity scoring mechanism, which can\ntheoretically debias the Cloze task in sequential recommendation. Finally we\nempirically demonstrate the debiasing capabilities of our proposed approach and\nits robustness to the severity of exposure bias.\n","authors":["Khalil Damak","Sami Khenissi","Olfa Nasraoui"],"pdf_url":"https://arxiv.org/pdf/2301.09210v1.pdf","comment":"10 pages, 3 figures, Accepted at KDD '22"},{"id":"http://arxiv.org/abs/2301.09201v1","updated":"2023-01-22T20:59:40Z","published":"2023-01-22T20:59:40Z","title":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis","summary":"  5G is the 5th generation cellular network protocol. It is the\nstate-of-the-art global wireless standard that enables an advanced kind of\nnetwork designed to connect virtually everyone and everything with increased\nspeed and reduced latency. Therefore, its development, analysis, and security\nare critical. However, all approaches to the 5G protocol development and\nsecurity analysis, e.g., property extraction, protocol summarization, and\nsemantic analysis of the protocol specifications and implementations are\ncompletely manual. To reduce such manual effort, in this paper, we curate\nSPEC5G the first-ever public 5G dataset for NLP research. The dataset contains\n3,547,586 sentences with 134M words, from 13094 cellular network specifications\nand 13 online websites. By leveraging large-scale pre-trained language models\nthat have achieved state-of-the-art results on NLP tasks, we use this dataset\nfor security-related text classification and summarization. Security-related\ntext classification can be used to extract relevant security-related properties\nfor protocol testing. On the other hand, summarization can help developers and\npractitioners understand the high level of the protocol, which is itself a\ndaunting task. Our results show the value of our 5G-centric dataset in 5G\nprotocol analysis automation. We believe that SPEC5G will enable a new research\ndirection into automatic analyses for the 5G cellular network protocol and\nnumerous related downstream tasks. Our data and code are publicly available.\n","authors":["Imtiaz Karim","Kazi Samin Mubasshir","Mirza Masfiqur Rahman","Elisa Bertino"],"pdf_url":"https://arxiv.org/pdf/2301.09201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10658v3","updated":"2023-01-22T14:07:11Z","published":"2022-06-21T18:16:31Z","title":"Questions Are All You Need to Train a Dense Passage Retriever","summary":"  We introduce ART, a new corpus-level autoencoding approach for training dense\nretrieval models that does not require any labeled training data. Dense\nretrieval is a central challenge for open-domain tasks, such as Open QA, where\nstate-of-the-art methods typically require large supervised datasets with\ncustom hard-negative mining and denoising of positive examples. ART, in\ncontrast, only requires access to unpaired inputs and outputs (e.g. questions\nand potential answer documents). It uses a new document-retrieval autoencoding\nscheme, where (1) an input question is used to retrieve a set of evidence\ndocuments, and (2) the documents are then used to compute the probability of\nreconstructing the original question. Training for retrieval based on question\nreconstruction enables effective unsupervised learning of both document and\nquestion encoders, which can be later incorporated into complete Open QA\nsystems without any further finetuning. Extensive experiments demonstrate that\nART obtains state-of-the-art results on multiple QA retrieval benchmarks with\nonly generic initialization from a pre-trained language model, removing the\nneed for labeled data and task-specific losses.\n","authors":["Devendra Singh Sachan","Mike Lewis","Dani Yogatama","Luke Zettlemoyer","Joelle Pineau","Manzil Zaheer"],"pdf_url":"https://arxiv.org/pdf/2206.10658v3.pdf","comment":"Accepted to TACL, pre MIT Press publication version"},{"id":"http://arxiv.org/abs/2301.09057v1","updated":"2023-01-22T04:56:35Z","published":"2023-01-22T04:56:35Z","title":"Durability and Availability of Erasure-Coded Storage Systems with\n  Concurrent Maintenance","summary":"  This initial version of this document was written back in 2014 for the sole\npurpose of providing fundamentals of reliability theory as well as to identify\nthe theoretical types of machinery for the prediction of\ndurability/availability of erasure-coded storage systems. Since the definition\nof a \"system\" is too broad, we specifically focus on warm/cold storage systems\nwhere the data is stored in a distributed fashion across different storage\nunits with or without continuous operation. The contents of this document are\ndedicated to a review of fundamentals, a few major improved stochastic models,\nand several contributions of my work relevant to the field. One of the\ncontributions of this document is the introduction of the most general form of\nMarkov models for the estimation of mean time to failure. This work was\npartially later published in IEEE Transactions on Reliability. Very good\napproximations for the closed-form solutions for this general model are also\ninvestigated. Various storage configurations under different policies are\ncompared using such advanced models. Later in a subsequent chapter, we have\nalso considered multi-dimensional Markov models to address detached\ndrive-medium combinations such as those found in optical disk and tape storage\nsystems. It is not hard to anticipate such a system structure would most likely\nbe part of future DNA storage libraries. This work is partially published in\nElsevier Reliability and System Safety. Topics that include simulation\nmodelings for more accurate estimations are included towards the end of the\ndocument by noting the deficiencies of the simplified canonical as well as more\ncomplex Markov models, due mainly to the stationary and static nature of\nMarkovinity. Throughout the document, we shall focus on concurrently maintained\nsystems although the discussions will only slightly change for the systems\nrepaired one device at a time.\n","authors":["Suayb S. Arslan"],"pdf_url":"https://arxiv.org/pdf/2301.09057v1.pdf","comment":"58 pages, 20 figures, 9 tables. arXiv admin note: substantial text\n  overlap with arXiv:1911.00329"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.09230v1","updated":"2023-01-22T23:44:18Z","published":"2023-01-22T23:44:18Z","title":"Deterministic Online Classification: Non-iteratively Reweighted\n  Recursive Least-Squares for Binary Class Rebalancing","summary":"  Deterministic solutions are becoming more critical for interpretability.\nWeighted Least-Squares (WLS) has been widely used as a deterministic batch\nsolution with a specific weight design. In the online settings of WLS, exact\nreweighting is necessary to converge to its batch settings. In order to comply\nwith its necessity, the iteratively reweighted least-squares algorithm is\nmainly utilized with a linearly growing time complexity which is not attractive\nfor online learning. Due to the high and growing computational costs, an\nefficient online formulation of reweighted least-squares is desired. We\nintroduce a new deterministic online classification algorithm of WLS with a\nconstant time complexity for binary class rebalancing. We demonstrate that our\nproposed online formulation exactly converges to its batch formulation and\noutperforms existing state-of-the-art stochastic online binary classification\nalgorithms in real-world data sets empirically.\n","authors":["Se-In Jang"],"pdf_url":"https://arxiv.org/pdf/2301.09230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.03787v3","updated":"2023-01-22T23:31:58Z","published":"2022-05-08T05:30:35Z","title":"Learning Regionally Decentralized AC Optimal Power Flows with ADMM","summary":"  One potential future for the next generation of smart grids is the use of\ndecentralized optimization algorithms and secured communications for\ncoordinating renewable generation (e.g., wind/solar), dispatchable devices\n(e.g., coal/gas/nuclear generations), demand response, battery & storage\nfacilities, and topology optimization. The Alternating Direction Method of\nMultipliers (ADMM) has been widely used in the community to address such\ndecentralized optimization problems and, in particular, the AC Optimal Power\nFlow (AC-OPF). This paper studies how machine learning may help in speeding up\nthe convergence of ADMM for solving AC-OPF. It proposes a novel decentralized\nmachine-learning approach, namely ML-ADMM, where each agent uses deep learning\nto learn the consensus parameters on the coupling branches. The paper also\nexplores the idea of learning only from ADMM runs that exhibit high-quality\nconvergence properties, and proposes filtering mechanisms to select these runs.\nExperimental results on test cases based on the French system demonstrate the\npotential of the approach in speeding up the convergence of ADMM significantly.\n","authors":["Terrence W. K. Mak","Minas Chatzos","Mathieu Tanneau","Pascal Van Hentenryck"],"pdf_url":"https://arxiv.org/pdf/2205.03787v3.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2208.08544v3","updated":"2023-01-22T23:17:39Z","published":"2022-08-17T21:25:09Z","title":"Estimating individual treatment effects under unobserved confounding\n  using binary instruments","summary":"  Estimating conditional average treatment effects (CATEs) from observational\ndata is relevant in many fields such as personalized medicine. However, in\npractice, the treatment assignment is usually confounded by unobserved\nvariables and thus introduces bias. A remedy to remove the bias is the use of\ninstrumental variables (IVs). Such settings are widespread in medicine (e.g.,\ntrials where the treatment assignment is used as binary IV). In this paper, we\npropose a novel, multiply robust machine learning framework, called MRIV, for\nestimating CATEs using binary IVs and thus yield an unbiased CATE estimator.\nDifferent from previous work for binary IVs, our framework estimates the CATE\ndirectly via a pseudo outcome regression. (1)~We provide a theoretical analysis\nwhere we show that our framework yields multiple robust convergence rates: our\nCATE estimator achieves fast convergence even if several nuisance estimators\nconverge slowly. (2)~We further show that our framework asymptotically\noutperforms state-of-the-art plug-in IV methods for CATE estimation, in the\nsense that it achieves a faster rate of convergence if the CATE is smoother\nthan the individual outcome surfaces. (3)~We build upon our theoretical results\nand propose a tailored deep neural network architecture called MRIV-Net for\nCATE estimation using binary IVs. Across various computational experiments, we\ndemonstrate empirically that our MRIV-Net achieves state-of-the-art\nperformance. To the best of our knowledge, our MRIV is the first multiply\nrobust machine learning framework tailored to estimating CATEs in the binary IV\nsetting.\n","authors":["Dennis Frauen","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2208.08544v3.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/1906.06852v5","updated":"2023-01-22T22:52:21Z","published":"2019-06-17T05:53:52Z","title":"Learning Interpretable Models Using an Oracle","summary":"  We look at a specific aspect of model interpretability: models often need to\nbe constrained in size for them to be considered interpretable. But smaller\nmodels also tend to have high bias. This suggests a trade-off between\ninterpretability and accuracy. Our work addresses this by: (a) showing that\nlearning a training distribution (often different from the test distribution)\ncan often increase accuracy of small models, and therefore may be used as a\nstrategy to compensate for small sizes, and (b) providing a model-agnostic\nalgorithm to learn such training distributions. We pose the distribution\nlearning problem as one of optimizing parameters for an Infinite Beta Mixture\nModel based on a Dirichlet Process, so that the held-out accuracy of a model\ntrained on a sample from this distribution is maximized. To make computation\ntractable, we project the training data onto one dimension: prediction\nuncertainty scores as provided by a highly accurate oracle model. A Bayesian\nOptimizer is used for learning the parameters. Empirical results using multiple\nreal world datasets, various oracles and interpretable models with different\nnotions of model sizes, are presented. We observe significant relative\nimprovements in the F1-score in most cases, occasionally seeing improvements\ngreater than 100% over baselines. Additionally we show that the proposed\nalgorithm provides the following benefits: (a) its a framework which allows for\nflexibility in implementation, (b) it can be used across feature spaces, e.g.,\nthe text classification accuracy of a Decision Tree using character n-grams is\nshown to improve when using a Gated Recurrent Unit as an oracle, which uses a\nsequence of characters as its input, (c) it can be used to train models that\nhave a non-differentiable training loss, e.g., Decision Trees, and (d)\nreasonable defaults exist for most parameters of the algorithm, which makes it\nconvenient to use.\n","authors":["Abhishek Ghose","Balaraman Ravindran"],"pdf_url":"https://arxiv.org/pdf/1906.06852v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09223v1","updated":"2023-01-22T22:36:43Z","published":"2023-01-22T22:36:43Z","title":"Doubly Adversarial Federated Bandits","summary":"  We study a new non-stochastic federated multi-armed bandit problem with\nmultiple agents collaborating via a communication network. The losses of the\narms are assigned by an oblivious adversary that specifies the loss of each arm\nnot only for each time step but also for each agent, which we call ``doubly\nadversarial\". In this setting, different agents may choose the same arm in the\nsame time step but observe different feedback. The goal of each agent is to\nfind a globally best arm in hindsight that has the lowest cumulative loss\naveraged over all agents, which necessities the communication among agents. We\nprovide regret lower bounds for any federated bandit algorithm under different\nsettings, when agents have access to full-information feedback, or the bandit\nfeedback. For the bandit feedback setting, we propose a near-optimal federated\nbandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an\nopen question proposed in Cesa-Bianchi et al. (2016): FEDEXP3 can guarantee a\nsub-linear regret without exchanging sequences of selected arm identities or\nloss sequences among agents. We also provide numerical evaluations of our\nalgorithm to validate our theoretical results and demonstrate its effectiveness\non synthetic and real-world datasets\n","authors":["Jialin Yi","Milan Vojnović"],"pdf_url":"https://arxiv.org/pdf/2301.09223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.17209v2","updated":"2023-01-22T22:14:56Z","published":"2022-03-31T17:36:15Z","title":"Adversarial Examples in Random Neural Networks with General Activations","summary":"  A substantial body of empirical work documents the lack of robustness in deep\nlearning models to adversarial examples. Recent theoretical work proved that\nadversarial examples are ubiquitous in two-layers networks with sub-exponential\nwidth and ReLU or smooth activations, and multi-layer ReLU networks with\nsub-exponential width. We present a result of the same type, with no\nrestriction on width and for general locally Lipschitz continuous activations.\n  More precisely, given a neural network $f(\\,\\cdot\\,;{\\boldsymbol \\theta})$\nwith random weights ${\\boldsymbol \\theta}$, and feature vector ${\\boldsymbol\nx}$, we show that an adversarial example ${\\boldsymbol x}'$ can be found with\nhigh probability along the direction of the gradient $\\nabla_{{\\boldsymbol\nx}}f({\\boldsymbol x};{\\boldsymbol \\theta})$. Our proof is based on a Gaussian\nconditioning technique. Instead of proving that $f$ is approximately linear in\na neighborhood of ${\\boldsymbol x}$, we characterize the joint distribution of\n$f({\\boldsymbol x};{\\boldsymbol \\theta})$ and $f({\\boldsymbol x}';{\\boldsymbol\n\\theta})$ for ${\\boldsymbol x}' = {\\boldsymbol x}-s({\\boldsymbol\nx})\\nabla_{{\\boldsymbol x}}f({\\boldsymbol x};{\\boldsymbol \\theta})$.\n","authors":["Andrea Montanari","Yuchen Wu"],"pdf_url":"https://arxiv.org/pdf/2203.17209v2.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2301.09210v1","updated":"2023-01-22T21:44:25Z","published":"2023-01-22T21:44:25Z","title":"Debiasing the Cloze Task in Sequential Recommendation with Bidirectional\n  Transformers","summary":"  Bidirectional Transformer architectures are state-of-the-art sequential\nrecommendation models that use a bi-directional representation capacity based\non the Cloze task, a.k.a. Masked Language Modeling. The latter aims to predict\nrandomly masked items within the sequence. Because they assume that the true\ninteracted item is the most relevant one, an exposure bias results, where\nnon-interacted items with low exposure propensities are assumed to be\nirrelevant. The most common approach to mitigating exposure bias in\nrecommendation has been Inverse Propensity Scoring (IPS), which consists of\ndown-weighting the interacted predictions in the loss function in proportion to\ntheir propensities of exposure, yielding a theoretically unbiased learning. In\nthis work, we argue and prove that IPS does not extend to sequential\nrecommendation because it fails to account for the temporal nature of the\nproblem. We then propose a novel propensity scoring mechanism, which can\ntheoretically debias the Cloze task in sequential recommendation. Finally we\nempirically demonstrate the debiasing capabilities of our proposed approach and\nits robustness to the severity of exposure bias.\n","authors":["Khalil Damak","Sami Khenissi","Olfa Nasraoui"],"pdf_url":"https://arxiv.org/pdf/2301.09210v1.pdf","comment":"10 pages, 3 figures, Accepted at KDD '22"},{"id":"http://arxiv.org/abs/2301.09203v1","updated":"2023-01-22T21:13:13Z","published":"2023-01-22T21:13:13Z","title":"Relaxed Models for Adversarial Streaming: The Advice Model and the\n  Bounded Interruptions Model","summary":"  Streaming algorithms are typically analyzed in the oblivious setting, where\nwe assume that the input stream is fixed in advance. Recently, there is a\ngrowing interest in designing adversarially robust streaming algorithms that\nmust maintain utility even when the input stream is chosen adaptively and\nadversarially as the execution progresses. While several fascinating results\nare known for the adversarial setting, in general, it comes at a very high cost\nin terms of the required space. Motivated by this, in this work we set out to\nexplore intermediate models that allow us to interpolate between the oblivious\nand the adversarial models. Specifically, we put forward the following two\nmodels:\n  (1) *The advice model*, in which the streaming algorithm may occasionally ask\nfor one bit of advice.\n  (2) *The bounded interruptions model*, in which we assume that the adversary\nis only partially adaptive.\n  We present both positive and negative results for each of these two models.\nIn particular, we present generic reductions from each of these models to the\noblivious model. This allows us to design robust algorithms with significantly\nimproved space complexity compared to what is known in the plain adversarial\nmodel.\n","authors":["Menachem Sadigurschi","Moshe Shechner","Uri Stemmer"],"pdf_url":"https://arxiv.org/pdf/2301.09203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09201v1","updated":"2023-01-22T20:59:40Z","published":"2023-01-22T20:59:40Z","title":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis","summary":"  5G is the 5th generation cellular network protocol. It is the\nstate-of-the-art global wireless standard that enables an advanced kind of\nnetwork designed to connect virtually everyone and everything with increased\nspeed and reduced latency. Therefore, its development, analysis, and security\nare critical. However, all approaches to the 5G protocol development and\nsecurity analysis, e.g., property extraction, protocol summarization, and\nsemantic analysis of the protocol specifications and implementations are\ncompletely manual. To reduce such manual effort, in this paper, we curate\nSPEC5G the first-ever public 5G dataset for NLP research. The dataset contains\n3,547,586 sentences with 134M words, from 13094 cellular network specifications\nand 13 online websites. By leveraging large-scale pre-trained language models\nthat have achieved state-of-the-art results on NLP tasks, we use this dataset\nfor security-related text classification and summarization. Security-related\ntext classification can be used to extract relevant security-related properties\nfor protocol testing. On the other hand, summarization can help developers and\npractitioners understand the high level of the protocol, which is itself a\ndaunting task. Our results show the value of our 5G-centric dataset in 5G\nprotocol analysis automation. We believe that SPEC5G will enable a new research\ndirection into automatic analyses for the 5G cellular network protocol and\nnumerous related downstream tasks. Our data and code are publicly available.\n","authors":["Imtiaz Karim","Kazi Samin Mubasshir","Mirza Masfiqur Rahman","Elisa Bertino"],"pdf_url":"https://arxiv.org/pdf/2301.09201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11126v2","updated":"2023-01-22T20:14:08Z","published":"2022-07-22T15:00:15Z","title":"Optimism in Face of a Context: Regret Guarantees for Stochastic\n  Contextual MDP","summary":"  We present regret minimization algorithms for stochastic contextual MDPs\nunder minimum reachability assumption, using an access to an offline least\nsquare regression oracle. We analyze three different settings: where the\ndynamics is known, where the dynamics is unknown but independent of the context\nand the most challenging setting where the dynamics is unknown and\ncontext-dependent. For the latter, our algorithm obtains regret bound of\n$\\widetilde{O}(\n(H+{1}/{p_{min}})H|S|^{3/2}\\sqrt{|A|T\\log(\\max\\{|\\mathcal{G}|,|\\mathcal{P}|\\}/\\delta)})$\nwith probability $1-\\delta$, where $\\mathcal{P}$ and $\\mathcal{G}$ are finite\nand realizable function classes used to approximate the dynamics and rewards\nrespectively, $p_{min}$ is the minimum reachability parameter, $S$ is the set\nof states, $A$ the set of actions, $H$ the horizon, and $T$ the number of\nepisodes. To our knowledge, our approach is the first optimistic approach\napplied to contextual MDPs with general function approximation (i.e., without\nadditional knowledge regarding the function class, such as it being linear and\netc.). We present a lower bound of $\\Omega(\\sqrt{T H |S| |A|\n\\ln(|\\mathcal{G}|)/\\ln(|A|)})$, on the expected regret which holds even in the\ncase of known dynamics. Lastly, we discuss an extension of our results to CMDPs\nwithout minimum reachability, that obtains $\\widetilde{O}(T^{3/4})$ regret.\n","authors":["Orin Levy","Yishay Mansour"],"pdf_url":"https://arxiv.org/pdf/2207.11126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09192v1","updated":"2023-01-22T20:01:34Z","published":"2023-01-22T20:01:34Z","title":"Lower Bounds on Learning Pauli Channels","summary":"  Understanding the noise affecting a quantum device is of fundamental\nimportance for scaling quantum technologies. A particularly important class of\nnoise models is that of Pauli channels, as randomized compiling techniques can\neffectively bring any quantum channel to this form and are significantly more\nstructured than general quantum channels. In this paper, we show fundamental\nlower bounds on the sample complexity for learning Pauli channels in diamond\nnorm with unentangled measurements. We consider both adaptive and non-adaptive\nstrategies. In the non-adaptive setting, we show a lower bound of\n$\\Omega(2^{3n}\\epsilon^{-2})$ to learn an $n$-qubit Pauli channel. In\nparticular, this shows that the recently introduced learning procedure by\nFlammia and Wallman is essentially optimal. In the adaptive setting, we show a\nlower bound of $\\Omega(2^{2.5n}\\epsilon^{-2})$ for\n$\\epsilon=\\mathcal{O}(2^{-n})$, and a lower bound of\n$\\Omega(2^{2n}\\epsilon^{-2} )$ for any $\\epsilon > 0$. This last lower bound\neven applies for arbitrarily many sequential uses of the channel, as long as\nthey are only interspersed with other unital operations.\n","authors":["Omar Fawzi","Aadil Oufkir","Daniel Stilck França"],"pdf_url":"https://arxiv.org/pdf/2301.09192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03116v2","updated":"2023-01-22T19:43:55Z","published":"2023-01-08T22:14:59Z","title":"Unsupervised Learning for Combinatorial Optimization Needs Meta-Learning","summary":"  A general framework of unsupervised learning for combinatorial optimization\n(CO) is to train a neural network (NN) whose output gives a problem solution by\ndirectly optimizing the CO objective. Albeit with some advantages over\ntraditional solvers, the current framework optimizes an averaged performance\nover the distribution of historical problem instances, which misaligns with the\nactual goal of CO that looks for a good solution to every future encountered\ninstance. With this observation, we propose a new objective of unsupervised\nlearning for CO where the goal of learning is to search for good initialization\nfor future problem instances rather than give direct solutions. We propose a\nmeta-learning-based training pipeline for this new objective. Our method\nachieves good empirical performance. We observe that even just the initial\nsolution given by our model before fine-tuning can significantly outperform the\nbaselines under various evaluation settings including evaluation across\nmultiple datasets, and the case with big shifts in the problem scale. The\nreason we conjecture is that meta-learning-based training lets the model be\nloosely tied to each local optima for a training instance while being more\nadaptive to the changes of optimization landscapes across instances.\n","authors":["Haoyu Wang","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2301.03116v2.pdf","comment":"Our code is available at: https://github.com/Graph-COM/Meta_CO"},{"id":"http://arxiv.org/abs/2208.10715v2","updated":"2023-01-22T19:08:34Z","published":"2022-08-23T03:45:39Z","title":"GANs and Closures: Micro-Macro Consistency in Multiscale Modeling","summary":"  Sampling the phase space of molecular systems -- and, more generally, of\ncomplex systems effectively modeled by stochastic differential equations -- is\na crucial modeling step in many fields, from protein folding to materials\ndiscovery. These problems are often multiscale in nature: they can be described\nin terms of low-dimensional effective free energy surfaces parametrized by a\nsmall number of \"slow\" reaction coordinates; the remaining \"fast\" degrees of\nfreedom populate an equilibrium measure on the reaction coordinate values.\nSampling procedures for such problems are used to estimate effective free\nenergy differences as well as ensemble averages with respect to the conditional\nequilibrium distributions; these latter averages lead to closures for effective\nreduced dynamic models. Over the years, enhanced sampling techniques coupled\nwith molecular simulation have been developed. An intriguing analogy arises\nwith the field of Machine Learning (ML), where Generative Adversarial Networks\ncan produce high dimensional samples from low dimensional probability\ndistributions. This sample generation returns plausible high dimensional space\nrealizations of a model state, from information about its low-dimensional\nrepresentation. In this work, we present an approach that couples physics-based\nsimulations and biasing methods for sampling conditional distributions with\nML-based conditional generative adversarial networks for the same task. The\n\"coarse descriptors\" on which we condition the fine scale realizations can\neither be known a priori, or learned through nonlinear dimensionality\nreduction. We suggest that this may bring out the best features of both\napproaches: we demonstrate that a framework that couples cGANs with\nphysics-based enhanced sampling techniques can improve multiscale SDE dynamical\nsystems sampling, and even shows promise for systems of increasing complexity.\n","authors":["Ellis R. Crabtree","Juan M. Bello-Rivas","Andrew L. Ferguson","Ioannis G. Kevrekidis"],"pdf_url":"https://arxiv.org/pdf/2208.10715v2.pdf","comment":"21 pages, 10 figures, 3 tables"},{"id":"http://arxiv.org/abs/2301.09174v1","updated":"2023-01-22T18:18:20Z","published":"2023-01-22T18:18:20Z","title":"MATT: Multimodal Attention Level Estimation for e-learning Platforms","summary":"  This work presents a new multimodal system for remote attention level\nestimation based on multimodal face analysis. Our multimodal approach uses\ndifferent parameters and signals obtained from the behavior and physiological\nprocesses that have been related to modeling cognitive load such as faces\ngestures (e.g., blink rate, facial actions units) and user actions (e.g., head\npose, distance to the camera). The multimodal system uses the following modules\nbased on Convolutional Neural Networks (CNNs): Eye blink detection, head pose\nestimation, facial landmark detection, and facial expression features. First,\nwe individually evaluate the proposed modules in the task of estimating the\nstudent's attention level captured during online e-learning sessions. For that\nwe trained binary classifiers (high or low attention) based on Support Vector\nMachines (SVM) for each module. Secondly, we find out to what extent multimodal\nscore level fusion improves the attention level estimation. The mEBAL database\nis used in the experimental framework, a public multi-modal database for\nattention level estimation obtained in an e-learning environment that contains\ndata from 38 users while conducting several e-learning tasks of variable\ndifficulty (creating changes in student cognitive loads).\n","authors":["Roberto Daza","Luis F. Gomez","Aythami Morales","Julian Fierrez","Ruben Tolosana","Ruth Cobos","Javier Ortega-Garcia"],"pdf_url":"https://arxiv.org/pdf/2301.09174v1.pdf","comment":"Preprint of the paper presented to the Workshop on Artificial\n  Intelligence for Education (AI4EDU) of AAAI 2023"},{"id":"http://arxiv.org/abs/2207.01783v2","updated":"2023-01-22T17:26:32Z","published":"2022-07-05T02:53:25Z","title":"On A Mallows-type Model For (Ranked) Choices","summary":"  We consider a preference learning setting where every participant chooses an\nordered list of $k$ most preferred items among a displayed set of candidates.\n(The set can be different for every participant.) We identify a distance-based\nranking model for the population's preferences and their (ranked) choice\nbehavior. The ranking model resembles the Mallows model but uses a new distance\nfunction called Reverse Major Index (RMJ). We find that despite the need to sum\nover all permutations, the RMJ-based ranking distribution aggregates into\n(ranked) choice probabilities with simple closed-form expression. We develop\neffective methods to estimate the model parameters and showcase their\ngeneralization power using real data, especially when there is a limited\nvariety of display sets.\n","authors":["Yifan Feng","Yuxuan Tang"],"pdf_url":"https://arxiv.org/pdf/2207.01783v2.pdf","comment":"Accepted by the Thirty-Sixth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2301.09165v1","updated":"2023-01-22T17:21:00Z","published":"2023-01-22T17:21:00Z","title":"Energy Prediction using Federated Learning","summary":"  In this work, we demonstrate the viability of using federated learning to\nsuccessfully predict energy consumption as well as solar production for all\nhouseholds within a certain network using low-power and low-space consuming\nembedded devices. We also demonstrate our prediction performance improving over\ntime without the need for sharing private consumer energy data. We simulate a\nsystem with four nodes using data for one year to show this.\n","authors":["Meghana Bharadwaj","Sanjana Sarda"],"pdf_url":"https://arxiv.org/pdf/2301.09165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09164v1","updated":"2023-01-22T17:12:58Z","published":"2023-01-22T17:12:58Z","title":"Unifying Synergies between Self-supervised Learning and Dynamic\n  Computation","summary":"  Self-supervised learning (SSL) approaches have made major strides forward by\nemulating the performance of their supervised counterparts on several computer\nvision benchmarks. This, however, comes at a cost of substantially larger model\nsizes, and computationally expensive training strategies, which eventually lead\nto larger inference times making it impractical for resource constrained\nindustrial settings. Techniques like knowledge distillation (KD), dynamic\ncomputation (DC), and pruning are often used to obtain a lightweight\nsub-network, which usually involves multiple epochs of fine-tuning of a large\npre-trained model, making it more computationally challenging.\n  In this work we propose a novel perspective on the interplay between SSL and\nDC paradigms that can be leveraged to simultaneously learn a dense and gated\n(sparse/lightweight) sub-network from scratch offering a good\naccuracy-efficiency trade-off, and therefore yielding a generic and\nmulti-purpose architecture for application specific industrial settings. Our\nstudy overall conveys a constructive message: exhaustive experiments on several\nimage classification benchmarks: CIFAR-10, STL-10, CIFAR-100, and ImageNet-100,\ndemonstrates that the proposed training strategy provides a dense and\ncorresponding sparse sub-network that achieves comparable (on-par) performance\ncompared with the vanilla self-supervised setting, but at a significant\nreduction in computation in terms of FLOPs under a range of target budgets.\n","authors":["Tarun Krishna","Ayush K Rai","Alexandru Drimbarean","Alan F Smeaton","Kevin McGuinness","Noel E O'Connor"],"pdf_url":"https://arxiv.org/pdf/2301.09164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09159v1","updated":"2023-01-22T16:54:06Z","published":"2023-01-22T16:54:06Z","title":"Abstracting Imperfect Information Away from Two-Player Zero-Sum Games","summary":"  In their seminal work, Nayyar et al. (2013) showed that imperfect information\ncan be abstracted away from common-payoff games by having players publicly\nannounce their policies as they play. This insight underpins sound solvers and\ndecision-time planning algorithms for common-payoff games. Unfortunately, a\nnaive application of the same insight to two-player zero-sum games fails\nbecause Nash equilibria of the game with public policy announcements may not\ncorrespond to Nash equilibria of the original game. As a consequence, existing\nsound decision-time planning algorithms require complicated additional\nmechanisms that have unappealing properties. The main contribution of this work\nis showing that certain regularized equilibria do not possess the\naforementioned non-correspondence problem -- thus, computing them can be\ntreated as perfect information problems. Because these regularized equilibria\ncan be made arbitrarily close to Nash equilibria, our result opens the door to\na new perspective on solving two-player zero-sum games and, in particular,\nyields a simplified framework for decision-time planning in two-player zero-sum\ngames, void of the unappealing properties that plague existing decision-time\nplanning approaches.\n","authors":["Samuel Sokota","Ryan D'Orazio","Chun Kai Ling","David J. Wu","J. Zico Kolter","Noam Brown"],"pdf_url":"https://arxiv.org/pdf/2301.09159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09152v1","updated":"2023-01-22T16:47:05Z","published":"2023-01-22T16:47:05Z","title":"Prompt Federated Learning for Weather Forecasting: Toward Foundation\n  Models on Meteorological Data","summary":"  To tackle the global climate challenge, it urgently needs to develop a\ncollaborative platform for comprehensive weather forecasting on large-scale\nmeteorological data. Despite urgency, heterogeneous meteorological sensors\nacross countries and regions, inevitably causing multivariate heterogeneity and\ndata exposure, become the main barrier. This paper develops a foundation model\nacross regions capable of understanding complex meteorological data and\nproviding weather forecasting. To relieve the data exposure concern across\nregions, a novel federated learning approach has been proposed to\ncollaboratively learn a brand-new spatio-temporal Transformer-based foundation\nmodel across participants with heterogeneous meteorological data. Moreover, a\nnovel prompt learning mechanism has been adopted to satisfy low-resourced\nsensors' communication and computational constraints. The effectiveness of the\nproposed method has been demonstrated on classical weather forecasting tasks\nusing three meteorological datasets with multivariate time series.\n","authors":["Shengchao Chen","Guodong Long","Tao Shen","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2301.09152v1.pdf","comment":"10 pages, 4 figures, 8 tables"},{"id":"http://arxiv.org/abs/2206.06243v3","updated":"2023-01-22T15:47:12Z","published":"2022-06-13T15:23:31Z","title":"Contrastive Learning for Unsupervised Domain Adaptation of Time Series","summary":"  Unsupervised domain adaptation (UDA) aims at learning a machine learning\nmodel using a labeled source domain that performs well on a similar yet\ndifferent, unlabeled target domain. UDA is important in many applications such\nas medicine, where it is used to adapt risk scores across different patient\ncohorts. In this paper, we develop a novel framework for UDA of time series\ndata, called CLUDA. Specifically, we propose a contrastive learning framework\nto learn contextual representations in multivariate time series, so that these\npreserve label information for the prediction task. In our framework, we\nfurther capture the variation in the contextual representations between source\nand target domain via a custom nearest-neighbor contrastive learning. To the\nbest of our knowledge, ours is the first framework to learn domain-invariant,\ncontextual representation for UDA of time series data. We evaluate our\nframework using a wide range of time series datasets to demonstrate its\neffectiveness and show that it achieves state-of-the-art performance for time\nseries UDA.\n","authors":["Yilmazcan Ozyurt","Stefan Feuerriegel","Ce Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.06243v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09142v1","updated":"2023-01-22T15:46:57Z","published":"2023-01-22T15:46:57Z","title":"LF-checker: Machine Learning Acceleration of Bounded Model Checking for\n  Concurrency Verification (Competition Contribution)","summary":"  We describe and evaluate LF-checker, a metaverifier tool based on machine\nlearning. It extracts multiple features of the program under test and predicts\nthe optimal configuration (flags) of a bounded model checker with a decision\ntree. Our current work is specialised in concurrency verification and employs\nESBMC as a back-end verification engine. In the paper, we demonstrate that\nLF-checker achieves better results than the default configuration of the\nunderlying verification engine.\n","authors":["Tong Wu","Edoardo Manino","Fatimah Aljaafari","Pavlos Petoumenos","Lucas C. Cordeiro"],"pdf_url":"https://arxiv.org/pdf/2301.09142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09138v1","updated":"2023-01-22T15:17:12Z","published":"2023-01-22T15:17:12Z","title":"Explainable Quantum Machine Learning","summary":"  Methods of artificial intelligence (AI) and especially machine learning (ML)\nhave been growing ever more complex, and at the same time have more and more\nimpact on people's lives. This leads to explainable AI (XAI) manifesting itself\nas an important research field that helps humans to better comprehend ML\nsystems. In parallel, quantum machine learning (QML) is emerging with the\nongoing improvement of quantum computing hardware combined with its increasing\navailability via cloud services. QML enables quantum-enhanced ML in which\nquantum mechanics is exploited to facilitate ML tasks, typically in form of\nquantum-classical hybrid algorithms that combine quantum and classical\nresources. Quantum gates constitute the building blocks of gate-based quantum\nhardware and form circuits that can be used for quantum computations. For QML\napplications, quantum circuits are typically parameterized and their parameters\nare optimized classically such that a suitably defined objective function is\nminimized. Inspired by XAI, we raise the question of explainability of such\ncircuits by quantifying the importance of (groups of) gates for specific goals.\nTo this end, we transfer and adapt the well-established concept of Shapley\nvalues to the quantum realm. The resulting attributions can be interpreted as\nexplanations for why a specific circuit works well for a given task, improving\nthe understanding of how to construct parameterized (or variational) quantum\ncircuits, and fostering their human interpretability in general. An\nexperimental evaluation on simulators and two superconducting quantum hardware\ndevices demonstrates the benefits of the proposed framework for classification,\ngenerative modeling, transpilation, and optimization. Furthermore, our results\nshed some light on the role of specific gates in popular QML approaches.\n","authors":["Raoul Heese","Thore Gerlach","Sascha Mücke","Sabine Müller","Matthias Jakobs","Nico Piatkowski"],"pdf_url":"https://arxiv.org/pdf/2301.09138v1.pdf","comment":"35 pages, 27 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.14613v7","updated":"2023-01-22T13:12:48Z","published":"2022-12-30T09:40:09Z","title":"Delving into Semantic Scale Imbalance","summary":"  Model bias triggered by long-tailed data has been widely studied. However,\nmeasure based on the number of samples cannot explicate three phenomena\nsimultaneously: (1) Given enough data, the classification performance gain is\nmarginal with additional samples. (2) Classification performance decays\nprecipitously as the number of training samples decreases when there is\ninsufficient data. (3) Model trained on sample-balanced datasets still has\ndifferent biases for different classes. In this work, we define and quantify\nthe semantic scale of classes, which is used to measure the feature diversity\nof classes. It is exciting to find experimentally that there is a marginal\neffect of semantic scale, which perfectly describes the first two phenomena.\nFurther, the quantitative measurement of semantic scale imbalance is proposed,\nwhich can accurately reflect model bias on multiple datasets, even on\nsample-balanced data, revealing a novel perspective for the study of class\nimbalance. Due to the prevalence of semantic scale imbalance, we propose\nsemantic-scale-balanced learning, including a general loss improvement scheme\nand a dynamic re-weighting training framework that overcomes the challenge of\ncalculating semantic scales in real-time during iterations. Comprehensive\nexperiments show that dynamic semantic-scale-balanced learning consistently\nenables the model to perform superiorly on large-scale long-tailed and\nnon-long-tailed natural and medical datasets, which is a good starting point\nfor mitigating the prevalent but unnoticed model bias.\n","authors":["Yanbiao Ma","Licheng Jiao","Fang Liu","Yuxin Li","Shuyuan Yang","Xu Liu"],"pdf_url":"https://arxiv.org/pdf/2212.14613v7.pdf","comment":"47 pages, 26 figures, 12 tables, Published as a conference paper at\n  ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09117v1","updated":"2023-01-22T13:02:38Z","published":"2023-01-22T13:02:38Z","title":"Design-based individual prediction","summary":"  A design-based individual prediction approach is developed based on the\nexpected cross-validation results, given the sampling design and the\nsample-splitting design for cross-validation. Whether the predictor is selected\nfrom an ensemble of models or a weighted average of them, valid inference of\nthe unobserved prediction errors is defined and obtained with respect to the\nsampling design, while outcomes and features are treated as constants.\n","authors":["Li-Chun Zhang","Danhyang Lee"],"pdf_url":"https://arxiv.org/pdf/2301.09117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.01922v3","updated":"2023-01-22T12:54:40Z","published":"2021-12-03T14:05:52Z","title":"MetaQA: Combining Expert Agents for Multi-Skill Question Answering","summary":"  The recent explosion of question answering (QA) datasets and models has\nincreased the interest in the generalization of models across multiple domains\nand formats by either training on multiple datasets or by combining multiple\nmodels. Despite the promising results of multi-dataset models, some domains or\nQA formats may require specific architectures, and thus the adaptability of\nthese models might be limited. In addition, current approaches for combining\nmodels disregard cues such as question-answer compatibility. In this work, we\npropose to combine expert agents with a novel, flexible, and training-efficient\narchitecture that considers questions, answer predictions, and\nanswer-prediction confidence scores to select the best answer among a list of\nanswer candidates. Through quantitative and qualitative experiments we show\nthat our model i) creates a collaboration between agents that outperforms\nprevious multi-agent and multi-dataset approaches in both in-domain and\nout-of-domain scenarios, ii) is highly data-efficient to train, and iii) can be\nadapted to any QA format. We release our code and a dataset of answer\npredictions from expert agents for 16 QA datasets to foster future developments\nof multi-agent systems on https://github.com/UKPLab/MetaQA.\n","authors":["Haritz Puerto","Gözde Gül Şahin","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2112.01922v3.pdf","comment":"Accepted at EACL 2023"},{"id":"http://arxiv.org/abs/2005.06284v3","updated":"2023-01-22T12:45:12Z","published":"2020-05-13T12:24:40Z","title":"Pruning coupled with learning, ensembles of minimal neural networks, and\n  future of XAI","summary":"  Pruning coupled with learning aims to optimize the neural network (NN)\nstructure for solving specific problems. This optimization can be used for\nvarious purposes: to prevent overfitting, to save resources for implementation\nand training, to provide explainability of the trained NN, and many others. The\nminimal structure that cannot be pruned further is not unique. Ensemble of\nminimal structures can be used as a committee of intellectual agents that\nsolves problems by voting. Each minimal NN presents an \"empirical knowledge\"\nabout the problem and can be verbalized. The non-uniqueness of such knowledge\nextracted from data is an important property of data-driven Artificial\nIntelligence (AI). In this work, we review an approach to pruning based on the\nprinciple: What controls training should control pruning. This principle is\nexpected to work both for artificial NN and for selection and modification of\nimportant synaptic contacts in brain. In back-propagation artificial NN\nlearning is controlled by the gradient of loss functions. Therefore, the first\norder sensitivity indicators are used for pruning and the algorithms based on\nthese indicators are reviewed. The notion of logically transparent NN was\nintroduced. The approach was illustrated on the problem of political\nforecasting: predicting the results of the US presidential election. Eight\nminimal NN were produced that give different forecasting algorithms. The\nnon-uniqueness of solution can be utilised by creation of expert panels\n(committee). Another use of NN pluralism is to identify areas of input signals\nwhere further data collection is most useful. In Conclusion, we discuss the\npossible future of widely advertised XAI program.\n","authors":["Alexander N. Gorban","Evgeny M. Mirkes"],"pdf_url":"https://arxiv.org/pdf/2005.06284v3.pdf","comment":"Significantly modified and extended version, 23 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.09112v1","updated":"2023-01-22T12:29:03Z","published":"2023-01-22T12:29:03Z","title":"Differentially Private Natural Language Models: Recent Advances and\n  Future Directions","summary":"  Recent developments in deep learning have led to great success in various\nnatural language processing (NLP) tasks. However, these applications may\ninvolve data that contain sensitive information. Therefore, how to achieve good\nperformance while also protect privacy of sensitive data is a crucial challenge\nin NLP. To preserve privacy, Differential Privacy (DP), which can prevent\nreconstruction attacks and protect against potential side knowledge, is\nbecoming a de facto technique for private data analysis. In recent years, NLP\nin DP models (DP-NLP) has been studied from different perspectives, which\ndeserves a comprehensive review. In this paper, we provide the first systematic\nreview of recent advances on DP deep learning models in NLP. In particular, we\nfirst discuss some differences and additional challenges of DP-NLP compared\nwith the standard DP deep learning. Then we investigate some existing work on\nDP-NLP and present its recent developments from two aspects: gradient\nperturbation based methods and embedding vector perturbation based methods. We\nalso discuss some challenges and future directions of this topic.\n","authors":["Lijie Hu","Ivan Habernal","Lei Shen","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09109v1","updated":"2023-01-22T12:13:25Z","published":"2023-01-22T12:13:25Z","title":"Federated Recommendation with Additive Personalization","summary":"  With rising concerns about privacy, developing recommendation systems in a\nfederated setting become a new paradigm to develop next-generation Internet\nservice architecture. However, existing approaches are usually derived from a\ndistributed recommendation framework with an additional mechanism for privacy\nprotection, thus most of them fail to fully exploit personalization in the new\ncontext of federated recommendation settings. In this paper, we propose a novel\napproach called Federated Recommendation with Additive Personalization (FedRAP)\nto enhance recommendation by learning user embedding and the user's personal\nview of item embeddings. Specifically, the proposed additive personalization is\nto add a personalized item embedding to a sparse global item embedding\naggregated from all users. Moreover, a curriculum learning mechanism has been\napplied for additive personalization on item embeddings by gradually increasing\nregularization weights to mitigate the performance degradation caused by large\nvariances among client-specific item embeddings. A unified formulation has been\nproposed with a sparse regularization of global item embeddings for reducing\ncommunication overhead. Experimental results on four real-world recommendation\ndatasets demonstrate the effectiveness of FedRAP.\n","authors":["Zhiwei Li","Guodong Long","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.09109v1.pdf","comment":"9 pages, conference"},{"id":"http://arxiv.org/abs/2301.09091v1","updated":"2023-01-22T10:17:02Z","published":"2023-01-22T10:17:02Z","title":"BallGAN: 3D-aware Image Synthesis with a Spherical Background","summary":"  3D-aware GANs aim to synthesize realistic 3D scenes such that they can be\nrendered in arbitrary perspectives to produce images. Although previous methods\nproduce realistic images, they suffer from unstable training or degenerate\nsolutions where the 3D geometry is unnatural. We hypothesize that the 3D\ngeometry is underdetermined due to the insufficient constraint, i.e., being\nclassified as real image to the discriminator is not enough. To solve this\nproblem, we propose to approximate the background as a spherical surface and\nrepresent a scene as a union of the foreground placed in the sphere and the\nthin spherical background. It reduces the degree of freedom in the background\nfield. Accordingly, we modify the volume rendering equation and incorporate\ndedicated constraints to design a novel 3D-aware GAN framework named BallGAN.\nBallGAN has multiple advantages as follows. 1) It produces more reasonable 3D\ngeometry; the images of a scene across different viewpoints have better\nphotometric consistency and fidelity than the state-of-the-art methods. 2) The\ntraining becomes much more stable. 3) The foreground can be separately rendered\non top of different arbitrary backgrounds.\n","authors":["Minjung Shin","Yunji Seo","Jeongmin Bae","Young Sun Choi","Hyunsu Kim","Hyeran Byun","Youngjung Uh"],"pdf_url":"https://arxiv.org/pdf/2301.09091v1.pdf","comment":"Project Page: https://minjung-s.github.io/ballgan"},{"id":"http://arxiv.org/abs/2301.09090v1","updated":"2023-01-22T09:56:26Z","published":"2023-01-22T09:56:26Z","title":"Parallel Approaches to Accelerate Bayesian Decision Trees","summary":"  Markov Chain Monte Carlo (MCMC) is a well-established family of algorithms\nprimarily used in Bayesian statistics to sample from a target distribution when\ndirect sampling is challenging. Existing work on Bayesian decision trees uses\nMCMC. Unfortunately, this can be slow, especially when considering large\nvolumes of data. It is hard to parallelise the accept-reject component of the\nMCMC. None-the-less, we propose two methods for exploiting parallelism in the\nMCMC: in the first, we replace the MCMC with another numerical Bayesian\napproach, the Sequential Monte Carlo (SMC) sampler, which has the appealing\nproperty that it is an inherently parallel algorithm; in the second, we\nconsider data partitioning. Both methods use multi-core processing with a\nHighPerformance Computing (HPC) resource. We test the two methods in various\nstudy settings to determine which method is the most beneficial for each test\ncase. Experiments show that data partitioning has limited utility in the\nsettings we consider and that the use of the SMC sampler can improve run-time\n(compared to the sequential implementation) by up to a factor of 343.\n","authors":["Efthyvoulos Drousiotis","Paul G. Spirakis","Simon Maskell"],"pdf_url":"https://arxiv.org/pdf/2301.09090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.07472v5","updated":"2023-01-22T08:42:29Z","published":"2021-08-17T07:06:46Z","title":"Is Nash Equilibrium Approximator Learnable?","summary":"  In this paper, we investigate the learnability of the function approximator\nthat approximates Nash equilibrium (NE) for games generated from a\ndistribution. First, we offer a generalization bound using the Probably\nApproximately Correct (PAC) learning model. The bound describes the gap between\nthe expected loss and empirical loss of the NE approximator. Afterward, we\nprove the agnostic PAC learnability of the Nash approximator. In addition to\ntheoretical analysis, we demonstrate an application of NE approximator in\nexperiments. The trained NE approximator can be used to warm-start and\naccelerate classical NE solvers. Together, our results show the practicability\nof approximating NE through function approximation.\n","authors":["Zhijian Duan","Wenhan Huang","Dinghuai Zhang","Yali Du","Jun Wang","Yaodong Yang","Xiaotie Deng"],"pdf_url":"https://arxiv.org/pdf/2108.07472v5.pdf","comment":"Accepted by AAMAS 2023"},{"id":"http://arxiv.org/abs/2301.09069v1","updated":"2023-01-22T07:45:51Z","published":"2023-01-22T07:45:51Z","title":"Provable Unrestricted Adversarial Training without Compromise with\n  Generalizability","summary":"  Adversarial training (AT) is widely considered as the most promising strategy\nto defend against adversarial attacks and has drawn increasing interest from\nresearchers. However, the existing AT methods still suffer from two challenges.\nFirst, they are unable to handle unrestricted adversarial examples (UAEs),\nwhich are built from scratch, as opposed to restricted adversarial examples\n(RAEs), which are created by adding perturbations bound by an $l_p$ norm to\nobserved examples. Second, the existing AT methods often achieve adversarial\nrobustness at the expense of standard generalizability (i.e., the accuracy on\nnatural examples) because they make a tradeoff between them. To overcome these\nchallenges, we propose a unique viewpoint that understands UAEs as\nimperceptibly perturbed unobserved examples. Also, we find that the tradeoff\nresults from the separation of the distributions of adversarial examples and\nnatural examples. Based on these ideas, we propose a novel AT approach called\nProvable Unrestricted Adversarial Training (PUAT), which can provide a target\nclassifier with comprehensive adversarial robustness against both UAE and RAE,\nand simultaneously improve its standard generalizability. Particularly, PUAT\nutilizes partially labeled data to achieve effective UAE generation by\naccurately capturing the natural data distribution through a novel augmented\ntriple-GAN. At the same time, PUAT extends the traditional AT by introducing\nthe supervised loss of the target classifier into the adversarial loss and\nachieves the alignment between the UAE distribution, the natural data\ndistribution, and the distribution learned by the classifier, with the\ncollaboration of the augmented triple-GAN. Finally, the solid theoretical\nanalysis and extensive experiments conducted on widely-used benchmarks\ndemonstrate the superiority of PUAT.\n","authors":["Lilin Zhang","Ning Yang","Yanchao Sun","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2301.09069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13892v2","updated":"2023-01-22T07:36:06Z","published":"2022-05-27T10:48:14Z","title":"EvenNet: Ignoring Odd-Hop Neighbors Improves Robustness of Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) have received extensive research attention for\ntheir promising performance in graph machine learning. Despite their\nextraordinary predictive accuracy, existing approaches, such as GCN and GPRGNN,\nare not robust in the face of homophily changes on test graphs, rendering these\nmodels vulnerable to graph structural attacks and with limited capacity in\ngeneralizing to graphs of varied homophily levels. Although many methods have\nbeen proposed to improve the robustness of GNN models, most of these techniques\nare restricted to the spatial domain and employ complicated defense mechanisms,\nsuch as learning new graph structures or calculating edge attentions. In this\npaper, we study the problem of designing simple and robust GNN models in the\nspectral domain. We propose EvenNet, a spectral GNN corresponding to an\neven-polynomial graph filter. Based on our theoretical analysis in both spatial\nand spectral domains, we demonstrate that EvenNet outperforms full-order models\nin generalizing across homophilic and heterophilic graphs, implying that\nignoring odd-hop neighbors improves the robustness of GNNs. We conduct\nexperiments on both synthetic and real-world datasets to demonstrate the\neffectiveness of EvenNet. Notably, EvenNet outperforms existing defense models\nagainst structural attacks without introducing additional computational costs\nand maintains competitiveness in traditional node classification tasks on\nhomophilic and heterophilic graphs.\n","authors":["Runlin Lei","Zhen Wang","Yaliang Li","Bolin Ding","Zhewei Wei"],"pdf_url":"https://arxiv.org/pdf/2205.13892v2.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2201.12489v3","updated":"2023-01-22T07:26:18Z","published":"2022-01-29T03:47:00Z","title":"A Context-Integrated Transformer-Based Neural Network for Auction Design","summary":"  One of the central problems in auction design is developing an\nincentive-compatible mechanism that maximizes the auctioneer's expected\nrevenue. While theoretical approaches have encountered bottlenecks in\nmulti-item auctions, recently, there has been much progress on finding the\noptimal mechanism through deep learning. However, these works either focus on a\nfixed set of bidders and items, or restrict the auction to be symmetric. In\nthis work, we overcome such limitations by factoring \\emph{public} contextual\ninformation of bidders and items into the auction learning framework. We\npropose $\\mathtt{CITransNet}$, a context-integrated transformer-based neural\nnetwork for optimal auction design, which maintains permutation-equivariance\nover bids and contexts while being able to find asymmetric solutions. We show\nby extensive experiments that $\\mathtt{CITransNet}$ can recover the known\noptimal solutions in single-item settings, outperform strong baselines in\nmulti-item auctions, and generalize well to cases other than those in training.\n","authors":["Zhijian Duan","Jingwu Tang","Yutong Yin","Zhe Feng","Xiang Yan","Manzil Zaheer","Xiaotie Deng"],"pdf_url":"https://arxiv.org/pdf/2201.12489v3.pdf","comment":"Accepted by ICML 2022. Code is available at\n  https://github.com/zjduan/CITransNet"},{"id":"http://arxiv.org/abs/2301.09063v1","updated":"2023-01-22T06:23:53Z","published":"2023-01-22T06:23:53Z","title":"DASTSiam: Spatio-Temporal Fusion and Discriminative Augmentation for\n  Improved Siamese Tracking","summary":"  Tracking tasks based on deep neural networks have greatly improved with the\nemergence of Siamese trackers. However, the appearance of targets often changes\nduring tracking, which can reduce the robustness of the tracker when facing\nchallenges such as aspect ratio change, occlusion, and scale variation. In\naddition, cluttered backgrounds can lead to multiple high response points in\nthe response map, leading to incorrect target positioning. In this paper, we\nintroduce two transformer-based modules to improve Siamese tracking called\nDASTSiam: the spatio-temporal (ST) fusion module and the Discriminative\nAugmentation (DA) module. The ST module uses cross-attention based accumulation\nof historical cues to improve robustness against object appearance changes,\nwhile the DA module associates semantic information between the template and\nsearch region to improve target discrimination. Moreover, Modifying the label\nassignment of anchors also improves the reliability of the object location. Our\nmodules can be used with all Siamese trackers and show improved performance on\nseveral public datasets through comparative and ablation experiments.\n","authors":["Yucheng Huang","Eksan Firkat","Ziwang Xiao","Jihong Zhu","Askar Hamdulla"],"pdf_url":"https://arxiv.org/pdf/2301.09063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04613v3","updated":"2023-01-22T05:27:05Z","published":"2022-06-09T17:00:23Z","title":"Explicit Regularization in Overparametrized Models via Noise Injection","summary":"  Injecting noise within gradient descent has several desirable features, such\nas smoothing and regularizing properties. In this paper, we investigate the\neffects of injecting noise before computing a gradient step. We demonstrate\nthat small perturbations can induce explicit regularization for simple models\nbased on the L1-norm, group L1-norms, or nuclear norms. However, when applied\nto overparametrized neural networks with large widths, we show that the same\nperturbations can cause variance explosion. To overcome this, we propose using\nindependent layer-wise perturbations, which provably allow for explicit\nregularization without variance explosion. Our empirical results show that\nthese small perturbations lead to improved generalization performance compared\nto vanilla gradient descent.\n","authors":["Antonio Orvieto","Anant Raj","Hans Kersting","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2206.04613v3.pdf","comment":"Accepted at AISTATS 2023 23 pages"},{"id":"http://arxiv.org/abs/2301.09058v1","updated":"2023-01-22T05:01:13Z","published":"2023-01-22T05:01:13Z","title":"Leveraging Speaker Embeddings with Adversarial Multi-task Learning for\n  Age Group Classification","summary":"  Recently, researchers have utilized neural network-based speaker embedding\ntechniques in speaker-recognition tasks to identify speakers accurately.\nHowever, speaker-discriminative embeddings do not always represent speech\nfeatures such as age group well. In an embedding model that has been highly\ntrained to capture speaker traits, the task of age group classification is\ncloser to speech information leakage. Hence, to improve age group\nclassification performance, we consider the use of speaker-discriminative\nembeddings derived from adversarial multi-task learning to align features and\nreduce the domain discrepancy in age subgroups. In addition, we investigated\ndifferent types of speaker embeddings to learn and generalize the\ndomain-invariant representations for age groups. Experimental results on the\nVoxCeleb Enrichment dataset verify the effectiveness of our proposed adaptive\nadversarial network in multi-objective scenarios and leveraging speaker\nembeddings for the domain adaptation task.\n","authors":["Kwangje Baeg","Yeong-Gwan Kim","Young-Sub Han","Byoung-Ki Jeon"],"pdf_url":"https://arxiv.org/pdf/2301.09058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11446v2","updated":"2023-01-22T03:28:46Z","published":"2022-05-23T16:35:46Z","title":"Overfitting in quantum machine learning and entangling dropout","summary":"  The ultimate goal in machine learning is to construct a model function that\nhas a generalization capability for unseen dataset, based on given training\ndataset. If the model function has too much expressibility power, then it may\noverfit to the training data and as a result lose the generalization\ncapability. To avoid such overfitting issue, several techniques have been\ndeveloped in the classical machine learning regime, and the dropout is one such\neffective method. This paper proposes a straightforward analogue of this\ntechnique in the quantum machine learning regime, the entangling dropout,\nmeaning that some entangling gates in a given parametrized quantum circuit are\nrandomly removed during the training process to reduce the expressibility of\nthe circuit. Some simple case studies are given to show that this technique\nactually suppresses the overfitting.\n","authors":["Masahiro Kobayashi","Kouhei Nakaji","Naoki Yamamoto"],"pdf_url":"https://arxiv.org/pdf/2205.11446v2.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2301.09044v1","updated":"2023-01-22T03:04:19Z","published":"2023-01-22T03:04:19Z","title":"Learning to Reject with a Fixed Predictor: Application to\n  Decontextualization","summary":"  We study the problem of classification with a reject option for a fixed\npredictor, applicable in natural language processing. \\ignore{where many\ncorrect labels are often possible} We introduce a new problem formulation for\nthis scenario, and an algorithm minimizing a new surrogate loss function. We\nprovide a complete theoretical analysis of the surrogate loss function with a\nstrong $H$-consistency guarantee. For evaluation, we choose the\n\\textit{decontextualization} task, and provide a manually-labelled dataset of\n$2\\mathord,000$ examples. Our algorithm significantly outperforms the baselines\nconsidered, with a $\\sim\\!\\!25\\%$ improvement in coverage when halving the\nerror rate, which is only $\\sim\\!\\! 3 \\%$ away from the theoretical limit.\n","authors":["Christopher Mohri","Daniel Andor","Eunsol Choi","Michael Collins"],"pdf_url":"https://arxiv.org/pdf/2301.09044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09042v1","updated":"2023-01-22T02:58:00Z","published":"2023-01-22T02:58:00Z","title":"The Shape of Explanations: A Topological Account of Rule-Based\n  Explanations in Machine Learning","summary":"  Rule-based explanations provide simple reasons explaining the behavior of\nmachine learning classifiers at given points in the feature space. Several\nrecent methods (Anchors, LORE, etc.) purport to generate rule-based\nexplanations for arbitrary or black-box classifiers. But what makes these\nmethods work in general? We introduce a topological framework for rule-based\nexplanation methods and provide a characterization of explainability in terms\nof the definability of a classifier relative to an explanation scheme. We\nemploy this framework to consider various explanation schemes and argue that\nthe preferred scheme depends on how much the user knows about the domain and\nthe probability measure over the feature space.\n","authors":["Brett Mullins"],"pdf_url":"https://arxiv.org/pdf/2301.09042v1.pdf","comment":"Accepted by The AAAI 2023 Workshop on Representation Learning for\n  Responsible Human-Centric AI"},{"id":"http://arxiv.org/abs/2301.09031v1","updated":"2023-01-22T00:58:14Z","published":"2023-01-22T00:58:14Z","title":"Counterfactual (Non-)identifiability of Learned Structural Causal Models","summary":"  Recent advances in probabilistic generative modeling have motivated learning\nStructural Causal Models (SCM) from observational datasets using deep\nconditional generative models, also known as Deep Structural Causal Models\n(DSCM). If successful, DSCMs can be utilized for causal estimation tasks, e.g.,\nfor answering counterfactual queries. In this work, we warn practitioners about\nnon-identifiability of counterfactual inference from observational data, even\nin the absence of unobserved confounding and assuming known causal structure.\nWe prove counterfactual identifiability of monotonic generation mechanisms with\nsingle dimensional exogenous variables. For general generation mechanisms with\nmulti-dimensional exogenous variables, we provide an impossibility result for\ncounterfactual identifiability, motivating the need for parametric assumptions.\nAs a practical approach, we propose a method for estimating worst-case errors\nof learned DSCMs' counterfactual predictions. The size of this error can be an\nessential metric for deciding whether or not DSCMs are a viable approach for\ncounterfactual inference in a specific problem setting. In evaluation, our\nmethod confirms negligible counterfactual errors for an identifiable SCM from\nprior work, and also provides informative error bounds on counterfactual errors\nfor a non-identifiable synthetic SCM.\n","authors":["Arash Nasr-Esfahany","Emre Kiciman"],"pdf_url":"https://arxiv.org/pdf/2301.09031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09030v1","updated":"2023-01-22T00:58:01Z","published":"2023-01-22T00:58:01Z","title":"Condition monitoring and anomaly detection in cyber-physical systems","summary":"  The modern industrial environment is equipping myriads of smart manufacturing\nmachines where the state of each device can be monitored continuously. Such\nmonitoring can help identify possible future failures and develop a\ncost-effective maintenance plan. However, it is a daunting task to perform\nearly detection with low false positives and negatives from the huge volume of\ncollected data. This requires developing a holistic machine learning framework\nto address the issues in condition monitoring of high-priority components and\ndevelop efficient techniques to detect anomalies that can detect and possibly\nlocalize the faulty components. This paper presents a comparative analysis of\nrecent machine learning approaches for robust, cost-effective anomaly detection\nin cyber-physical systems. While detection has been extensively studied, very\nfew researchers have analyzed the localization of the anomalies. We show that\nsupervised learning outperforms unsupervised algorithms. For supervised cases,\nwe achieve near-perfect accuracy of 98 percent (specifically for tree-based\nalgorithms). In contrast, the best-case accuracy in the unsupervised cases was\n63 percent :the area under the receiver operating characteristic curve (AUC)\nexhibits similar outcomes as an additional metric.\n","authors":["William Marfo","Deepak K. Tosh","Shirley V. Moore"],"pdf_url":"https://arxiv.org/pdf/2301.09030v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2301.09028v1","updated":"2023-01-22T00:24:22Z","published":"2023-01-22T00:24:22Z","title":"Characterization and Learning of Causal Graphs with Small Conditioning\n  Sets","summary":"  Constraint-based causal discovery algorithms learn part of the causal graph\nstructure by systematically testing conditional independences observed in the\ndata. These algorithms, such as the PC algorithm and its variants, rely on\ngraphical characterizations of the so-called equivalence class of causal graphs\nproposed by Pearl. However, constraint-based causal discovery algorithms\nstruggle when data is limited since conditional independence tests quickly lose\ntheir statistical power, especially when the conditioning set is large. To\naddress this, we propose using conditional independence tests where the size of\nthe conditioning set is upper bounded by some integer $k$ for robust causal\ndiscovery. The existing graphical characterizations of the equivalence classes\nof causal graphs are not applicable when we cannot leverage all the conditional\nindependence statements. We first define the notion of $k$-Markov equivalence:\nTwo causal graphs are $k$-Markov equivalent if they entail the same conditional\nindependence constraints where the conditioning set size is upper bounded by\n$k$. We propose a novel representation that allows us to graphically\ncharacterize $k$-Markov equivalence between two causal graphs. We propose a\nsound constraint-based algorithm called the $k$-PC algorithm for learning this\nequivalence class. Finally, we conduct synthetic, and semi-synthetic\nexperiments to demonstrate that the $k$-PC algorithm enables more robust causal\ndiscovery in the small sample regime compared to the baseline PC algorithm.\n","authors":["Murat Kocaoglu"],"pdf_url":"https://arxiv.org/pdf/2301.09028v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2301.09027v1","updated":"2023-01-22T00:18:10Z","published":"2023-01-22T00:18:10Z","title":"Cellular Network Speech Enhancement: Removing Background and\n  Transmission Noise","summary":"  The primary objective of speech enhancement is to reduce background noise\nwhile preserving the target's speech. A common dilemma occurs when a speaker is\nconfined to a noisy environment and receives a call with high background and\ntransmission noise. To address this problem, the Deep Noise Suppression (DNS)\nChallenge focuses on removing the background noise with the next-generation\ndeep learning models to enhance the target's speech; however, researchers fail\nto consider Voice Over IP (VoIP) applications their transmission noise.\nFocusing on Google Meet and its cellular application, our work achieves\nstate-of-the-art performance on the Google Meet To Phone Track of the VoIP DNS\nChallenge. This paper demonstrates how to beat industrial performance and\nachieve 1.92 PESQ and 0.88 STOI, as well as superior acoustic fidelity,\nperceptual quality, and intelligibility in various metrics.\n","authors":["Amanda Shu","Hamza Khalid","Haohui Liu","Shikhar Agnihotri","Joseph Konan","Ojas Bhargave"],"pdf_url":"https://arxiv.org/pdf/2301.09027v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.09080v1","updated":"2023-01-22T08:35:51Z","published":"2023-01-22T08:35:51Z","title":"Dance2MIDI: Dance-driven multi-instruments music generation","summary":"  Dance-driven music generation aims to generate musical pieces conditioned on\ndance videos. Previous works focus on monophonic or raw audio generation, while\nthe multiinstruments scenario is under-explored. The challenges of the\ndance-driven multi-instruments music (MIDI) generation are two-fold: 1) no\npublicly available multi-instruments MIDI and video paired dataset and 2) the\nweak correlation between music and video. To tackle these challenges, we build\nthe first multi-instruments MIDI and dance paired dataset (D2MIDI). Based on\nour proposed dataset, we introduce a multi-instruments MIDI generation\nframework (Dance2MIDI) conditioned on dance video. Specifically, 1) to model\nthe correlation between music and dance, we encode the dance motion using the\nGCN, and 2) to generate harmonious and coherent music, we employ Transformer to\ndecode the MIDI sequence. We evaluate the generated music of our framework\ntrained on D2MIDI dataset and demonstrate that our method outperforms existing\nmethods. The data and code are available on\nhttps://github.com/Dance2MIDI/Dance2MIDI\n","authors":["Bo Han","Yi Ren"],"pdf_url":"https://arxiv.org/pdf/2301.09080v1.pdf","comment":null}]},"2023-01-21T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.09017v1","updated":"2023-01-21T21:58:00Z","published":"2023-01-21T21:58:00Z","title":"Transfer Knowledge from Natural Language to Electrocardiography: Can We\n  Detect Cardiovascular Disease Through Language Models?","summary":"  Recent advancements in Large Language Models (LLMs) have drawn increasing\nattention since the learned embeddings pretrained on large-scale datasets have\nshown powerful ability in various downstream applications. However, whether the\nlearned knowledge by LLMs can be transferred to clinical cardiology remains\nunknown. In this work, we aim to bridge this gap by transferring the knowledge\nof LLMs to clinical Electrocardiography (ECG). We propose an approach for\ncardiovascular disease diagnosis and automatic ECG diagnosis report generation.\nWe also introduce an additional loss function by Optimal Transport (OT) to\nalign the distribution between ECG and language embedding. The learned\nembeddings are evaluated on two downstream tasks: (1) automatic ECG diagnosis\nreport generation, and (2) zero-shot cardiovascular disease detection. Our\napproach is able to generate high-quality cardiac diagnosis reports and also\nachieves competitive zero-shot classification performance even compared with\nsupervised baselines, which proves the feasibility of transferring knowledge\nfrom LLMs to the cardiac domain.\n","authors":["Jielin Qiu","William Han","Jiacheng Zhu","Mengdi Xu","Michael Rosenberg","Emerson Liu","Douglas Weber","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.09017v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2301.09008v1","updated":"2023-01-21T21:02:16Z","published":"2023-01-21T21:02:16Z","title":"Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics\n  Without the Reference","summary":"  Machine translation quality estimation (QE) predicts human judgements of a\ntranslation hypothesis without seeing the reference. State-of-the-art QE\nsystems based on pretrained language models have been achieving remarkable\ncorrelations with human judgements yet they are computationally heavy and\nrequire human annotations, which are slow and expensive to create. To address\nthese limitations, we define the problem of metric estimation (ME) where one\npredicts the automated metric scores also without the reference. We show that\neven without access to the reference, our model can estimate automated metrics\n($\\rho$=60% for BLEU, $\\rho$=51% for other metrics) at the sentence-level.\nBecause automated metrics correlate with human judgements, we can leverage the\nME task for pre-training a QE model. For the QE task, we find that pre-training\non TER is better ($\\rho$=23%) than training for scratch ($\\rho$=20%).\n","authors":["Vilém Zouhar","Shehzaad Dhuliawala","Wangchunshu Zhou","Nico Daheim","Tom Kocmi","Yuchen Eleanor Jiang","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2301.09008v1.pdf","comment":"Accepted at EACL23 (main)"},{"id":"http://arxiv.org/abs/2301.09003v1","updated":"2023-01-21T20:23:09Z","published":"2023-01-21T20:23:09Z","title":"Blacks is to Anger as Whites is to Joy? Understanding Latent Affective\n  Bias in Large Pre-trained Neural Language Models","summary":"  Groundbreaking inventions and highly significant performance improvements in\ndeep learning based Natural Language Processing are witnessed through the\ndevelopment of transformer based large Pre-trained Language Models (PLMs). The\nwide availability of unlabeled data within human generated data deluge along\nwith self-supervised learning strategy helps to accelerate the success of large\nPLMs in language generation, language understanding, etc. But at the same time,\nlatent historical bias/unfairness in human minds towards a particular gender,\nrace, etc., encoded unintentionally/intentionally into the corpora harms and\nquestions the utility and efficacy of large PLMs in many real-world\napplications, particularly for the protected groups. In this paper, we present\nan extensive investigation towards understanding the existence of \"Affective\nBias\" in large PLMs to unveil any biased association of emotions such as anger,\nfear, joy, etc., towards a particular gender, race or religion with respect to\nthe downstream task of textual emotion detection. We conduct our exploration of\naffective bias from the very initial stage of corpus level affective bias\nanalysis by searching for imbalanced distribution of affective words within a\ndomain, in large scale corpora that are used to pre-train and fine-tune PLMs.\nLater, to quantify affective bias in model predictions, we perform an extensive\nset of class-based and intensity-based evaluations using various bias\nevaluation corpora. Our results show the existence of statistically significant\naffective bias in the PLM based emotion detection systems, indicating biased\nassociation of certain emotions towards a particular gender, race, and\nreligion.\n","authors":["Anoop Kadan","Deepak P.","Sahely Bhadra","Manjary P. Gangan","Lajish V. L"],"pdf_url":"https://arxiv.org/pdf/2301.09003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08998v1","updated":"2023-01-21T19:42:02Z","published":"2023-01-21T19:42:02Z","title":"Syntax-guided Neural Module Distillation to Probe Compositionality in\n  Sentence Embeddings","summary":"  Past work probing compositionality in sentence embedding models faces issues\ndetermining the causal impact of implicit syntax representations. Given a\nsentence, we construct a neural module net based on its syntax parse and train\nit end-to-end to approximate the sentence's embedding generated by a\ntransformer model. The distillability of a transformer to a Syntactic NeurAl\nModule Net (SynNaMoN) then captures whether syntax is a strong causal model of\nits compositional ability. Furthermore, we address questions about the geometry\nof semantic composition by specifying individual SynNaMoN modules' internal\narchitecture & linearity. We find differences in the distillability of various\nsentence embedding models that broadly correlate with their performance, but\nobserve that distillability doesn't considerably vary by model size. We also\npresent preliminary evidence that much syntax-guided composition in sentence\nembedding models is linear, and that non-linearities may serve primarily to\nhandle non-compositional phrases.\n","authors":["Rohan Pandey"],"pdf_url":"https://arxiv.org/pdf/2301.08998v1.pdf","comment":"EACL 2023 (accepted)"},{"id":"http://arxiv.org/abs/2301.08995v1","updated":"2023-01-21T19:28:25Z","published":"2023-01-21T19:28:25Z","title":"REDAffectiveLM: Leveraging Affect Enriched Embedding and\n  Transformer-based Neural Language Model for Readers' Emotion Detection","summary":"  Technological advancements in web platforms allow people to express and share\nemotions towards textual write-ups written and shared by others. This brings\nabout different interesting domains for analysis; emotion expressed by the\nwriter and emotion elicited from the readers. In this paper, we propose a novel\napproach for Readers' Emotion Detection from short-text documents using a deep\nlearning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is\nwell understood that utilizing context-specific representations from\ntransformer-based pre-trained language models helps achieve improved\nperformance. Within this affective computing task, we explore how incorporating\naffective information can further enhance performance. Towards this, we\nleverage context-specific and affect enriched representations by using a\ntransformer-based pre-trained language model in tandem with affect enriched\nBi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k,\nbesides using RENh-4k and SemEval-2007. We evaluate the performance of our\nREDAffectiveLM rigorously across these datasets, against a vast set of\nstate-of-the-art baselines, where our model consistently outperforms baselines\nand obtains statistically significant results. Our results establish that\nutilizing affect enriched representation along with context-specific\nrepresentation within a neural architecture can considerably enhance readers'\nemotion detection. Since the impact of affect enrichment specifically in\nreaders' emotion detection isn't well explored, we conduct a detailed analysis\nover affect enriched Bi-LSTM+Attention using qualitative and quantitative model\nbehavior evaluation techniques. We observe that compared to conventional\nsemantic embedding, affect enriched embedding increases ability of the network\nto effectively identify and assign weightage to key terms responsible for\nreaders' emotion detection.\n","authors":["Anoop Kadan","Deepak P.","Manjary P. Gangan","Savitha Sam Abraham","Lajish V. L"],"pdf_url":"https://arxiv.org/pdf/2301.08995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07476v2","updated":"2023-01-21T18:16:14Z","published":"2022-12-14T19:50:35Z","title":"The Infinite Index: Information Retrieval on Generative Text-To-Image\n  Models","summary":"  Conditional generative models such as DALL-E and Stable Diffusion generate\nimages based on a user-defined text, the prompt. Finding and refining prompts\nthat produce a desired image has become the art of prompt engineering.\nGenerative models do not provide a built-in retrieval model for a user's\ninformation need expressed through prompts. In light of an extensive literature\nreview, we reframe prompt engineering for generative models as interactive\ntext-based retrieval on a novel kind of \"infinite index\". We apply these\ninsights for the first time in a case study on image generation for game design\nwith an expert. Finally, we envision how active learning may help to guide the\nretrieval of generated images.\n","authors":["Niklas Deckers","Maik Fröbe","Johannes Kiesel","Gianluca Pandolfo","Christopher Schröder","Benno Stein","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2212.07476v2.pdf","comment":"Final version for CHIIR 2023"},{"id":"http://arxiv.org/abs/2301.08986v1","updated":"2023-01-21T17:57:53Z","published":"2023-01-21T17:57:53Z","title":"Adapting a Language Model While Preserving its General Knowledge","summary":"  Domain-adaptive pre-training (or DA-training for short), also known as\npost-training, aims to train a pre-trained general-purpose language model (LM)\nusing an unlabeled corpus of a particular domain to adapt the LM so that\nend-tasks in the domain can give improved performances. However, existing\nDA-training methods are in some sense blind as they do not explicitly identify\nwhat knowledge in the LM should be preserved and what should be changed by the\ndomain corpus. This paper shows that the existing methods are suboptimal and\nproposes a novel method to perform a more informed adaptation of the knowledge\nin the LM by (1) soft-masking the attention heads based on their importance to\nbest preserve the general knowledge in the LM and (2) contrasting the\nrepresentations of the general and the full (both general and domain knowledge)\nto learn an integrated representation with both general and domain-specific\nknowledge. Experimental results will demonstrate the effectiveness of the\nproposed approach.\n","authors":["Zixuan Ke","Yijia Shao","Haowei Lin","Hu Xu","Lei Shu","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2301.08986v1.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2301.08937v1","updated":"2023-01-21T11:04:20Z","published":"2023-01-21T11:04:20Z","title":"Exploring Methods for Building Dialects-Mandarin Code-Mixing Corpora: A\n  Case Study in Taiwanese Hokkien","summary":"  In natural language processing (NLP), code-mixing (CM) is a challenging task,\nespecially when the mixed languages include dialects. In Southeast Asian\ncountries such as Singapore, Indonesia, and Malaysia, Hokkien-Mandarin is the\nmost widespread code-mixed language pair among Chinese immigrants, and it is\nalso common in Taiwan. However, dialects such as Hokkien often have a scarcity\nof resources and the lack of an official writing system, limiting the\ndevelopment of dialect CM research. In this paper, we propose a method to\nconstruct a Hokkien-Mandarin CM dataset to mitigate the limitation, overcome\nthe morphological issue under the Sino-Tibetan language family, and offer an\nefficient Hokkien word segmentation method through a linguistics-based toolkit.\nFurthermore, we use our proposed dataset and employ transfer learning to train\nthe XLM (cross-lingual language model) for translation tasks. To fit the\ncode-mixing scenario, we adapt XLM slightly. We found that by using linguistic\nknowledge, rules, and language tags, the model produces good results on CM data\ntranslation while maintaining monolingual translation quality.\n","authors":["Sin-En Lu","Bo-Han Lu","Chao-Yi Lu","Richard Tzong-Han Tsai"],"pdf_url":"https://arxiv.org/pdf/2301.08937v1.pdf","comment":"The paper was accepted by EMNLP 2022 findings"},{"id":"http://arxiv.org/abs/2301.08914v1","updated":"2023-01-21T08:26:27Z","published":"2023-01-21T08:26:27Z","title":"ExClaim: Explainable Neural Claim Verification Using Rationalization","summary":"  With the advent of deep learning, text generation language models have\nimproved dramatically, with text at a similar level as human-written text. This\ncan lead to rampant misinformation because content can now be created cheaply\nand distributed quickly. Automated claim verification methods exist to validate\nclaims, but they lack foundational data and often use mainstream news as\nevidence sources that are strongly biased towards a specific agenda. Current\nclaim verification methods use deep neural network models and complex\nalgorithms for a high classification accuracy but it is at the expense of model\nexplainability. The models are black-boxes and their decision-making process\nand the steps it took to arrive at a final prediction are obfuscated from the\nuser. We introduce a novel claim verification approach, namely: ExClaim, that\nattempts to provide an explainable claim verification system with foundational\nevidence. Inspired by the legal system, ExClaim leverages rationalization to\nprovide a verdict for the claim and justifies the verdict through a natural\nlanguage explanation (rationale) to describe the model's decision-making\nprocess. ExClaim treats the verdict classification task as a question-answer\nproblem and achieves a performance of 0.93 F1 score. It provides subtasks\nexplanations to also justify the intermediate outcomes. Statistical and\nExplainable AI (XAI) evaluations are conducted to ensure valid and trustworthy\noutcomes. Ensuring claim verification systems are assured, rational, and\nexplainable is an essential step toward improving Human-AI trust and the\naccessibility of black-box systems.\n","authors":["Sai Gurrapu","Lifu Huang","Feras A. Batarseh"],"pdf_url":"https://arxiv.org/pdf/2301.08914v1.pdf","comment":"Published at 2022 IEEE 29th STC"},{"id":"http://arxiv.org/abs/2301.08913v1","updated":"2023-01-21T08:18:11Z","published":"2023-01-21T08:18:11Z","title":"Unifying Structure Reasoning and Language Model Pre-training for Complex\n  Reasoning","summary":"  Recent knowledge enhanced pre-trained language models have shown remarkable\nperformance on downstream tasks by incorporating structured knowledge from\nexternal sources into language models. However, they usually suffer from a\nheterogeneous information alignment problem and a noisy knowledge injection\nproblem. For complex reasoning, the contexts contain rich knowledge that\ntypically exists in complex and sparse forms. In order to model structured\nknowledge in the context and avoid these two problems, we propose to unify\nstructure reasoning and language model pre-training. It identifies four types\nof elementary knowledge structures from contexts to construct structured\nqueries, and utilizes the box embedding method to conduct explicit structure\nreasoning along queries during language modeling. To fuse textual and\nstructured semantics, we utilize contextual language representations of\nknowledge structures to initialize their box embeddings for structure\nreasoning. We conduct experiments on complex language reasoning and knowledge\ngraph (KG) reasoning tasks. The results show that our model can effectively\nenhance the performance of complex reasoning of both language and KG\nmodalities.\n","authors":["Siyuan Wang","Zhongyu Wei","Jiarong Xu","Zhihao Fan"],"pdf_url":"https://arxiv.org/pdf/2301.08913v1.pdf","comment":"10 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2301.08912v1","updated":"2023-01-21T07:58:03Z","published":"2023-01-21T07:58:03Z","title":"Rationalization for Explainable NLP: A Survey","summary":"  Recent advances in deep learning have improved the performance of many\nNatural Language Processing (NLP) tasks such as translation,\nquestion-answering, and text classification. However, this improvement comes at\nthe expense of model explainability. Black-box models make it difficult to\nunderstand the internals of a system and the process it takes to arrive at an\noutput. Numerical (LIME, Shapley) and visualization (saliency heatmap)\nexplainability techniques are helpful; however, they are insufficient because\nthey require specialized knowledge. These factors led rationalization to emerge\nas a more accessible explainable technique in NLP. Rationalization justifies a\nmodel's output by providing a natural language explanation (rationale). Recent\nimprovements in natural language generation have made rationalization an\nattractive technique because it is intuitive, human-comprehensible, and\naccessible to non-technical users. Since rationalization is a relatively new\nfield, it is disorganized. As the first survey, rationalization literature in\nNLP from 2007-2022 is analyzed. This survey presents available methods,\nexplainable evaluations, code, and datasets used across various NLP tasks that\nuse rationalization. Further, a new subfield in Explainable AI (XAI), namely,\nRational AI (RAI), is introduced to advance the current state of\nrationalization. A discussion on observed insights, challenges, and future\ndirections is provided to point to promising research opportunities.\n","authors":["Sai Gurrapu","Ajay Kulkarni","Lifu Huang","Ismini Lourentzou","Laura Freeman","Feras A. Batarseh"],"pdf_url":"https://arxiv.org/pdf/2301.08912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08881v1","updated":"2023-01-21T03:57:18Z","published":"2023-01-21T03:57:18Z","title":"Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL\n  Robustness","summary":"  Neural text-to-SQL models have achieved remarkable performance in translating\nnatural language questions into SQL queries. However, recent studies reveal\nthat text-to-SQL models are vulnerable to task-specific perturbations. Previous\ncurated robustness test sets usually focus on individual phenomena. In this\npaper, we propose a comprehensive robustness benchmark based on Spider, a\ncross-domain text-to-SQL benchmark, to diagnose the model robustness. We design\n17 perturbations on databases, natural language questions, and SQL queries to\nmeasure the robustness from different angles. In order to collect more\ndiversified natural question perturbations, we utilize large pretrained\nlanguage models (PLMs) to simulate human behaviors in creating natural\nquestions. We conduct a diagnostic study of the state-of-the-art models on the\nrobustness set. Experimental results reveal that even the most robust model\nsuffers from a 14.0% performance drop overall and a 50.7% performance drop on\nthe most challenging perturbation. We also present a breakdown analysis\nregarding text-to-SQL model designs and provide insights for improving model\nrobustness.\n","authors":["Shuaichen Chang","Jun Wang","Mingwen Dong","Lin Pan","Henghui Zhu","Alexander Hanbo Li","Wuwei Lan","Sheng Zhang","Jiarong Jiang","Joseph Lilien","Steve Ash","William Yang Wang","Zhiguo Wang","Vittorio Castelli","Patrick Ng","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2301.08881v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2301.08855v1","updated":"2023-01-21T02:20:43Z","published":"2023-01-21T02:20:43Z","title":"ProKD: An Unsupervised Prototypical Knowledge Distillation Network for\n  Zero-Resource Cross-Lingual Named Entity Recognition","summary":"  For named entity recognition (NER) in zero-resource languages, utilizing\nknowledge distillation methods to transfer language-independent knowledge from\nthe rich-resource source languages to zero-resource languages is an effective\nmeans. Typically, these approaches adopt a teacher-student architecture, where\nthe teacher network is trained in the source language, and the student network\nseeks to learn knowledge from the teacher network and is expected to perform\nwell in the target language. Despite the impressive performance achieved by\nthese methods, we argue that they have two limitations. Firstly, the teacher\nnetwork fails to effectively learn language-independent knowledge shared across\nlanguages due to the differences in the feature distribution between the source\nand target languages. Secondly, the student network acquires all of its\nknowledge from the teacher network and ignores the learning of target\nlanguage-specific knowledge. Undesirably, these limitations would hinder the\nmodel's performance in the target language. This paper proposes an unsupervised\nprototype knowledge distillation network (ProKD) to address these issues.\nSpecifically, ProKD presents a contrastive learning-based prototype alignment\nmethod to achieve class feature alignment by adjusting the distance among\nprototypes in the source and target languages, boosting the teacher network's\ncapacity to acquire language-independent knowledge. In addition, ProKD\nintroduces a prototypical self-training method to learn the intrinsic structure\nof the language by retraining the student network on the target data using\nsamples' distance information from prototypes, thereby enhancing the student\nnetwork's ability to acquire language-specific knowledge. Extensive experiments\non three benchmark cross-lingual NER datasets demonstrate the effectiveness of\nour approach.\n","authors":["Ling Ge","Chuming Hu","Guanghui Ma","Hong Zhang","Jihong Liu"],"pdf_url":"https://arxiv.org/pdf/2301.08855v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2301.08846v1","updated":"2023-01-21T01:33:34Z","published":"2023-01-21T01:33:34Z","title":"Regeneration Learning: A Learning Paradigm for Data Generation","summary":"  Machine learning methods for conditional data generation usually build a\nmapping from source conditional data X to target data Y. The target Y (e.g.,\ntext, speech, music, image, video) is usually high-dimensional and complex, and\ncontains information that does not exist in source data, which hinders\neffective and efficient learning on the source-target mapping. In this paper,\nwe present a learning paradigm called regeneration learning for data\ngeneration, which first generates Y' (an abstraction/representation of Y) from\nX and then generates Y from Y'. During training, Y' is obtained from Y through\neither handcrafted rules or self-supervised learning and is used to learn\nX-->Y' and Y'-->Y. Regeneration learning extends the concept of representation\nlearning to data generation tasks, and can be regarded as a counterpart of\ntraditional representation learning, since 1) regeneration learning handles the\nabstraction (Y') of the target data Y for data generation while traditional\nrepresentation learning handles the abstraction (X') of source data X for data\nunderstanding; 2) both the processes of Y'-->Y in regeneration learning and\nX-->X' in representation learning can be learned in a self-supervised way\n(e.g., pre-training); 3) both the mappings from X to Y' in regeneration\nlearning and from X' to Y in representation learning are simpler than the\ndirect mapping from X to Y. We show that regeneration learning can be a\nwidely-used paradigm for data generation (e.g., text generation, speech\nrecognition, speech synthesis, music composition, image generation, and video\ngeneration) and can provide valuable insights into developing data generation\nmethods.\n","authors":["Xu Tan","Tao Qin","Jiang Bian","Tie-Yan Liu","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2301.08846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00068v2","updated":"2023-01-21T01:23:00Z","published":"2022-08-31T18:55:22Z","title":"Incorporating Task-specific Concept Knowledge into Script Learning","summary":"  In this paper, we present Tetris, a new task of Goal-Oriented Script\nCompletion. Unlike previous work, it considers a more realistic and general\nsetting, where the input includes not only the goal but also additional user\ncontext, including preferences and history. To address this problem, we propose\na novel approach, which uses two techniques to improve performance: (1) concept\nprompting, and (2) script-oriented contrastive learning that addresses step\nrepetition and hallucination problems. On our WikiHow-based dataset, we find\nthat both methods improve performance. The dataset, repository, and models will\nbe publicly available to facilitate further research on this new task.\n","authors":["Chenkai Sun","Tie Xu","ChengXiang Zhai","Heng ji"],"pdf_url":"https://arxiv.org/pdf/2209.00068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09640v1","updated":"2023-01-21T22:18:24Z","published":"2023-01-21T22:18:24Z","title":"Weakly-Supervised Questions for Zero-Shot Relation Extraction","summary":"  Zero-Shot Relation Extraction (ZRE) is the task of Relation Extraction where\nthe training and test sets have no shared relation types. This very challenging\ndomain is a good test of a model's ability to generalize. Previous approaches\nto ZRE reframed relation extraction as Question Answering (QA), allowing for\nthe use of pre-trained QA models. However, this method required manually\ncreating gold question templates for each new relation. Here, we do away with\nthese gold templates and instead learn a model that can generate questions for\nunseen relations. Our technique can successfully translate relation\ndescriptions into relevant questions, which are then leveraged to generate the\ncorrect tail entity. On tail entity extraction, we outperform the previous\nstate-of-the-art by more than 16 F1 points without using gold question\ntemplates. On the RE-QA dataset where no previous baseline for relation\nextraction exists, our proposed algorithm comes within 0.7 F1 points of a\nsystem that uses gold question templates. Our model also outperforms the\nstate-of-the-art ZRE baselines on the FewRel and WikiZSL datasets, showing that\nQA models no longer need template questions to match the performance of models\nspecifically tailored to the ZRE task. Our implementation is available at\nhttps://github.com/fyshelab/QA-ZRE.\n","authors":["Saeed Najafi","Alona Fyshe"],"pdf_url":"https://arxiv.org/pdf/2301.09640v1.pdf","comment":"EACL 2023 (main track)"},{"id":"http://arxiv.org/abs/2301.10172v1","updated":"2023-01-21T06:55:44Z","published":"2023-01-21T06:55:44Z","title":"MTTN: Multi-Pair Text to Text Narratives for Prompt Generation","summary":"  The explosive popularity of diffusion models[ 1][ 2][ 3 ] has provided a huge\nstage for further development in generative-text modelling. As prompt based\nmodels are very nuanced, such that a carefully generated prompt can produce\ntruely breath taking images, on the contrary producing powerful or even\nmeaningful prompt is a hit or a miss. To lavish on this we have introduced a\nlarge scale derived and synthesized dataset built with on real prompts and\nindexed with popular image-text datasets like MS-COCO[4 ], Flickr[ 5], etc. We\nhave also introduced staging for these sentences that sequentially reduce the\ncontext and increase the complexity, that will further strengthen the output\nbecause of the complex annotations that are being created. MTTN consists of\nover 2.4M sentences that are divided over 5 stages creating a combination\namounting to over 12M pairs, along with a vocab size of consisting more than\n300 thousands unique words that creates an abundance of variations. The\noriginal 2.4M million pairs are broken down in such a manner that it produces a\ntrue scenario of internet lingo that is used globally thereby heightening the\nrobustness of the dataset, and any model trained on it.\n","authors":["Archan Ghosh","Debgandhar Ghosh","Madhurima Maji","Suchinta Chanda","Kalporup Goswami"],"pdf_url":"https://arxiv.org/pdf/2301.10172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10180v1","updated":"2023-01-21T05:13:30Z","published":"2023-01-21T05:13:30Z","title":"A Multi-Purpose Audio-Visual Corpus for Multi-Modal Persian Speech\n  Recognition: the Arman-AV Dataset","summary":"  In recent years, significant progress has been made in automatic lip reading.\nBut these methods require large-scale datasets that do not exist for many\nlow-resource languages. In this paper, we have presented a new multipurpose\naudio-visual dataset for Persian. This dataset consists of almost 220 hours of\nvideos with 1760 corresponding speakers. In addition to lip reading, the\ndataset is suitable for automatic speech recognition, audio-visual speech\nrecognition, and speaker recognition. Also, it is the first large-scale lip\nreading dataset in Persian. A baseline method was provided for each mentioned\ntask. In addition, we have proposed a technique to detect visemes (a visual\nequivalent of a phoneme) in Persian. The visemes obtained by this method\nincrease the accuracy of the lip reading task by 7% relatively compared to the\npreviously proposed visemes, which can be applied to other languages as well.\n","authors":["Javad Peymanfard","Samin Heydarian","Ali Lashini","Hossein Zeinali","Mohammad Reza Mohammadi","Nasser Mozayani"],"pdf_url":"https://arxiv.org/pdf/2301.10180v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2201.01415v3","updated":"2023-01-21T22:01:14Z","published":"2022-01-05T02:27:35Z","title":"Problem-dependent attention and effort in neural networks with\n  application to image resolution and model selection","summary":"  This paper introduces a new ensemble-based approach to reduce the data and\ncomputation costs of accurate classification. When faced with a new test case,\na low cost classifier is used first, only moving to a higher cost approach if\nthe initial classifier does not have a high degree of confidence in its\nprojection. This multi-stage strategy can be used with any set of classifiers\nand does not require additional training. The approach is first applied to\nreduce the amount of data required to classify test images; it is found to be\neffective for problems in which at least some fraction of cases can be\ncorrectly classified based upon coarser data than are typically used. For\nneural networks performing digit recognition, for example, the proposed\napproach reduces the number of bytes of data read by 60% to 85% with less than\n5% reduction in accuracy. For the ImageNet data, the number of bytes read by\nthe typical network is reduced by 20% with less than 5% reduction in accuracy\n-- and in some cases, the resource savings reach 40%. The second application is\nto reduce computational complexity, with simpler neural networks used for test\ncases that are easier to classify and complex networks used for more difficult\ncases. For classification both of digits and of ImageNet images, computation\ncost is reduced by as much as 82% to 89% with less than 5% reduction in\naccuracy. The results also show that, for situations in which computational\ncost is not a concern, calculating multiple models' projections and selecting\nthe one from the most confident classifier can increase classification accuracy\non ImageNet by as much as two percent over the best standalone classifier\nconsidered here.\n","authors":["Chris Rohlfs"],"pdf_url":"https://arxiv.org/pdf/2201.01415v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09015v1","updated":"2023-01-21T21:53:33Z","published":"2023-01-21T21:53:33Z","title":"E$^3$Pose: Energy-Efficient Edge-assisted Multi-camera System for\n  Multi-human 3D Pose Estimation","summary":"  Multi-human 3D pose estimation plays a key role in establishing a seamless\nconnection between the real world and the virtual world. Recent efforts adopted\na two-stage framework that first builds 2D pose estimations in multiple camera\nviews from different perspectives and then synthesizes them into 3D poses.\nHowever, the focus has largely been on developing new computer vision\nalgorithms on the offline video datasets without much consideration on the\nenergy constraints in real-world systems with flexibly-deployed and\nbattery-powered cameras. In this paper, we propose an energy-efficient\nedge-assisted multiple-camera system, dubbed E$^3$Pose, for real-time\nmulti-human 3D pose estimation, based on the key idea of adaptive camera\nselection. Instead of always employing all available cameras to perform 2D pose\nestimations as in the existing works, E$^3$Pose selects only a subset of\ncameras depending on their camera view qualities in terms of occlusion and\nenergy states in an adaptive manner, thereby reducing the energy consumption\n(which translates to extended battery lifetime) and improving the estimation\naccuracy. To achieve this goal, E$^3$Pose incorporates an attention-based LSTM\nto predict the occlusion information of each camera view and guide camera\nselection before cameras are selected to process the images of a scene, and\nruns a camera selection algorithm based on the Lyapunov optimization framework\nto make long-term adaptive selection decisions. We build a prototype of\nE$^3$Pose on a 5-camera testbed, demonstrate its feasibility and evaluate its\nperformance. Our results show that a significant energy saving (up to 31.21%)\ncan be achieved while maintaining a high 3D pose estimation accuracy comparable\nto state-of-the-art methods.\n","authors":["Letian Zhang","Jie Xu"],"pdf_url":"https://arxiv.org/pdf/2301.09015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09007v1","updated":"2023-01-21T20:53:57Z","published":"2023-01-21T20:53:57Z","title":"MultiNet with Transformers: A Model for Cancer Diagnosis Using Images","summary":"  Cancer is a leading cause of death in many countries. An early diagnosis of\ncancer based on biomedical imaging ensures effective treatment and a better\nprognosis. However, biomedical imaging presents challenges to both clinical\ninstitutions and researchers. Physiological anomalies are often characterized\nby slight abnormalities in individual cells or tissues, making them difficult\nto detect visually. Traditionally, anomalies are diagnosed by radiologists and\npathologists with extensive training. This procedure, however, demands the\nparticipation of professionals and incurs a substantial cost. The cost makes\nlarge-scale biological image classification impractical. In this study, we\nprovide unique deep neural network designs for multiclass classification of\nmedical images, in particular cancer images. We incorporated transformers into\na multiclass framework to take advantage of data-gathering capability and\nperform more accurate classifications. We evaluated models on publicly\naccessible datasets using various measures to ensure the reliability of the\nmodels. Extensive assessment metrics suggest this method can be used for a\nmultitude of classification tasks.\n","authors":["Hosein Barzekar","Yash Patel","Ling Tong","Zeyun Yu"],"pdf_url":"https://arxiv.org/pdf/2301.09007v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07476v2","updated":"2023-01-21T18:16:14Z","published":"2022-12-14T19:50:35Z","title":"The Infinite Index: Information Retrieval on Generative Text-To-Image\n  Models","summary":"  Conditional generative models such as DALL-E and Stable Diffusion generate\nimages based on a user-defined text, the prompt. Finding and refining prompts\nthat produce a desired image has become the art of prompt engineering.\nGenerative models do not provide a built-in retrieval model for a user's\ninformation need expressed through prompts. In light of an extensive literature\nreview, we reframe prompt engineering for generative models as interactive\ntext-based retrieval on a novel kind of \"infinite index\". We apply these\ninsights for the first time in a case study on image generation for game design\nwith an expert. Finally, we envision how active learning may help to guide the\nretrieval of generated images.\n","authors":["Niklas Deckers","Maik Fröbe","Johannes Kiesel","Gianluca Pandolfo","Christopher Schröder","Benno Stein","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2212.07476v2.pdf","comment":"Final version for CHIIR 2023"},{"id":"http://arxiv.org/abs/2111.05978v3","updated":"2023-01-21T17:26:07Z","published":"2021-11-10T22:46:05Z","title":"SUPER-Net: Trustworthy Medical Image Segmentation with Uncertainty\n  Propagation in Encoder-Decoder Networks","summary":"  Deep Learning (DL) holds great promise in reshaping the healthcare industry\nowing to its precision, efficiency, and objectivity. However, the brittleness\nof DL models to noisy and out-of-distribution inputs is ailing their deployment\nin the clinic. Most models produce point estimates without further information\nabout model uncertainty or confidence. This paper introduces a new Bayesian DL\nframework for uncertainty quantification in segmentation neural networks:\nSUPER-Net: trustworthy medical image Segmentation with Uncertainty Propagation\nin Encoder-decodeR Networks. SUPER-Net analytically propagates, using Taylor\nseries approximations, the first two moments (mean and covariance) of the\nposterior distribution of the model parameters across the nonlinear layers. In\nparticular, SUPER-Net simultaneously learns the mean and covariance without\nexpensive post-hoc Monte Carlo sampling or model ensembling. The output\nconsists of two simultaneous maps: the segmented image and its pixelwise\nuncertainty map, which corresponds to the covariance matrix of the predictive\ndistribution. We conduct an extensive evaluation of SUPER-Net on medical image\nsegmentation of Magnetic Resonances Imaging and Computed Tomography scans under\nvarious noisy and adversarial conditions. Our experiments on multiple benchmark\ndatasets demonstrate that SUPER-Net is more robust to noise and adversarial\nattacks than state-of-the-art segmentation models. Moreover, the uncertainty\nmap of the proposed SUPER-Net associates low confidence (or equivalently high\nuncertainty) to patches in the test input images that are corrupted with noise,\nartifacts, or adversarial attacks. Perhaps more importantly, the model exhibits\nthe ability of self-assessment of its segmentation decisions, notably when\nmaking erroneous predictions due to noise or adversarial examples.\n","authors":["Giuseppina Carannante","Dimah Dera","Nidhal C. Bouaynaya","Hassan M. Fathallah-Shaykh","Ghulam Rasool"],"pdf_url":"https://arxiv.org/pdf/2111.05978v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08965v1","updated":"2023-01-21T15:42:53Z","published":"2023-01-21T15:42:53Z","title":"Raw or Cooked? Object Detection on RAW Images","summary":"  Images fed to a deep neural network have in general undergone several\nhandcrafted image signal processing (ISP) operations, all of which have been\noptimized to produce visually pleasing images. In this work, we investigate the\nhypothesis that the intermediate representation of visually pleasing images is\nsub-optimal for downstream computer vision tasks compared to the RAW image\nrepresentation. We suggest that the operations of the ISP instead should be\noptimized towards the end task, by learning the parameters of the operations\njointly during training. We extend previous works on this topic and propose a\nnew learnable operation that enables an object detector to achieve superior\nperformance when compared to both previous works and traditional RGB images. In\nexperiments on the open PASCALRAW dataset, we empirically confirm our\nhypothesis.\n","authors":["William Ljungbergh","Joakim Johnander","Christoffer Petersson","Michael Felsberg"],"pdf_url":"https://arxiv.org/pdf/2301.08965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12753v2","updated":"2023-01-21T15:29:47Z","published":"2022-09-26T15:00:18Z","title":"On Investigating the Conservative Property of Score-Based Generative\n  Models","summary":"  Existing Score-based Generative Models (SGMs) can be categorized into\nconstrained SGMs (CSGMs) or unconstrained SGMs (USGMs) according to their\nparameterization approaches. CSGMs model probability density functions as\nBoltzmann distributions, and assign their predictions as the negative gradients\nof some scalar-valued energy functions. On the other hand, USGMs employ\nflexible architectures capable of directly estimating scores without the need\nto explicitly model energy functions. In this paper, we demonstrate that the\narchitectural constraints of CSGMs may limit their modeling ability. In\naddition, we show that USGMs' inability to preserve the property of\nconservativeness may lead to degraded sampling performance in practice. To\naddress the above issues, we propose Quasi-Conservative Score-based Generative\nModels (QCSGMs) for keeping the advantages of both CSGMs and USGMs. Our\ntheoretical derivations demonstrate that the training objective of QCSGMs can\nbe efficiently integrated into the training processes by leveraging the\nHutchinson trace estimator. In addition, our experimental results on the\nCIFAR-10, CIFAR-100, ImageNet, and SVHN datasets validate the effectiveness of\nQCSGMs. Finally, we justify the advantage of QCSGMs using an example of a\none-layered autoencoder.\n","authors":["Chen-Hao Chao","Wei-Fang Sun","Bo-Wun Cheng","Chun-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2209.12753v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08959v1","updated":"2023-01-21T15:00:59Z","published":"2023-01-21T15:00:59Z","title":"Successive Subspace Learning for Cardiac Disease Classification with\n  Two-phase Deformation Fields from Cine MRI","summary":"  Cardiac cine magnetic resonance imaging (MRI) has been used to characterize\ncardiovascular diseases (CVD), often providing a noninvasive phenotyping\ntool.~While recently flourished deep learning based approaches using cine MRI\nyield accurate characterization results, the performance is often degraded by\nsmall training samples. In addition, many deep learning models are deemed a\n``black box,\" for which models remain largely elusive in how models yield a\nprediction and how reliable they are. To alleviate this, this work proposes a\nlightweight successive subspace learning (SSL) framework for CVD\nclassification, based on an interpretable feedforward design, in conjunction\nwith a cardiac atlas. Specifically, our hierarchical SSL model is based on (i)\nneighborhood voxel expansion, (ii) unsupervised subspace approximation, (iii)\nsupervised regression, and (iv) multi-level feature integration. In addition,\nusing two-phase 3D deformation fields, including end-diastolic and end-systolic\nphases, derived between the atlas and individual subjects as input offers\nobjective means of assessing CVD, even with small training samples. We evaluate\nour framework on the ACDC2017 database, comprising one healthy group and four\ndisease groups. Compared with 3D CNN-based approaches, our framework achieves\nsuperior classification performance with 140$\\times$ fewer parameters, which\nsupports its potential value in clinical use.\n","authors":["Xiaofeng Liu","Fangxu Xing","Hanna K. Gaggin","C. -C. Jay Kuo","Georges El Fakhri","Jonghye Woo"],"pdf_url":"https://arxiv.org/pdf/2301.08959v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2301.08957v1","updated":"2023-01-21T14:33:02Z","published":"2023-01-21T14:33:02Z","title":"Slice Transformer and Self-supervised Learning for 6DoF Localization in\n  3D Point Cloud Maps","summary":"  Precise localization is critical for autonomous vehicles. We present a\nself-supervised learning method that employs Transformers for the first time\nfor the task of outdoor localization using LiDAR data. We propose a pre-text\ntask that reorganizes the slices of a $360^\\circ$ LiDAR scan to leverage its\naxial properties. Our model, called Slice Transformer, employs multi-head\nattention while systematically processing the slices. To the best of our\nknowledge, this is the first instance of leveraging multi-head attention for\noutdoor point clouds. We additionally introduce the Perth-WA dataset, which\nprovides a large-scale LiDAR map of Perth city in Western Australia, covering\n$\\sim$4km$^2$ area. Localization annotations are provided for Perth-WA. The\nproposed localization method is thoroughly evaluated on Perth-WA and\nAppollo-SouthBay datasets. We also establish the efficacy of our\nself-supervised learning approach for the common downstream task of object\nclassification using ModelNet40 and ScanNN datasets. The code and Perth-WA data\nwill be publicly released.\n","authors":["Muhammad Ibrahim","Naveed Akhtar","Saeed Anwar","Michael Wise","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2301.08957v1.pdf","comment":"Accepted in IEEE International Conference on Robotics and Automation\n  (ICRA), 2023"},{"id":"http://arxiv.org/abs/2301.08951v1","updated":"2023-01-21T13:39:39Z","published":"2023-01-21T13:39:39Z","title":"Time-Conditioned Generative Modeling of Object-Centric Representations\n  for Video Decomposition and Prediction","summary":"  When perceiving the world from multiple viewpoints, humans have the ability\nto reason about the complete objects in a compositional manner even when the\nobject is completely occluded from partial viewpoints. Meanwhile, humans can\nimagine the novel views after observing multiple viewpoints. The remarkable\nrecent advance in multi-view object-centric learning leaves some problems: 1)\nthe partially or completely occluded shape of objects can not be well\nreconstructed. 2) the novel viewpoint prediction depends on expensive viewpoint\nannotations rather than implicit view rules. This makes the agent fail to\nperform like humans. In this paper, we introduce a time-conditioned generative\nmodel for videos. To reconstruct the complete shape of the object accurately,\nwe enhance the disentanglement between different latent representations: view\nlatent representations are jointly inferred based on the Transformer and then\ncooperate with the sequential extension of Slot Attention to learn\nobject-centric representations. The model also achieves the new ability:\nGaussian processes are employed as priors of view latent variables for\ngeneration and novel-view prediction without viewpoint annotations. Experiments\non multiple specifically designed synthetic datasets have shown that the\nproposed model can 1) make the video decomposition, 2) reconstruct the complete\nshapes of objects, and 3) make the novel viewpoint prediction without viewpoint\nannotations.\n","authors":["Chengmin Gao","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2301.08951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08939v1","updated":"2023-01-21T11:14:34Z","published":"2023-01-21T11:14:34Z","title":"Counterfactual Explanation and Instance-Generation using\n  Cycle-Consistent Generative Adversarial Networks","summary":"  The image-based diagnosis is now a vital aspect of modern automation assisted\ndiagnosis. To enable models to produce pixel-level diagnosis, pixel-level\nground-truth labels are essentially required. However, since it is often not\nstraight forward to obtain the labels in many application domains such as in\nmedical image, classification-based approaches have become the de facto\nstandard to perform the diagnosis. Though they can identify class-salient\nregions, they may not be useful for diagnosis where capturing all of the\nevidences is important requirement. Alternatively, a counterfactual explanation\n(CX) aims at providing explanations using a casual reasoning process of form\n\"If X has not happend, Y would not heppend\". Existing CX approaches, however,\nuse classifier to explain features that can change its predictions. Thus, they\ncan only explain class-salient features, rather than entire object of interest.\nThis hence motivates us to propose a novel CX strategy that is not reliant on\nimage classification. This work is inspired from the recent developments in\ngenerative adversarial networks (GANs) based image-to-image domain translation,\nand leverages to translate an abnormal image to counterpart normal image (i.e.\ncounterfactual instance CI) to find discrepancy maps between the two. Since it\nis generally not possible to obtain abnormal and normal image pairs, we\nleverage Cycle-Consistency principle (a.k.a CycleGAN) to perform the\ntranslation in unsupervised way. We formulate CX in terms of a discrepancy map\nthat, when added from the abnormal image, will make it indistinguishable from\nthe CI. We evaluate our method on three datasets including a synthetic,\ntuberculosis and BraTS dataset. All these experiments confirm the supremacy of\npropose method in generating accurate CX and CI.\n","authors":["Tehseen Zia","Zeeshan Nisar","Shakeeb Murtaza"],"pdf_url":"https://arxiv.org/pdf/2301.08939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01222v5","updated":"2023-01-21T11:06:03Z","published":"2022-12-02T14:55:31Z","title":"Evaluation of Explanation Methods of AI -- CNNs in Image Classification\n  Tasks with Reference-based and No-reference Metrics","summary":"  The most popular methods in AI-machine learning paradigm are mainly black\nboxes. This is why explanation of AI decisions is of emergency. Although\ndedicated explanation tools have been massively developed, the evaluation of\ntheir quality remains an open research question. In this paper, we generalize\nthe methodologies of evaluation of post-hoc explainers of CNNs' decisions in\nvisual classification tasks with reference and no-reference based metrics. We\napply them on our previously developed explainers (FEM, MLFEM), and popular\nGrad-CAM. The reference-based metrics are Pearson correlation coefficient and\nSimilarity computed between the explanation map and its ground truth\nrepresented by a Gaze Fixation Density Map obtained with a psycho-visual\nexperiment. As a no-reference metric, we use stability metric, proposed by\nAlvarez-Melis and Jaakkola. We study its behaviour, consensus with\nreference-based metrics and show that in case of several kinds of degradation\non input images, this metric is in agreement with reference-based ones.\nTherefore, it can be used for evaluation of the quality of explainers when the\nground truth is not available.\n","authors":["A. Zhukov","J. Benois-Pineau","R. Giot"],"pdf_url":"https://arxiv.org/pdf/2212.01222v5.pdf","comment":"Due to a bug found in the code, all tables and figures were redone.\n  The new results did not change the main conclusion, except for the best\n  explainer. FEM has performed better than MLFEM; 25 pages, 16 tables, 16\n  figures; Submitted to \"Advances in Artificial Intelligence and Machine\n  Learning\" (ISSN: 2582-9793)"},{"id":"http://arxiv.org/abs/2301.08930v1","updated":"2023-01-21T09:54:07Z","published":"2023-01-21T09:54:07Z","title":"Dense RGB SLAM with Neural Implicit Maps","summary":"  There is an emerging trend of using neural implicit functions for map\nrepresentation in Simultaneous Localization and Mapping (SLAM). Some pioneer\nworks have achieved encouraging results on RGB-D SLAM. In this paper, we\npresent a dense RGB SLAM method with neural implicit map representation. To\nreach this challenging goal without depth input, we introduce a hierarchical\nfeature volume to facilitate the implicit map decoder. This design effectively\nfuses shape cues across different scales to facilitate map reconstruction. Our\nmethod simultaneously solves the camera motion and the neural implicit map by\nmatching the rendered and input video frames. To facilitate optimization, we\nfurther propose a photometric warping loss in the spirit of multi-view stereo\nto better constrain the camera pose and scene geometry. We evaluate our method\non commonly used benchmarks and compare it with modern RGB and RGB-D SLAM\nsystems. Our method achieves favorable results than previous methods and even\nsurpasses some recent RGB-D SLAM methods. Our source code will be publicly\navailable.\n","authors":["Heng Li","Xiaodong Gu","Weihao Yuan","Luwei Yang","Zilong Dong","Ping Tan"],"pdf_url":"https://arxiv.org/pdf/2301.08930v1.pdf","comment":"Accepted by ICLR 2023; Pre-Camera-Ready Version"},{"id":"http://arxiv.org/abs/2301.08915v1","updated":"2023-01-21T08:30:15Z","published":"2023-01-21T08:30:15Z","title":"Improving Deep Regression with Ordinal Entropy","summary":"  In computer vision, it is often observed that formulating regression problems\nas a classification task often yields better performance. We investigate this\ncurious phenomenon and provide a derivation to show that classification, with\nthe cross-entropy loss, outperforms regression with a mean squared error loss\nin its ability to learn high-entropy feature representations. Based on the\nanalysis, we propose an ordinal entropy loss to encourage higher-entropy\nfeature spaces while maintaining ordinal relationships to improve the\nperformance of regression tasks. Experiments on synthetic and real-world\nregression tasks demonstrate the importance and benefits of increasing entropy\nfor regression.\n","authors":["Shihao Zhang","Linlin Yang","Michael Bi Mi","Xiaoxu Zheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2301.08915v1.pdf","comment":"Accepted to ICLR 2023. Project page:\n  https://github.com/needylove/OrdinalEntropy"},{"id":"http://arxiv.org/abs/2301.08898v1","updated":"2023-01-21T05:34:29Z","published":"2023-01-21T05:34:29Z","title":"Recurrent Contour-based Instance Segmentation with Progressive Learning","summary":"  Contour-based instance segmentation has been actively studied, thanks to its\nflexibility and elegance in processing visual objects within complex\nbackgrounds. In this work, we propose a novel deep network architecture, i.e.,\nPolySnake, for contour-based instance segmentation. Motivated by the classic\nSnake algorithm, the proposed PolySnake achieves superior and robust\nsegmentation performance with an iterative and progressive contour refinement\nstrategy. Technically, PolySnake introduces a recurrent update operator to\nestimate the object contour iteratively. It maintains a single estimate of the\ncontour that is progressively deformed toward the object boundary. At each\niteration, PolySnake builds a semantic-rich representation for the current\ncontour and feeds it to the recurrent operator for further contour adjustment.\nThrough the iterative refinements, the contour finally progressively converges\nto a stable status that tightly encloses the object instance. Moreover, with a\ncompact design of the recurrent architecture, we ensure the running efficiency\nunder multiple iterations. Extensive experiments are conducted to validate the\nmerits of our method, and the results demonstrate that the proposed PolySnake\noutperforms the existing contour-based instance segmentation methods on several\nprevalent instance segmentation benchmarks. The codes and models are available\nat https://github.com/fh2019ustc/PolySnake.\n","authors":["Hao Feng","Wengang Zhou","Yufei Yin","Jiajun Deng","Qi Sun","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2301.08898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16570v2","updated":"2023-01-21T05:29:40Z","published":"2022-11-29T20:11:11Z","title":"Performance Evaluation of Vanilla, Residual, and Dense 2D U-Net\n  Architectures for Skull Stripping of Augmented 3D T1-weighted MRI Head Scans","summary":"  Skull Stripping is a requisite preliminary step in most diagnostic\nneuroimaging applications. Manual Skull Stripping methods define the gold\nstandard for the domain but are time-consuming and challenging to integrate\ninto processing pipelines with a high number of data samples. Automated methods\nare an active area of research for head MRI segmentation, especially deep\nlearning methods such as U-Net architecture implementations. This study\ncompares Vanilla, Residual, and Dense 2D U-Net architectures for Skull\nStripping. The Dense 2D U-Net architecture outperforms the Vanilla and Residual\ncounterparts by achieving an accuracy of 99.75% on a test dataset. It is\nobserved that dense interconnections in a U-Net encourage feature reuse across\nlayers of the architecture and allow for shallower models with the strengths of\na deeper network.\n","authors":["Anway S. Pimpalkar","Rashmika K. Patole","Ketaki D. Kamble","Mahesh H. Shindikar"],"pdf_url":"https://arxiv.org/pdf/2211.16570v2.pdf","comment":"Research Article submitted to the 2nd International Conference on\n  Biomedical Engineering Science and Technology: Roadway from Laboratory to\n  Market, at the National Institute of Technology Raipur, Chhattisgarh, India"},{"id":"http://arxiv.org/abs/2301.08888v1","updated":"2023-01-21T04:47:35Z","published":"2023-01-21T04:47:35Z","title":"Pre-text Representation Transfer for Deep Learning with Limited\n  Imbalanced Data : Application to CT-based COVID-19 Detection","summary":"  Annotating medical images for disease detection is often tedious and\nexpensive. Moreover, the available training samples for a given task are\ngenerally scarce and imbalanced. These conditions are not conducive for\nlearning effective deep neural models. Hence, it is common to 'transfer' neural\nnetworks trained on natural images to the medical image domain. However, this\nparadigm lacks in performance due to the large domain gap between the natural\nand medical image data. To address that, we propose a novel concept of Pre-text\nRepresentation Transfer (PRT). In contrast to the conventional transfer\nlearning, which fine-tunes a source model after replacing its classification\nlayers, PRT retains the original classification layers and updates the\nrepresentation layers through an unsupervised pre-text task. The task is\nperformed with (original, not synthetic) medical images, without utilizing any\nannotations. This enables representation transfer with a large amount of\ntraining data. This high-fidelity representation transfer allows us to use the\nresulting model as a more effective feature extractor. Moreover, we can also\nsubsequently perform the traditional transfer learning with this model. We\ndevise a collaborative representation based classification layer for the case\nwhen we leverage the model as a feature extractor. We fuse the output of this\nlayer with the predictions of a model induced with the traditional transfer\nlearning performed over our pre-text transferred model. The utility of our\ntechnique for limited and imbalanced data classification problem is\ndemonstrated with an extensive five-fold evaluation for three large-scale\nmodels, tested for five different class-imbalance ratios for CT based COVID-19\ndetection. Our results show a consistent gain over the conventional transfer\nlearning with the proposed method.\n","authors":["Fouzia Altaf","Syed M. S. Islam","Naeem K. Janjua","Naveed Akhtar"],"pdf_url":"https://arxiv.org/pdf/2301.08888v1.pdf","comment":"Best paper at IVCNZ"},{"id":"http://arxiv.org/abs/2112.09428v2","updated":"2023-01-21T04:26:35Z","published":"2021-12-17T10:53:35Z","title":"Dynamics-aware Adversarial Attack of 3D Sparse Convolution Network","summary":"  In this paper, we investigate the dynamics-aware adversarial attack problem\nin deep neural networks. Most existing adversarial attack algorithms are\ndesigned under a basic assumption -- the network architecture is fixed\nthroughout the attack process. However, this assumption does not hold for many\nrecently proposed networks, e.g. 3D sparse convolution network, which contains\ninput-dependent execution to improve computational efficiency. It results in a\nserious issue of lagged gradient, making the learned attack at the current step\nineffective due to the architecture changes afterward. To address this issue,\nwe propose a Leaded Gradient Method (LGM) and show the significant effects of\nthe lagged gradient. More specifically, we re-formulate the gradients to be\naware of the potential dynamic changes of network architectures, so that the\nlearned attack better \"leads\" the next step than the dynamics-unaware methods\nwhen network architecture changes dynamically. Extensive experiments on various\ndatasets show that our LGM achieves impressive performance on semantic\nsegmentation and classification. Compared with the dynamic-unaware methods, LGM\nachieves about 20% lower mIoU averagely on the ScanNet and S3DIS datasets. LGM\nalso outperforms the recent point cloud attacks.\n","authors":["An Tao","Yueqi Duan","He Wang","Ziyi Wu","Pengliang Ji","Haowen Sun","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2112.09428v2.pdf","comment":"We have improved the quality of this work and updated a new version\n  to address the limitations of the proposed method"},{"id":"http://arxiv.org/abs/2205.08738v2","updated":"2023-01-21T04:21:18Z","published":"2022-05-18T06:19:15Z","title":"Passive Defense Against 3D Adversarial Point Clouds Through the Lens of\n  3D Steganalysis","summary":"  Nowadays, 3D data plays an indelible role in the computer vision field.\nHowever, extensive studies have proved that deep neural networks (DNNs) fed\nwith 3D data, such as point clouds, are susceptible to adversarial examples,\nwhich aim to misguide DNNs and might bring immeasurable losses. Currently, 3D\nadversarial point clouds are chiefly generated in three fashions, i.e., point\nshifting, point adding, and point dropping. These point manipulations would\nmodify geometrical properties and local correlations of benign point clouds\nmore or less. Motivated by this basic fact, we propose to defend such\nadversarial examples with the aid of 3D steganalysis techniques. Specifically,\nwe first introduce an adversarial attack and defense model adapted from the\ncelebrated Prisoners' Problem in steganography to help us comprehend 3D\nadversarial attack and defense more generally. Then we rethink two significant\nbut vague concepts in the field of adversarial example, namely, active defense\nand passive defense, from the perspective of steganalysis. Most importantly, we\ndesign a 3D adversarial point cloud detector through the lens of 3D\nsteganalysis. Our detector is double-blind, that is to say, it does not rely on\nthe exact knowledge of the adversarial attack means and victim models. To\nenable the detector to effectively detect malicious point clouds, we craft a\n64-D discriminant feature set, including features related to first-order and\nsecond-order local descriptions of point clouds. To our knowledge, this work is\nthe first to apply 3D steganalysis to 3D adversarial example defense. Extensive\nexperimental results demonstrate that the proposed 3D adversarial point cloud\ndetector can achieve good detection performance on multiple types of 3D\nadversarial point clouds.\n","authors":["Jiahao Zhu"],"pdf_url":"https://arxiv.org/pdf/2205.08738v2.pdf","comment":"This paper is out-of-date"},{"id":"http://arxiv.org/abs/2301.08880v1","updated":"2023-01-21T03:52:35Z","published":"2023-01-21T03:52:35Z","title":"A Large-scale Film Style Dataset for Learning Multi-frequency Driven\n  Film Enhancement","summary":"  Film, a classic image style, is culturally significant to the whole\nphotographic industry since it marks the birth of photography. However, film\nphotography is time-consuming and expensive, necessitating a more efficient\nmethod for collecting film-style photographs. Numerous datasets that have\nemerged in the field of image enhancement so far are not film-specific. In\norder to facilitate film-based image stylization research, we construct\nFilmSet, a large-scale and high-quality film style dataset. Our dataset\nincludes three different film types and more than 5000 in-the-wild high\nresolution images. Inspired by the features of FilmSet images, we propose a\nnovel framework called FilmNet based on Laplacian Pyramid for stylizing images\nacross frequency bands and achieving film style outcomes. Experiments reveal\nthat the performance of our model is superior than state-of-the-art techniques.\nOur dataset and code will be made publicly available.\n","authors":["Xuhang Chen","Zinuo Li","Chi-Man Pun","Shuqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.08880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08874v1","updated":"2023-01-21T03:41:07Z","published":"2023-01-21T03:41:07Z","title":"Improving Accuracy of Zero-Shot Action Recognition with Handcrafted\n  Features","summary":"  With the development of machine learning, datasets for models are getting\nincreasingly larger. This leads to increased data annotation costs and training\ntime, which undoubtedly hinders the development of machine learning. To solve\nthis problem, zero-shot learning is gaining considerable attention. With\nzero-shot learning, objects can be recognized or classified, even without\nhaving been seen before. Nevertheless, the accuracy of this method is still\nlow, thus limiting its practical application. To solve this problem, we propose\na video-text matching model, which can learn from handcrafted features. Our\nmodel can be used alone to predict the action classes and can also be added to\nany other model to improve its accuracy. Moreover, our model can be\ncontinuously optimized to improve its accuracy. We only need to manually\nannotate some features, which incurs some labor costs; in many situations, the\ncosts are worth it. The results with UCF101 and HMDB51 show that our model\nachieves the best accuracy and also improves the accuracies of other models.\n","authors":["Nan Wu","Hiroshi Kera","Kazuhiko Kawamoto"],"pdf_url":"https://arxiv.org/pdf/2301.08874v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2301.08868v1","updated":"2023-01-21T02:58:51Z","published":"2023-01-21T02:58:51Z","title":"Dynamic MLP for MRI Reconstruction","summary":"  As convolutional neural networks (CNN) become the most successful\nreconstruction technique for accelerated Magnetic Resonance Imaging (MRI), CNN\nreaches its limit on image quality especially in sharpness. Further improvement\non image quality often comes at massive computational costs, hindering their\npracticability in the clinic setting. MRI reconstruction is essentially a\ndeconvolution problem, which demands long-distance information that is\ndifficult to be captured by CNNs with small convolution kernels. The\nmulti-layer perceptron (MLP) is able to model such long-distance information,\nbut it restricts a fixed input size while the reconstruction of images in\nflexible resolutions is required in the clinic setting. In this paper, we\nproposed a hybrid CNN and MLP reconstruction strategy, featured by dynamic MLP\n(dMLP) that accepts arbitrary image sizes. Experiments were conducted using 3D\nmulti-coil MRI. Our results suggested the proposed dMLP can improve image\nsharpness compared to its pure CNN counterpart, while costing minor additional\nGPU memory and computation time. We further compared the proposed dMLP with\nCNNs using large kernels and studied pure MLP-based reconstruction using a\nstack of 1D dMLPs, as well as its CNN counterpart using only 1D convolutions.\nWe observed the enlarged receptive field has noticeably improved image quality,\nwhile simply using CNN with a large kernel leads to difficulties in training.\nNoticeably, the pure MLP-based method has been outperformed by CNN-involved\nmethods, which matches the observations in other computer vision tasks for\nnatural images.\n","authors":["Chi Zhang","Eric Z. Chen","Xiao Chen","Yikang Liu","Terrence Chen","Shanhui Sun"],"pdf_url":"https://arxiv.org/pdf/2301.08868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05861v2","updated":"2023-01-21T02:46:41Z","published":"2022-10-12T01:53:58Z","title":"SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric\n  Models","summary":"  Understanding dynamics from visual observations is a challenging problem that\nrequires disentangling individual objects from the scene and learning their\ninteractions. While recent object-centric models can successfully decompose a\nscene into objects, modeling their dynamics effectively still remains a\nchallenge. We address this problem by introducing SlotFormer -- a\nTransformer-based autoregressive model operating on learned object-centric\nrepresentations. Given a video clip, our approach reasons over object features\nto model spatio-temporal relationships and predicts accurate future object\nstates. In this paper, we successfully apply SlotFormer to perform video\nprediction on datasets with complex object interactions. Moreover, the\nunsupervised SlotFormer's dynamics model can be used to improve the performance\non supervised downstream tasks, such as Visual Question Answering (VQA), and\ngoal-conditioned planning. Compared to past works on dynamics modeling, our\nmethod achieves significantly better long-term synthesis of object dynamics,\nwhile retaining high quality visual generation. Besides, SlotFormer enables VQA\nmodels to reason about the future without object-level labels, even\noutperforming counterparts that use ground-truth annotations. Finally, we show\nits ability to serve as a world model for model-based planning, which is\ncompetitive with methods designed specifically for such tasks.\n","authors":["Ziyi Wu","Nikita Dvornik","Klaus Greff","Thomas Kipf","Animesh Garg"],"pdf_url":"https://arxiv.org/pdf/2210.05861v2.pdf","comment":"Accepted by ICLR 2023. Project page: https://slotformer.github.io/"},{"id":"http://arxiv.org/abs/2301.08849v1","updated":"2023-01-21T01:52:17Z","published":"2023-01-21T01:52:17Z","title":"CADA-GAN: Context-Aware GAN with Data Augmentation","summary":"  Current child face generators are restricted by the limited size of the\navailable datasets. In addition, feature selection can prove to be a\nsignificant challenge, especially due to the large amount of features that need\nto be trained for. To manage these problems, we proposed CADA-GAN, a\n\\textbf{C}ontext-\\textbf{A}ware GAN that allows optimal feature extraction,\nwith added robustness from additional \\textbf{D}ata \\textbf{A}ugmentation.\nCADA-GAN is adapted from the popular StyleGAN2-Ada model, with attention on\naugmentation and segmentation of the parent images. The model has the lowest\n\\textit{Mean Squared Error Loss} (MSEloss) on latent feature representations\nand the generated child image is robust compared with the one that generated\nfrom baseline models.\n","authors":["Sofie Daniels","Jiugeng Sun","Jiaqing Xie"],"pdf_url":"https://arxiv.org/pdf/2301.08849v1.pdf","comment":"Submitted to ETHDL2023"},{"id":"http://arxiv.org/abs/2301.08846v1","updated":"2023-01-21T01:33:34Z","published":"2023-01-21T01:33:34Z","title":"Regeneration Learning: A Learning Paradigm for Data Generation","summary":"  Machine learning methods for conditional data generation usually build a\nmapping from source conditional data X to target data Y. The target Y (e.g.,\ntext, speech, music, image, video) is usually high-dimensional and complex, and\ncontains information that does not exist in source data, which hinders\neffective and efficient learning on the source-target mapping. In this paper,\nwe present a learning paradigm called regeneration learning for data\ngeneration, which first generates Y' (an abstraction/representation of Y) from\nX and then generates Y from Y'. During training, Y' is obtained from Y through\neither handcrafted rules or self-supervised learning and is used to learn\nX-->Y' and Y'-->Y. Regeneration learning extends the concept of representation\nlearning to data generation tasks, and can be regarded as a counterpart of\ntraditional representation learning, since 1) regeneration learning handles the\nabstraction (Y') of the target data Y for data generation while traditional\nrepresentation learning handles the abstraction (X') of source data X for data\nunderstanding; 2) both the processes of Y'-->Y in regeneration learning and\nX-->X' in representation learning can be learned in a self-supervised way\n(e.g., pre-training); 3) both the mappings from X to Y' in regeneration\nlearning and from X' to Y in representation learning are simpler than the\ndirect mapping from X to Y. We show that regeneration learning can be a\nwidely-used paradigm for data generation (e.g., text generation, speech\nrecognition, speech synthesis, music composition, image generation, and video\ngeneration) and can provide valuable insights into developing data generation\nmethods.\n","authors":["Xu Tan","Tao Qin","Jiang Bian","Tie-Yan Liu","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2301.08846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04746v3","updated":"2023-01-21T01:06:34Z","published":"2023-01-11T22:55:05Z","title":"Switchable Lightweight Anti-symmetric Processing (SLAP) with CNN\n  Outspeeds Data Augmentation by Smaller Sample -- Application in Gomoku\n  Reinforcement Learning","summary":"  To replace data augmentation, this paper proposed a method called SLAP to\nintensify experience to speed up machine learning and reduce the sample size.\nSLAP is a model-independent protocol/function to produce the same output given\ndifferent transformation variants. SLAP improved the convergence speed of\nconvolutional neural network learning by 83% in the experiments with Gomoku\ngame states, with only one eighth of the sample size compared with data\naugmentation. In reinforcement learning for Gomoku, using AlphaGo\nZero/AlphaZero algorithm with data augmentation as baseline, SLAP reduced the\nnumber of training samples by a factor of 8 and achieved similar winning rate\nagainst the same evaluator, but it was not yet evident that it could speed up\nreinforcement learning. The benefits should at least apply to domains that are\ninvariant to symmetry or certain transformations. As future work, SLAP may aid\nmore explainable learning and transfer learning for domains that are not\ninvariant to symmetry, as a small step towards artificial general intelligence.\n","authors":["Chi-Hang Suen"],"pdf_url":"https://arxiv.org/pdf/2301.04746v3.pdf","comment":"Change title; 6 pages, 8 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2212.07476v2","updated":"2023-01-21T18:16:14Z","published":"2022-12-14T19:50:35Z","title":"The Infinite Index: Information Retrieval on Generative Text-To-Image\n  Models","summary":"  Conditional generative models such as DALL-E and Stable Diffusion generate\nimages based on a user-defined text, the prompt. Finding and refining prompts\nthat produce a desired image has become the art of prompt engineering.\nGenerative models do not provide a built-in retrieval model for a user's\ninformation need expressed through prompts. In light of an extensive literature\nreview, we reframe prompt engineering for generative models as interactive\ntext-based retrieval on a novel kind of \"infinite index\". We apply these\ninsights for the first time in a case study on image generation for game design\nwith an expert. Finally, we envision how active learning may help to guide the\nretrieval of generated images.\n","authors":["Niklas Deckers","Maik Fröbe","Johannes Kiesel","Gianluca Pandolfo","Christopher Schröder","Benno Stein","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2212.07476v2.pdf","comment":"Final version for CHIIR 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.09024v1","updated":"2023-01-21T23:28:55Z","published":"2023-01-21T23:28:55Z","title":"Statistically Optimal Robust Mean and Covariance Estimation for\n  Anisotropic Gaussians","summary":"  Assume that $X_{1}, \\ldots, X_{N}$ is an $\\varepsilon$-contaminated sample of\n$N$ independent Gaussian vectors in $\\mathbb{R}^d$ with mean $\\mu$ and\ncovariance $\\Sigma$. In the strong $\\varepsilon$-contamination model we assume\nthat the adversary replaced an $\\varepsilon$ fraction of vectors in the\noriginal Gaussian sample by any other vectors. We show that there is an\nestimator $\\widehat \\mu$ of the mean satisfying, with probability at least $1 -\n\\delta$, a bound of the form \\[ \\|\\widehat{\\mu} - \\mu\\|_2 \\le\nc\\left(\\sqrt{\\frac{\\operatorname{Tr}(\\Sigma)}{N}} +\n\\sqrt{\\frac{\\|\\Sigma\\|\\log(1/\\delta)}{N}} +\n\\varepsilon\\sqrt{\\|\\Sigma\\|}\\right), \\] where $c > 0$ is an absolute constant\nand $\\|\\Sigma\\|$ denotes the operator norm of $\\Sigma$. In the same\ncontaminated Gaussian setup, we construct an estimator $\\widehat \\Sigma$ of the\ncovariance matrix $\\Sigma$ that satisfies, with probability at least $1 -\n\\delta$, \\[ \\left\\|\\widehat{\\Sigma} - \\Sigma\\right\\| \\le\nc\\left(\\sqrt{\\frac{\\|\\Sigma\\|\\operatorname{Tr}(\\Sigma)}{N}} +\n\\|\\Sigma\\|\\sqrt{\\frac{\\log(1/\\delta)}{N}} + \\varepsilon\\|\\Sigma\\|\\right). \\]\nBoth results are optimal up to multiplicative constant factors. Despite the\nrecent significant interest in robust statistics, achieving both dimension-free\nbounds in the canonical Gaussian case remained open. In fact, several\npreviously known results were either dimension-dependent and required $\\Sigma$\nto be close to identity, or had a sub-optimal dependence on the contamination\nlevel $\\varepsilon$.\n  As a part of the analysis, we derive sharp concentration inequalities for\ncentral order statistics of Gaussian, folded normal, and chi-squared\ndistributions.\n","authors":["Arshak Minasyan","Nikita Zhivotovskiy"],"pdf_url":"https://arxiv.org/pdf/2301.09024v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2205.15460v2","updated":"2023-01-21T23:19:35Z","published":"2022-05-30T23:14:24Z","title":"Critic Sequential Monte Carlo","summary":"  We introduce CriticSMC, a new algorithm for planning as inference built from\na composition of sequential Monte Carlo with learned Soft-Q function heuristic\nfactors. These heuristic factors, obtained from parametric approximations of\nthe marginal likelihood ahead, more effectively guide SMC towards the desired\ntarget distribution, which is particularly helpful for planning in environments\nwith hard constraints placed sparsely in time. Compared with previous work, we\nmodify the placement of such heuristic factors, which allows us to cheaply\npropose and evaluate large numbers of putative action particles, greatly\nincreasing inference and planning efficiency. CriticSMC is compatible with\ninformative priors, whose density function need not be known, and can be used\nas a model-free control algorithm. Our experiments on collision avoidance in a\nhigh-dimensional simulated driving task show that CriticSMC significantly\nreduces collision rates at a low computational cost while maintaining realism\nand diversity of driving behaviors across vehicles and environment scenarios.\n","authors":["Vasileios Lioutas","Jonathan Wilder Lavington","Justice Sefas","Matthew Niedoba","Yunpeng Liu","Berend Zwartsenberg","Setareh Dabiri","Frank Wood","Adam Scibior"],"pdf_url":"https://arxiv.org/pdf/2205.15460v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2208.04187v3","updated":"2023-01-21T22:31:52Z","published":"2022-08-05T03:15:28Z","title":"DIVISION: Memory Efficient Training via Dual Activation Precision","summary":"  Existing work of activation compressed training relies on searching for\noptimal bit-width during DNN training to reduce the quantization noise, which\nmakes the procedure complicated and less transparent. To this end, we propose a\nsimple and effective method to compress DNN training. Our method is motivated\nby an instructive observation: DNN backward propagation mainly utilizes the\nlow-frequency component (LFC) of the activation maps, while the majority of\nmemory is for caching the high-frequency component (HFC) during the training.\nThis indicates the HFC of activation maps is highly redundant and compressible\nduring DNN training, which inspires our proposed Dual Activation Precision\n(DIVISION). During the training, DIVISION preserves the high-precision copy of\nLFC and compresses the HFC into a light-weight copy with low numerical\nprecision. This can significantly reduce the memory cost without negatively\naffecting the precision of backward propagation such that DIVISION maintains\ncompetitive model accuracy. Experimental results show DIVISION achieves over\n10x compression of activation maps, and significantly higher training\nthroughput than state-of-the-art ACT methods, without loss of model accuracy.\n","authors":["Guanchu Wang","Zirui Liu","Zhimeng Jiang","Ninghao Liu","Na Zou","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2208.04187v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.01415v3","updated":"2023-01-21T22:01:14Z","published":"2022-01-05T02:27:35Z","title":"Problem-dependent attention and effort in neural networks with\n  application to image resolution and model selection","summary":"  This paper introduces a new ensemble-based approach to reduce the data and\ncomputation costs of accurate classification. When faced with a new test case,\na low cost classifier is used first, only moving to a higher cost approach if\nthe initial classifier does not have a high degree of confidence in its\nprojection. This multi-stage strategy can be used with any set of classifiers\nand does not require additional training. The approach is first applied to\nreduce the amount of data required to classify test images; it is found to be\neffective for problems in which at least some fraction of cases can be\ncorrectly classified based upon coarser data than are typically used. For\nneural networks performing digit recognition, for example, the proposed\napproach reduces the number of bytes of data read by 60% to 85% with less than\n5% reduction in accuracy. For the ImageNet data, the number of bytes read by\nthe typical network is reduced by 20% with less than 5% reduction in accuracy\n-- and in some cases, the resource savings reach 40%. The second application is\nto reduce computational complexity, with simpler neural networks used for test\ncases that are easier to classify and complex networks used for more difficult\ncases. For classification both of digits and of ImageNet images, computation\ncost is reduced by as much as 82% to 89% with less than 5% reduction in\naccuracy. The results also show that, for situations in which computational\ncost is not a concern, calculating multiple models' projections and selecting\nthe one from the most confident classifier can increase classification accuracy\non ImageNet by as much as two percent over the best standalone classifier\nconsidered here.\n","authors":["Chris Rohlfs"],"pdf_url":"https://arxiv.org/pdf/2201.01415v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.04616v3","updated":"2023-01-21T21:49:58Z","published":"2021-10-09T17:22:24Z","title":"Discriminative Multimodal Learning via Conditional Priors in Generative\n  Models","summary":"  Deep generative models with latent variables have been used lately to learn\njoint representations and generative processes from multi-modal data. These two\nlearning mechanisms can, however, conflict with each other and representations\ncan fail to embed information on the data modalities. This research studies the\nrealistic scenario in which all modalities and class labels are available for\nmodel training, but where some modalities and labels required for downstream\ntasks are missing. We show, in this scenario, that the variational lower bound\nlimits mutual information between joint representations and missing modalities.\nWe, to counteract these problems, introduce a novel conditional multi-modal\ndiscriminative model that uses an informative prior distribution and optimizes\na likelihood-free objective function that maximizes mutual information between\njoint representations and missing modalities. Extensive experimentation\ndemonstrates the benefits of our proposed model, empirical results show that\nour model achieves state-of-the-art results in representative problems such as\ndownstream classification, acoustic inversion, and image and annotation\ngeneration.\n","authors":["Rogelio A. Mancisidor","Michael Kampffmeyer","Kjersti Aas","Robert Jenssen"],"pdf_url":"https://arxiv.org/pdf/2110.04616v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09009v1","updated":"2023-01-21T21:08:45Z","published":"2023-01-21T21:08:45Z","title":"A Semantic Modular Framework for Events Topic Modeling in Social Media","summary":"  The advancement of social media contributes to the growing amount of content\nthey share frequently. This framework provides a sophisticated place for people\nto report various real-life events. Detecting these events with the help of\nnatural language processing has received researchers' attention, and various\nalgorithms have been developed for this goal. In this paper, we propose a\nSemantic Modular Model (SMM) consisting of 5 different modules, namely\nDistributional Denoising Autoencoder, Incremental Clustering, Semantic\nDenoising, Defragmentation, and Ranking and Processing. The proposed model aims\nto (1) cluster various documents and ignore the documents that might not\ncontribute to the identification of events, (2) identify more important and\ndescriptive keywords. Compared to the state-of-the-art methods, the results\nshow that the proposed model has a higher performance in identifying events\nwith lower ranks and extracting keywords for more important events in three\nEnglish Twitter datasets: FACup, SuperTuesday, and USElection. The proposed\nmethod outperformed the best reported results in the mean keyword-precision\nmetric by 7.9\\%.\n","authors":["Arya Hadizadeh Moghaddam","Saeedeh Momtazi"],"pdf_url":"https://arxiv.org/pdf/2301.09009v1.pdf","comment":"32 pages, 2 figures"},{"id":"http://arxiv.org/abs/2209.07850v3","updated":"2023-01-21T18:58:26Z","published":"2022-09-16T10:43:10Z","title":"FairGBM: Gradient Boosting with Fairness Constraints","summary":"  Tabular data is prevalent in many high stakes domains, such as financial\nservices or public policy. Gradient boosted decision trees (GBDT) are popular\nin these settings due to performance guarantees and low cost. However, in\nconsequential decision-making fairness is a foremost concern. Despite GBDT's\npopularity, existing in-processing Fair ML methods are either inapplicable to\nGBDT, or incur in significant train time overhead, or are inadequate for\nproblems with high class imbalance -- a typical issue in these domains. We\npresent FairGBM, a dual ascent learning framework for training GBDT under\nfairness constraints, with little to no impact on predictive performance when\ncompared to unconstrained GBDT. Since observational fairness metrics are\nnon-differentiable, we have to employ a \"proxy-Lagrangian\" formulation using\nsmooth convex error rate proxies to enable gradient-based optimization. Our\nimplementation shows an order of magnitude speedup in training time when\ncompared with related work, a pivotal aspect to foster the widespread adoption\nof FairGBM by real-world practitioners.\n","authors":["André F Cruz","Catarina Belém","Sérgio Jesus","João Bravo","Pedro Saleiro","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2209.07850v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.08987v1","updated":"2023-01-21T18:05:59Z","published":"2023-01-21T18:05:59Z","title":"Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors","summary":"  The pursuit of long-term fairness involves the interplay between\ndecision-making and the underlying data generating process. In this paper,\nthrough causal modeling with a directed acyclic graph (DAG) on the\ndecision-distribution interplay, we investigate the possibility of achieving\nlong-term fairness from a dynamic perspective. We propose Tier Balancing, a\ntechnically more challenging but more natural notion to achieve in the context\nof long-term, dynamic fairness analysis. Different from previous fairness\nnotions that are defined purely on observed variables, our notion goes one step\nfurther, capturing behind-the-scenes situation changes on the unobserved latent\ncausal factors that directly carry out the influence from the current decision\nto the future data distribution. Under the specified dynamics, we prove that in\ngeneral one cannot achieve the long-term fairness goal only through one-step\ninterventions. Furthermore, in the effort of approaching long-term fairness, we\nconsider the mission of \"getting closer to\" the long-term fairness goal and\npresent possibility and impossibility results accordingly.\n","authors":["Zeyu Tang","Yatong Chen","Yang Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08986v1","updated":"2023-01-21T17:57:53Z","published":"2023-01-21T17:57:53Z","title":"Adapting a Language Model While Preserving its General Knowledge","summary":"  Domain-adaptive pre-training (or DA-training for short), also known as\npost-training, aims to train a pre-trained general-purpose language model (LM)\nusing an unlabeled corpus of a particular domain to adapt the LM so that\nend-tasks in the domain can give improved performances. However, existing\nDA-training methods are in some sense blind as they do not explicitly identify\nwhat knowledge in the LM should be preserved and what should be changed by the\ndomain corpus. This paper shows that the existing methods are suboptimal and\nproposes a novel method to perform a more informed adaptation of the knowledge\nin the LM by (1) soft-masking the attention heads based on their importance to\nbest preserve the general knowledge in the LM and (2) contrasting the\nrepresentations of the general and the full (both general and domain knowledge)\nto learn an integrated representation with both general and domain-specific\nknowledge. Experimental results will demonstrate the effectiveness of the\nproposed approach.\n","authors":["Zixuan Ke","Yijia Shao","Haowei Lin","Hu Xu","Lei Shu","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2301.08986v1.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2206.04285v2","updated":"2023-01-21T17:53:13Z","published":"2022-06-09T05:33:02Z","title":"A Unification Framework for Euclidean and Hyperbolic Graph Neural\n  Networks","summary":"  Hyperbolic neural networks are able to capture the inherent hierarchy of\ngraph datasets, and consequently a powerful choice of GNNs. However, they\nentangle multiple incongruent (gyro-)vector spaces within a layer, which makes\nthem limited in terms of generalization and scalability. In this work, we\npropose to use Poincar\\'e disk model as our search space, and apply all\napproximations on the disk (as if the disk is a tangent space derived from the\norigin), and thus getting rid of all inter-space transformations. Such an\napproach enables us to propose a hyperbolic normalization layer, and to further\nsimplify the entire hyperbolic model to a Euclidean model cascaded with our\nhyperbolic normalization layer. We applied our proposed nonlinear hyperbolic\nnormalization to the current state-of-the-art homogeneous and multi-relational\ngraph networks. We demonstrate that not only does the model leverage the power\nof Euclidean networks such as interpretability and efficient execution of\nvarious model components, but also it outperforms both Euclidean and hyperbolic\ncounterparts in our benchmarks.\n","authors":["Mehrdad Khatir","Nurendra Choudhary","Sutanay Choudhury","Khushbu Agarwal","Chandan K. Reddy"],"pdf_url":"https://arxiv.org/pdf/2206.04285v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.05978v3","updated":"2023-01-21T17:26:07Z","published":"2021-11-10T22:46:05Z","title":"SUPER-Net: Trustworthy Medical Image Segmentation with Uncertainty\n  Propagation in Encoder-Decoder Networks","summary":"  Deep Learning (DL) holds great promise in reshaping the healthcare industry\nowing to its precision, efficiency, and objectivity. However, the brittleness\nof DL models to noisy and out-of-distribution inputs is ailing their deployment\nin the clinic. Most models produce point estimates without further information\nabout model uncertainty or confidence. This paper introduces a new Bayesian DL\nframework for uncertainty quantification in segmentation neural networks:\nSUPER-Net: trustworthy medical image Segmentation with Uncertainty Propagation\nin Encoder-decodeR Networks. SUPER-Net analytically propagates, using Taylor\nseries approximations, the first two moments (mean and covariance) of the\nposterior distribution of the model parameters across the nonlinear layers. In\nparticular, SUPER-Net simultaneously learns the mean and covariance without\nexpensive post-hoc Monte Carlo sampling or model ensembling. The output\nconsists of two simultaneous maps: the segmented image and its pixelwise\nuncertainty map, which corresponds to the covariance matrix of the predictive\ndistribution. We conduct an extensive evaluation of SUPER-Net on medical image\nsegmentation of Magnetic Resonances Imaging and Computed Tomography scans under\nvarious noisy and adversarial conditions. Our experiments on multiple benchmark\ndatasets demonstrate that SUPER-Net is more robust to noise and adversarial\nattacks than state-of-the-art segmentation models. Moreover, the uncertainty\nmap of the proposed SUPER-Net associates low confidence (or equivalently high\nuncertainty) to patches in the test input images that are corrupted with noise,\nartifacts, or adversarial attacks. Perhaps more importantly, the model exhibits\nthe ability of self-assessment of its segmentation decisions, notably when\nmaking erroneous predictions due to noise or adversarial examples.\n","authors":["Giuseppina Carannante","Dimah Dera","Nidhal C. Bouaynaya","Hassan M. Fathallah-Shaykh","Ghulam Rasool"],"pdf_url":"https://arxiv.org/pdf/2111.05978v3.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2209.08212v2","updated":"2023-01-21T20:52:38Z","published":"2022-09-17T01:20:59Z","title":"Compose & Embellish: Well-Structured Piano Performance Generation via A\n  Two-Stage Approach","summary":"  Even with strong sequence models like Transformers, generating expressive\npiano performances with long-range musical structures remains challenging.\nMeanwhile, methods to compose well-structured melodies or lead sheets (melody +\nchords), i.e., simpler forms of music, gained more success. Observing the\nabove, we devise a two-stage Transformer-based framework that Composes a lead\nsheet first, and then Embellishes it with accompaniment and expressive touches.\nSuch a factorization also enables pretraining on non-piano data. Our objective\nand subjective experiments show that Compose & Embellish shrinks the gap in\nstructureness between a current state of the art and real performances by half,\nand improves other musical aspects such as richness and coherence as well.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2209.08212v2.pdf","comment":"Preprint. 4 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2205.08738v2","updated":"2023-01-21T04:21:18Z","published":"2022-05-18T06:19:15Z","title":"Passive Defense Against 3D Adversarial Point Clouds Through the Lens of\n  3D Steganalysis","summary":"  Nowadays, 3D data plays an indelible role in the computer vision field.\nHowever, extensive studies have proved that deep neural networks (DNNs) fed\nwith 3D data, such as point clouds, are susceptible to adversarial examples,\nwhich aim to misguide DNNs and might bring immeasurable losses. Currently, 3D\nadversarial point clouds are chiefly generated in three fashions, i.e., point\nshifting, point adding, and point dropping. These point manipulations would\nmodify geometrical properties and local correlations of benign point clouds\nmore or less. Motivated by this basic fact, we propose to defend such\nadversarial examples with the aid of 3D steganalysis techniques. Specifically,\nwe first introduce an adversarial attack and defense model adapted from the\ncelebrated Prisoners' Problem in steganography to help us comprehend 3D\nadversarial attack and defense more generally. Then we rethink two significant\nbut vague concepts in the field of adversarial example, namely, active defense\nand passive defense, from the perspective of steganalysis. Most importantly, we\ndesign a 3D adversarial point cloud detector through the lens of 3D\nsteganalysis. Our detector is double-blind, that is to say, it does not rely on\nthe exact knowledge of the adversarial attack means and victim models. To\nenable the detector to effectively detect malicious point clouds, we craft a\n64-D discriminant feature set, including features related to first-order and\nsecond-order local descriptions of point clouds. To our knowledge, this work is\nthe first to apply 3D steganalysis to 3D adversarial example defense. Extensive\nexperimental results demonstrate that the proposed 3D adversarial point cloud\ndetector can achieve good detection performance on multiple types of 3D\nadversarial point clouds.\n","authors":["Jiahao Zhu"],"pdf_url":"https://arxiv.org/pdf/2205.08738v2.pdf","comment":"This paper is out-of-date"}]},"2023-01-24T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.10226v1","updated":"2023-01-24T18:52:59Z","published":"2023-01-24T18:52:59Z","title":"A Watermark for Large Language Models","summary":"  Potential harms of large language models can be mitigated by watermarking\nmodel output, i.e., embedding signals into generated text that are invisible to\nhumans but algorithmically detectable from a short span of tokens. We propose a\nwatermarking framework for proprietary language models. The watermark can be\nembedded with negligible impact on text quality, and can be detected using an\nefficient open-source algorithm without access to the language model API or\nparameters. The watermark works by selecting a randomized set of whitelist\ntokens before a word is generated, and then softly promoting use of whitelist\ntokens during sampling. We propose a statistical test for detecting the\nwatermark with interpretable p-values, and derive an information-theoretic\nframework for analyzing the sensitivity of the watermark. We test the watermark\nusing a multi-billion parameter model from the Open Pretrained Transformer\n(OPT) family, and discuss robustness and security.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Jonathan Katz","Ian Miers","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2301.10226v1.pdf","comment":"12 pages in the main body. Code will be available at\n  github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2301.10186v1","updated":"2023-01-24T17:53:21Z","published":"2023-01-24T17:53:21Z","title":"ViHOS: Hate Speech Spans Detection for Vietnamese","summary":"  The rise in hateful and offensive language directed at other users is one of\nthe adverse side effects of the increased use of social networking platforms.\nThis could make it difficult for human moderators to review tagged comments\nfiltered by classification systems. To help address this issue, we present the\nViHOS (Vietnamese Hate and Offensive Spans) dataset, the first human-annotated\ncorpus containing 26k spans on 11k comments. We also provide definitions of\nhateful and offensive spans in Vietnamese comments as well as detailed\nannotation guidelines. Besides, we conduct experiments with various\nstate-of-the-art models. Specifically, XLM-R$_{Large}$ achieved the best\nF1-scores in Single span detection and All spans detection, while\nPhoBERT$_{Large}$ obtained the highest in Multiple spans detection. Finally,\nour error analysis demonstrates the difficulties in detecting specific types of\nspans in our data for future research.\n  Disclaimer: This paper contains real comments that could be considered\nprofane, offensive, or abusive.\n","authors":["Phu Gia Hoang","Canh Duc Luu","Khanh Quoc Tran","Kiet Van Nguyen","Ngan Luu-Thuy Nguyen"],"pdf_url":"https://arxiv.org/pdf/2301.10186v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2301.10140v1","updated":"2023-01-24T17:13:08Z","published":"2023-01-24T17:13:08Z","title":"The Semantic Scholar Open Data Platform","summary":"  The volume of scientific output is creating an urgent need for automated\ntools to help scientists keep up with developments in their field. Semantic\nScholar (S2) is an open data platform and website aimed at accelerating science\nby helping scholars discover and understand scientific literature. We combine\npublic and proprietary data sources using state-of-the-art techniques for\nscholarly PDF content extraction and automatic knowledge graph construction to\nbuild the Semantic Scholar Academic Graph, the largest open scientific\nliterature graph to-date, with 200M+ papers, 80M+ authors, 550M+\npaper-authorship edges, and 2.4B+ citation edges. The graph includes advanced\nsemantic features such as structurally parsed text, natural language summaries,\nand vector embeddings. In this paper, we describe the components of the S2 data\nprocessing pipeline and the associated APIs offered by the platform. We will\nupdate this living document to reflect changes as we add new data offerings and\nimprove existing services.\n","authors":["Rodney Kinney","Chloe Anastasiades","Russell Authur","Iz Beltagy","Jonathan Bragg","Alexandra Buraczynski","Isabel Cachola","Stefan Candra","Yoganand Chandrasekhar","Arman Cohan","Miles Crawford","Doug Downey","Jason Dunkelberger","Oren Etzioni","Rob Evans","Sergey Feldman","Joseph Gorney","David Graham","Fangzhou Hu","Regan Huff","Daniel King","Sebastian Kohlmeier","Bailey Kuehl","Michael Langan","Daniel Lin","Haokun Liu","Kyle Lo","Jaron Lochner","Kelsey MacMillan","Tyler Murray","Chris Newell","Smita Rao","Shaurya Rohatgi","Paul Sayre","Zejiang Shen","Amanpreet Singh","Luca Soldaini","Shivashankar Subramanian","Amber Tanaka","Alex D. Wade","Linda Wagner","Lucy Lu Wang","Chris Wilhelm","Caroline Wu","Jiangjiang Yang","Angele Zamarron","Madeleine Van Zuylen","Daniel S. Weld"],"pdf_url":"https://arxiv.org/pdf/2301.10140v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2009.01822v2","updated":"2023-01-24T16:15:08Z","published":"2020-09-03T17:40:27Z","title":"Fine-grained Early Frequency Attention for Deep Speaker Representation\n  Learning","summary":"  Deep learning techniques have considerably improved speech processing in\nrecent years. Speaker representations extracted by deep learning models are\nbeing used in a wide range of tasks such as speaker recognition and speech\nemotion recognition. Attention mechanisms have started to play an important\nrole in improving deep learning models in the field of speech processing.\nNonetheless, despite the fact that important speaker-related information can be\nembedded in individual frequency-bins of the input spectral representations,\ncurrent attention models are unable to attend to fine-grained information items\nin spectral representations. In this paper we propose Fine-grained Early\nFrequency Attention (FEFA) for speaker representation learning. Our model is a\nsimple and lightweight model that can be integrated into various CNN pipelines\nand is capable of focusing on information items as small as frequency-bins. We\nevaluate the proposed model on three tasks of speaker recognition, speech\nemotion recognition, and spoken digit recognition. We use Three widely used\npublic datasets, namely VoxCeleb, IEMOCAP, and Free Spoken Digit Dataset for\nour experiments. We attach FEFA to several prominent deep learning models and\nevaluate its impact on the final performance. We also compare our work with\nother related works in the area. Our experiments show that by adding FEFA to\ndifferent CNN architectures, performance is consistently improved by\nsubstantial margins, and the models equipped with FEFA outperform all the other\nattentive models. We also test our model against different levels of added\nnoise showing improvements in robustness and less sensitivity compared to the\nbackbone networks.\n","authors":["Amirhossein Hajavi","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2009.01822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10095v1","updated":"2023-01-24T16:03:20Z","published":"2023-01-24T16:03:20Z","title":"Large Language Models as Fiduciaries: A Case Study Toward Robustly\n  Communicating With Artificial Intelligence Through Legal Standards","summary":"  Artificial Intelligence (AI) is taking on increasingly autonomous roles,\ne.g., browsing the web as a research assistant and managing money. But\nspecifying goals and restrictions for AI behavior is difficult. Similar to how\nparties to a legal contract cannot foresee every potential \"if-then\"\ncontingency of their future relationship, we cannot specify desired AI behavior\nfor all circumstances. Legal standards facilitate the robust communication of\ninherently vague and underspecified goals. Instructions (in the case of\nlanguage models, \"prompts\") that employ legal standards will allow AI agents to\ndevelop shared understandings of the spirit of a directive that can adapt to\nnovel situations, and generalize expectations regarding acceptable actions to\ntake in unspecified states of the world. Standards have built-in context that\nis lacking from other goal specification languages, such as plain language and\nprogramming languages. Through an empirical study on thousands of evaluation\nlabels we constructed from U.S. court opinions, we demonstrate that large\nlanguage models (LLMs) are beginning to exhibit an \"understanding\" of one of\nthe most relevant legal standards for AI agents: fiduciary obligations.\nPerformance comparisons across models suggest that, as LLMs continue to exhibit\nimproved core capabilities, their legal standards understanding will also\ncontinue to improve. OpenAI's latest LLM has 78% accuracy on our data, their\nprevious release has 73% accuracy, and a model from their 2020 GPT-3 paper has\n27% accuracy (worse than random). Our research is an initial step toward a\nframework for evaluating AI understanding of legal standards more broadly, and\nfor conducting reinforcement learning with legal feedback (RLLF).\n","authors":["John J. Nay"],"pdf_url":"https://arxiv.org/pdf/2301.10095v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.13020"},{"id":"http://arxiv.org/abs/2301.10075v1","updated":"2023-01-24T15:26:36Z","published":"2023-01-24T15:26:36Z","title":"From Inclusive Language to Gender-Neutral Machine Translation","summary":"  Gender inclusivity in language has become a central topic of debate and\nresearch. Its application in the cross-lingual contexts of human and machine\ntranslation (MT), however, remains largely unexplored. Here, we discuss\nGender-Neutral Translation (GNT) as a form of gender inclusivity in translation\nand advocate for its adoption for MT models, which have been found to\nperpetuate gender bias and discrimination. To this aim, we review a selection\nof relevant institutional guidelines for Gender-Inclusive Language (GIL) to\ncollect and systematize useful strategies of gender neutralization. Then, we\ndiscuss GNT and its scenarios of use, devising a list of desiderata. Finally,\nwe identify the main technical challenges to the implementation of GNT in MT.\nThroughout these contributions we focus on translation from English into\nItalian, as representative of salient linguistic transfer problems, due to the\ndifferent rules for gender marking in their grammar.\n","authors":["Andrea Piergentili","Dennis Fucci","Beatrice Savoldi","Luisa Bentivogli","Matteo Negri"],"pdf_url":"https://arxiv.org/pdf/2301.10075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05767v5","updated":"2023-01-24T15:18:47Z","published":"2022-12-12T08:40:04Z","title":"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and\n  Multi-Modal","summary":"  Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, i.e., static models,\ntemporal models, and multi-modal models. The early works in this domain mainly\nfocus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n","authors":["Ke Liang","Lingyuan Meng","Meng Liu","Yue Liu","Wenxuan Tu","Siwei Wang","Sihang Zhou","Xinwang Liu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.05767v5.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2301.09992v1","updated":"2023-01-24T13:39:23Z","published":"2023-01-24T13:39:23Z","title":"Multitask Instruction-based Prompting for Fallacy Recognition","summary":"  Fallacies are used as seemingly valid arguments to support a position and\npersuade the audience about its validity. Recognizing fallacies is an\nintrinsically difficult task both for humans and machines. Moreover, a big\nchallenge for computational models lies in the fact that fallacies are\nformulated differently across the datasets with differences in the input format\n(e.g., question-answer pair, sentence with fallacy fragment), genre (e.g.,\nsocial media, dialogue, news), as well as types and number of fallacies (from 5\nto 18 types per dataset). To move towards solving the fallacy recognition task,\nwe approach these differences across datasets as multiple tasks and show how\ninstruction-based prompting in a multitask setup based on the T5 model improves\nthe results against approaches built for a specific dataset such as T5, BERT or\nGPT-3. We show the ability of this multitask prompting approach to recognize 28\nunique fallacies across domains and genres and study the effect of model size\nand prompt choice by analyzing the per-class (i.e., fallacy type) results.\nFinally, we analyze the effect of annotation quality on model performance, and\nthe feasibility of complementing this approach with external knowledge.\n","authors":["Tariq Alhindi","Tuhin Chakrabarty","Elena Musi","Smaranda Muresan"],"pdf_url":"https://arxiv.org/pdf/2301.09992v1.pdf","comment":"In Proceedings of the 2022 Conference on Empirical Methods in Natural\n  Language Processing, pages 8172 - 8187"},{"id":"http://arxiv.org/abs/2207.08143v3","updated":"2023-01-24T12:23:48Z","published":"2022-07-17T11:24:44Z","title":"Can large language models reason about medical questions?","summary":"  Although large language models (LLMs) often produce impressive outputs, it\nremains unclear how they perform in real-world scenarios requiring strong\nreasoning skills and expert domain knowledge. We set out to investigate whether\nGPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about\ndifficult real-world-based questions. We utilize two multiple-choice medical\nexam questions (USMLE and MedMCQA) and a medical reading comprehension dataset\n(PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT,\nthink step-by-step), zero- and few-shot (prepending the question with\nquestion-answer exemplars) and retrieval augmentation (injecting Wikipedia\npassages into the prompt). For a subset of the USMLE questions, a medical\nexpert reviewed and annotated the model's CoT. We found that InstructGPT can\noften read, reason and recall expert knowledge. Failure are primarily due to\nlack of knowledge and reasoning errors and trivial guessing heuristics are\nobserved, e.g.\\ too often predicting labels A and D on USMLE. Sampling and\ncombining many completions overcome some of these limitations. Using 100\nsamples, Codex 5-shot CoT not only gives close to well-calibrated predictive\nprobability but also achieves human-level performances on the three datasets.\nUSMLE: 60.2%, MedMCQA: 62.7% and PubMedQA: 78.2%.\n","authors":["Valentin Liévin","Christoffer Egeberg Hother","Ole Winther"],"pdf_url":"https://arxiv.org/pdf/2207.08143v3.pdf","comment":"33 pages, 6 figures, to be submitted. v1: results using InstructGPT,\n  v2: added the Codex experiments, v3: added the missing test MedMCQA results\n  for Codex 5-shot CoT and using k=100 samples"},{"id":"http://arxiv.org/abs/2112.03104v2","updated":"2023-01-24T11:19:27Z","published":"2021-11-22T11:02:35Z","title":"HTMOT : Hierarchical Topic Modelling Over Time","summary":"  Over the years, topic models have provided an efficient way of extracting\ninsights from text. However, while many models have been proposed, none are\nable to model topic temporality and hierarchy jointly. Modelling time provide\nmore precise topics by separating lexically close but temporally distinct\ntopics while modelling hierarchy provides a more detailed view of the content\nof a document corpus. In this study, we therefore propose a novel method,\nHTMOT, to perform Hierarchical Topic Modelling Over Time. We train HTMOT using\na new implementation of Gibbs sampling, which is more efficient. Specifically,\nwe show that only applying time modelling to deep sub-topics provides a way to\nextract specific stories or events while high level topics extract larger\nthemes in the corpus. Our results show that our training procedure is fast and\ncan extract accurate high-level topics and temporally precise sub-topics. We\nmeasured our model's performance using the Word Intrusion task and outlined\nsome limitations of this evaluation method, especially for hierarchical models.\nAs a case study, we focused on the various developments in the space industry\nin 2020.\n","authors":["Judicael Poumay","Ashwin Ittoo"],"pdf_url":"https://arxiv.org/pdf/2112.03104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09919v1","updated":"2023-01-24T11:00:17Z","published":"2023-01-24T11:00:17Z","title":"Opportunities and Challenges in Neural Dialog Tutoring","summary":"  Designing dialog tutors has been challenging as it involves modeling the\ndiverse and complex pedagogical strategies employed by human tutors. Although\nthere have been significant recent advances in neural conversational systems\nusing large language models and growth in available dialog corpora, dialog\ntutoring has largely remained unaffected by these advances. In this paper, we\nrigorously analyze various generative language models on two dialog tutoring\ndatasets for language learning using automatic and human evaluations to\nunderstand the new opportunities brought by these advances as well as the\nchallenges we must overcome to build models that would be usable in real\neducational settings. We find that although current approaches can model\ntutoring in constrained learning scenarios when the number of concepts to be\ntaught and possible teacher strategies are small, they perform poorly in less\nconstrained scenarios. Our human quality evaluation shows that both models and\nground-truth annotations exhibit low performance in terms of equitable\ntutoring, which measures learning opportunities for students and how engaging\nthe dialog is. To understand the behavior of our models in a real tutoring\nsetting, we conduct a user study using expert annotators and find a\nsignificantly large number of model reasoning errors in 45% of conversations.\nFinally, we connect our findings to outline future work.\n","authors":["Jakub Macina","Nico Daheim","Lingzhi Wang","Tanmay Sinha","Manu Kapur","Iryna Gurevych","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2301.09919v1.pdf","comment":"Accepted to EACL 2023 (main conference)"},{"id":"http://arxiv.org/abs/2110.11205v3","updated":"2023-01-24T10:55:13Z","published":"2021-10-21T15:30:40Z","title":"Robustness through Data Augmentation Loss Consistency","summary":"  While deep learning through empirical risk minimization (ERM) has succeeded\nat achieving human-level performance at a variety of complex tasks, ERM is not\nrobust to distribution shifts or adversarial attacks. Synthetic data\naugmentation followed by empirical risk minimization (DA-ERM) is a simple and\nwidely used solution to improve robustness in ERM. In addition, consistency\nregularization can be applied to further improve the robustness of the model by\nforcing the representation of the original sample and the augmented one to be\nsimilar. However, existing consistency regularization methods are not\napplicable to covariant data augmentation, where the label in the augmented\nsample is dependent on the augmentation function. For example, dialog state\ncovaries with named entity when we augment data with a new named entity. In\nthis paper, we propose data augmented loss invariant regularization (DAIR), a\nsimple form of consistency regularization that is applied directly at the loss\nlevel rather than intermediate features, making it widely applicable to both\ninvariant and covariant data augmentation regardless of network architecture,\nproblem setup, and task. We apply DAIR to real-world learning problems\ninvolving covariant data augmentation: robust neural task-oriented dialog state\ntracking and robust visual question answering. We also apply DAIR to tasks\ninvolving invariant data augmentation: robust regression, robust classification\nagainst adversarial attacks, and robust ImageNet classification under\ndistribution shift. Our experiments show that DAIR consistently outperforms ERM\nand DA-ERM with little marginal computational cost and sets new\nstate-of-the-art results in several benchmarks involving covariant data\naugmentation. Our code of all experiments is available at:\nhttps://github.com/optimization-for-data-driven-science/DAIR.git\n","authors":["Tianjian Huang","Shaunak Halbe","Chinnadhurai Sankar","Pooyan Amini","Satwik Kottur","Alborz Geramifard","Meisam Razaviyayn","Ahmad Beirami"],"pdf_url":"https://arxiv.org/pdf/2110.11205v3.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2301.09912v1","updated":"2023-01-24T10:49:21Z","published":"2023-01-24T10:49:21Z","title":"Applications and Challenges of Sentiment Analysis in Real-life Scenarios","summary":"  Sentiment analysis has benefited from the availability of lexicons and\nbenchmark datasets created over decades of research. However, its applications\nto the real world are a driving force for research in SA. This chapter\ndescribes some of these applications and related challenges in real-life\nscenarios. In this chapter, we focus on five applications of SA: health, social\npolicy, e-commerce, digital humanities and other areas of NLP. This chapter is\nintended to equip an NLP researcher with the `what', `why' and `how' of\napplications of SA: what is the application about, why it is important and\nchallenging and how current research in SA deals with the application. We note\nthat, while the use of deep learning techniques is a popular paradigm that\nspans these applications, challenges around privacy and selection bias of\ndatasets is a recurring theme across several applications.\n","authors":["Diptesh Kanojia","Aditya Joshi"],"pdf_url":"https://arxiv.org/pdf/2301.09912v1.pdf","comment":"Book Chapter (3rd Chapter in \"Computational Intelligence Applications\n  for Text and Sentiment Data Analysis\" published by Elsevier)"},{"id":"http://arxiv.org/abs/2301.09911v1","updated":"2023-01-24T10:49:01Z","published":"2023-01-24T10:49:01Z","title":"Conclusion-based Counter-Argument Generation","summary":"  In real-world debates, the most common way to counter an argument is to\nreason against its main point, that is, its conclusion. Existing work on the\nautomatic generation of natural language counter-arguments does not address the\nrelation to the conclusion, possibly because many arguments leave their\nconclusion implicit. In this paper, we hypothesize that the key to effective\ncounter-argument generation is to explicitly model the argument's conclusion\nand to ensure that the stance of the generated counter is opposite to that\nconclusion. In particular, we propose a multitask approach that jointly learns\nto generate both the conclusion and the counter of an input argument. The\napproach employs a stance-based ranking component that selects the counter from\na diverse set of generated candidates whose stance best opposes the generated\nconclusion. In both automatic and manual evaluation, we provide evidence that\nour approach generates more relevant and stance-adhering counters than strong\nbaselines.\n","authors":["Milad Alshomary","Henning Wachsmuth"],"pdf_url":"https://arxiv.org/pdf/2301.09911v1.pdf","comment":"8 pages, 1 figure, conference paper, eacl-23"},{"id":"http://arxiv.org/abs/2301.09908v1","updated":"2023-01-24T10:35:28Z","published":"2023-01-24T10:35:28Z","title":"Cross-lingual German Biomedical Information Extraction: from Zero-shot\n  to Human-in-the-Loop","summary":"  This paper presents our project proposal for extracting biomedical\ninformation from German clinical narratives with limited amounts of\nannotations. We first describe the applied strategies in transfer learning and\nactive learning for solving our problem. After that, we discuss the design of\nthe user interface for both supplying model inspection and obtaining user\nannotations in the interactive environment.\n","authors":["Siting Liang","Mareike Hartmann","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2301.09908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09896v1","updated":"2023-01-24T10:13:00Z","published":"2023-01-24T10:13:00Z","title":"Automated Identification of Disaster News For Crisis Management Using\n  Machine Learning","summary":"  A lot of news sources picked up on Typhoon Rai (also known locally as Typhoon\nOdette), along with fake news outlets. The study honed in on the issue, to\ncreate a model that can identify between legitimate and illegitimate news\narticles. With this in mind, we chose the following machine learning algorithms\nin our development: Logistic Regression, Random Forest and Multinomial Naive\nBayes. Bag of Words, TF-IDF and Lemmatization were implemented in the Model.\nGathering 160 datasets from legitimate and illegitimate sources, the machine\nlearning was trained and tested. By combining all the machine learning\ntechniques, the Combined BOW model was able to reach an accuracy of 91.07%,\nprecision of 88.33%, recall of 94.64%, and F1 score of 91.38% and Combined\nTF-IDF model was able to reach an accuracy of 91.18%, precision of 86.89%,\nrecall of 94.64%, and F1 score of 90.60%.\n","authors":["Lord Christian Carl H. Regacho","Ai Matsushita","Angie M. Ceniza-Canillo"],"pdf_url":"https://arxiv.org/pdf/2301.09896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01621v2","updated":"2023-01-24T09:31:25Z","published":"2023-01-04T13:49:14Z","title":"Grammar construction methods for extended deterministic expressions","summary":"  Extended regular expressions with counting and interleaving are widely used\nin practice. However the related theoretical studies for this kind of\nexpressions currently cannot meet the need of practical work. This paper\ndevelops syntax definitions for extended deterministic expressions and their\nsubclasses, hope to completely solve the long-standing problem that there are\nno syntax definitions for this kind of expressions, which has become an\nimportant reason for restricting the use of extended expressions.\n","authors":["Xiaoying Mou","Haiming Chen"],"pdf_url":"https://arxiv.org/pdf/2301.01621v2.pdf","comment":"in Chinese language"},{"id":"http://arxiv.org/abs/2212.08072v2","updated":"2023-01-24T09:24:23Z","published":"2022-12-13T19:06:00Z","title":"Foresight -- Generative Pretrained Transformer (GPT) for Modelling of\n  Patient Timelines using EHRs","summary":"  Background: Electronic Health Records hold detailed longitudinal information\nabout each patient's health status and general clinical history, a large\nportion of which is stored within the unstructured text. Existing approaches\nfocus mostly on structured data and a subset of single-domain outcomes. We\nexplore how temporal modelling of patients from free text and structured data,\nusing deep generative transformers can be used to forecast a wide range of\nfuture disorders, substances, procedures or findings. Methods: We present\nForesight, a novel transformer-based pipeline that uses named entity\nrecognition and linking tools to convert document text into structured, coded\nconcepts, followed by providing probabilistic forecasts for future medical\nevents such as disorders, substances, procedures and findings. We processed the\nentire free-text portion from three different hospital datasets totalling\n811336 patients covering both physical and mental health. Findings: On tests in\ntwo UK hospitals (King's College Hospital, South London and Maudsley) and the\nUS MIMIC-III dataset precision@10 0.68, 0.76 and 0.88 was achieved for\nforecasting the next disorder in a patient timeline, while precision@10 of\n0.80, 0.81 and 0.91 was achieved for forecasting the next biomedical concept.\nForesight was also validated on 34 synthetic patient timelines by five\nclinicians and achieved relevancy of 97% for the top forecasted candidate\ndisorder. As a generative model, it can forecast follow-on biomedical concepts\nfor as many steps as required. Interpretation: Foresight is a general-purpose\nmodel for biomedical concept modelling that can be used for real-world risk\nforecasting, virtual trials and clinical research to study the progression of\ndisorders, simulate interventions and counterfactuals, and educational\npurposes.\n","authors":["Zeljko Kraljevic","Dan Bean","Anthony Shek","Rebecca Bendayan","Harry Hemingway","Joshua Au Yeung","Alexander Deng","Alfie Baston","Jack Ross","Esther Idowu","James T Teo","Richard J Dobson"],"pdf_url":"https://arxiv.org/pdf/2212.08072v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09820v1","updated":"2023-01-24T05:11:17Z","published":"2023-01-24T05:11:17Z","title":"A Stability Analysis of Fine-Tuning a Pre-Trained Model","summary":"  Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,\netc.) has proven to be one of the most promising paradigms in recent NLP\nresearch. However, numerous recent works indicate that fine-tuning suffers from\nthe instability problem, i.e., tuning the same model under the same setting\nresults in significantly different performance. Many recent works have proposed\ndifferent methods to solve this problem, but there is no theoretical\nunderstanding of why and how these methods work. In this paper, we propose a\nnovel theoretical stability analysis of fine-tuning that focuses on two\ncommonly used settings, namely, full fine-tuning and head tuning. We define the\nstability under each setting and prove the corresponding stability bounds. The\ntheoretical bounds explain why and how several existing methods can stabilize\nthe fine-tuning procedure. In addition to being able to explain most of the\nobserved empirical discoveries, our proposed theoretical analysis framework can\nalso help in the design of effective and provable methods. Based on our theory,\nwe propose three novel strategies to stabilize the fine-tuning procedure,\nnamely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self\nUnsupervised Re-Training (SURT). We extensively evaluate our proposed\napproaches on 11 widely used real-world benchmark datasets, as well as hundreds\nof synthetic classification datasets. The experiment results show that our\nproposed methods significantly stabilize the fine-tuning procedure and also\ncorroborate our theoretical analysis.\n","authors":["Zihao Fu","Anthony Man-Cho So","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2301.09820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09809v1","updated":"2023-01-24T04:27:27Z","published":"2023-01-24T04:27:27Z","title":"Low-Resource Compositional Semantic Parsing with Concept Pretraining","summary":"  Semantic parsing plays a key role in digital voice assistants such as Alexa,\nSiri, and Google Assistant by mapping natural language to structured meaning\nrepresentations. When we want to improve the capabilities of a voice assistant\nby adding a new domain, the underlying semantic parsing model needs to be\nretrained using thousands of annotated examples from the new domain, which is\ntime-consuming and expensive. In this work, we present an architecture to\nperform such domain adaptation automatically, with only a small amount of\nmetadata about the new domain and without any new training data (zero-shot) or\nwith very few examples (few-shot). We use a base seq2seq (sequence-to-sequence)\narchitecture and augment it with a concept encoder that encodes intent and slot\ntags from the new domain. We also introduce a novel decoder-focused approach to\npretrain seq2seq models to be concept aware using Wikidata and use it to help\nour model learn important concepts and perform well in low-resource settings.\nWe report few-shot and zero-shot results for compositional semantic parsing on\nthe TOPv2 dataset and show that our model outperforms prior approaches in\nfew-shot settings for the TOPv2 and SNIPS datasets.\n","authors":["Subendhu Rongali","Mukund Sridhar Harakere","Haidar Khan","Konstantine Arkoudas","Wael Hamza","Andrew McCallum"],"pdf_url":"https://arxiv.org/pdf/2301.09809v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2301.09790v1","updated":"2023-01-24T02:44:02Z","published":"2023-01-24T02:44:02Z","title":"Can Very Large Pretrained Language Models Learn Storytelling With A Few\n  Examples?","summary":"  While pre-trained language models can generate individually fluent sentences\nfor automatic story generation, they struggle to generate stories that are\ncoherent, sensible and interesting. Current state-of-the-art (SOTA) story\ngeneration models explore using higher-level features such as plots or\ncommonsense knowledge to improve the quality of generated stories. Prompt-based\nlearning using very large pre-trained language models (VLPLMs) such as GPT3 has\ndemonstrated impressive performance even across various NLP tasks. In this\npaper, we present an extensive study using automatic and human evaluation to\ncompare the story generation capability of VLPLMs to those SOTA models in three\ndifferent datasets where stories differ in style, register and length. Our\nresults show that VLPLMs generate much higher quality stories than other story\ngeneration models, and to a certain extent rival human authors, although\npreliminary investigation also reveals that they tend to ``plagiarise'' real\nstories in scenarios that involve world knowledge.\n","authors":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"pdf_url":"https://arxiv.org/pdf/2301.09790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09785v1","updated":"2023-01-24T02:12:42Z","published":"2023-01-24T02:12:42Z","title":"Transformer-Patcher: One Mistake worth One Neuron","summary":"  Large Transformer-based Pretrained Language Models (PLMs) dominate almost all\nNatural Language Processing (NLP) tasks. Nevertheless, they still make mistakes\nfrom time to time. For a model deployed in an industrial environment, fixing\nthese mistakes quickly and robustly is vital to improve user experiences.\nPrevious works formalize such problems as Model Editing (ME) and mostly focus\non fixing one mistake. However, the one-mistake-fixing scenario is not an\naccurate abstraction of the real-world challenge. In the deployment of AI\nservices, there are ever-emerging mistakes, and the same mistake may recur if\nnot corrected in time. Thus a preferable solution is to rectify the mistakes as\nsoon as they appear nonstop. Therefore, we extend the existing ME into\nSequential Model Editing (SME) to help develop more practical editing methods.\nOur study shows that most current ME methods could yield unsatisfying results\nin this scenario. We then introduce Transformer-Patcher, a novel model editor\nthat can shift the behavior of transformer-based models by simply adding and\ntraining a few neurons in the last Feed-Forward Network layer. Experimental\nresults on both classification and generation tasks show that\nTransformer-Patcher can successively correct up to thousands of errors\n(Reliability) and generalize to their equivalent inputs (Generality) while\nretaining the model's accuracy on irrelevant inputs (Locality). Our method\noutperforms previous fine-tuning and HyperNetwork-based methods and achieves\nstate-of-the-art performance for Sequential Model Editing (SME). The code is\navailable at https://github.com/ZeroYuHuang/Transformer-Patcher.\n","authors":["Zeyu Huang","Yikang Shen","Xiaofeng Zhang","Jie Zhou","Wenge Rong","Zhang Xiong"],"pdf_url":"https://arxiv.org/pdf/2301.09785v1.pdf","comment":"accepted in ICLR 2023"},{"id":"http://arxiv.org/abs/2301.08506v2","updated":"2023-01-24T00:48:14Z","published":"2023-01-20T10:33:03Z","title":"Language Agnostic Data-Driven Inverse Text Normalization","summary":"  With the emergence of automatic speech recognition (ASR) models, converting\nthe spoken form text (from ASR) to the written form is in urgent need. This\ninverse text normalization (ITN) problem attracts the attention of researchers\nfrom various fields. Recently, several works show that data-driven ITN methods\ncan output high-quality written form text. Due to the scarcity of labeled\nspoken-written datasets, the studies on non-English data-driven ITN are quite\nlimited. In this work, we propose a language-agnostic data-driven ITN framework\nto fill this gap. Specifically, we leverage the data augmentation in\nconjunction with neural machine translated data for low resource languages.\nMoreover, we design an evaluation method for language agnostic ITN model when\nonly English data is available. Our empirical evaluation shows this language\nagnostic modeling approach is effective for low resource languages while\npreserving the performance for high resource languages.\n","authors":["Szu-Jui Chen","Debjyoti Paul","Yutong Pang","Peng Su","Xuedong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09767v1","updated":"2023-01-24T00:32:56Z","published":"2023-01-24T00:32:56Z","title":"Truveta Mapper: A Zero-shot Ontology Alignment Framework","summary":"  In this paper, a new perspective is suggested for unsupervised Ontology\nMatching (OM) or Ontology Alignment (OA) by treating it as a translation task.\nOntologies are represented as graphs, and the translation is performed from a\nnode in the source ontology graph to a path in the target ontology graph. The\nproposed framework, Truveta Mapper (TM), leverages a multi-task\nsequence-to-sequence transformer model to perform alignment across multiple\nontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables\nthe model to implicitly learn the relationship between different ontologies via\ntransfer-learning without requiring any explicit cross-ontology manually\nlabeled data. This also enables the formulated framework to outperform existing\nsolutions for both runtime latency and alignment quality. The model is\npre-trained and fine-tuned only on publicly available text corpus and\ninner-ontologies data. The proposed solution outperforms state-of-the-art\napproaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented\nnew OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers\nlog-linear complexity in contrast to quadratic in the existing end-to-end\nmethods, and overall makes the OM task efficient and more straightforward\nwithout much post-processing involving mapping extension or mapping repair.\n","authors":["Mariyam Amir","Murchana Baruah","Mahsa Eslamialishah","Sina Ehsani","Alireza Bahramali","Sadra Naddaf-Sh","Saman Zarandioon"],"pdf_url":"https://arxiv.org/pdf/2301.09767v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.10241v1","updated":"2023-01-24T18:59:08Z","published":"2023-01-24T18:59:08Z","title":"K-Planes: Explicit Radiance Fields in Space, Time, and Appearance","summary":"  We introduce k-planes, a white-box model for radiance fields in arbitrary\ndimensions. Our model uses d choose 2 planes to represent a d-dimensional\nscene, providing a seamless way to go from static (d=3) to dynamic (d=4)\nscenes. This planar factorization makes adding dimension-specific priors easy,\ne.g. temporal smoothness and multi-resolution spatial structure, and induces a\nnatural decomposition of static and dynamic components of a scene. We use a\nlinear feature decoder with a learned color basis that yields similar\nperformance as a nonlinear black-box MLP decoder. Across a range of synthetic\nand real, static and dynamic, fixed and varying appearance scenes, k-planes\nyields competitive and often state-of-the-art reconstruction fidelity with low\nmemory usage, achieving 1000x compression over a full 4D grid, and fast\noptimization with a pure PyTorch implementation. For video results and code,\nplease see sarafridov.github.io/K-Planes.\n","authors":["Sara Fridovich-Keil","Giacomo Meanti","Frederik Warburg","Benjamin Recht","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2301.10241v1.pdf","comment":"Project page https://sarafridov.github.io/K-Planes/"},{"id":"http://arxiv.org/abs/2301.10222v1","updated":"2023-01-24T18:50:48Z","published":"2023-01-24T18:50:48Z","title":"RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in\n  Autonomous Driving","summary":"  Casting semantic segmentation of outdoor LiDAR point clouds as a 2D problem,\ne.g., via range projection, is an effective and popular approach. These\nprojection-based methods usually benefit from fast computations and, when\ncombined with techniques which use other point cloud representations, achieve\nstate-of-the-art results. Today, projection-based methods leverage 2D CNNs but\nrecent advances in computer vision show that vision transformers (ViTs) have\nachieved state-of-the-art results in many image-based benchmarks. In this work,\nwe question if projection-based methods for 3D semantic segmentation can\nbenefit from these latest improvements on ViTs. We answer positively but only\nafter combining them with three key ingredients: (a) ViTs are notoriously hard\nto train and require a lot of training data to learn powerful representations.\nBy preserving the same backbone architecture as for RGB images, we can exploit\nthe knowledge from long training on large image collections that are much\ncheaper to acquire and annotate than point clouds. We reach our best results\nwith pre-trained ViTs on large image datasets. (b) We compensate ViTs' lack of\ninductive bias by substituting a tailored convolutional stem for the classical\nlinear embedding layer. (c) We refine pixel-wise predictions with a\nconvolutional decoder and a skip connection from the convolutional stem to\ncombine low-level but fine-grained features of the the convolutional stem with\nthe high-level but coarse predictions of the ViT encoder. With these\ningredients, we show that our method, called RangeViT, outperforms existing\nprojection-based methods on nuScenes and SemanticKITTI. We provide the\nimplementation code at https://github.com/valeoai/rangevit.\n","authors":["Angelika Ando","Spyros Gidaris","Andrei Bursuc","Gilles Puy","Alexandre Boulch","Renaud Marlet"],"pdf_url":"https://arxiv.org/pdf/2301.10222v1.pdf","comment":"Code at https://github.com/valeoai/rangevit"},{"id":"http://arxiv.org/abs/2301.10218v1","updated":"2023-01-24T18:46:33Z","published":"2023-01-24T18:46:33Z","title":"Detecting and measuring human gastric peristalsis using magnetically\n  controlled capsule endoscope","summary":"  Magnetically controlled capsule endoscope (MCCE) is an emerging tool for the\ndiagnosis of gastric diseases with the advantages of comfort, safety, and no\nanesthesia. In this paper, we develop algorithms to detect and measure human\ngastric peristalsis (contraction wave) using video sequences acquired by MCCE.\nWe develop a spatial-temporal deep learning algorithm to detect gastric\ncontraction waves and measure human gastric peristalsis periods. The quality of\nMCCE video sequences is prone to camera motion. We design a camera motion\ndetector (CMD) to process the MCCE video sequences, mitigating the camera\nmovement during MCCE examination. To the best of our knowledge, we are the\nfirst to propose computer vision-based solutions to detect and measure human\ngastric peristalsis. Our methods have great potential in assisting the\ndiagnosis of gastric diseases by evaluating gastric motility.\n","authors":["Xueshen Li","Yu Gan","David Duan","Xiao Yang"],"pdf_url":"https://arxiv.org/pdf/2301.10218v1.pdf","comment":"5 pages, 5 figures, accepted by IEEE ISBI 2023"},{"id":"http://arxiv.org/abs/2301.10208v1","updated":"2023-01-24T18:28:21Z","published":"2023-01-24T18:28:21Z","title":"A Simple Adaptive Unfolding Network for Hyperspectral Image\n  Reconstruction","summary":"  We present a simple, efficient, and scalable unfolding network, SAUNet, to\nsimplify the network design with an adaptive alternate optimization framework\nfor hyperspectral image (HSI) reconstruction. SAUNet customizes a Residual\nAdaptive ADMM Framework (R2ADMM) to connect each stage of the network via a\ngroup of learnable parameters to promote the usage of mask prior, which greatly\nstabilizes training and solves the accuracy degradation issue. Additionally, we\nintroduce a simple convolutional modulation block (CMB), which leads to\nefficient training, easy scale-up, and less computation. Coupling these two\ndesigns, SAUNet can be scaled to non-trivial 13 stages with continuous\nimprovement. Without bells and whistles, SAUNet improves both performance and\nspeed compared with the previous state-of-the-art counterparts, which makes it\nfeasible for practical high-resolution HSI reconstruction scenarios. We set new\nrecords on CAVE and KAIST HSI reconstruction benchmarks. Code and models are\navailable at https://github.com/hustvl/SAUNet.\n","authors":["Junyu Wang","Shijie Wang","Wenyu Liu","Zengqiang Zheng","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.10208v1.pdf","comment":"Project page: https://github.com/hustvl/SAUNet"},{"id":"http://arxiv.org/abs/2301.10187v1","updated":"2023-01-24T17:54:01Z","published":"2023-01-24T17:54:01Z","title":"Enhanced Sharp-GAN For Histopathology Image Synthesis","summary":"  Histopathology image synthesis aims to address the data shortage issue in\ntraining deep learning approaches for accurate cancer detection. However,\nexisting methods struggle to produce realistic images that have accurate nuclei\nboundaries and less artifacts, which limits the application in downstream\ntasks. To address the challenges, we propose a novel approach that enhances the\nquality of synthetic images by using nuclei topology and contour\nregularization. The proposed approach uses the skeleton map of nuclei to\nintegrate nuclei topology and separate touching nuclei. In the loss function,\nwe propose two new contour regularization terms that enhance the contrast\nbetween contour and non-contour pixels and increase the similarity between\ncontour pixels. We evaluate the proposed approach on the two datasets using\nimage quality metrics and a downstream task (nuclei segmentation). The proposed\napproach outperforms Sharp-GAN in all four image quality metrics on two\ndatasets. By integrating 6k synthetic images from the proposed approach into\ntraining, a nuclei segmentation model achieves the state-of-the-art\nsegmentation performance on TNBC dataset and its detection quality (DQ),\nsegmentation quality (SQ), panoptic quality (PQ), and aggregated Jaccard index\n(AJI) is 0.855, 0.863, 0.691, and 0.683, respectively.\n","authors":["Sujata Butte","Haotian Wang","Aleksandar Vakanski","Min Xian"],"pdf_url":"https://arxiv.org/pdf/2301.10187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02412v2","updated":"2023-01-24T17:27:34Z","published":"2022-09-02T16:45:46Z","title":"SIAN: Style-Guided Instance-Adaptive Normalization for Multi-Organ\n  Histopathology Image Synthesis","summary":"  Existing deep neural networks for histopathology image synthesis cannot\ngenerate image styles that align with different organs, and cannot produce\naccurate boundaries of clustered nuclei. To address these issues, we propose a\nstyle-guided instance-adaptive normalization (SIAN) approach to synthesize\nrealistic color distributions and textures for histopathology images from\ndifferent organs. SIAN contains four phases, semantization, stylization,\ninstantiation, and modulation. The first two phases synthesize image semantics\nand styles by using semantic maps and learned image style vectors. The\ninstantiation module integrates geometrical and topological information and\ngenerates accurate nuclei boundaries. We validate the proposed approach on a\nmultiple-organ dataset, Extensive experimental results demonstrate that the\nproposed method generates more realistic histopathology images than four\nstate-of-the-art approaches for five organs. By incorporating synthetic images\nfrom the proposed approach to model training, an instance segmentation network\ncan achieve state-of-the-art performance.\n","authors":["Haotian Wang","Min Xian","Aleksandar Vakanski","Bryar Shareef"],"pdf_url":"https://arxiv.org/pdf/2209.02412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10134v1","updated":"2023-01-24T16:59:46Z","published":"2023-01-24T16:59:46Z","title":"Bipartite Graph Diffusion Model for Human Interaction Generation","summary":"  The generation of natural human motion interactions is a hot topic in\ncomputer vision and computer animation. It is a challenging task due to the\ndiversity of possible human motion interactions. Diffusion models, which have\nalready shown remarkable generative capabilities in other domains, are a good\ncandidate for this task. In this paper, we introduce a novel bipartite graph\ndiffusion method (BiGraphDiff) to generate human motion interactions between\ntwo persons. Specifically, bipartite node sets are constructed to model the\ninherent geometric constraints between skeleton nodes during interactions. The\ninteraction graph diffusion model is transformer-based, combining some\nstate-of-the-art motion methods. We show that the proposed achieves new\nstate-of-the-art results on leading benchmarks for the human interaction\ngeneration task.\n","authors":["Baptiste Chopin","Hao Tang","Mohamed Daoudi"],"pdf_url":"https://arxiv.org/pdf/2301.10134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10127v1","updated":"2023-01-24T16:46:37Z","published":"2023-01-24T16:46:37Z","title":"Improving Open-Set Semi-Supervised Learning with Self-Supervision","summary":"  Open-set semi-supervised learning (OSSL) is a realistic setting of\nsemi-supervised learning where the unlabeled training set contains classes that\nare not present in the labeled set. Many existing OSSL methods assume that\nthese out-of-distribution data are harmful and put effort into excluding data\nfrom unknown classes from the training objective. In contrast, we propose an\nOSSL framework that facilitates learning from all unlabeled data through\nself-supervision. Additionally, we utilize an energy-based score to accurately\nrecognize data belonging to the known classes, making our method well-suited\nfor handling uncurated data in deployment. We show through extensive\nexperimental evaluations on several datasets that our method shows overall\nunmatched robustness and performance in terms of closed-set accuracy and\nopen-set recognition compared with state-of-the-art for OSSL. Our code will be\nreleased upon publication.\n","authors":["Erik Wallin","Lennart Svensson","Fredrik Kahl","Lars Hammarstrand"],"pdf_url":"https://arxiv.org/pdf/2301.10127v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2201.11620v2","updated":"2023-01-24T16:18:30Z","published":"2022-01-27T16:26:36Z","title":"Domain generalization in deep learning-based mass detection in\n  mammography: A large-scale multi-center study","summary":"  Computer-aided detection systems based on deep learning have shown great\npotential in breast cancer detection. However, the lack of domain\ngeneralization of artificial neural networks is an important obstacle to their\ndeployment in changing clinical environments. In this work, we explore the\ndomain generalization of deep learning methods for mass detection in digital\nmammography and analyze in-depth the sources of domain shift in a large-scale\nmulti-center setting. To this end, we compare the performance of eight\nstate-of-the-art detection methods, including Transformer-based models, trained\nin a single domain and tested in five unseen domains. Moreover, a single-source\nmass detection training pipeline is designed to improve the domain\ngeneralization without requiring images from the new domain. The results show\nthat our workflow generalizes better than state-of-the-art transfer\nlearning-based approaches in four out of five domains while reducing the domain\nshift caused by the different acquisition protocols and scanner manufacturers.\nSubsequently, an extensive analysis is performed to identify the covariate\nshifts with bigger effects on the detection performance, such as due to\ndifferences in patient age, breast density, mass size, and mass malignancy.\nUltimately, this comprehensive study provides key insights and best practices\nfor future research on domain generalization in deep learning-based breast\ncancer detection.\n","authors":["Lidia Garrucho","Kaisar Kushibar","Socayna Jouide","Oliver Diaz","Laura Igual","Karim Lekadir"],"pdf_url":"https://arxiv.org/pdf/2201.11620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.00725v4","updated":"2023-01-24T16:17:47Z","published":"2021-12-01T18:59:54Z","title":"The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from\n  a Single Image","summary":"  What can neural networks learn about the visual world when provided with only\na single image as input? While any image obviously cannot contain the\nmultitudes of all existing objects, scenes and lighting conditions - within the\nspace of all 256^(3x224x224) possible 224-sized square images, it might still\nprovide a strong prior for natural images. To analyze this `augmented image\nprior' hypothesis, we develop a simple framework for training neural networks\nfrom scratch using a single image and augmentations using knowledge\ndistillation from a supervised pretrained teacher. With this, we find the\nanswer to the above question to be: `surprisingly, a lot'. In quantitative\nterms, we find accuracies of 94%/74% on CIFAR-10/100, 69% on ImageNet, and by\nextending this method to video and audio, 51% on Kinetics-400 and 84% on\nSpeechCommands. In extensive analyses spanning 13 datasets, we disentangle the\neffect of augmentations, choice of data and network architectures and also\nprovide qualitative evaluations that include lucid `panda neurons' in networks\nthat have never even seen one.\n","authors":["Yuki M. Asano","Aaqib Saeed"],"pdf_url":"https://arxiv.org/pdf/2112.00725v4.pdf","comment":"Accepted at ICLR'23. Webpage:\n  https://single-image-distill.github.io/, code:\n  https://github.com/yukimasano/single-img-extrapolating"},{"id":"http://arxiv.org/abs/2209.09809v2","updated":"2023-01-24T16:15:33Z","published":"2022-09-20T15:57:12Z","title":"High-resolution synthesis of high-density breast mammograms: Application\n  to improved fairness in deep learning based mass detection","summary":"  Computer-aided detection systems based on deep learning have shown good\nperformance in breast cancer detection. However, high-density breasts show\npoorer detection performance since dense tissues can mask or even simulate\nmasses. Therefore, the sensitivity of mammography for breast cancer detection\ncan be reduced by more than 20% in dense breasts. Additionally, extremely dense\ncases reported an increased risk of cancer compared to low-density breasts.\nThis study aims to improve the mass detection performance in highdensity\nbreasts using synthetic high-density full-field digital mammograms (FFDM) as\ndata augmentation during breast mass detection model training. To this end, a\ntotal of five cycle-consistent GAN (CycleGAN) models using three FFDM datasets\nwere trained for low-to-high-density image translation in highresolution\nmammograms. The training images were split by breast density BIRADS categories,\nbeing BI-RADS A almost entirely fatty and BI-RADS D extremely dense breasts.\nOur results showed that the proposed data augmentation technique improved the\nsensitivity and precision of mass detection in models trained with small\ndatasets and improved the domain generalization of the models trained with\nlarge databases. In addition, the clinical realism of the synthetic images was\nevaluated in a reader study involving two expert radiologists and one surgical\noncologist.\n","authors":["Lidia Garrucho","Kaisar Kushibar","Richard Osuala","Oliver Diaz","Alessandro Catanese","Javier del Riego","Maciej Bobowicz","Fredrik Strand","Laura Igual","Karim Lekadir"],"pdf_url":"https://arxiv.org/pdf/2209.09809v2.pdf","comment":"9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2301.10100v1","updated":"2023-01-24T16:10:08Z","published":"2023-01-24T16:10:08Z","title":"Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation","summary":"  Semantic segmentation of point clouds in autonomous driving datasets requires\ntechniques that can process large numbers of points over large field of views.\nToday, most deep networks designed for this task exploit 3D sparse convolutions\nto reduce memory and computational loads. The best methods then further exploit\nspecificities of rotating lidar sampling patterns to further improve the\nperformance, e.g., cylindrical voxels, or range images (for feature fusion from\nmultiple point cloud representations). In contrast, we show that one can build\na well-performing point-based backbone free of these specialized tools. This\nbackbone, WaffleIron, relies heavily on generic MLPs and dense 2D convolutions,\nmaking it easy to implement, and contains just a few parameters easy to tune.\nDespite its simplicity, our experiments on SemanticKITTI and nuScenes show that\nWaffleIron competes with the best methods designed specifically for these\nautonomous driving datasets. Hence, WaffleIron is a strong, easy-to-implement,\nbaseline for semantic segmentation of sparse outdoor point clouds.\n","authors":["Gilles Puy","Alexandre Boulch","Renaud Marlet"],"pdf_url":"https://arxiv.org/pdf/2301.10100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10092v1","updated":"2023-01-24T15:59:07Z","published":"2023-01-24T15:59:07Z","title":"Model soups to increase inference without increasing compute time","summary":"  In this paper, we compare Model Soups performances on three different models\n(ResNet, ViT and EfficientNet) using three Soup Recipes (Greedy Soup Sorted,\nGreedy Soup Random and Uniform soup) from arXiv:2203.05482, and reproduce the\nresults of the authors. We then introduce a new Soup Recipe called Pruned Soup.\nResults from the soups were better than the best individual model for the\npre-trained vision transformer, but were much worst for the ResNet and the\nEfficientNet. Our pruned soup performed better than the uniform and greedy\nsoups presented in the original paper. We also discuss the limitations of\nweight-averaging that were found during the experiments. The code for our model\nsoup library and the experiments with different models can be found here:\nhttps://github.com/milo-sobral/ModelSoup\n","authors":["Charles Dansereau","Milo Sobral","Maninder Bhogal","Mehdi Zalai"],"pdf_url":"https://arxiv.org/pdf/2301.10092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10908v2","updated":"2023-01-24T15:48:04Z","published":"2022-11-20T08:58:34Z","title":"ESTAS: Effective and Stable Trojan Attacks in Self-supervised Encoders\n  with One Target Unlabelled Sample","summary":"  Emerging self-supervised learning (SSL) has become a popular image\nrepresentation encoding method to obviate the reliance on labeled data and\nlearn rich representations from large-scale, ubiquitous unlabelled data. Then\none can train a downstream classifier on top of the pre-trained SSL image\nencoder with few or no labeled downstream data. Although extensive works show\nthat SSL has achieved remarkable and competitive performance on different\ndownstream tasks, its security concerns, e.g, Trojan attacks in SSL encoders,\nare still not well-studied. In this work, we present a novel Trojan Attack\nmethod, denoted by ESTAS, that can enable an effective and stable attack in SSL\nencoders with only one target unlabeled sample. In particular, we propose\nconsistent trigger poisoning and cascade optimization in ESTAS to improve\nattack efficacy and model accuracy, and eliminate the expensive target-class\ndata sample extraction from large-scale disordered unlabelled data. Our\nsubstantial experiments on multiple datasets show that ESTAS stably achieves >\n99% attacks success rate (ASR) with one target-class sample. Compared to prior\nworks, ESTAS attains > 30% ASR increase and > 8.3% accuracy improvement on\naverage.\n","authors":["Jiaqi Xue","Qian Lou"],"pdf_url":"https://arxiv.org/pdf/2211.10908v2.pdf","comment":"10 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2210.09224v2","updated":"2023-01-24T15:46:41Z","published":"2022-10-17T16:19:53Z","title":"Self-Supervised Learning Through Efference Copies","summary":"  Self-supervised learning (SSL) methods aim to exploit the abundance of\nunlabelled data for machine learning (ML), however the underlying principles\nare often method-specific. An SSL framework derived from biological first\nprinciples of embodied learning could unify the various SSL methods, help\nelucidate learning in the brain, and possibly improve ML. SSL commonly\ntransforms each training datapoint into a pair of views, uses the knowledge of\nthis pairing as a positive (i.e. non-contrastive) self-supervisory sign, and\npotentially opposes it to unrelated, (i.e. contrastive) negative examples.\nHere, we show that this type of self-supervision is an incomplete\nimplementation of a concept from neuroscience, the Efference Copy (EC).\nSpecifically, the brain also transforms the environment through efference, i.e.\nmotor commands, however it sends to itself an EC of the full commands, i.e.\nmore than a mere SSL sign. In addition, its action representations are likely\negocentric. From such a principled foundation we formally recover and extend\nSSL methods such as SimCLR, BYOL, and ReLIC under a common theoretical\nframework, i.e. Self-supervision Through Efference Copies (S-TEC). Empirically,\nS-TEC restructures meaningfully the within- and between-class representations.\nThis manifests as improvement in recent strong SSL baselines in image\nclassification, segmentation, object detection, and in audio. These results\nhypothesize a testable positive influence from the brain's motor outputs onto\nits sensory representations.\n","authors":["Franz Scherr","Qinghai Guo","Timoleon Moraitis"],"pdf_url":"https://arxiv.org/pdf/2210.09224v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.10057v1","updated":"2023-01-24T15:02:44Z","published":"2023-01-24T15:02:44Z","title":"Planar Object Tracking via Weighted Optical Flow","summary":"  We propose WOFT -- a novel method for planar object tracking that estimates a\nfull 8 degrees-of-freedom pose, i.e. the homography w.r.t. a reference view.\nThe method uses a novel module that leverages dense optical flow and assigns a\nweight to each optical flow correspondence, estimating a homography by weighted\nleast squares in a fully differentiable manner. The trained module assigns zero\nweights to incorrect correspondences (outliers) in most cases, making the\nmethod robust and eliminating the need of the typically used non-differentiable\nrobust estimators like RANSAC. The proposed weighted optical flow tracker\n(WOFT) achieves state-of-the-art performance on two benchmarks, POT-210 and\nPOIC, tracking consistently well across a wide range of scenarios.\n","authors":["Jonas Serych","Jiri Matas"],"pdf_url":"https://arxiv.org/pdf/2301.10057v1.pdf","comment":"WACV 2023"},{"id":"http://arxiv.org/abs/2301.10056v1","updated":"2023-01-24T15:00:47Z","published":"2023-01-24T15:00:47Z","title":"Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from\n  Smartphone Cameras with Rolling Shutters and Movable Lenses","summary":"  Our research discovers how the rolling shutter and movable lens structures\nwidely found in smartphone cameras modulate structure-borne sounds onto camera\nimages, creating a point-of-view (POV) optical-acoustic side channel for\nacoustic eavesdropping. The movement of smartphone camera hardware leaks\nacoustic information because images unwittingly modulate ambient sound as\nimperceptible distortions. Our experiments find that the side channel is\nfurther amplified by intrinsic behaviors of Complementary\nmetal-oxide-semiconductor (CMOS) rolling shutters and movable lenses such as in\nOptical Image Stabilization (OIS) and Auto Focus (AF). Our paper characterizes\nthe limits of acoustic information leakage caused by structure-borne sound that\nperturbs the POV of smartphone cameras. In contrast with traditional\noptical-acoustic eavesdropping on vibrating objects, this side channel requires\nno line of sight and no object within the camera's field of view (images of a\nceiling suffice). Our experiments test the limits of this side channel with a\nnovel signal processing pipeline that extracts and recognizes the leaked\nacoustic information. Our evaluation with 10 smartphones on a spoken digit\ndataset reports 80.66%, 91.28%, and 99.67% accuracies on recognizing 10 spoken\ndigits, 20 speakers, and 2 genders respectively. We further systematically\ndiscuss the possible defense strategies and implementations. By modeling,\nmeasuring, and demonstrating the limits of acoustic eavesdropping from\nsmartphone camera image streams, our contributions explain the physics-based\ncausality and possible ways to reduce the threat on current and future devices.\n","authors":["Yan Long","Pirouz Naghavi","Blas Kojusner","Kevin Butler","Sara Rampazzi","Kevin Fu"],"pdf_url":"https://arxiv.org/pdf/2301.10056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.09076v3","updated":"2023-01-24T14:56:46Z","published":"2021-11-17T12:39:04Z","title":"To Trust or Not To Trust Prediction Scores for Membership Inference\n  Attacks","summary":"  Membership inference attacks (MIAs) aim to determine whether a specific\nsample was used to train a predictive model. Knowing this may indeed lead to a\nprivacy breach. Most MIAs, however, make use of the model's prediction scores -\nthe probability of each output given some input - following the intuition that\nthe trained model tends to behave differently on its training data. We argue\nthat this is a fallacy for many modern deep network architectures.\nConsequently, MIAs will miserably fail since overconfidence leads to high\nfalse-positive rates not only on known domains but also on out-of-distribution\ndata and implicitly acts as a defense against MIAs. Specifically, using\ngenerative adversarial networks, we are able to produce a potentially infinite\nnumber of samples falsely classified as part of the training data. In other\nwords, the threat of MIAs is overestimated, and less information is leaked than\npreviously assumed. Moreover, there is actually a trade-off between the\noverconfidence of models and their susceptibility to MIAs: the more classifiers\nknow when they do not know, making low confidence predictions, the more they\nreveal the training data.\n","authors":["Dominik Hintersdorf","Lukas Struppek","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2111.09076v3.pdf","comment":"15 pages, 8 figures, 10 tables"},{"id":"http://arxiv.org/abs/2301.10052v1","updated":"2023-01-24T14:52:54Z","published":"2023-01-24T14:52:54Z","title":"Event Detection in Football using Graph Convolutional Networks","summary":"  The massive growth of data collection in sports has opened numerous avenues\nfor professional teams and media houses to gain insights from this data. The\ndata collected includes per frame player and ball trajectories, and event\nannotations such as passes, fouls, cards, goals, etc. Graph Convolutional\nNetworks (GCNs) have recently been employed to process this highly unstructured\ntracking data which can be otherwise difficult to model because of lack of\nclarity on how to order players in a sequence and how to handle missing objects\nof interest. In this thesis, we focus on the goal of automatic event detection\nfrom football videos. We show how to model the players and the ball in each\nframe of the video sequence as a graph, and present the results for graph\nconvolutional layers and pooling methods that can be used to model the temporal\ncontext present around each action.\n","authors":["Aditya Sangram Singh Rana"],"pdf_url":"https://arxiv.org/pdf/2301.10052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10051v1","updated":"2023-01-24T14:50:40Z","published":"2023-01-24T14:50:40Z","title":"Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism","summary":"  The loss function for bounding box regression (BBR) is essential to object\ndetection. Its good definition will bring significant performance improvement\nto the model. Most existing works assume that the examples in the training data\nare high-quality and focus on strengthening the fitting ability of BBR loss. If\nwe blindly strengthen BBR on low-quality examples, it will jeopardize\nlocalization performance. Focal-EIoU v1 was proposed to solve this problem, but\ndue to its static focusing mechanism (FM), the potential of non-monotonic FM\nwas not fully exploited. Based on this idea, we propose an IoU-based loss with\na dynamic non-monotonic FM named Wise-IoU (WIoU). When WIoU is applied to the\nstate-of-the-art real-time detector YOLOv7, the AP-75 on the MS-COCO dataset is\nimproved from 53.03% to 54.50%.\n","authors":["Zanjia Tong","Yuhang Chen","Zewei Xu","Rong Yu"],"pdf_url":"https://arxiv.org/pdf/2301.10051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10048v1","updated":"2023-01-24T14:44:44Z","published":"2023-01-24T14:44:44Z","title":"Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting","summary":"  Transformers have been widely used for video processing owing to the\nmulti-head self attention (MHSA) mechanism. However, the MHSA mechanism\nencounters an intrinsic difficulty for video inpainting, since the features\nassociated with the corrupted regions are degraded and incur inaccurate self\nattention. This problem, termed query degradation, may be mitigated by first\ncompleting optical flows and then using the flows to guide the self attention,\nwhich was verified in our previous work - flow-guided transformer (FGT). We\nfurther exploit the flow guidance and propose FGT++ to pursue more effective\nand efficient video inpainting. First, we design a lightweight flow completion\nnetwork by using local aggregation and edge loss. Second, to address the query\ndegradation, we propose a flow guidance feature integration module, which uses\nthe motion discrepancy to enhance the features, together with a flow-guided\nfeature propagation module that warps the features according to the flows.\nThird, we decouple the transformer along the temporal and spatial dimensions,\nwhere flows are used to select the tokens through a temporally deformable MHSA\nmechanism, and global tokens are combined with the inner-window local tokens\nthrough a dual perspective MHSA mechanism. FGT++ is experimentally evaluated to\nbe outperforming the existing video inpainting networks qualitatively and\nquantitatively.\n","authors":["Kaidong Zhang","Jialun Peng","Jingjing Fu","Dong Liu"],"pdf_url":"https://arxiv.org/pdf/2301.10048v1.pdf","comment":"This manuscript is a journal extension of our ECCV 2022 paper\n  (arXiv:2208.06768)"},{"id":"http://arxiv.org/abs/2301.10047v1","updated":"2023-01-24T14:44:03Z","published":"2023-01-24T14:44:03Z","title":"DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion\n  Model","summary":"  Speech-driven gesture synthesis is a field of growing interest in virtual\nhuman creation. However, a critical challenge is the inherent intricate\none-to-many mapping between speech and gestures. Previous studies have explored\nand achieved significant progress with generative models. Notwithstanding, most\nsynthetic gestures are still vastly less natural. This paper presents\nDiffMotion, a novel speech-driven gesture synthesis architecture based on\ndiffusion models. The model comprises an autoregressive temporal encoder and a\ndenoising diffusion probability Module. The encoder extracts the temporal\ncontext of the speech input and historical gestures. The diffusion module\nlearns a parameterized Markov chain to gradually convert a simple distribution\ninto a complex distribution and generates the gestures according to the\naccompanied speech. Compared with baselines, objective and subjective\nevaluations confirm that our approach can produce natural and diverse\ngesticulation and demonstrate the benefits of diffusion-based models on\nspeech-driven gesture synthesis.\n","authors":["Fan Zhang","Naye Ji","Fuxing Gao","Yongping Li"],"pdf_url":"https://arxiv.org/pdf/2301.10047v1.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.10038v1","updated":"2023-01-24T14:28:05Z","published":"2023-01-24T14:28:05Z","title":"Progressive Meta-Pooling Learning for Lightweight Image Classification\n  Model","summary":"  Practical networks for edge devices adopt shallow depth and small\nconvolutional kernels to save memory and computational cost, which leads to a\nrestricted receptive field. Conventional efficient learning methods focus on\nlightweight convolution designs, ignoring the role of the receptive field in\nneural network design. In this paper, we propose the Meta-Pooling framework to\nmake the receptive field learnable for a lightweight network, which consists of\nparameterized pooling-based operations. Specifically, we introduce a\nparameterized spatial enhancer, which is composed of pooling operations to\nprovide versatile receptive fields for each layer of a lightweight model. Then,\nwe present a Progressive Meta-Pooling Learning (PMPL) strategy for the\nparameterized spatial enhancer to acquire a suitable receptive field size. The\nresults on the ImageNet dataset demonstrate that MobileNetV2 using Meta-Pooling\nachieves top1 accuracy of 74.6\\%, which outperforms MobileNetV2 by 2.3\\%.\n","authors":["Peijie Dong","Xin Niu","Zhiliang Tian","Lujun Li","Xiaodong Wang","Zimian Wei","Hengyue Pan","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2301.10038v1.pdf","comment":"5 pages, 2 figures, ICASSP23"},{"id":"http://arxiv.org/abs/2212.08479v2","updated":"2023-01-24T14:06:01Z","published":"2022-12-16T13:46:17Z","title":"Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR\n  Imaging","summary":"  In this work, we propose a novel image reconstruction framework that directly\nlearns a neural implicit representation in k-space for ECG-triggered\nnon-Cartesian Cardiac Magnetic Resonance Imaging (CMR). While existing methods\nbin acquired data from neighboring time points to reconstruct one phase of the\ncardiac motion, our framework allows for a continuous, binning-free, and\nsubject-specific k-space representation.We assign a unique coordinate that\nconsists of time, coil index, and frequency domain location to each sampled\nk-space point. We then learn the subject-specific mapping from these unique\ncoordinates to k-space intensities using a multi-layer perceptron with\nfrequency domain regularization. During inference, we obtain a complete k-space\nfor Cartesian coordinates and an arbitrary temporal resolution. A simple\ninverse Fourier transform recovers the image, eliminating the need for density\ncompensation and costly non-uniform Fourier transforms for non-Cartesian data.\nThis novel imaging framework was tested on 42 radially sampled datasets from 6\nsubjects. The proposed method outperforms other techniques qualitatively and\nquantitatively using data from four and one heartbeat(s) and 30 cardiac phases.\nOur results for one heartbeat reconstruction of 50 cardiac phases show improved\nartifact removal and spatio-temporal resolution, leveraging the potential for\nreal-time CMR.\n","authors":["Wenqi Huang","Hongwei Li","Jiazhen Pan","Gastao Cruz","Daniel Rueckert","Kerstin Hammernik"],"pdf_url":"https://arxiv.org/pdf/2212.08479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10008v1","updated":"2023-01-24T13:57:25Z","published":"2023-01-24T13:57:25Z","title":"Few-shot Font Generation by Learning Style Difference and Similarity","summary":"  Few-shot font generation (FFG) aims to preserve the underlying global\nstructure of the original character while generating target fonts by referring\nto a few samples. It has been applied to font library creation, a personalized\nsignature, and other scenarios. Existing FFG methods explicitly disentangle\ncontent and style of reference glyphs universally or component-wisely. However,\nthey ignore the difference between glyphs in different styles and the\nsimilarity of glyphs in the same style, which results in artifacts such as\nlocal distortions and style inconsistency. To address this issue, we propose a\nnovel font generation approach by learning the Difference between different\nstyles and the Similarity of the same style (DS-Font). We introduce contrastive\nlearning to consider the positive and negative relationship between styles.\nSpecifically, we propose a multi-layer style projector for style encoding and\nrealize a distinctive style representation via our proposed Cluster-level\nContrastive Style (CCS) loss. In addition, we design a multi-task patch\ndiscriminator, which comprehensively considers different areas of the image and\nensures that each style can be distinguished independently. We conduct\nqualitative and quantitative evaluations comprehensively to demonstrate that\nour approach achieves significantly better results than state-of-the-art\nmethods.\n","authors":["Xiao He","Mingrui Zhu","Nannan Wang","Xinbo Gao","Heng Yang"],"pdf_url":"https://arxiv.org/pdf/2301.10008v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2301.09964v1","updated":"2023-01-24T12:53:06Z","published":"2023-01-24T12:53:06Z","title":"Uncertainty-Aware Distillation for Semi-Supervised Few-Shot\n  Class-Incremental Learning","summary":"  Given a model well-trained with a large-scale base dataset, Few-Shot\nClass-Incremental Learning (FSCIL) aims at incrementally learning novel classes\nfrom a few labeled samples by avoiding overfitting, without catastrophically\nforgetting all encountered classes previously. Currently, semi-supervised\nlearning technique that harnesses freely-available unlabeled data to compensate\nfor limited labeled data can boost the performance in numerous vision tasks,\nwhich heuristically can be applied to tackle issues in FSCIL, i.e., the\nSemi-supervised FSCIL (Semi-FSCIL). So far, very limited work focuses on the\nSemi-FSCIL task, leaving the adaptability issue of semi-supervised learning to\nthe FSCIL task unresolved. In this paper, we focus on this adaptability issue\nand present a simple yet efficient Semi-FSCIL framework named Uncertainty-aware\nDistillation with Class-Equilibrium (UaD-CE), encompassing two modules UaD and\nCE. Specifically, when incorporating unlabeled data into each incremental\nsession, we introduce the CE module that employs a class-balanced self-training\nto avoid the gradual dominance of easy-to-classified classes on pseudo-label\ngeneration. To distill reliable knowledge from the reference model, we further\nimplement the UaD module that combines uncertainty-guided knowledge refinement\nwith adaptive distillation. Comprehensive experiments on three benchmark\ndatasets demonstrate that our method can boost the adaptability of unlabeled\ndata with the semi-supervised learning technique in FSCIL tasks.\n","authors":["Yawen Cui","Wanxia Deng","Haoyu Chen","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2301.09964v1.pdf","comment":"Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems"},{"id":"http://arxiv.org/abs/2301.08664v2","updated":"2023-01-24T11:04:47Z","published":"2023-01-20T16:30:44Z","title":"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","summary":"  The quality of the video stream is key to neural network-based video\nanalytics. However, low-quality video is inevitably collected by existing\nsurveillance systems because of poor quality cameras or over-compressed/pruned\nvideo streaming protocols, e.g., as a result of upstream bandwidth limit. To\naddress this issue, existing studies use quality enhancers (e.g., neural\nsuper-resolution) to improve the quality of videos (e.g., resolution) and\neventually ensure inference accuracy. Nevertheless, directly applying quality\nenhancers does not work in practice because it will introduce unacceptable\nlatency. In this paper, we present AccDecoder, a novel accelerated decoder for\nreal-time and neural-enhanced video analytics. AccDecoder can select a few\nframes adaptively via Deep Reinforcement Learning (DRL) to enhance the quality\nby neural super-resolution and then up-scale the unselected frames that\nreference them, which leads to 6-21% accuracy improvement. AccDecoder provides\nefficient inference capability via filtering important frames using DRL for\nDNN-based inference and reusing the results for the other frames via extracting\nthe reference relationship among frames and blocks, which results in a latency\nreduction of 20-80% than baselines.\n","authors":["Tingting Yuan","Liang Mi","Weijun Wang","Haipeng Dai","Xiaoming Fu"],"pdf_url":"https://arxiv.org/pdf/2301.08664v2.pdf","comment":"Accepted by 2023 IEEE INFOCOM"},{"id":"http://arxiv.org/abs/2110.11205v3","updated":"2023-01-24T10:55:13Z","published":"2021-10-21T15:30:40Z","title":"Robustness through Data Augmentation Loss Consistency","summary":"  While deep learning through empirical risk minimization (ERM) has succeeded\nat achieving human-level performance at a variety of complex tasks, ERM is not\nrobust to distribution shifts or adversarial attacks. Synthetic data\naugmentation followed by empirical risk minimization (DA-ERM) is a simple and\nwidely used solution to improve robustness in ERM. In addition, consistency\nregularization can be applied to further improve the robustness of the model by\nforcing the representation of the original sample and the augmented one to be\nsimilar. However, existing consistency regularization methods are not\napplicable to covariant data augmentation, where the label in the augmented\nsample is dependent on the augmentation function. For example, dialog state\ncovaries with named entity when we augment data with a new named entity. In\nthis paper, we propose data augmented loss invariant regularization (DAIR), a\nsimple form of consistency regularization that is applied directly at the loss\nlevel rather than intermediate features, making it widely applicable to both\ninvariant and covariant data augmentation regardless of network architecture,\nproblem setup, and task. We apply DAIR to real-world learning problems\ninvolving covariant data augmentation: robust neural task-oriented dialog state\ntracking and robust visual question answering. We also apply DAIR to tasks\ninvolving invariant data augmentation: robust regression, robust classification\nagainst adversarial attacks, and robust ImageNet classification under\ndistribution shift. Our experiments show that DAIR consistently outperforms ERM\nand DA-ERM with little marginal computational cost and sets new\nstate-of-the-art results in several benchmarks involving covariant data\naugmentation. Our code of all experiments is available at:\nhttps://github.com/optimization-for-data-driven-science/DAIR.git\n","authors":["Tianjian Huang","Shaunak Halbe","Chinnadhurai Sankar","Pooyan Amini","Satwik Kottur","Alborz Geramifard","Meisam Razaviyayn","Ahmad Beirami"],"pdf_url":"https://arxiv.org/pdf/2110.11205v3.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2301.09914v1","updated":"2023-01-24T10:50:45Z","published":"2023-01-24T10:50:45Z","title":"Multimodal Interactive Lung Lesion Segmentation: A Framework for\n  Annotating PET/CT Images based on Physiological and Anatomical Cues","summary":"  Recently, deep learning enabled the accurate segmentation of various diseases\nin medical imaging. These performances, however, typically demand large amounts\nof manual voxel annotations. This tedious process for volumetric data becomes\nmore complex when not all required information is available in a single imaging\ndomain as is the case for PET/CT data. We propose a multimodal interactive\nsegmentation framework that mitigates these issues by combining anatomical and\nphysiological cues from PET/CT data. Our framework utilizes the geodesic\ndistance transform to represent the user annotations and we implement a novel\nellipsoid-based user simulation scheme during training. We further propose two\nannotation interfaces and conduct a user study to estimate their usability. We\nevaluated our model on the in-domain validation dataset and an unseen PET/CT\ndataset. We make our code publicly available:\nhttps://github.com/verena-hallitschke/pet-ct-annotate.\n","authors":["Verena Jasmin Hallitschke","Tobias Schlumberger","Philipp Kataliakos","Zdravko Marinov","Moon Kim","Lars Heiliger","Constantin Seibold","Jens Kleesiek","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2301.09914v1.pdf","comment":"Accepted at ISBI 2023; 5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.09906v1","updated":"2023-01-24T10:31:43Z","published":"2023-01-24T10:31:43Z","title":"Transfer Learning for Olfactory Object Detection","summary":"  We investigate the effect of style and category similarity in multiple\ndatasets used for object detection pretraining. We find that including an\nadditional stage of object-detection pretraining can increase the detection\nperformance considerably. While our experiments suggest that style similarities\nbetween pre-training and target datasets are less important than matching\ncategories, further experiments are needed to verify this hypothesis.\n","authors":["Mathias Zinnen","Prathmesh Madhu","Peter Bell","Andreas Maier","Vincent Christlein"],"pdf_url":"https://arxiv.org/pdf/2301.09906v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.09338v2","updated":"2023-01-24T10:18:24Z","published":"2023-01-23T09:42:49Z","title":"Employing similarity to highlight differences: On the impact of\n  anatomical assumptions in chest X-ray registration methods","summary":"  To facilitate both the detection and the interpretation of findings in chest\nX-rays, comparison with a previous image of the same patient is very valuable\nto radiologists. Today, the most common approach for deep learning methods to\nautomatically inspect chest X-rays disregards the patient history and\nclassifies only single images as normal or abnormal. Nevertheless, several\nmethods for assisting in the task of comparison through image registration have\nbeen proposed in the past. However, as we illustrate, they tend to miss\nspecific types of pathological changes like cardiomegaly and effusion. Due to\nassumptions on fixed anatomical structures or their measurements of\nregistration quality, they produce unnaturally deformed warp fields impacting\nvisualization of differences between moving and fixed images. We aim to\novercome these limitations, through a new paradigm based on individual rib pair\nsegmentation for anatomy penalized registration. Our method proves to be a\nnatural way to limit the folding percentage of the warp field to 1/6 of the\nstate of the art while increasing the overlap of ribs by more than 25%,\nimplying difference images showing pathological changes overlooked by other\nmethods. We develop an anatomically penalized convolutional multi-stage\nsolution on the National Institutes of Health (NIH) data set, starting from\nless than 25 fully and 50 partly labeled training images, employing sequential\ninstance memory segmentation with hole dropout, weak labeling, coarse-to-fine\nrefinement and Gaussian mixture model histogram matching. We statistically\nevaluate the benefits of our method and highlight the limits of currently used\nmetrics for registration of chest X-rays.\n","authors":["Astrid Berg","Eva Vandersmissen","Maria Wimmer","David Major","Theresa Neubauer","Dimitrios Lenis","Jeroen Cant","Annemiek Snoeckx","Katja Bühler"],"pdf_url":"https://arxiv.org/pdf/2301.09338v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09461v2","updated":"2023-01-24T09:58:36Z","published":"2023-01-23T14:46:43Z","title":"Study on the identification limits of craniofacial superimposition","summary":"  Craniofacial Superimposition involves the superimposition of an image of a\nskull with a number of ante-mortem face images of an individual and the\nanalysis of their morphological correspondence. Despite being used for one\ncentury, it is not yet a mature and fully accepted technique due to the absence\nof solid scientific approaches, significant reliability studies, and\ninternational standards. In this paper we present a comprehensive\nexperimentation on the limitations of Craniofacial Superimposition as a\nforensic identification technique. The study involves different experiments\nover more than 1 Million comparisons performed by a landmark-based automatic\n3D/2D superimposition method. The total sample analyzed consists of 320\nsubjects and 29 craniofacial landmarks.\n","authors":["Óscar Ibáñez","Enrique Bermejo","Andrea Valsecchi"],"pdf_url":"https://arxiv.org/pdf/2301.09461v2.pdf","comment":"7 pages, 4 figures. To be submitted to Scientific Reports"},{"id":"http://arxiv.org/abs/2301.09887v1","updated":"2023-01-24T09:46:47Z","published":"2023-01-24T09:46:47Z","title":"Deep learning-based method for segmenting epithelial layer of tubules in\n  histopathological images of testicular tissue","summary":"  There is growing concern that male reproduction is affected by environmental\nchemicals. One way to determine the adverse effect of environmental pollutants\nis to use wild animals as monitors and evaluate testicular toxicity using\nhistopathology. Automated methods are necessary tools in the quantitative\nassessment of histopathology to overcome the subjectivity of manual evaluation\nand accelerate the process. We propose an automated method to process histology\nimages of testicular tissue. Segmenting the epithelial layer of the\nseminiferous tubule is a prerequisite for developing automated methods to\ndetect abnormalities in tissue. We suggest an encoder-decoder fully connected\nconvolutional neural network (F-CNN) model to segment the epithelial layer of\nthe seminiferous tubules in histological images. Using ResNet-34 modules in the\nencoder adds a shortcut mechanism to avoid the gradient vanishing and\naccelerate the network convergence. The squeeze & excitation (SE) attention\nblock is integrated into the encoding module improving the segmentation and\nlocalization of epithelium. We applied the proposed method for the 2-class\nproblem where the epithelial layer of the tubule is the target class. The\nf-score and IoU of the proposed method are 0.85 and 0.92. Although the proposed\nmethod is trained on a limited training set, it performs well on an independent\ndataset and outperforms other state-of-the-art methods. The pretrained\nResNet-34 in the encoder and attention block suggested in the decoder result in\nbetter segmentation and generalization. The proposed method can be applied to\ntesticular tissue images from any mammalian species and can be used as the\nfirst part of a fully automated testicular tissue processing pipeline. The\ndataset and codes are publicly available on GitHub.\n","authors":["Azadeh Fakhrzadeh","Pouya Karimian","Mahsa Meyari","Cris L. Luengo Hendriks","Lena Holm","Christian Sonne","Rune Dietz","Ellinor Spörndly-Nees"],"pdf_url":"https://arxiv.org/pdf/2301.09887v1.pdf","comment":"submitted to Journal of Medical Imaging, 16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.09879v1","updated":"2023-01-24T09:36:39Z","published":"2023-01-24T09:36:39Z","title":"Data Augmentation Alone Can Improve Adversarial Training","summary":"  Adversarial training suffers from the issue of robust overfitting, which\nseriously impairs its generalization performance. Data augmentation, which is\neffective at preventing overfitting in standard training, has been observed by\nmany previous works to be ineffective in mitigating overfitting in adversarial\ntraining. This work proves that, contrary to previous findings, data\naugmentation alone can significantly boost accuracy and robustness in\nadversarial training. We find that the hardness and the diversity of data\naugmentation are important factors in combating robust overfitting. In general,\ndiversity can improve both accuracy and robustness, while hardness can boost\nrobustness at the cost of accuracy within a certain limit and degrade them both\nover that limit. To mitigate robust overfitting, we first propose a new crop\ntransformation, Cropshift, which has improved diversity compared to the\nconventional one (Padcrop). We then propose a new data augmentation scheme,\nbased on Cropshift, with much improved diversity and well-balanced hardness.\nEmpirically, our augmentation method achieves the state-of-the-art accuracy and\nrobustness for data augmentations in adversarial training. Furthermore, when\ncombined with weight averaging it matches, or even exceeds, the performance of\nthe best contemporary regularization methods for alleviating robust\noverfitting. Code is available at:\nhttps://github.com/TreeLLi/DA-Alone-Improves-AT.\n","authors":["Lin Li","Michael Spratling"],"pdf_url":"https://arxiv.org/pdf/2301.09879v1.pdf","comment":"published at conference ICLR2023"},{"id":"http://arxiv.org/abs/2301.09878v1","updated":"2023-01-24T09:35:43Z","published":"2023-01-24T09:35:43Z","title":"ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition","summary":"  The Odeuropa Challenge on Olfactory Object Recognition aims to foster the\ndevelopment of object detection in the visual arts and to promote an olfactory\nperspective on digital heritage. Object detection in historical artworks is\nparticularly challenging due to varying styles and artistic periods. Moreover,\nthe task is complicated due to the particularity and historical variance of\npredefined target objects, which exhibit a large intra-class variance, and the\nlong tail distribution of the dataset labels, with some objects having only\nvery few training examples. These challenges should encourage participants to\ncreate innovative approaches using domain adaptation or few-shot learning. We\nprovide a dataset of 2647 artworks annotated with 20 120 tightly fit bounding\nboxes that are split into a training and validation set (public). A test set\ncontaining 1140 artworks and 15 480 annotations is kept private for the\nchallenge evaluation.\n","authors":["Mathias Zinnen","Prathmesh Madhu","Ronak Kosti","Peter Bell","Andreas Maier","Vincent Christlein"],"pdf_url":"https://arxiv.org/pdf/2301.09878v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2202.07993v2","updated":"2023-01-24T09:33:37Z","published":"2022-02-16T11:13:37Z","title":"Planckian Jitter: countering the color-crippling effects of color jitter\n  on self-supervised training","summary":"  Several recent works on self-supervised learning are trained by mapping\ndifferent augmentations of the same image to the same feature representation.\nThe data augmentations used are of crucial importance to the quality of learned\nfeature representations. In this paper, we analyze how the color jitter\ntraditionally used in data augmentation negatively impacts the quality of the\ncolor features in learned feature representations. To address this problem, we\npropose a more realistic, physics-based color data augmentation - which we call\nPlanckian Jitter - that creates realistic variations in chromaticity and\nproduces a model robust to illumination changes that can be commonly observed\nin real life, while maintaining the ability to discriminate image content based\non color information. Experiments confirm that such a representation is\ncomplementary to the representations learned with the currently-used color\njitter augmentation and that a simple concatenation leads to significant\nperformance gains on a wide range of downstream datasets. In addition, we\npresent a color sensitivity analysis that documents the impact of different\ntraining methods on model neurons and shows that the performance of the learned\nfeatures is robust with respect to illuminant variations.\n","authors":["Simone Zini","Alex Gomez-Villa","Marco Buzzelli","Bartłomiej Twardowski","Andrew D. Bagdanov","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2202.07993v2.pdf","comment":"Accepted at Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2301.09869v1","updated":"2023-01-24T09:09:35Z","published":"2023-01-24T09:09:35Z","title":"Image Super-Resolution using Efficient Striped Window Transformer","summary":"  Recently, transformer-based methods have made impressive progress in\nsingle-image super-resolu-tion (SR). However, these methods are difficult to\napply to lightweight SR (LSR) due to the challenge of balancing model\nperformance and complexity. In this paper, we propose an efficient striped\nwindow transformer (ESWT). ESWT consists of efficient transformation layers\n(ETLs), allowing a clean structure and avoiding redundant operations. Moreover,\nwe designed a striped window mechanism to obtain a more efficient ESWT in\nmodeling long-term dependencies. To further exploit the potential of the\ntransformer, we propose a novel flexible window training strategy. Without any\nadditional cost, this strategy can further improve the performance of ESWT.\nExtensive experiments show that the proposed method outperforms\nstate-of-the-art transformer-based LSR methods with fewer parameters, faster\ninference, smaller FLOPs, and less memory consumption, achieving a better\ntrade-off between model performance and complexity.\n","authors":["Jinpeng Shi","Hui Li","Tianle Liu","Yulong Liu","Mingjian Zhang","Jinchen Zhu","Ling Zheng","Shizhuang Weng"],"pdf_url":"https://arxiv.org/pdf/2301.09869v1.pdf","comment":"SOTA lightweight super-resolution transformer. 9 pages, 13 figures\n  and tables. The Code is available at\n  https://github.com/Fried-Rice-Lab/FriedRiceLab"},{"id":"http://arxiv.org/abs/2203.15058v2","updated":"2023-01-24T09:07:27Z","published":"2022-03-28T19:57:14Z","title":"A distribution-dependent Mumford-Shah model for unsupervised\n  hyperspectral image segmentation","summary":"  Hyperspectral images provide a rich representation of the underlying spectrum\nfor each pixel, allowing for a pixel-wise classification/segmentation into\ndifferent classes. As the acquisition of labeled training data is very\ntime-consuming, unsupervised methods become crucial in hyperspectral image\nanalysis. The spectral variability and noise in hyperspectral data make this\ntask very challenging and define special requirements for such methods.\n  Here, we present a novel unsupervised hyperspectral segmentation framework.\nIt starts with a denoising and dimensionality reduction step by the\nwell-established Minimum Noise Fraction (MNF) transform. Then, the Mumford-Shah\n(MS) segmentation functional is applied to segment the data. We equipped the MS\nfunctional with a novel robust distribution-dependent indicator function\ndesigned to handle the characteristic challenges of hyperspectral data. To\noptimize our objective function with respect to the parameters for which no\nclosed form solution is available, we propose an efficient fixed point\niteration scheme. Numerical experiments on four public benchmark datasets show\nthat our method produces competitive results, which outperform three\nstate-of-the-art methods substantially on three of these datasets.\n","authors":["Jan-Christopher Cohrs","Chandrajit Bajaj","Benjamin Berkels"],"pdf_url":"https://arxiv.org/pdf/2203.15058v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09213v2","updated":"2023-01-24T08:52:34Z","published":"2023-01-22T21:59:38Z","title":"FRAME: Fast and Robust Autonomous 3D point cloud Map-merging for\n  Egocentric multi-robot exploration","summary":"  This article presents a 3D point cloud map-merging framework for egocentric\nheterogeneous multi-robot exploration, based on overlap detection and\nalignment, that is independent of a manual initial guess or prior knowledge of\nthe robots' poses. The novel proposed solution utilizes state-of-the-art place\nrecognition learned descriptors, that through the framework's main pipeline,\noffer a fast and robust region overlap estimation, hence eliminating the need\nfor the time-consuming global feature extraction and feature matching process\nthat is typically used in 3D map integration. The region overlap estimation\nprovides a homogeneous rigid transform that is applied as an initial condition\nin the point cloud registration algorithm Fast-GICP, which provides the final\nand refined alignment. The efficacy of the proposed framework is experimentally\nevaluated based on multiple field multi-robot exploration missions in\nunderground environments, where both ground and aerial robots are deployed,\nwith different sensor configurations.\n","authors":["Nikolaos Stathoulopoulos","Anton Koval","Ali-akbar Agha-mohammadi","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2301.09213v2.pdf","comment":"to be published"},{"id":"http://arxiv.org/abs/2301.09858v1","updated":"2023-01-24T08:30:14Z","published":"2023-01-24T08:30:14Z","title":"PowerQuant: Automorphism Search for Non-Uniform Quantization","summary":"  Deep neural networks (DNNs) are nowadays ubiquitous in many domains such as\ncomputer vision. However, due to their high latency, the deployment of DNNs\nhinges on the development of compression techniques such as quantization which\nconsists in lowering the number of bits used to encode the weights and\nactivations. Growing concerns for privacy and security have motivated the\ndevelopment of data-free techniques, at the expanse of accuracy. In this paper,\nwe identity the uniformity of the quantization operator as a limitation of\nexisting approaches, and propose a data-free non-uniform method. More\nspecifically, we argue that to be readily usable without dedicated hardware and\nimplementation, non-uniform quantization shall not change the nature of the\nmathematical operations performed by the DNN. This leads to search among the\ncontinuous automorphisms of $(\\mathbb{R}_+^*,\\times)$, which boils down to the\npower functions defined by their exponent. To find this parameter, we propose\nto optimize the reconstruction error of each layer: in particular, we show that\nthis procedure is locally convex and admits a unique solution. At inference\ntime, we show that our approach, dubbed PowerQuant, only require simple\nmodifications in the quantized DNN activation functions. As such, with only\nnegligible overhead, it significantly outperforms existing methods in a variety\nof configurations.\n","authors":["Edouard Yvinec","Arnaud Dapogny","Matthieu Cord","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2301.09858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09850v1","updated":"2023-01-24T07:49:04Z","published":"2023-01-24T07:49:04Z","title":"RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking\n  Distillation from Zero-cost Proxies","summary":"  Neural architecture search (NAS) has made tremendous progress in the\nautomatic design of effective neural network structures but suffers from a\nheavy computational burden. One-shot NAS significantly alleviates the burden\nthrough weight sharing and improves computational efficiency. Zero-shot NAS\nfurther reduces the cost by predicting the performance of the network from its\ninitial state, which conducts no training. Both methods aim to distinguish\nbetween \"good\" and \"bad\" architectures, i.e., ranking consistency of predicted\nand true performance. In this paper, we propose Ranking Distillation one-shot\nNAS (RD-NAS) to enhance ranking consistency, which utilizes zero-cost proxies\nas the cheap teacher and adopts the margin ranking loss to distill the ranking\nknowledge. Specifically, we propose a margin subnet sampler to distill the\nranking knowledge from zero-shot NAS to one-shot NAS by introducing Group\ndistance as margin. Our evaluation of the NAS-Bench-201 and ResNet-based search\nspace demonstrates that RD-NAS achieve 10.7\\% and 9.65\\% improvements in\nranking ability, respectively. Our codes are available at\nhttps://github.com/pprp/CVPR2022-NAS-competition-Track1-3th-solution\n","authors":["Peijie Dong","Xin Niu","Lujun Li","Zhiliang Tian","Xiaodong Wang","Zimian Wei","Hengyue Pan","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2301.09850v1.pdf","comment":"6 pages, 2 figures, 4 tables, ICASSP 2023"},{"id":"http://arxiv.org/abs/2201.06268v3","updated":"2023-01-24T07:42:08Z","published":"2022-01-17T08:20:09Z","title":"Continual Transformers: Redundancy-Free Attention for Online Inference","summary":"  Transformers in their common form are inherently limited to operate on whole\ntoken sequences rather than on one token at a time. Consequently, their use\nduring online inference on time-series data entails considerable redundancy due\nto the overlap in successive token sequences. In this work, we propose novel\nformulations of the Scaled Dot-Product Attention, which enable Transformers to\nperform efficient online token-by-token inference on a continual input stream.\nImportantly, our modifications are purely to the order of computations, while\nthe outputs and learned weights are identical to those of the original\nTransformer Encoder. We validate our Continual Transformer Encoder with\nexperiments on the THUMOS14, TVSeries and GTZAN datasets with remarkable\nresults: Our Continual one- and two-block architectures reduce the floating\npoint operations per prediction by up to 63x and 2.6x, respectively, while\nretaining predictive performance.\n","authors":["Lukas Hedegaard","Arian Bakhtiarnia","Alexandros Iosifidis"],"pdf_url":"https://arxiv.org/pdf/2201.06268v3.pdf","comment":"16 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2212.10699v2","updated":"2023-01-24T07:23:55Z","published":"2022-12-21T00:20:01Z","title":"PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields","summary":"  Recent advances in neural radiance fields have enabled the high-fidelity 3D\nreconstruction of complex scenes for novel view synthesis. However, it remains\nunderexplored how the appearance of such representations can be efficiently\nedited while maintaining photorealism.\n  In this work, we present PaletteNeRF, a novel method for photorealistic\nappearance editing of neural radiance fields (NeRF) based on 3D color\ndecomposition. Our method decomposes the appearance of each 3D point into a\nlinear combination of palette-based bases (i.e., 3D segmentations defined by a\ngroup of NeRF-type functions) that are shared across the scene. While our\npalette-based bases are view-independent, we also predict a view-dependent\nfunction to capture the color residual (e.g., specular shading). During\ntraining, we jointly optimize the basis functions and the color palettes, and\nwe also introduce novel regularizers to encourage the spatial coherence of the\ndecomposition.\n  Our method allows users to efficiently edit the appearance of the 3D scene by\nmodifying the color palettes. We also extend our framework with compressed\nsemantic features for semantic-aware appearance editing. We demonstrate that\nour technique is superior to baseline methods both quantitatively and\nqualitatively for appearance editing of complex real-world scenes.\n","authors":["Zhengfei Kuang","Fujun Luan","Sai Bi","Zhixin Shu","Gordon Wetzstein","Kalyan Sunkavalli"],"pdf_url":"https://arxiv.org/pdf/2212.10699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11300v2","updated":"2023-01-24T05:57:03Z","published":"2022-08-24T04:53:32Z","title":"E-NeRF: Neural Radiance Fields from a Moving Event Camera","summary":"  Estimating neural radiance fields (NeRFs) from \"ideal\" images has been\nextensively studied in the computer vision community. Most approaches assume\noptimal illumination and slow camera motion. These assumptions are often\nviolated in robotic applications, where images may contain motion blur, and the\nscene may not have suitable illumination. This can cause significant problems\nfor downstream tasks such as navigation, inspection, or visualization of the\nscene. To alleviate these problems, we present E-NeRF, the first method which\nestimates a volumetric scene representation in the form of a NeRF from a\nfast-moving event camera. Our method can recover NeRFs during very fast motion\nand in high-dynamic-range conditions where frame-based approaches fail. We show\nthat rendering high-quality frames is possible by only providing an event\nstream as input. Furthermore, by combining events and frames, we can estimate\nNeRFs of higher quality than state-of-the-art approaches under severe motion\nblur. We also show that combining events and frames can overcome failure cases\nof NeRF estimation in scenarios where only a few input views are available\nwithout requiring additional regularization.\n","authors":["Simon Klenk","Lukas Koestler","Davide Scaramuzza","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2208.11300v2.pdf","comment":"revised RAL version + added suppl. material"},{"id":"http://arxiv.org/abs/2110.06632v2","updated":"2023-01-24T05:22:45Z","published":"2021-10-13T10:52:45Z","title":"Unsupervised Contrastive Learning with Simple Transformation for 3D\n  Point Cloud Data","summary":"  Though a number of point cloud learning methods have been proposed to handle\nunordered points, most of them are supervised and require labels for training.\nBy contrast, unsupervised learning of point cloud data has received much less\nattention to date. In this paper, we propose a simple yet effective approach\nfor unsupervised point cloud learning. In particular, we identify a very useful\ntransformation which generates a good contrastive version of an original point\ncloud. They make up a pair. After going through a shared encoder and a shared\nhead network, the consistency between the output representations are maximized\nwith introducing two variants of contrastive losses to respectively facilitate\ndownstream classification and segmentation. To demonstrate the efficacy of our\nmethod, we conduct experiments on three downstream tasks which are 3D object\nclassification (on ModelNet40 and ModelNet10), shape part segmentation (on\nShapeNet Part dataset) as well as scene segmentation (on S3DIS). Comprehensive\nresults show that our unsupervised contrastive representation learning enables\nimpressive outcomes in object classification and semantic segmentation. It\ngenerally outperforms current unsupervised methods, and even achieves\ncomparable performance to supervised methods. Our source codes will be made\npublicly available.\n","authors":["Jincen Jiang","Xuequan Lu","Wanli Ouyang","Meili Wang"],"pdf_url":"https://arxiv.org/pdf/2110.06632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15076v3","updated":"2023-01-24T04:55:36Z","published":"2022-09-29T19:54:13Z","title":"3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical\n  Transformer for Medical Image Segmentation","summary":"  The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art\nperformances on several 3D volumetric data benchmarks, including 3D medical\nimage segmentation. Hierarchical transformers (e.g., Swin Transformers)\nreintroduced several ConvNet priors and further enhanced the practical\nviability of adapting volumetric segmentation in 3D medical datasets. The\neffectiveness of hybrid approaches is largely credited to the large receptive\nfield for non-local self-attention and the large number of model parameters. In\nthis work, we propose a lightweight volumetric ConvNet, termed 3D UX-Net, which\nadapts the hierarchical transformer using ConvNet modules for robust volumetric\nsegmentation. Specifically, we revisit volumetric depth-wise convolutions with\nlarge kernel size (e.g. starting from $7\\times7\\times7$) to enable the larger\nglobal receptive fields, inspired by Swin Transformer. We further substitute\nthe multi-layer perceptron (MLP) in Swin Transformer blocks with pointwise\ndepth convolutions and enhance model performances with fewer normalization and\nactivation layers, thus reducing the number of model parameters. 3D UX-Net\ncompetes favorably with current SOTA transformers (e.g. SwinUNETR) using three\nchallenging public datasets on volumetric brain and abdominal imaging: 1)\nMICCAI Challenge 2021 FLARE, 2) MICCAI Challenge 2021 FeTA, and 3) MICCAI\nChallenge 2022 AMOS. 3D UX-Net consistently outperforms SwinUNETR with\nimprovement from 0.929 to 0.938 Dice (FLARE2021) and 0.867 to 0.874 Dice\n(Feta2021). We further evaluate the transfer learning capability of 3D UX-Net\nwith AMOS2022 and demonstrates another improvement of $2.27\\%$ Dice (from 0.880\nto 0.900). The source code with our proposed model are available at\nhttps://github.com/MASILab/3DUX-Net.\n","authors":["Ho Hin Lee","Shunxing Bao","Yuankai Huo","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2209.15076v3.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2211.02239v2","updated":"2023-01-24T04:44:19Z","published":"2022-11-04T03:16:23Z","title":"Towards Asteroid Detection in Microlensing Surveys with Deep Learning","summary":"  Asteroids are an indelible part of most astronomical surveys though only a\nfew surveys are dedicated to their detection. Over the years, high cadence\nmicrolensing surveys have amassed several terabytes of data while scanning\nprimarily the Galactic Bulge and Magellanic Clouds for microlensing events and\nthus provide a treasure trove of opportunities for scientific data mining. In\nparticular, numerous asteroids have been observed by visual inspection of\nselected images. This paper presents novel deep learning-based solutions for\nthe recovery and discovery of asteroids in the microlensing data gathered by\nthe MOA project. Asteroid tracklets can be clearly seen by combining all the\nobservations on a given night and these tracklets inform the structure of the\ndataset. Known asteroids were identified within these composite images and used\nfor creating the labelled datasets required for supervised learning. Several\ncustom CNN models were developed to identify images with asteroid tracklets.\nModel ensembling was then employed to reduce the variance in the predictions as\nwell as to improve the generalisation error, achieving a recall of 97.67%.\nFurthermore, the YOLOv4 object detector was trained to localize asteroid\ntracklets, achieving a mean Average Precision (mAP) of 90.97%. These trained\nnetworks will be applied to 16 years of MOA archival data to find both known\nand unknown asteroids that have been observed by the survey over the years. The\nmethodologies developed can be adapted for use by other surveys for asteroid\nrecovery and discovery.\n","authors":["Preeti Cowan","Ian A. Bond","Napoleon H. Reyes"],"pdf_url":"https://arxiv.org/pdf/2211.02239v2.pdf","comment":"15 pages, 17 figures, to be published in Astronomy and Computing"},{"id":"http://arxiv.org/abs/2301.09799v1","updated":"2023-01-24T03:47:37Z","published":"2023-01-24T03:47:37Z","title":"LDMIC: Learning-based Distributed Multi-view Image Coding","summary":"  Multi-view image compression plays a critical role in 3D-related\napplications. Existing methods adopt a predictive coding architecture, which\nrequires joint encoding to compress the corresponding disparity as well as\nresidual information. This demands collaboration among cameras and enforces the\nepipolar geometric constraint between different views, which makes it\nchallenging to deploy these methods in distributed camera systems with randomly\noverlapping fields of view. Meanwhile, distributed source coding theory\nindicates that efficient data compression of correlated sources can be achieved\nby independent encoding and joint decoding, which motivates us to design a\nlearning-based distributed multi-view image coding (LDMIC) framework. With\nindependent encoders, LDMIC introduces a simple yet effective joint context\ntransfer module based on the cross-attention mechanism at the decoder to\neffectively capture the global inter-view correlations, which is insensitive to\nthe geometric relationships between images. Experimental results show that\nLDMIC significantly outperforms both traditional and learning-based MIC methods\nwhile enjoying fast encoding speed. Code will be released at\nhttps://github.com/Xinjie-Q/LDMIC.\n","authors":["Xinjie Zhang","Jiawei Shao","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.09799v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2208.08988v2","updated":"2023-01-24T03:33:28Z","published":"2022-08-18T17:59:41Z","title":"The 8-Point Algorithm as an Inductive Bias for Relative Pose Prediction\n  by ViTs","summary":"  We present a simple baseline for directly estimating the relative pose\n(rotation and translation, including scale) between two images. Deep methods\nhave recently shown strong progress but often require complex or multi-stage\narchitectures. We show that a handful of modifications can be applied to a\nVision Transformer (ViT) to bring its computations close to the Eight-Point\nAlgorithm. This inductive bias enables a simple method to be competitive in\nmultiple settings, often substantially improving over the state of the art with\nstrong performance gains in limited data regimes.\n","authors":["Chris Rockwell","Justin Johnson","David F. Fouhey"],"pdf_url":"https://arxiv.org/pdf/2208.08988v2.pdf","comment":"Accepted to 3DV 2022; Project Page:\n  https://crockwell.github.io/rel_pose/ Revision: Fixed Epipolar Lines in\n  Figure 3, Figure 10"},{"id":"http://arxiv.org/abs/2208.10531v2","updated":"2023-01-24T02:50:44Z","published":"2022-08-22T18:18:47Z","title":"RAIN: RegulArization on Input and Network for Black-Box Domain\n  Adaptation","summary":"  Source-Free domain adaptation transits the source-trained model towards\ntarget domain without exposing the source data, trying to dispel these concerns\nabout data privacy and security. However, this paradigm is still at risk of\ndata leakage due to adversarial attacks on the source model. Hence, the\nBlack-Box setting only allows to use the outputs of source model, but still\nsuffers from overfitting on the source domain more severely due to source\nmodel's unseen weights. In this paper, we propose a novel approach named RAIN\n(RegulArization on Input and Network) for Black-Box domain adaptation from both\ninput-level and network-level regularization. For the input-level, we design a\nnew data augmentation technique as Phase MixUp, which highlights task-relevant\nobjects in the interpolations, thus enhancing input-level regularization and\nclass consistency for target models. For network-level, we develop a Subnetwork\nDistillation mechanism to transfer knowledge from the target subnetwork to the\nfull target network via knowledge distillation, which thus alleviates\noverfitting on the source domain by learning diverse target representations.\nExtensive experiments show that our method achieves state-of-the-art\nperformance on several cross-domain benchmarks under both single- and\nmulti-source black-box domain adaptation.\n","authors":["Qucheng Peng","Zhengming Ding","Lingjuan Lyu","Lichao Sun","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2208.10531v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08975v3","updated":"2023-01-24T02:21:22Z","published":"2022-07-18T23:07:53Z","title":"Superficial White Matter Analysis: An Efficient Point-cloud-based Deep\n  Learning Framework with Supervised Contrastive Learning for Consistent\n  Tractography Parcellation across Populations and dMRI Acquisitions","summary":"  Diffusion MRI tractography is an advanced imaging technique that enables in\nvivo mapping of the brain's white matter connections. White matter parcellation\nclassifies tractography streamlines into clusters or anatomically meaningful\ntracts. It enables quantification and visualization of whole-brain\ntractography. Currently, most parcellation methods focus on the deep white\nmatter (DWM), whereas fewer methods address the superficial white matter (SWM)\ndue to its complexity. We propose a novel two-stage deep-learning-based\nframework, Superficial White Matter Analysis (SupWMA), that performs an\nefficient and consistent parcellation of 198 SWM clusters from whole-brain\ntractography. A point-cloud-based network is adapted to our SWM parcellation\ntask, and supervised contrastive learning enables more discriminative\nrepresentations between plausible streamlines and outliers for SWM. We train\nour model on a large-scale tractography dataset including streamline samples\nfrom labeled long- and medium-range (over 40 mm) SWM clusters and anatomically\nimplausible streamline samples, and we perform testing on six independently\nacquired datasets of different ages and health conditions (including neonates\nand patients with space-occupying brain tumors). Compared to several\nstate-of-the-art methods, SupWMA obtains highly consistent and accurate SWM\nparcellation results on all datasets, showing good generalization across the\nlifespan in health and disease. In addition, the computational speed of SupWMA\nis much faster than other methods.\n","authors":["Tengfei Xue","Fan Zhang","Chaoyi Zhang","Yuqian Chen","Yang Song","Alexandra J. Golby","Nikos Makris","Yogesh Rathi","Weidong Cai","Lauren J. O'Donnell"],"pdf_url":"https://arxiv.org/pdf/2207.08975v3.pdf","comment":"Accepted by Medical Image Analysis"},{"id":"http://arxiv.org/abs/2301.06678v2","updated":"2023-01-24T01:15:13Z","published":"2023-01-17T03:43:19Z","title":"Feature-based Image Matching for Identifying Individual Kākā","summary":"  This report investigates an unsupervised, feature-based image matching\npipeline for the novel application of identifying individual k\\=ak\\=a. Applied\nwith a similarity network for clustering, this addresses a weakness of current\nsupervised approaches to identifying individual birds which struggle to handle\nthe introduction of new individuals to the population. Our approach uses object\nlocalisation to locate k\\=ak\\=a within images and then extracts local features\nthat are invariant to rotation and scale. These features are matched between\nimages with nearest neighbour matching techniques and mismatch removal to\nproduce a similarity score for image match comparison. The results show that\nmatches obtained via the image matching pipeline achieve high accuracy of true\nmatches. We conclude that feature-based image matching could be used with a\nsimilarity network to provide a viable alternative to existing supervised\napproaches.\n","authors":["Fintan O'Sullivan","Kirita-Rose Escott","Rachael C. Shaw","Andrew Lensen"],"pdf_url":"https://arxiv.org/pdf/2301.06678v2.pdf","comment":"42 pages, honour's report from Victoria University of Wellington"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.10105v1","updated":"2023-01-24T16:16:51Z","published":"2023-01-24T16:16:51Z","title":"Does Search Engine Optimization come along with high-quality content? A\n  comparison between optimized and non-optimized health-related web pages","summary":"  Searching for medical information is both a common and important activity\nsince it influences decisions people make about their healthcare. Using search\nengine optimization (SEO), content producers seek to increase the visibility of\ntheir content. SEO is more likely to be practiced by commercially motivated\ncontent producers such as pharmaceutical companies than by non-commercial\nproviders such as governmental bodies. In this study, we ask whether content\nquality correlates with the presence or absence of SEO measures on a web page.\nWe conducted a user study in which N = 61 participants comprising laypeople as\nwell as experts in health information assessment evaluated health-related web\npages classified as either optimized or non-optimized. The subjects rated the\nexpertise of non-optimized web pages as higher than the expertise of optimized\npages, justifying their appraisal by the more competent and reputable\nappearance of non-optimized pages. In addition, comments about the website\noperators of the non-optimized pages were exclusively positive, while optimized\npages tended to receive positive as well as negative assessments. We found no\ndifferences between the ratings of laypeople and experts. Since non-optimized,\nbut high-quality content may be outranked by optimized content of lower\nquality, trusted sources should be prioritized in rankings.\n","authors":["Sebastian Schultheiß","Helena Häußler","Dirk Lewandowski"],"pdf_url":"https://arxiv.org/pdf/2301.10105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10086v1","updated":"2023-01-24T15:48:18Z","published":"2023-01-24T15:48:18Z","title":"How search engine marketing influences user knowledge gain: Development\n  and empirical testing of an information search behavior model","summary":"  People use search engines to find answers to questions related to their\nhealth, finances, or other socially relevant issues. However, most users are\nunaware that search results are considerably influenced by search engine\nmarketing (SEM). SEM measures are driven by commercial, political, or other\nmotives. Due to these motivations, two questions arise: What information\nquality is mediated through SEM? And how is collecting documents of different\nquality affecting user knowledge gain? Both questions are not considered by\nexisting models of information behavior. Hence, the doctoral research project\ndescribed in this paper aims to develop and empirically test an information\nsearch behavior model on the influences of SEM on user knowledge gain and\nthereby contribute to the search as learning body of research.\n","authors":["Sebastian Schultheiß"],"pdf_url":"https://arxiv.org/pdf/2301.10086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05767v5","updated":"2023-01-24T15:18:47Z","published":"2022-12-12T08:40:04Z","title":"Reasoning over Different Types of Knowledge Graphs: Static, Temporal and\n  Multi-Modal","summary":"  Knowledge graph reasoning (KGR), aiming to deduce new facts from existing\nfacts based on mined logic rules underlying knowledge graphs (KGs), has become\na fast-growing research direction. It has been proven to significantly benefit\nthe usage of KGs in many AI applications, such as question answering and\nrecommendation systems, etc. According to the graph types, the existing KGR\nmodels can be roughly divided into three categories, i.e., static models,\ntemporal models, and multi-modal models. The early works in this domain mainly\nfocus on static KGR and tend to directly apply general knowledge graph\nembedding models to the reasoning task. However, these models are not suitable\nfor more complex but practical tasks, such as inductive static KGR, temporal\nKGR, and multi-modal KGR. To this end, multiple works have been developed\nrecently, but no survey papers and open-source repositories comprehensively\nsummarize and discuss models in this important direction. To fill the gap, we\nconduct a survey for knowledge graph reasoning tracing from static to temporal\nand then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR\nmodels, and typical datasets are introduced and discussed consequently.\nMoreover, we discuss the challenges and potential opportunities. The\ncorresponding open-source repository is shared on GitHub:\nhttps://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.\n","authors":["Ke Liang","Lingyuan Meng","Meng Liu","Yue Liu","Wenxuan Tu","Siwei Wang","Sihang Zhou","Xinwang Liu","Fuchun Sun"],"pdf_url":"https://arxiv.org/pdf/2212.05767v5.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2112.03104v2","updated":"2023-01-24T11:19:27Z","published":"2021-11-22T11:02:35Z","title":"HTMOT : Hierarchical Topic Modelling Over Time","summary":"  Over the years, topic models have provided an efficient way of extracting\ninsights from text. However, while many models have been proposed, none are\nable to model topic temporality and hierarchy jointly. Modelling time provide\nmore precise topics by separating lexically close but temporally distinct\ntopics while modelling hierarchy provides a more detailed view of the content\nof a document corpus. In this study, we therefore propose a novel method,\nHTMOT, to perform Hierarchical Topic Modelling Over Time. We train HTMOT using\na new implementation of Gibbs sampling, which is more efficient. Specifically,\nwe show that only applying time modelling to deep sub-topics provides a way to\nextract specific stories or events while high level topics extract larger\nthemes in the corpus. Our results show that our training procedure is fast and\ncan extract accurate high-level topics and temporally precise sub-topics. We\nmeasured our model's performance using the Word Intrusion task and outlined\nsome limitations of this evaluation method, especially for hierarchical models.\nAs a case study, we focused on the various developments in the space industry\nin 2020.\n","authors":["Judicael Poumay","Ashwin Ittoo"],"pdf_url":"https://arxiv.org/pdf/2112.03104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05544v3","updated":"2023-01-24T10:39:05Z","published":"2023-01-13T13:41:20Z","title":"UserSimCRS: A User Simulation Toolkit for Evaluating Conversational\n  Recommender Systems","summary":"  We present an extensible user simulation toolkit to facilitate automatic\nevaluation of conversational recommender systems. It builds on an established\nagenda-based approach and extends it with several novel elements, including\nuser satisfaction prediction, persona and context modeling, and conditional\nnatural language generation. We showcase the toolkit with a pre-existing movie\nrecommender system and demonstrate its ability to simulate dialogues that mimic\nreal conversations, while requiring only a handful of manually annotated\ndialogues as training data.\n","authors":["Jafar Afzali","Aleksander Mark Drzewiecki","Krisztian Balog","Shuo Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.05544v3.pdf","comment":"Proceedings of the Sixteenth ACM International Conference on Web\n  Search and Data Mining"},{"id":"http://arxiv.org/abs/2301.08632v2","updated":"2023-01-24T10:29:43Z","published":"2023-01-20T15:28:09Z","title":"Generative Slate Recommendation with Reinforcement Learning","summary":"  Recent research has employed reinforcement learning (RL) algorithms to\noptimize long-term user engagement in recommender systems, thereby avoiding\ncommon pitfalls such as user boredom and filter bubbles. They capture the\nsequential and interactive nature of recommendations, and thus offer a\nprincipled way to deal with long-term rewards and avoid myopic behaviors.\nHowever, RL approaches are intractable in the slate recommendation scenario -\nwhere a list of items is recommended at each interaction turn - due to the\ncombinatorial action space. In that setting, an action corresponds to a slate\nthat may contain any combination of items.\n  While previous work has proposed well-chosen decompositions of actions so as\nto ensure tractability, these rely on restrictive and sometimes unrealistic\nassumptions. Instead, in this work we propose to encode slates in a continuous,\nlow-dimensional latent space learned by a variational auto-encoder. Then, the\nRL agent selects continuous actions in this latent space, which are ultimately\ndecoded into the corresponding slates. By doing so, we are able to (i) relax\nassumptions required by previous work, and (ii) improve the quality of the\naction selection by modeling full slates instead of independent items, in\nparticular by enabling diversity. Our experiments performed on a wide array of\nsimulated environments confirm the effectiveness of our generative modeling of\nslates over baselines in practical scenarios where the restrictive assumptions\nunderlying the baselines are lifted. Our findings suggest that representation\nlearning using generative models is a promising direction towards generalizable\nRL-based slate recommendation.\n","authors":["Romain Deffayet","Thibaut Thonet","Jean-Michel Renders","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2301.08632v2.pdf","comment":"WSDM 2023, 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.08062v2","updated":"2023-01-24T06:56:49Z","published":"2023-01-19T13:21:36Z","title":"New Metrics to Encourage Innovation and Diversity in Information\n  Retrieval Approaches","summary":"  In evaluation campaigns, participants often explore variations of popular,\nstate-of-the-art baselines as a low-risk strategy to achieve competitive\nresults. While effective, this can lead to local \"hill climbing\" rather than\nmore radical and innovative departure from standard methods. Moreover, if many\nparticipants build on similar baselines, the overall diversity of approaches\nconsidered may be limited. In this work, we propose a new class of IR\nevaluation metrics intended to promote greater diversity of approaches in\nevaluation campaigns. Whereas traditional IR metrics focus on user experience,\nour two \"innovation\" metrics instead reward exploration of more divergent,\nhigher-risk strategies finding relevant documents missed by other systems.\nExperiments on four TREC collections show that our metrics do change system\nrankings by rewarding systems that find such rare, relevant documents. This\nresult is further supported by a controlled, synthetic data experiment, and a\nqualitative analysis. In addition, we show that our metrics achieve higher\nevaluation stability and discriminative power than the standard metrics we\nmodify. To support reproducibility, we share our source code.\n","authors":["Mehmet Deniz Türkmen","Matthew Lease","Mucahid Kutlu"],"pdf_url":"https://arxiv.org/pdf/2301.08062v2.pdf","comment":"16 pages, 6 figures, to be published in ECIR 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.10230v1","updated":"2023-01-24T18:54:29Z","published":"2023-01-24T18:54:29Z","title":"Double Matching Under Complementary Preferences","summary":"  In this paper, we propose a new algorithm for addressing the problem of\nmatching markets with complementary preferences, where agents' preferences are\nunknown a priori and must be learned from data. The presence of complementary\npreferences can lead to instability in the matching process, making this\nproblem challenging to solve. To overcome this challenge, we formulate the\nproblem as a bandit learning framework and propose the Multi-agent Multi-type\nThompson Sampling (MMTS) algorithm. The algorithm combines the strengths of\nThompson Sampling for exploration with a double matching technique to achieve a\nstable matching outcome. Our theoretical analysis demonstrates the\neffectiveness of MMTS as it is able to achieve stability at every matching\nstep, satisfies the incentive-compatibility property, and has a sublinear\nBayesian regret over time. Our approach provides a useful method for addressing\ncomplementary preferences in real-world scenarios.\n","authors":["Yuantong Li","Guang Cheng","Xiaowu Dai"],"pdf_url":"https://arxiv.org/pdf/2301.10230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10226v1","updated":"2023-01-24T18:52:59Z","published":"2023-01-24T18:52:59Z","title":"A Watermark for Large Language Models","summary":"  Potential harms of large language models can be mitigated by watermarking\nmodel output, i.e., embedding signals into generated text that are invisible to\nhumans but algorithmically detectable from a short span of tokens. We propose a\nwatermarking framework for proprietary language models. The watermark can be\nembedded with negligible impact on text quality, and can be detected using an\nefficient open-source algorithm without access to the language model API or\nparameters. The watermark works by selecting a randomized set of whitelist\ntokens before a word is generated, and then softly promoting use of whitelist\ntokens during sampling. We propose a statistical test for detecting the\nwatermark with interpretable p-values, and derive an information-theoretic\nframework for analyzing the sensitivity of the watermark. We test the watermark\nusing a multi-billion parameter model from the Open Pretrained Transformer\n(OPT) family, and discuss robustness and security.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Jonathan Katz","Ian Miers","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2301.10226v1.pdf","comment":"12 pages in the main body. Code will be available at\n  github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2301.10222v1","updated":"2023-01-24T18:50:48Z","published":"2023-01-24T18:50:48Z","title":"RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in\n  Autonomous Driving","summary":"  Casting semantic segmentation of outdoor LiDAR point clouds as a 2D problem,\ne.g., via range projection, is an effective and popular approach. These\nprojection-based methods usually benefit from fast computations and, when\ncombined with techniques which use other point cloud representations, achieve\nstate-of-the-art results. Today, projection-based methods leverage 2D CNNs but\nrecent advances in computer vision show that vision transformers (ViTs) have\nachieved state-of-the-art results in many image-based benchmarks. In this work,\nwe question if projection-based methods for 3D semantic segmentation can\nbenefit from these latest improvements on ViTs. We answer positively but only\nafter combining them with three key ingredients: (a) ViTs are notoriously hard\nto train and require a lot of training data to learn powerful representations.\nBy preserving the same backbone architecture as for RGB images, we can exploit\nthe knowledge from long training on large image collections that are much\ncheaper to acquire and annotate than point clouds. We reach our best results\nwith pre-trained ViTs on large image datasets. (b) We compensate ViTs' lack of\ninductive bias by substituting a tailored convolutional stem for the classical\nlinear embedding layer. (c) We refine pixel-wise predictions with a\nconvolutional decoder and a skip connection from the convolutional stem to\ncombine low-level but fine-grained features of the the convolutional stem with\nthe high-level but coarse predictions of the ViT encoder. With these\ningredients, we show that our method, called RangeViT, outperforms existing\nprojection-based methods on nuScenes and SemanticKITTI. We provide the\nimplementation code at https://github.com/valeoai/rangevit.\n","authors":["Angelika Ando","Spyros Gidaris","Andrei Bursuc","Gilles Puy","Alexandre Boulch","Renaud Marlet"],"pdf_url":"https://arxiv.org/pdf/2301.10222v1.pdf","comment":"Code at https://github.com/valeoai/rangevit"},{"id":"http://arxiv.org/abs/2210.01078v3","updated":"2023-01-24T18:38:50Z","published":"2022-10-03T16:49:30Z","title":"Unsupervised Model Selection for Time-series Anomaly Detection","summary":"  Anomaly detection in time-series has a wide range of practical applications.\nWhile numerous anomaly detection methods have been proposed in the literature,\na recent survey concluded that no single method is the most accurate across\nvarious datasets. To make matters worse, anomaly labels are scarce and rarely\navailable in practice. The practical problem of selecting the most accurate\nmodel for a given dataset without labels has received little attention in the\nliterature. This paper answers this question i.e. Given an unlabeled dataset\nand a set of candidate anomaly detectors, how can we select the most accurate\nmodel? To this end, we identify three classes of surrogate (unsupervised)\nmetrics, namely, prediction error, model centrality, and performance on\ninjected synthetic anomalies, and show that some metrics are highly correlated\nwith standard supervised anomaly detection performance metrics such as the\n$F_1$ score, but to varying degrees. We formulate metric combination with\nmultiple imperfect surrogate metrics as a robust rank aggregation problem. We\nthen provide theoretical justification behind the proposed approach.\nLarge-scale experiments on multiple real-world datasets demonstrate that our\nproposed unsupervised approach is as effective as selecting the most accurate\nmodel based on partially labeled data.\n","authors":["Mononito Goswami","Cristian Challu","Laurent Callot","Lenon Minorics","Andrey Kan"],"pdf_url":"https://arxiv.org/pdf/2210.01078v3.pdf","comment":"Accepted at International Conference on Learning Representations\n  (ICLR) 2023 with a notable-top-25% recommendation. Reviewer, AC and author\n  discussion available at https://openreview.net/forum?id=gOZ_pKANaPW"},{"id":"http://arxiv.org/abs/2111.07911v3","updated":"2023-01-24T18:26:14Z","published":"2021-11-15T17:00:03Z","title":"On the Tradeoff between Energy, Precision, and Accuracy in Federated\n  Quantized Neural Networks","summary":"  Deploying federated learning (FL) over wireless networks with\nresource-constrained devices requires balancing between accuracy, energy\nefficiency, and precision. Prior art on FL often requires devices to train deep\nneural networks (DNNs) using a 32-bit precision level for data representation\nto improve accuracy. However, such algorithms are impractical for\nresource-constrained devices since DNNs could require execution of millions of\noperations. Thus, training DNNs with a high precision level incurs a high\nenergy cost for FL. In this paper, a quantized FL framework, that represents\ndata with a finite level of precision in both local training and uplink\ntransmission, is proposed. Here, the finite level of precision is captured\nthrough the use of quantized neural networks (QNNs) that quantize weights and\nactivations in fixed-precision format. In the considered FL model, each device\ntrains its QNN and transmits a quantized training result to the base station.\nEnergy models for the local training and the transmission with the quantization\nare rigorously derived. An energy minimization problem is formulated with\nrespect to the level of precision while ensuring convergence. To solve the\nproblem, we first analytically derive the FL convergence rate and use a line\nsearch method. Simulation results show that our FL framework can reduce energy\nconsumption by up to 53% compared to a standard FL model. The results also shed\nlight on the tradeoff between precision, energy, and accuracy in FL over\nwireless networks.\n","authors":["Minsu Kim","Walid Saad","Mohammad Mozaffari","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2111.07911v3.pdf","comment":"This paper is submitted to IEEE International Conference on\n  Communications 2022"},{"id":"http://arxiv.org/abs/2207.09387v2","updated":"2023-01-24T18:22:34Z","published":"2022-07-19T16:37:24Z","title":"Green, Quantized Federated Learning over Wireless Networks: An\n  Energy-Efficient Design","summary":"  In this paper, a green-quantized FL framework, which represents data with a\nfinite precision level in both local training and uplink transmission, is\nproposed. Here, the finite precision level is captured through the use of\nquantized neural networks (QNNs) that quantize weights and activations in\nfixed-precision format. In the considered FL model, each device trains its QNN\nand transmits a quantized training result to the base station. Energy models\nfor the local training and the transmission with quantization are rigorously\nderived. To minimize the energy consumption and the number of communication\nrounds simultaneously, a multi-objective optimization problem is formulated\nwith respect to the number of local iterations, the number of selected devices,\nand the precision levels for both local training and transmission while\nensuring convergence under a target accuracy constraint. To solve this problem,\nthe convergence rate of the proposed FL system is analytically derived with\nrespect to the system control variables. Then, the Pareto boundary of the\nproblem is characterized to provide efficient solutions using the normal\nboundary inspection method. Design insights on balancing the tradeoff between\nthe two objectives while achieving a target accuracy are drawn from using the\nNash bargaining solution and analyzing the derived convergence rate. Simulation\nresults show that the proposed FL framework can reduce energy consumption until\nconvergence by up to 70\\% compared to a baseline FL algorithm that represents\ndata with full precision without damaging the convergence rate.\n","authors":["Minsu Kim","Walid Saad","Mohammad Mozaffari","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2207.09387v2.pdf","comment":"Submitted to IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2301.10203v1","updated":"2023-01-24T18:21:33Z","published":"2023-01-24T18:21:33Z","title":"Neuronal architecture extracts statistical temporal patterns","summary":"  Neuronal systems need to process temporal signals. We here show how\nhigher-order temporal (co-)fluctuations can be employed to represent and\nprocess information. Concretely, we demonstrate that a simple biologically\ninspired feedforward neuronal model is able to extract information from up to\nthe third order cumulant to perform time series classification. This model\nrelies on a weighted linear summation of synaptic inputs followed by a\nnonlinear gain function. Training both - the synaptic weights and the nonlinear\ngain function - exposes how the non-linearity allows for the transfer of higher\norder correlations to the mean, which in turn enables the synergistic use of\ninformation encoded in multiple cumulants to maximize the classification\naccuracy. The approach is demonstrated both on a synthetic and on real world\ndatasets of multivariate time series. Moreover, we show that the biologically\ninspired architecture makes better use of the number of trainable parameters as\ncompared to a classical machine-learning scheme. Our findings emphasize the\nbenefit of biological neuronal architectures, paired with dedicated learning\nalgorithms, for the processing of information embedded in higher-order\nstatistical cumulants of temporal (co-)fluctuations.\n","authors":["Sandra Nestler","Moritz Helias","Matthieu Gilson"],"pdf_url":"https://arxiv.org/pdf/2301.10203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10194v1","updated":"2023-01-24T18:10:11Z","published":"2023-01-24T18:10:11Z","title":"WEASEL 2.0 -- A Random Dilated Dictionary Transform for Fast, Accurate\n  and Memory Constrained Time Series Classification","summary":"  A time series is a sequence of sequentially ordered real values in time. Time\nseries classification (TSC) is the task of assigning a time series to one of a\nset of predefined classes, usually based on a model learned from examples.\nDictionary-based methods for TSC rely on counting the frequency of certain\npatterns in time series and are important components of the currently most\naccurate TSC ensembles. One of the early dictionary-based methods was WEASEL,\nwhich at its time achieved SotA results while also being very fast. However, it\nis outperformed both in terms of speed and accuracy by other methods.\nFurthermore, its design leads to an unpredictably large memory footprint,\nmaking it inapplicable for many applications.\n  In this paper, we present WEASEL 2.0, a complete overhaul of WEASEL based on\ntwo recent advancements in TSC: Dilation and ensembling of randomized\nhyper-parameter settings. These two techniques allow WEASEL 2.0 to work with a\nfixed-size memory footprint while at the same time improving accuracy. Compared\nto 15 other SotA methods on the UCR benchmark set, WEASEL 2.0 is significantly\nmore accurate than other dictionary methods and not significantly worse than\nthe currently best methods. Actually, it achieves the highest median accuracy\nover all data sets, and it performs best in 5 out of 12 problem classes. We\nthus believe that WEASEL 2.0 is a viable alternative for current TSC and also a\npotentially interesting input for future ensembles.\n","authors":["Patrick Schäfer","Ulf Leser"],"pdf_url":"https://arxiv.org/pdf/2301.10194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08893v2","updated":"2023-01-24T18:01:05Z","published":"2023-01-21T05:14:29Z","title":"Spatial Attention Kinetic Networks with E(n)-Equivariance","summary":"  Neural networks that are equivariant to rotations, translations, reflections,\nand permutations on n-dimensional geometric space have shown promise in\nphysical modeling for tasks such as accurately but inexpensively modeling\ncomplex potential energy surfaces to guiding the sampling of complex dynamical\nsystems or forecasting their time evolution. Current state-of-the-art methods\nemploy spherical harmonics to encode higher-order interactions among particles,\nwhich are computationally expensive. In this paper, we propose a simple\nalternative functional form that uses neurally parametrized linear combinations\nof edge vectors to achieve equivariance while still universally approximating\nnode environments. Incorporating this insight, we design spatial attention\nkinetic networks with E(n)-equivariance, or SAKE, which are competitive in\nmany-body system modeling tasks while being significantly faster.\n","authors":["Yuanqing Wang","John D. Chodera"],"pdf_url":"https://arxiv.org/pdf/2301.08893v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10183v1","updated":"2023-01-24T17:50:19Z","published":"2023-01-24T17:50:19Z","title":"Mesostructures: Beyond Spectrogram Loss in Differentiable Time-Frequency\n  Analysis","summary":"  Computer musicians refer to mesostructures as the intermediate levels of\narticulation between the microstructure of waveshapes and the macrostructure of\nmusical forms. Examples of mesostructures include melody, arpeggios,\nsyncopation, polyphonic grouping, and textural contrast. Despite their central\nrole in musical expression, they have received limited attention in deep\nlearning. Currently, autoencoders and neural audio synthesizers are only\ntrained and evaluated at the scale of microstructure: i.e., local amplitude\nvariations up to 100 milliseconds or so. In this paper, we formulate and\naddress the problem of mesostructural audio modeling via a composition of a\ndifferentiable arpeggiator and time-frequency scattering. We empirically\ndemonstrate that time--frequency scattering serves as a differentiable model of\nsimilarity between synthesis parameters that govern mesostructure. By exposing\nthe sensitivity of short-time spectral distances to time alignment, we motivate\nthe need for a time-invariant and multiscale differentiable time--frequency\nmodel of similarity at the level of both local spectra and spectrotemporal\nmodulations.\n","authors":["Cyrus Vahidi","Han Han","Changhong Wang","Mathieu Lagrange","György Fazekas","Vincent Lostanlen"],"pdf_url":"https://arxiv.org/pdf/2301.10183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10152v1","updated":"2023-01-24T17:39:10Z","published":"2023-01-24T17:39:10Z","title":"How Jellyfish Characterise Alternating Group Equivariant Neural Networks","summary":"  We provide a full characterisation of all of the possible alternating group\n($A_n$) equivariant neural networks whose layers are some tensor power of\n$\\mathbb{R}^{n}$. In particular, we find a basis of matrices for the learnable,\nlinear, $A_n$-equivariant layer functions between such tensor power spaces in\nthe standard basis of $\\mathbb{R}^{n}$. We also describe how our approach\ngeneralises to the construction of neural networks that are equivariant to\nlocal symmetries.\n","authors":["Edward Pearce-Crump"],"pdf_url":"https://arxiv.org/pdf/2301.10152v1.pdf","comment":"10 pages. arXiv admin note: text overlap with arXiv:2212.08648,\n  arXiv:2212.08630"},{"id":"http://arxiv.org/abs/2209.02412v2","updated":"2023-01-24T17:27:34Z","published":"2022-09-02T16:45:46Z","title":"SIAN: Style-Guided Instance-Adaptive Normalization for Multi-Organ\n  Histopathology Image Synthesis","summary":"  Existing deep neural networks for histopathology image synthesis cannot\ngenerate image styles that align with different organs, and cannot produce\naccurate boundaries of clustered nuclei. To address these issues, we propose a\nstyle-guided instance-adaptive normalization (SIAN) approach to synthesize\nrealistic color distributions and textures for histopathology images from\ndifferent organs. SIAN contains four phases, semantization, stylization,\ninstantiation, and modulation. The first two phases synthesize image semantics\nand styles by using semantic maps and learned image style vectors. The\ninstantiation module integrates geometrical and topological information and\ngenerates accurate nuclei boundaries. We validate the proposed approach on a\nmultiple-organ dataset, Extensive experimental results demonstrate that the\nproposed method generates more realistic histopathology images than four\nstate-of-the-art approaches for five organs. By incorporating synthetic images\nfrom the proposed approach to model training, an instance segmentation network\ncan achieve state-of-the-art performance.\n","authors":["Haotian Wang","Min Xian","Aleksandar Vakanski","Bryar Shareef"],"pdf_url":"https://arxiv.org/pdf/2209.02412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02742v3","updated":"2023-01-24T17:15:33Z","published":"2022-12-06T04:15:24Z","title":"A Learning Based Hypothesis Test for Harmful Covariate Shift","summary":"  The ability to quickly and accurately identify covariate shift at test time\nis a critical and often overlooked component of safe machine learning systems\ndeployed in high-risk domains. While methods exist for detecting when\npredictions should not be made on out-of-distribution test examples,\nidentifying distributional level differences between training and test time can\nhelp determine when a model should be removed from the deployment setting and\nretrained. In this work, we define harmful covariate shift (HCS) as a change in\ndistribution that may weaken the generalization of a predictive model. To\ndetect HCS, we use the discordance between an ensemble of classifiers trained\nto agree on training data and disagree on test data. We derive a loss function\nfor training this ensemble and show that the disagreement rate and entropy\nrepresent powerful discriminative statistics for HCS. Empirically, we\ndemonstrate the ability of our method to detect harmful covariate shift with\nstatistical certainty on a variety of high-dimensional datasets. Across\nnumerous domains and modalities, we show state-of-the-art performance compared\nto existing methods, particularly when the number of observed test samples is\nsmall.\n","authors":["Tom Ginsberg","Zhongyuan Liang","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2212.02742v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10133v1","updated":"2023-01-24T16:57:00Z","published":"2023-01-24T16:57:00Z","title":"Read the Signs: Towards Invariance to Gradient Descent's Hyperparameter\n  Initialization","summary":"  We propose ActiveLR, an optimization meta algorithm that localizes the\nlearning rate, $\\alpha$, and adapts them at each epoch according to whether the\ngradient at each epoch changes sign or not. This sign-conscious algorithm is\naware of whether from the previous step to the current one the update of each\nparameter has been too large or too small and adjusts the $\\alpha$ accordingly.\nWe implement the Active version (ours) of widely used and recently published\ngradient descent optimizers, namely SGD with momentum, AdamW, RAdam, and\nAdaBelief. Our experiments on ImageNet, CIFAR-10, WikiText-103, WikiText-2, and\nPASCAL VOC using different model architectures, such as ResNet and\nTransformers, show an increase in generalizability and training set fit, and\ndecrease in training time for the Active variants of the tested optimizers. The\nresults also show robustness of the Active variant of these optimizers to\ndifferent values of the initial learning rate. Furthermore, the detrimental\neffects of using large mini-batch sizes are mitigated. ActiveLR, thus,\nalleviates the need for hyper-parameter search for two of the most commonly\ntuned hyper-parameters that require heavy time and computational costs to pick.\nWe encourage AI researchers and practitioners to use the Active variant of\ntheir optimizer of choice for faster training, better generalizability, and\nreducing carbon footprint of training deep neural networks.\n","authors":["Davood Wadi","Marc Fredette","Sylvain Senecal"],"pdf_url":"https://arxiv.org/pdf/2301.10133v1.pdf","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2301.10127v1","updated":"2023-01-24T16:46:37Z","published":"2023-01-24T16:46:37Z","title":"Improving Open-Set Semi-Supervised Learning with Self-Supervision","summary":"  Open-set semi-supervised learning (OSSL) is a realistic setting of\nsemi-supervised learning where the unlabeled training set contains classes that\nare not present in the labeled set. Many existing OSSL methods assume that\nthese out-of-distribution data are harmful and put effort into excluding data\nfrom unknown classes from the training objective. In contrast, we propose an\nOSSL framework that facilitates learning from all unlabeled data through\nself-supervision. Additionally, we utilize an energy-based score to accurately\nrecognize data belonging to the known classes, making our method well-suited\nfor handling uncurated data in deployment. We show through extensive\nexperimental evaluations on several datasets that our method shows overall\nunmatched robustness and performance in terms of closed-set accuracy and\nopen-set recognition compared with state-of-the-art for OSSL. Our code will be\nreleased upon publication.\n","authors":["Erik Wallin","Lennart Svensson","Fredrik Kahl","Lars Hammarstrand"],"pdf_url":"https://arxiv.org/pdf/2301.10127v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2301.10123v1","updated":"2023-01-24T16:43:29Z","published":"2023-01-24T16:43:29Z","title":"Inducing Point Allocation for Sparse Gaussian Processes in\n  High-Throughput Bayesian Optimisation","summary":"  Sparse Gaussian Processes are a key component of high-throughput Bayesian\nOptimisation (BO) loops; however, we show that existing methods for allocating\ntheir inducing points severely hamper optimisation performance. By exploiting\nthe quality-diversity decomposition of Determinantal Point Processes, we\npropose the first inducing point allocation strategy designed specifically for\nuse in BO. Unlike existing methods which seek only to reduce global uncertainty\nin the objective function, our approach provides the local high-fidelity\nmodelling of promising regions required for precise optimisation. More\ngenerally, we demonstrate that our proposed framework provides a flexible way\nto allocate modelling capacity in sparse models and so is suitable broad range\nof downstream sequential decision making tasks.\n","authors":["Henry B. Moss","Sebastian W. Ober","Victor Picheny"],"pdf_url":"https://arxiv.org/pdf/2301.10123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10119v1","updated":"2023-01-24T16:40:01Z","published":"2023-01-24T16:40:01Z","title":"Minimal Value-Equivalent Partial Models for Scalable and Robust Planning\n  in Lifelong Reinforcement Learning","summary":"  Learning models of the environment from pure interaction is often considered\nan essential component of building lifelong reinforcement learning agents.\nHowever, the common practice in model-based reinforcement learning is to learn\nmodels that model every aspect of the agent's environment, regardless of\nwhether they are important in coming up with optimal decisions or not. In this\npaper, we argue that such models are not particularly well-suited for\nperforming scalable and robust planning in lifelong reinforcement learning\nscenarios and we propose new kinds of models that only model the relevant\naspects of the environment, which we call \"minimal value-equivalent partial\nmodels\". After providing a formal definition for these models, we provide\ntheoretical results demonstrating the scalability advantages of performing\nplanning with such models and then perform experiments to empirically\nillustrate our theoretical results. Then, we provide some useful heuristics on\nhow to learn these kinds of models with deep learning architectures and\nempirically demonstrate that models learned in such a way can allow for\nperforming planning that is robust to distribution shifts and compounding model\nerrors. Overall, both our theoretical and empirical results suggest that\nminimal value-equivalent partial models can provide significant benefits to\nperforming scalable and robust planning in lifelong reinforcement learning\nscenarios.\n","authors":["Safa Alver","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2301.10119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10115v1","updated":"2023-01-24T16:31:49Z","published":"2023-01-24T16:31:49Z","title":"A Robust Hypothesis Test for Tree Ensemble Pruning","summary":"  Gradient boosted decision trees are some of the most popular algorithms in\napplied machine learning. They are a flexible and powerful tool that can\nrobustly fit to any tabular dataset in a scalable and computationally efficient\nway. One of the most critical parameters to tune when fitting these models are\nthe various penalty terms used to distinguish signal from noise in the current\nmodel. These penalties are effective in practice, but are lacking in robust\ntheoretical justifications. In this paper we develop and present a novel\ntheoretically justified hypothesis test of split quality for gradient boosted\ntree ensembles and demonstrate that using this method instead of the common\npenalty terms leads to a significant reduction in out of sample loss.\nAdditionally, this method provides a theoretically well-justified stopping\ncondition for the tree growing algorithm. We also present several innovative\nextensions to the method, opening the door for a wide variety of novel tree\npruning algorithms.\n","authors":["Daniel de Marchi","Matthew Welch","Michael Kosorok"],"pdf_url":"https://arxiv.org/pdf/2301.10115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10114v1","updated":"2023-01-24T16:31:11Z","published":"2023-01-24T16:31:11Z","title":"When does the student surpass the teacher? Federated Semi-supervised\n  Learning with Teacher-Student EMA","summary":"  Semi-Supervised Learning (SSL) has received extensive attention in the domain\nof computer vision, leading to development of promising approaches such as\nFixMatch. In scenarios where training data is decentralized and resides on\nclient devices, SSL must be integrated with privacy-aware training techniques\nsuch as Federated Learning. We consider the problem of federated image\nclassification and study the performance and privacy challenges with existing\nfederated SSL (FSSL) approaches. Firstly, we note that even state-of-the-art\nFSSL algorithms can trivially compromise client privacy and other real-world\nconstraints such as client statelessness and communication cost. Secondly, we\nobserve that it is challenging to integrate EMA (Exponential Moving Average)\nupdates into the federated setting, which comes at a trade-off between\nperformance and communication cost. We propose a novel approach FedSwitch, that\nimproves privacy as well as generalization performance through Exponential\nMoving Average (EMA) updates. FedSwitch utilizes a federated semi-supervised\nteacher-student EMA framework with two features - local teacher adaptation and\nadaptive switching between teacher and student for pseudo-label generation. Our\nproposed approach outperforms the state-of-the-art on federated image\nclassification, can be adapted to real-world constraints, and achieves good\ngeneralization performance with minimal communication cost overhead.\n","authors":["Jessica Zhao","Sayan Ghosh","Akash Bharadwaj","Chih-Yao Ma"],"pdf_url":"https://arxiv.org/pdf/2301.10114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10110v1","updated":"2023-01-24T16:22:31Z","published":"2023-01-24T16:22:31Z","title":"PolarAir: A Compressed Sensing Scheme for Over-the-Air Federated\n  Learning","summary":"  We explore a scheme that enables the training of a deep neural network in a\nFederated Learning configuration over an additive white Gaussian noise channel.\nThe goal is to create a low complexity, linear compression strategy, called\nPolarAir, that reduces the size of the gradient at the user side to lower the\nnumber of channel uses needed to transmit it. The suggested approach belongs to\nthe family of compressed sensing techniques, yet it constructs the sensing\nmatrix and the recovery procedure using multiple access techniques. Simulations\nshow that it can reduce the number of channel uses by ~30% when compared to\nconveying the gradient without compression. The main advantage of the proposed\nscheme over other schemes in the literature is its low time complexity. We also\ninvestigate the behavior of gradient updates and the performance of PolarAir\nthroughout the training process to obtain insight on how best to construct this\ncompression scheme based on compressed sensing.\n","authors":["Michail Gkagkos","Krishna R. Narayanan","Jean-Francois Chamberland","Costas N. Georghiades"],"pdf_url":"https://arxiv.org/pdf/2301.10110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.11620v2","updated":"2023-01-24T16:18:30Z","published":"2022-01-27T16:26:36Z","title":"Domain generalization in deep learning-based mass detection in\n  mammography: A large-scale multi-center study","summary":"  Computer-aided detection systems based on deep learning have shown great\npotential in breast cancer detection. However, the lack of domain\ngeneralization of artificial neural networks is an important obstacle to their\ndeployment in changing clinical environments. In this work, we explore the\ndomain generalization of deep learning methods for mass detection in digital\nmammography and analyze in-depth the sources of domain shift in a large-scale\nmulti-center setting. To this end, we compare the performance of eight\nstate-of-the-art detection methods, including Transformer-based models, trained\nin a single domain and tested in five unseen domains. Moreover, a single-source\nmass detection training pipeline is designed to improve the domain\ngeneralization without requiring images from the new domain. The results show\nthat our workflow generalizes better than state-of-the-art transfer\nlearning-based approaches in four out of five domains while reducing the domain\nshift caused by the different acquisition protocols and scanner manufacturers.\nSubsequently, an extensive analysis is performed to identify the covariate\nshifts with bigger effects on the detection performance, such as due to\ndifferences in patient age, breast density, mass size, and mass malignancy.\nUltimately, this comprehensive study provides key insights and best practices\nfor future research on domain generalization in deep learning-based breast\ncancer detection.\n","authors":["Lidia Garrucho","Kaisar Kushibar","Socayna Jouide","Oliver Diaz","Laura Igual","Karim Lekadir"],"pdf_url":"https://arxiv.org/pdf/2201.11620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2009.01822v2","updated":"2023-01-24T16:15:08Z","published":"2020-09-03T17:40:27Z","title":"Fine-grained Early Frequency Attention for Deep Speaker Representation\n  Learning","summary":"  Deep learning techniques have considerably improved speech processing in\nrecent years. Speaker representations extracted by deep learning models are\nbeing used in a wide range of tasks such as speaker recognition and speech\nemotion recognition. Attention mechanisms have started to play an important\nrole in improving deep learning models in the field of speech processing.\nNonetheless, despite the fact that important speaker-related information can be\nembedded in individual frequency-bins of the input spectral representations,\ncurrent attention models are unable to attend to fine-grained information items\nin spectral representations. In this paper we propose Fine-grained Early\nFrequency Attention (FEFA) for speaker representation learning. Our model is a\nsimple and lightweight model that can be integrated into various CNN pipelines\nand is capable of focusing on information items as small as frequency-bins. We\nevaluate the proposed model on three tasks of speaker recognition, speech\nemotion recognition, and spoken digit recognition. We use Three widely used\npublic datasets, namely VoxCeleb, IEMOCAP, and Free Spoken Digit Dataset for\nour experiments. We attach FEFA to several prominent deep learning models and\nevaluate its impact on the final performance. We also compare our work with\nother related works in the area. Our experiments show that by adding FEFA to\ndifferent CNN architectures, performance is consistently improved by\nsubstantial margins, and the models equipped with FEFA outperform all the other\nattentive models. We also test our model against different levels of added\nnoise showing improvements in robustness and less sensitivity compared to the\nbackbone networks.\n","authors":["Amirhossein Hajavi","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2009.01822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10908v2","updated":"2023-01-24T15:48:04Z","published":"2022-11-20T08:58:34Z","title":"ESTAS: Effective and Stable Trojan Attacks in Self-supervised Encoders\n  with One Target Unlabelled Sample","summary":"  Emerging self-supervised learning (SSL) has become a popular image\nrepresentation encoding method to obviate the reliance on labeled data and\nlearn rich representations from large-scale, ubiquitous unlabelled data. Then\none can train a downstream classifier on top of the pre-trained SSL image\nencoder with few or no labeled downstream data. Although extensive works show\nthat SSL has achieved remarkable and competitive performance on different\ndownstream tasks, its security concerns, e.g, Trojan attacks in SSL encoders,\nare still not well-studied. In this work, we present a novel Trojan Attack\nmethod, denoted by ESTAS, that can enable an effective and stable attack in SSL\nencoders with only one target unlabeled sample. In particular, we propose\nconsistent trigger poisoning and cascade optimization in ESTAS to improve\nattack efficacy and model accuracy, and eliminate the expensive target-class\ndata sample extraction from large-scale disordered unlabelled data. Our\nsubstantial experiments on multiple datasets show that ESTAS stably achieves >\n99% attacks success rate (ASR) with one target-class sample. Compared to prior\nworks, ESTAS attains > 30% ASR increase and > 8.3% accuracy improvement on\naverage.\n","authors":["Jiaqi Xue","Qian Lou"],"pdf_url":"https://arxiv.org/pdf/2211.10908v2.pdf","comment":"10 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2210.09224v2","updated":"2023-01-24T15:46:41Z","published":"2022-10-17T16:19:53Z","title":"Self-Supervised Learning Through Efference Copies","summary":"  Self-supervised learning (SSL) methods aim to exploit the abundance of\nunlabelled data for machine learning (ML), however the underlying principles\nare often method-specific. An SSL framework derived from biological first\nprinciples of embodied learning could unify the various SSL methods, help\nelucidate learning in the brain, and possibly improve ML. SSL commonly\ntransforms each training datapoint into a pair of views, uses the knowledge of\nthis pairing as a positive (i.e. non-contrastive) self-supervisory sign, and\npotentially opposes it to unrelated, (i.e. contrastive) negative examples.\nHere, we show that this type of self-supervision is an incomplete\nimplementation of a concept from neuroscience, the Efference Copy (EC).\nSpecifically, the brain also transforms the environment through efference, i.e.\nmotor commands, however it sends to itself an EC of the full commands, i.e.\nmore than a mere SSL sign. In addition, its action representations are likely\negocentric. From such a principled foundation we formally recover and extend\nSSL methods such as SimCLR, BYOL, and ReLIC under a common theoretical\nframework, i.e. Self-supervision Through Efference Copies (S-TEC). Empirically,\nS-TEC restructures meaningfully the within- and between-class representations.\nThis manifests as improvement in recent strong SSL baselines in image\nclassification, segmentation, object detection, and in audio. These results\nhypothesize a testable positive influence from the brain's motor outputs onto\nits sensory representations.\n","authors":["Franz Scherr","Qinghai Guo","Timoleon Moraitis"],"pdf_url":"https://arxiv.org/pdf/2210.09224v2.pdf","comment":"Accepted at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.10077v1","updated":"2023-01-24T15:31:22Z","published":"2023-01-24T15:31:22Z","title":"Autonomous particles","summary":"  Consider a reinforcement learning problem where an agent has access to a very\nlarge amount of information about the environment, but it can only take very\nfew actions to accomplish its task and to maximize its reward. Evidently, the\nmain problem for the agent is to learn a map from a very high-dimensional space\n(which represents its environment) to a very low-dimensional space (which\nrepresents its actions). The high-to-low dimensional map implies that most of\nthe information about the environment is irrelevant for the actions to be\ntaken, and only a small fraction of information is relevant. In this paper we\nargue that the relevant information need not be learned by brute force (which\nis the standard approach), but can be identified from the intrinsic symmetries\nof the system. We analyze in details a reinforcement learning problem of\nautonomous driving, where the corresponding symmetry is the Galilean symmetry,\nand argue that the learning task can be accomplished with very few relevant\nparameters, or, more precisely, invariants. For a numerical demonstration, we\nshow that the autonomous vehicles (which we call autonomous particles since\nthey describe very primitive vehicles) need only four relevant invariants to\nlearn how to drive very well without colliding with other particles. The simple\nmodel can be easily generalized to include different types of particles (e.g.\nfor cars, for pedestrians, for buildings, for road signs, etc.) with different\ntypes of relevant invariants describing interactions between them. We also\nargue that there must exist a field theory description of the learning system\nwhere autonomous particles would be described by fermionic degrees of freedom\nand interactions mediated by the relevant invariants would be described by\nbosonic degrees of freedom.\n","authors":["Nikola Andrejic","Vitaly Vanchurin"],"pdf_url":"https://arxiv.org/pdf/2301.10077v1.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.14681v2","updated":"2023-01-24T15:26:26Z","published":"2022-12-30T13:14:46Z","title":"An Entropy-Based Model for Hierarchical Learning","summary":"  Machine learning is the dominant approach to artificial intelligence, through\nwhich computers learn from data and experience. In the framework of supervised\nlearning, a necessity for a computer to learn from data accurately and\nefficiently is to be provided with auxiliary information about the data\ndistribution and target function through the learning model. This notion of\nauxiliary information relates to the concept of regularization in statistical\nlearning theory. A common feature among real-world datasets is that data\ndomains are multiscale and target functions are well-behaved and smooth. This\npaper proposes an entropy-based learning model that exploits this data\nstructure and discusses its statistical and computational benefits. The\nhierarchical learning model is inspired by human beings' logical and\nprogressive easy-to-hard learning mechanism and has interpretable levels. The\nmodel apportions computational resources according to the complexity of data\ninstances and target functions. This property can have multiple benefits,\nincluding higher inference speed and computational savings in training a model\nfor many users or when training is interrupted. We provide a statistical\nanalysis of the learning mechanism using multiscale entropies and show that it\ncan yield significantly stronger guarantees than uniform convergence bounds.\n","authors":["Amir R. Asadi"],"pdf_url":"https://arxiv.org/pdf/2212.14681v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01121v3","updated":"2023-01-24T15:25:21Z","published":"2022-03-01T13:55:56Z","title":"VaiPhy: a Variational Inference Based Algorithm for Phylogeny","summary":"  Phylogenetics is a classical methodology in computational biology that today\nhas become highly relevant for medical investigation of single-cell data, e.g.,\nin the context of cancer development. The exponential size of the tree space\nis, unfortunately, a substantial obstacle for Bayesian phylogenetic inference\nusing Markov chain Monte Carlo based methods since these rely on local\noperations. And although more recent variational inference (VI) based methods\noffer speed improvements, they rely on expensive auto-differentiation\noperations for learning the variational parameters. We propose VaiPhy, a\nremarkably fast VI based algorithm for approximate posterior inference in an\naugmented tree space. VaiPhy produces marginal log-likelihood estimates on par\nwith the state-of-the-art methods on real data and is considerably faster since\nit does not require auto-differentiation. Instead, VaiPhy combines coordinate\nascent update equations with two novel sampling schemes: (i) SLANTIS, a\nproposal distribution for tree topologies in the augmented tree space, and (ii)\nthe JC sampler, to the best of our knowledge, the first-ever scheme for\nsampling branch lengths directly from the popular Jukes-Cantor model. We\ncompare VaiPhy in terms of density estimation and runtime. Additionally, we\nevaluate the reproducibility of the baselines. We provide our code on GitHub:\n\\url{https://github.com/Lagergren-Lab/VaiPhy}.\n","authors":["Hazal Koptagel","Oskar Kviman","Harald Melin","Negar Safinianaini","Jens Lagergren"],"pdf_url":"https://arxiv.org/pdf/2203.01121v3.pdf","comment":"NeurIPS-22 conference paper"},{"id":"http://arxiv.org/abs/2301.10074v1","updated":"2023-01-24T15:25:16Z","published":"2023-01-24T15:25:16Z","title":"Explainable Data-Driven Optimization: From Context to Decision and Back\n  Again","summary":"  Data-driven optimization uses contextual information and machine learning\nalgorithms to find solutions to decision problems with uncertain parameters.\nWhile a vast body of work is dedicated to interpreting machine learning models\nin the classification setting, explaining decision pipelines involving learning\nalgorithms remains unaddressed. This lack of interpretability can block the\nadoption of data-driven solutions as practitioners may not understand or trust\nthe recommended decisions. We bridge this gap by introducing a counterfactual\nexplanation methodology tailored to explain solutions to data-driven problems.\nWe introduce two classes of explanations and develop methods to find nearest\nexplanations of random forest and nearest-neighbor predictors. We demonstrate\nour approach by explaining key problems in operations management such as\ninventory management and routing.\n","authors":["Alexandre Forel","Axel Parmentier","Thibaut Vidal"],"pdf_url":"https://arxiv.org/pdf/2301.10074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10067v1","updated":"2023-01-24T15:13:02Z","published":"2023-01-24T15:13:02Z","title":"Intrinsic Motivation in Model-based Reinforcement Learning: A Brief\n  Review","summary":"  The reinforcement learning research area contains a wide range of methods for\nsolving the problems of intelligent agent control. Despite the progress that\nhas been made, the task of creating a highly autonomous agent is still a\nsignificant challenge. One potential solution to this problem is intrinsic\nmotivation, a concept derived from developmental psychology. This review\nconsiders the existing methods for determining intrinsic motivation based on\nthe world model obtained by the agent. We propose a systematic approach to\ncurrent research in this field, which consists of three categories of methods,\ndistinguished by the way they utilize a world model in the agent's components:\ncomplementary intrinsic reward, exploration policy, and intrinsically motivated\ngoals. The proposed unified framework describes the architecture of agents\nusing a world model and intrinsic motivation to improve learning. The potential\nfor developing new techniques in this area of research is also examined.\n","authors":["Artem Latyshev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2301.10067v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2301.10060v1","updated":"2023-01-24T15:04:19Z","published":"2023-01-24T15:04:19Z","title":"Inference of Continuous Linear Systems from Data with Guaranteed\n  Stability","summary":"  Machine-learning technologies for learning dynamical systems from data play\nan important role in engineering design. This research focuses on learning\ncontinuous linear models from data. Stability, a key feature of dynamic\nsystems, is especially important in design tasks such as prediction and\ncontrol. Thus, there is a need to develop methodologies that provide stability\nguarantees. To that end, we leverage the parameterization of stable matrices\nproposed in [Gillis/Sharma, Automatica, 2017] to realize the desired models.\nFurthermore, to avoid the estimation of derivative information to learn\ncontinuous systems, we formulate the inference problem in an integral form. We\nalso discuss a few extensions, including those related to control systems.\nNumerical experiments show that the combination of a stable matrix\nparameterization and an integral form of differential equations allows us to\nlearn stable systems without requiring derivative information, which can be\nchallenging to obtain in situations with noisy or limited data.\n","authors":["Pawan Goyal","Igor Pontes Duff","Peter Benner"],"pdf_url":"https://arxiv.org/pdf/2301.10060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.09076v3","updated":"2023-01-24T14:56:46Z","published":"2021-11-17T12:39:04Z","title":"To Trust or Not To Trust Prediction Scores for Membership Inference\n  Attacks","summary":"  Membership inference attacks (MIAs) aim to determine whether a specific\nsample was used to train a predictive model. Knowing this may indeed lead to a\nprivacy breach. Most MIAs, however, make use of the model's prediction scores -\nthe probability of each output given some input - following the intuition that\nthe trained model tends to behave differently on its training data. We argue\nthat this is a fallacy for many modern deep network architectures.\nConsequently, MIAs will miserably fail since overconfidence leads to high\nfalse-positive rates not only on known domains but also on out-of-distribution\ndata and implicitly acts as a defense against MIAs. Specifically, using\ngenerative adversarial networks, we are able to produce a potentially infinite\nnumber of samples falsely classified as part of the training data. In other\nwords, the threat of MIAs is overestimated, and less information is leaked than\npreviously assumed. Moreover, there is actually a trade-off between the\noverconfidence of models and their susceptibility to MIAs: the more classifiers\nknow when they do not know, making low confidence predictions, the more they\nreveal the training data.\n","authors":["Dominik Hintersdorf","Lukas Struppek","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2111.09076v3.pdf","comment":"15 pages, 8 figures, 10 tables"},{"id":"http://arxiv.org/abs/2301.10053v1","updated":"2023-01-24T14:56:36Z","published":"2023-01-24T14:56:36Z","title":"A Linear Reconstruction Approach for Attribute Inference Attacks against\n  Synthetic Data","summary":"  Personal data collected at scale from surveys or digital devices offers\nimportant insights for statistical analysis and scientific research. Safely\nsharing such data while protecting privacy is however challenging.\nAnonymization allows data to be shared while minimizing privacy risks, but\ntraditional anonymization techniques have been repeatedly shown to provide\nlimited protection against re-identification attacks in practice. Among modern\nanonymization techniques, synthetic data generation (SDG) has emerged as a\npotential solution to find a good tradeoff between privacy and statistical\nutility. Synthetic data is typically generated using algorithms that learn the\nstatistical distribution of the original records, to then generate \"artificial\"\nrecords that are structurally and statistically similar to the original ones.\nYet, the fact that synthetic records are \"artificial\" does not, per se,\nguarantee that privacy is protected. In this work, we systematically evaluate\nthe tradeoffs between protecting privacy and preserving statistical utility for\na wide range of synthetic data generation algorithms. Modeling privacy as\nprotection against attribute inference attacks (AIAs), we extend and adapt\nlinear reconstruction attacks, which have not been previously studied in the\ncontext of synthetic data. While prior work suggests that AIAs may be effective\nonly on few outlier records, we show they can be very effective even on\nrandomly selected records. We evaluate attacks on synthetic datasets ranging\nfrom 10^3 to 10^6 records, showing that even for the same generative model, the\nattack effectiveness can drastically increase when a larger number of synthetic\nrecords is generated. Overall, our findings prove that synthetic data is\nsubject to privacy-utility tradeoffs just like other anonymization techniques:\nwhen good utility is preserved, attribute inference can be a risk for many data\nsubjects.\n","authors":["Meenatchi Sundaram Muthu Selva Annamalai","Andrea Gadotti","Luc Rocher"],"pdf_url":"https://arxiv.org/pdf/2301.10053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.17246v2","updated":"2023-01-24T14:24:07Z","published":"2022-11-30T18:47:30Z","title":"Pex: Memory-efficient Microcontroller Deep Learning through Partial\n  Execution","summary":"  Embedded and IoT devices, largely powered by microcontroller units (MCUs),\ncould be made more intelligent by leveraging on-device deep learning. One of\nthe main challenges of neural network inference on an MCU is the extremely\nlimited amount of read-write on-chip memory (SRAM, < 512 kB). SRAM is consumed\nby the neural network layer (operator) input and output buffers, which,\ntraditionally, must be in memory (materialised) for an operator to execute. We\ndiscuss a novel execution paradigm for microcontroller deep learning, which\nmodifies the execution of neural networks to avoid materialising full buffers\nin memory, drastically reducing SRAM usage with no computation overhead. This\nis achieved by exploiting the properties of operators, which can\nconsume/produce a fraction of their input/output at a time. We describe a\npartial execution compiler, Pex, which produces memory-efficient execution\nschedules automatically by identifying subgraphs of operators whose execution\ncan be split along the feature (\"channel\") dimension. Memory usage is reduced\nfurther by targeting memory bottlenecks with structured pruning, leading to the\nco-design of the network architecture and its execution schedule. Our\nevaluation of image and audio classification models: (a) establishes\nstate-of-the-art performance in low SRAM usage regimes for considered tasks\nwith up to +2.9% accuracy increase; (b) finds that a 4x memory reduction is\npossible by applying partial execution alone, or up to 10.5x when using the\ncompiler-pruning co-design, while maintaining the classification accuracy\ncompared to prior work; (c) uses the recovered SRAM to process higher\nresolution inputs instead, increasing accuracy by up to +3.9% on Visual Wake\nWords.\n","authors":["Edgar Liberis","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2211.17246v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15375v2","updated":"2023-01-24T14:21:21Z","published":"2022-11-24T06:08:24Z","title":"Visual Simulation Software Demonstration for Quantum Multi-Drone\n  Reinforcement Learning","summary":"  Quantum computing (QC) has received a lot of attention according to its light\ntraining parameter numbers and computational speeds by qubits. Moreover,\nvarious researchers have tried to enable quantum machine learning (QML) using\nQC, where there are also multifarious efforts to use QC to implement quantum\nmulti-agent reinforcement learning (QMARL). Existing classical multi-agent\nreinforcement learning (MARL) using neural network features non-stationarity\nand uncertain properties due to its large number of parameters. Therefore, this\npaper presents a visual simulation software framework for a novel QMARL\nalgorithm to control autonomous multi-drone systems to take advantage of QC.\nOur proposed QMARL framework accomplishes reasonable reward convergence and\nservice quality performance with fewer trainable parameters than the classical\nMARL. Furthermore, QMARL shows more stable training results than existing MARL\nalgorithms. Lastly, our proposed visual simulation software allows us to\nanalyze the agents' training process and results.\n","authors":["Chanyoung Park","Jae Pyoung Kim","Won Joon Yun","Soyi Jung","Joongheon Kim"],"pdf_url":"https://arxiv.org/pdf/2211.15375v2.pdf","comment":"We need to revise and resubmit this paper to new version"},{"id":"http://arxiv.org/abs/2301.10022v1","updated":"2023-01-24T14:10:15Z","published":"2023-01-24T14:10:15Z","title":"Koopman neural operator as a mesh-free solver of non-linear partial\n  differential equations","summary":"  The lacking of analytic solutions of diverse partial differential equations\n(PDEs) gives birth to series of computational techniques for numerical\nsolutions. In machine learning, numerous latest advances of solver designs are\naccomplished in developing neural operators, a kind of mesh-free approximators\nof the infinite-dimensional operators that map between different\nparameterization spaces of equation solutions. Although neural operators\nexhibit generalization capacities for learning an entire PDE family\nsimultaneously, they become less accurate and explainable while learning\nlong-term behaviours of non-linear PDE families. In this paper, we propose\nKoopman neural operator (KNO), a new neural operator, to overcome these\nchallenges. With the same objective of learning an infinite-dimensional mapping\nbetween Banach spaces that serves as the solution operator of target PDE\nfamily, our approach differs from existing models by formulating a non-linear\ndynamic system of equation solution. By approximating the Koopman operator, an\ninfinite-dimensional linear operator governing all possible observations of the\ndynamic system, to act on the flow mapping of dynamic system, we can\nequivalently learn the solution of an entire non-linear PDE family by solving\nsimple linear prediction problems. In zero-shot prediction and long-term\nprediction experiments on representative PDEs (e.g., the Navier-Stokes\nequation), KNO exhibits notable advantages in breaking the tradeoff between\naccuracy and efficiency (e.g., model size) while previous state-of-the-art\nmodels are limited. These results suggest that more efficient PDE solvers can\nbe developed by the joint efforts from physics and machine learning.\n","authors":["Wei Xiong","Xiaomeng Huang","Ziyang Zhang","Ruixuan Deng","Pei Sun","Yang Tian"],"pdf_url":"https://arxiv.org/pdf/2301.10022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08479v2","updated":"2023-01-24T14:06:01Z","published":"2022-12-16T13:46:17Z","title":"Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR\n  Imaging","summary":"  In this work, we propose a novel image reconstruction framework that directly\nlearns a neural implicit representation in k-space for ECG-triggered\nnon-Cartesian Cardiac Magnetic Resonance Imaging (CMR). While existing methods\nbin acquired data from neighboring time points to reconstruct one phase of the\ncardiac motion, our framework allows for a continuous, binning-free, and\nsubject-specific k-space representation.We assign a unique coordinate that\nconsists of time, coil index, and frequency domain location to each sampled\nk-space point. We then learn the subject-specific mapping from these unique\ncoordinates to k-space intensities using a multi-layer perceptron with\nfrequency domain regularization. During inference, we obtain a complete k-space\nfor Cartesian coordinates and an arbitrary temporal resolution. A simple\ninverse Fourier transform recovers the image, eliminating the need for density\ncompensation and costly non-uniform Fourier transforms for non-Cartesian data.\nThis novel imaging framework was tested on 42 radially sampled datasets from 6\nsubjects. The proposed method outperforms other techniques qualitatively and\nquantitatively using data from four and one heartbeat(s) and 30 cardiac phases.\nOur results for one heartbeat reconstruction of 50 cardiac phases show improved\nartifact removal and spatio-temporal resolution, leveraging the potential for\nreal-time CMR.\n","authors":["Wenqi Huang","Hongwei Li","Jiazhen Pan","Gastao Cruz","Daniel Rueckert","Kerstin Hammernik"],"pdf_url":"https://arxiv.org/pdf/2212.08479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.11910v3","updated":"2023-01-24T13:51:06Z","published":"2022-04-25T18:28:55Z","title":"Integrating Reward Maximization and Population Estimation: Sequential\n  Decision-Making for Internal Revenue Service Audit Selection","summary":"  We introduce a new setting, optimize-and-estimate structured bandits. Here, a\npolicy must select a batch of arms, each characterized by its own context, that\nwould allow it to both maximize reward and maintain an accurate (ideally\nunbiased) population estimate of the reward. This setting is inherent to many\npublic and private sector applications and often requires handling delayed\nfeedback, small data, and distribution shifts. We demonstrate its importance on\nreal data from the United States Internal Revenue Service (IRS). The IRS\nperforms yearly audits of the tax base. Two of its most important objectives\nare to identify suspected misreporting and to estimate the \"tax gap\" -- the\nglobal difference between the amount paid and true amount owed. Based on a\nunique collaboration with the IRS, we cast these two processes as a unified\noptimize-and-estimate structured bandit. We analyze optimize-and-estimate\napproaches to the IRS problem and propose a novel mechanism for unbiased\npopulation estimation that achieves rewards comparable to baseline approaches.\nThis approach has the potential to improve audit efficacy, while maintaining\npolicy-relevant estimates of the tax gap. This has important social\nconsequences given that the current tax gap is estimated at nearly half a\ntrillion dollars. We suggest that this problem setting is fertile ground for\nfurther research and we highlight its interesting challenges. The results of\nthis and related research are currently being incorporated into the continual\nimprovement of the IRS audit selection methods.\n","authors":["Peter Henderson","Ben Chugg","Brandon Anderson","Kristen Altenburger","Alex Turk","John Guyton","Jacob Goldin","Daniel E. Ho"],"pdf_url":"https://arxiv.org/pdf/2204.11910v3.pdf","comment":"Accepted to the Thirty-Seventh AAAI Conference On Artificial\n  Intelligence (AAAI), 2023"},{"id":"http://arxiv.org/abs/2301.02819v3","updated":"2023-01-24T13:48:15Z","published":"2023-01-07T09:42:03Z","title":"ExcelFormer: A Neural Network Surpassing GBDTs on Tabular Data","summary":"  Though deep neural networks have gained enormous successes in various fields\n(e.g., computer vision) with supervised learning, they have so far been still\ntrailing after the performances of GBDTs on tabular data. Delving into this\ntask, we determine that a judicious handling of feature interactions and\nfeature representation is crucial to the effectiveness of neural networks on\ntabular data. We develop a novel neural network called ExcelFormer, which\nalternates in turn between two attention modules that shrewdly manipulate\nfeature interactions and feature representation updates, respectively. A\nbespoke training methodology is jointly introduced to facilitate model\nperformances. Specifically, by initializing parameters with minuscule values,\nthese attention modules are attenuated when the training begins, and the\neffects of feature interactions and representation updates grow progressively\nup to optimum levels under the guidance of our proposed specific regularization\nschemes Feat-Mix and Hidden-Mix as the training proceeds. Experiments on 28\npublic tabular datasets show that our ExcelFormer approach is superior to\nextensively-tuned GBDTs, which is an unprecedented progress of deep neural\nnetworks on supervised tabular learning.\n","authors":["Jintai Chen","Jiahuan Yan","Danny Ziyi Chen","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2301.02819v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.15651v2","updated":"2023-01-24T13:43:30Z","published":"2022-03-29T15:10:17Z","title":"Gaze-based Object Detection in the Wild","summary":"  In human-robot collaboration, one challenging task is to teach a robot new\nyet unknown objects enabling it to interact with them. Thereby, gaze can\ncontain valuable information. We investigate if it is possible to detect\nobjects (object or no object) merely from gaze data and determine their\nbounding box parameters. For this purpose, we explore different sizes of\ntemporal windows, which serve as a basis for the computation of heatmaps, i.e.,\nthe spatial distribution of the gaze data. Additionally, we analyze different\ngrid sizes of these heatmaps, and demonstrate the functionality in a proof of\nconcept using different machine learning techniques. Our method is\ncharacterized by its speed and resource efficiency compared to conventional\nobject detectors. In order to generate the required data, we conducted a study\nwith five subjects who could move freely and thus, turn towards arbitrary\nobjects. This way, we chose a scenario for our data collection that is as\nrealistic as possible. Since the subjects move while facing objects, the\nheatmaps also contain gaze data trajectories, complicating the detection and\nparameter regression. We make our data set publicly available to the research\ncommunity for download.\n","authors":["Daniel Weber","Wolfgang Fuhl","Andreas Zell","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2203.15651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09991v1","updated":"2023-01-24T13:37:50Z","published":"2023-01-24T13:37:50Z","title":"Solving the Discretised Neutron Diffusion Equations using Neural\n  Networks: Applications in neutron transport","summary":"  In this paper we solve the Boltzmann transport equation using AI libraries.\nThe reason why this is attractive is because it enables one to use the highly\noptimised software within AI libraries, enabling one to run on different\ncomputer architectures and enables one to tap into the vast quantity of\ncommunity based software that has been developed for AI and ML applications\ne.g. mixed arithmetic precision or model parallelism. Here we take the first\nsteps towards developing this approach for the Boltzmann transport equation and\ndevelop the necessary methods in order to do that effectively. This includes:\n1) A space-angle multigrid solution method that can extract the level of\nparallelism necessary to run efficiently on GPUs or new AI computers. 2) A new\nConvolutional Finite Element Method (ConvFEM) that greatly simplifies the\nimplementation of high order finite elements (quadratic to quintic, say). 3) A\nnew non-linear Petrov-Galerkin method that introduces dissipation\nanisotropically.\n","authors":["T. R. F. Phillips","C. E. Heaney","C. Boyang","A. G. Buchan","C. C. Pain"],"pdf_url":"https://arxiv.org/pdf/2301.09991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11572v4","updated":"2023-01-24T13:18:12Z","published":"2022-03-22T09:51:24Z","title":"Fast Multi-view Clustering via Ensembles: Towards Scalability,\n  Superiority, and Simplicity","summary":"  Despite significant progress, there remain three limitations to the previous\nmulti-view clustering algorithms. First, they often suffer from high\ncomputational complexity, restricting their feasibility for large-scale\ndatasets. Second, they typically fuse multi-view information via one-stage\nfusion, neglecting the possibilities in multi-stage fusions. Third,\ndataset-specific hyperparameter-tuning is frequently required, further\nundermining their practicability. In light of this, we propose a fast\nmulti-view clustering via ensembles (FastMICE) approach. Particularly, the\nconcept of random view groups is presented to capture the versatile view-wise\nrelationships, through which the hybrid early-late fusion strategy is designed\nto enable efficient multi-stage fusions. With multiple views extended to many\nview groups, three levels of diversity (w.r.t. features, anchors, and\nneighbors, respectively) are jointly leveraged for constructing the\nview-sharing bipartite graphs in the early-stage fusion. Then, a set of\ndiversified base clusterings for different view groups are obtained via fast\ngraph partitioning, which are further formulated into a unified bipartite graph\nfor final clustering in the late-stage fusion. Notably, FastMICE has almost\nlinear time and space complexity, and is free of dataset-specific tuning.\nExperiments on 22 multi-view datasets demonstrate its advantages in scalability\n(for extremely large datasets), superiority (in clustering performance), and\nsimplicity (to be applied) over the state-of-the-art. Code available:\nhttps://github.com/huangdonghere/FastMICE.\n","authors":["Dong Huang","Chang-Dong Wang","Jian-Huang Lai"],"pdf_url":"https://arxiv.org/pdf/2203.11572v4.pdf","comment":"To appear in IEEE Transactions on Knowledge and Data Engineering"},{"id":"http://arxiv.org/abs/2208.12268v3","updated":"2023-01-24T13:07:01Z","published":"2022-08-25T15:27:41Z","title":"FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning\n  in Federated Learning","summary":"  Federated learning (FL) has enabled global model training on decentralized\ndata in a privacy-preserving way by aggregating model updates. However, for\nmany natural language processing (NLP) tasks that utilize pre-trained language\nmodels (PLMs) with large numbers of parameters, there are considerable\ncommunication costs associated with FL. Recently, prompt tuning, which tunes\nsome soft prompts without modifying PLMs, has achieved excellent performance as\na new learning paradigm. Therefore we want to combine the two methods and\nexplore the effect of prompt tuning under FL. In this paper, we propose\n\"FedPrompt\" to study prompt tuning in a model split aggregation way using FL,\nand prove that split aggregation greatly reduces the communication cost, only\n0.01% of the PLMs' parameters, with little decrease on accuracy both on IID and\nNon-IID data distribution. This improves the efficiency of FL method while also\nprotecting the data privacy in prompt tuning. In addition, like PLMs, prompts\nare uploaded and downloaded between public platforms and personal users, so we\ntry to figure out whether there is still a backdoor threat using only soft\nprompts in FL scenarios. We further conduct backdoor attacks by data poisoning\non FedPrompt. Our experiments show that normal backdoor attack can not achieve\na high attack success rate, proving the robustness of FedPrompt. We hope this\nwork can promote the application of prompt in FL and raise the awareness of the\npossible security threats.\n","authors":["Haodong Zhao","Wei Du","Fangqi Li","Peixuan Li","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2208.12268v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.08549v4","updated":"2023-01-24T13:02:18Z","published":"2021-09-17T13:45:46Z","title":"Measuring Fairness Under Unawareness of Sensitive Attributes: A\n  Quantification-Based Approach","summary":"  Algorithms and models are increasingly deployed to inform decisions about\npeople, inevitably affecting their lives. As a consequence, those in charge of\ndeveloping these models must carefully evaluate their impact on different\ngroups of people and favour group fairness, that is, ensure that groups\ndetermined by sensitive demographic attributes, such as race or sex, are not\ntreated unjustly. To achieve this goal, the availability (awareness) of these\ndemographic attributes to those evaluating the impact of these models is\nfundamental. Unfortunately, collecting and storing these attributes is often in\nconflict with industry practices and legislation on data minimisation and\nprivacy. For this reason, it can be hard to measure the group fairness of\ntrained models, even from within the companies developing them. In this work,\nwe tackle the problem of measuring group fairness under unawareness of\nsensitive attributes, by using techniques from quantification, a supervised\nlearning task concerned with directly providing group-level prevalence\nestimates (rather than individual-level class labels). We show that\nquantification approaches are particularly suited to tackle the\nfairness-under-unawareness problem, as they are robust to inevitable\ndistribution shifts while at the same time decoupling the (desirable) objective\nof measuring group fairness from the (undesirable) side effect of allowing the\ninference of sensitive attributes of individuals. More in detail, we show that\nfairness under unawareness can be cast as a quantification problem and solved\nwith proven methods from the quantification literature. We show that these\nmethods outperform previous approaches to measure demographic parity in five\nexperimental protocols, corresponding to important challenges that complicate\nthe estimation of classifier fairness under unawareness.\n","authors":["Alessandro Fabris","Andrea Esuli","Alejandro Moreo","Fabrizio Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2109.08549v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09956v1","updated":"2023-01-24T12:34:27Z","published":"2023-01-24T12:34:27Z","title":"Membership Inference of Diffusion Models","summary":"  Recent years have witnessed the tremendous success of diffusion models in\ndata synthesis. However, when diffusion models are applied to sensitive data,\nthey also give rise to severe privacy concerns. In this paper, we\nsystematically present the first study about membership inference attacks\nagainst diffusion models, which aims to infer whether a sample was used to\ntrain the model. Two attack methods are proposed, namely loss-based and\nlikelihood-based attacks. Our attack methods are evaluated on several\nstate-of-the-art diffusion models, over different datasets in relation to\nprivacy-sensitive data. Extensive experimental evaluations show that our\nattacks can achieve remarkable performance. Furthermore, we exhaustively\ninvestigate various factors which can affect attack performance. Finally, we\nalso evaluate the performance of our attack methods on diffusion models trained\nwith differential privacy.\n","authors":["Hailong Hu","Jun Pang"],"pdf_url":"https://arxiv.org/pdf/2301.09956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08143v3","updated":"2023-01-24T12:23:48Z","published":"2022-07-17T11:24:44Z","title":"Can large language models reason about medical questions?","summary":"  Although large language models (LLMs) often produce impressive outputs, it\nremains unclear how they perform in real-world scenarios requiring strong\nreasoning skills and expert domain knowledge. We set out to investigate whether\nGPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about\ndifficult real-world-based questions. We utilize two multiple-choice medical\nexam questions (USMLE and MedMCQA) and a medical reading comprehension dataset\n(PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT,\nthink step-by-step), zero- and few-shot (prepending the question with\nquestion-answer exemplars) and retrieval augmentation (injecting Wikipedia\npassages into the prompt). For a subset of the USMLE questions, a medical\nexpert reviewed and annotated the model's CoT. We found that InstructGPT can\noften read, reason and recall expert knowledge. Failure are primarily due to\nlack of knowledge and reasoning errors and trivial guessing heuristics are\nobserved, e.g.\\ too often predicting labels A and D on USMLE. Sampling and\ncombining many completions overcome some of these limitations. Using 100\nsamples, Codex 5-shot CoT not only gives close to well-calibrated predictive\nprobability but also achieves human-level performances on the three datasets.\nUSMLE: 60.2%, MedMCQA: 62.7% and PubMedQA: 78.2%.\n","authors":["Valentin Liévin","Christoffer Egeberg Hother","Ole Winther"],"pdf_url":"https://arxiv.org/pdf/2207.08143v3.pdf","comment":"33 pages, 6 figures, to be submitted. v1: results using InstructGPT,\n  v2: added the Codex experiments, v3: added the missing test MedMCQA results\n  for Codex 5-shot CoT and using k=100 samples"},{"id":"http://arxiv.org/abs/2301.09943v1","updated":"2023-01-24T12:01:45Z","published":"2023-01-24T12:01:45Z","title":"Learning To Dive In Branch And Bound","summary":"  Primal heuristics are important for solving mixed integer linear programs,\nbecause they find feasible solutions that facilitate branch and bound search. A\nprominent group of primal heuristics are diving heuristics. They iteratively\nmodify and resolve linear programs to conduct a depth-first search from any\nnode in the search tree. Existing divers rely on generic decision rules that\nfail to exploit structural commonality between similar problem instances that\noften arise in practice. Therefore, we propose L2Dive to learn specific diving\nheuristics with graph neural networks: We train generative models to predict\nvariable assignments and leverage the duality of linear programs to make diving\ndecisions based on the model's predictions. L2Dive is fully integrated into the\nopen-source solver SCIP. We find that L2Dive outperforms standard divers to\nfind better feasible solutions on a range of combinatorial optimization\nproblems. For real-world applications from server load balancing and neural\nnetwork verification, L2Dive improves the primal-dual integral by up to 7%\n(35%) on average over a tuned (default) solver baseline and reduces average\nsolving time by 20% (29%).\n","authors":["Max B. Paulus","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2301.09943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09939v1","updated":"2023-01-24T11:46:09Z","published":"2023-01-24T11:46:09Z","title":"Solving the Discretised Neutron Diffusion Equations using Neural\n  Networks","summary":"  This paper presents a new approach which uses the tools within Artificial\nIntelligence (AI) software libraries as an alternative way of solving partial\ndifferential equations (PDEs) that have been discretised using standard\nnumerical methods. In particular, we describe how to represent numerical\ndiscretisations arising from the finite volume and finite element methods by\npre-determining the weights of convolutional layers within a neural network. As\nthe weights are defined by the discretisation scheme, no training of the\nnetwork is required and the solutions obtained are identical (accounting for\nsolver tolerances) to those obtained with standard codes often written in\nFortran or C++. We also explain how to implement the Jacobi method and a\nmultigrid solver using the functions available in AI libraries. For the latter,\nwe use a U-Net architecture which is able to represent a sawtooth multigrid\nmethod. A benefit of using AI libraries in this way is that one can exploit\ntheir power and their built-in technologies. For example, their executions are\nalready optimised for different computer architectures, whether it be CPUs,\nGPUs or new-generation AI processors. In this article, we apply the proposed\napproach to eigenvalue problems in reactor physics where neutron transport is\ndescribed by diffusion theory. For a fuel assembly benchmark, we demonstrate\nthat the solution obtained from our new approach is the same (accounting for\nsolver tolerances) as that obtained from the same discretisation coded in a\nstandard way using Fortran. We then proceed to solve a reactor core benchmark\nusing the new approach.\n","authors":["T. R. F. Phillips","C. E. Heaney","C. Boyang","A. G. Buchan","C. C. Pain"],"pdf_url":"https://arxiv.org/pdf/2301.09939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09937v1","updated":"2023-01-24T11:41:25Z","published":"2023-01-24T11:41:25Z","title":"Explainable Deep Reinforcement Learning: State of the Art and Challenges","summary":"  Interpretability, explainability and transparency are key issues to\nintroducing Artificial Intelligence methods in many critical domains: This is\nimportant due to ethical concerns and trust issues strongly connected to\nreliability, robustness, auditability and fairness, and has important\nconsequences towards keeping the human in the loop in high levels of\nautomation, especially in critical cases for decision making, where both (human\nand the machine) play important roles. While the research community has given\nmuch attention to explainability of closed (or black) prediction boxes, there\nare tremendous needs for explainability of closed-box methods that support\nagents to act autonomously in the real world. Reinforcement learning methods,\nand especially their deep versions, are such closed-box methods. In this\narticle we aim to provide a review of state of the art methods for explainable\ndeep reinforcement learning methods, taking also into account the needs of\nhuman operators - i.e., of those that take the actual and critical decisions in\nsolving real-world problems. We provide a formal specification of the deep\nreinforcement learning explainability problems, and we identify the necessary\ncomponents of a general explainable reinforcement learning framework. Based on\nthese, we provide a comprehensive review of state of the art methods,\ncategorizing them in classes according to the paradigm they follow, the\ninterpretable models they use, and the surface representation of explanations\nprovided. The article concludes identifying open questions and important\nchallenges.\n","authors":["George A. Vouros"],"pdf_url":"https://arxiv.org/pdf/2301.09937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09936v1","updated":"2023-01-24T11:40:28Z","published":"2023-01-24T11:40:28Z","title":"Efficient learning of large sets of locally optimal classification rules","summary":"  Conventional rule learning algorithms aim at finding a set of simple rules,\nwhere each rule covers as many examples as possible. In this paper, we argue\nthat the rules found in this way may not be the optimal explanations for each\nof the examples they cover. Instead, we propose an efficient algorithm that\naims at finding the best rule covering each training example in a greedy\noptimization consisting of one specialization and one generalization loop.\nThese locally optimal rules are collected and then filtered for a final rule\nset, which is much larger than the sets learned by conventional rule learning\nalgorithms. A new example is classified by selecting the best among the rules\nthat cover this example. In our experiments on small to very large datasets,\nthe approach's average classification accuracy is higher than that of\nstate-of-the-art rule learning algorithms. Moreover, the algorithm is highly\nefficient and can inherently be processed in parallel without affecting the\nlearned rule set and so the classification accuracy. We thus believe that it\ncloses an important gap for large-scale classification rule induction.\n","authors":["Van Quoc Phuong Huynh","Johannes Fürnkranz","Florian Beck"],"pdf_url":"https://arxiv.org/pdf/2301.09936v1.pdf","comment":"article, 40 pages, Machine Learning journal (2023)"},{"id":"http://arxiv.org/abs/2301.09930v1","updated":"2023-01-24T11:27:17Z","published":"2023-01-24T11:27:17Z","title":"Quadruple-star systems are not always nested triples: a machine learning\n  approach to dynamical stability","summary":"  The dynamical stability of quadruple-star systems has traditionally been\ntreated as a problem involving two `nested' triples which constitute a\nquadruple. In this novel study, we employed a machine learning algorithm, the\nmulti-layer perceptron (MLP), to directly classify 2+2 and 3+1 quadruples based\non their stability (or long-term boundedness). The training data sets for the\nclassification, comprised of $5\\times10^5$ quadruples each, were integrated\nusing the highly accurate direct $N$-body code MSTAR. We also carried out a\nlimited parameter space study of zero-inclination systems to directly compare\nquadruples to triples. We found that both our quadruple MLP models perform\nbetter than a `nested' triple MLP approach, which is especially significant for\n3+1 quadruples. The classification accuracies for the 2+2 MLP and 3+1 MLP\nmodels are 94% and 93% respectively, while the scores for the `nested' triple\napproach are 88% and 66% respectively. This is a crucial implication for\nquadruple population synthesis studies. Our MLP models, which are very simple\nand almost instantaneous to implement, are available on GitHub, along with\nPython3 scripts to access them.\n","authors":["Pavan Vynatheya","Rosemary A. Mardling","Adrian S. Hamers"],"pdf_url":"https://arxiv.org/pdf/2301.09930v1.pdf","comment":"10 pages, 7 figures; Submitted to MNRAS"},{"id":"http://arxiv.org/abs/2301.09926v1","updated":"2023-01-24T11:24:18Z","published":"2023-01-24T11:24:18Z","title":"A two stages Deep Learning Architecture for Model Reduction of\n  Parametric Time-Dependent Problems","summary":"  Parametric time-dependent systems are of a crucial importance in modeling\nreal phenomena, often characterized by non-linear behaviors too. Those\nsolutions are typically difficult to generalize in a sufficiently wide\nparameter space while counting on limited computational resources available. As\nsuch, we present a general two-stages deep learning framework able to perform\nthat generalization with low computational effort in time. It consists in a\nseparated training of two pipe-lined predictive models. At first, a certain\nnumber of independent neural networks are trained with data-sets taken from\ndifferent subsets of the parameter space. Successively, a second predictive\nmodel is specialized to properly combine the first-stage guesses and compute\nthe right predictions. Promising results are obtained applying the framework to\nincompressible Navier-Stokes equations in a cavity (Rayleigh-Bernard cavity),\nobtaining a 97% reduction in the computational time comparing with its\nnumerical resolution for a new value of the Grashof number.\n","authors":["Isabella Carla Gonnella","Martin W. Hess","Giovanni Stabile","Gianluigi Rozza"],"pdf_url":"https://arxiv.org/pdf/2301.09926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.03104v2","updated":"2023-01-24T11:19:27Z","published":"2021-11-22T11:02:35Z","title":"HTMOT : Hierarchical Topic Modelling Over Time","summary":"  Over the years, topic models have provided an efficient way of extracting\ninsights from text. However, while many models have been proposed, none are\nable to model topic temporality and hierarchy jointly. Modelling time provide\nmore precise topics by separating lexically close but temporally distinct\ntopics while modelling hierarchy provides a more detailed view of the content\nof a document corpus. In this study, we therefore propose a novel method,\nHTMOT, to perform Hierarchical Topic Modelling Over Time. We train HTMOT using\na new implementation of Gibbs sampling, which is more efficient. Specifically,\nwe show that only applying time modelling to deep sub-topics provides a way to\nextract specific stories or events while high level topics extract larger\nthemes in the corpus. Our results show that our training procedure is fast and\ncan extract accurate high-level topics and temporally precise sub-topics. We\nmeasured our model's performance using the Word Intrusion task and outlined\nsome limitations of this evaluation method, especially for hierarchical models.\nAs a case study, we focused on the various developments in the space industry\nin 2020.\n","authors":["Judicael Poumay","Ashwin Ittoo"],"pdf_url":"https://arxiv.org/pdf/2112.03104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10291v3","updated":"2023-01-24T11:09:30Z","published":"2022-08-22T13:19:02Z","title":"Efficient Planning in a Compact Latent Action Space","summary":"  Planning-based reinforcement learning has shown strong performance in tasks\nin discrete and low-dimensional continuous action spaces. However, planning\nusually brings significant computational overhead for decision-making, and\nscaling such methods to high-dimensional action spaces remains challenging. To\nadvance efficient planning for high-dimensional continuous control, we propose\nTrajectory Autoencoding Planner (TAP), which learns low-dimensional latent\naction codes with a state-conditional VQ-VAE. The decoder of the VQ-VAE thus\nserves as a novel dynamics model that takes latent actions and current state as\ninput and reconstructs long-horizon trajectories. During inference time, given\na starting state, TAP searches over discrete latent actions to find\ntrajectories that have both high probability under the training distribution\nand high predicted cumulative reward. Empirical evaluation in the offline RL\nsetting demonstrates low decision latency which is indifferent to the growing\nraw action dimensionality. For Adroit robotic hand manipulation tasks with\nhigh-dimensional continuous action space, TAP surpasses existing model-based\nmethods by a large margin and also beats strong model-free actor-critic\nbaselines.\n","authors":["Zhengyao Jiang","Tianjun Zhang","Michael Janner","Yueying Li","Tim Rocktäschel","Edward Grefenstette","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2208.10291v3.pdf","comment":"Accepted by ICLR2023. Code available at\n  https://github.com/ZhengyaoJiang/latentplan"},{"id":"http://arxiv.org/abs/2301.08664v2","updated":"2023-01-24T11:04:47Z","published":"2023-01-20T16:30:44Z","title":"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","summary":"  The quality of the video stream is key to neural network-based video\nanalytics. However, low-quality video is inevitably collected by existing\nsurveillance systems because of poor quality cameras or over-compressed/pruned\nvideo streaming protocols, e.g., as a result of upstream bandwidth limit. To\naddress this issue, existing studies use quality enhancers (e.g., neural\nsuper-resolution) to improve the quality of videos (e.g., resolution) and\neventually ensure inference accuracy. Nevertheless, directly applying quality\nenhancers does not work in practice because it will introduce unacceptable\nlatency. In this paper, we present AccDecoder, a novel accelerated decoder for\nreal-time and neural-enhanced video analytics. AccDecoder can select a few\nframes adaptively via Deep Reinforcement Learning (DRL) to enhance the quality\nby neural super-resolution and then up-scale the unselected frames that\nreference them, which leads to 6-21% accuracy improvement. AccDecoder provides\nefficient inference capability via filtering important frames using DRL for\nDNN-based inference and reusing the results for the other frames via extracting\nthe reference relationship among frames and blocks, which results in a latency\nreduction of 20-80% than baselines.\n","authors":["Tingting Yuan","Liang Mi","Weijun Wang","Haipeng Dai","Xiaoming Fu"],"pdf_url":"https://arxiv.org/pdf/2301.08664v2.pdf","comment":"Accepted by 2023 IEEE INFOCOM"},{"id":"http://arxiv.org/abs/2110.11205v3","updated":"2023-01-24T10:55:13Z","published":"2021-10-21T15:30:40Z","title":"Robustness through Data Augmentation Loss Consistency","summary":"  While deep learning through empirical risk minimization (ERM) has succeeded\nat achieving human-level performance at a variety of complex tasks, ERM is not\nrobust to distribution shifts or adversarial attacks. Synthetic data\naugmentation followed by empirical risk minimization (DA-ERM) is a simple and\nwidely used solution to improve robustness in ERM. In addition, consistency\nregularization can be applied to further improve the robustness of the model by\nforcing the representation of the original sample and the augmented one to be\nsimilar. However, existing consistency regularization methods are not\napplicable to covariant data augmentation, where the label in the augmented\nsample is dependent on the augmentation function. For example, dialog state\ncovaries with named entity when we augment data with a new named entity. In\nthis paper, we propose data augmented loss invariant regularization (DAIR), a\nsimple form of consistency regularization that is applied directly at the loss\nlevel rather than intermediate features, making it widely applicable to both\ninvariant and covariant data augmentation regardless of network architecture,\nproblem setup, and task. We apply DAIR to real-world learning problems\ninvolving covariant data augmentation: robust neural task-oriented dialog state\ntracking and robust visual question answering. We also apply DAIR to tasks\ninvolving invariant data augmentation: robust regression, robust classification\nagainst adversarial attacks, and robust ImageNet classification under\ndistribution shift. Our experiments show that DAIR consistently outperforms ERM\nand DA-ERM with little marginal computational cost and sets new\nstate-of-the-art results in several benchmarks involving covariant data\naugmentation. Our code of all experiments is available at:\nhttps://github.com/optimization-for-data-driven-science/DAIR.git\n","authors":["Tianjian Huang","Shaunak Halbe","Chinnadhurai Sankar","Pooyan Amini","Satwik Kottur","Alborz Geramifard","Meisam Razaviyayn","Ahmad Beirami"],"pdf_url":"https://arxiv.org/pdf/2110.11205v3.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2301.08632v2","updated":"2023-01-24T10:29:43Z","published":"2023-01-20T15:28:09Z","title":"Generative Slate Recommendation with Reinforcement Learning","summary":"  Recent research has employed reinforcement learning (RL) algorithms to\noptimize long-term user engagement in recommender systems, thereby avoiding\ncommon pitfalls such as user boredom and filter bubbles. They capture the\nsequential and interactive nature of recommendations, and thus offer a\nprincipled way to deal with long-term rewards and avoid myopic behaviors.\nHowever, RL approaches are intractable in the slate recommendation scenario -\nwhere a list of items is recommended at each interaction turn - due to the\ncombinatorial action space. In that setting, an action corresponds to a slate\nthat may contain any combination of items.\n  While previous work has proposed well-chosen decompositions of actions so as\nto ensure tractability, these rely on restrictive and sometimes unrealistic\nassumptions. Instead, in this work we propose to encode slates in a continuous,\nlow-dimensional latent space learned by a variational auto-encoder. Then, the\nRL agent selects continuous actions in this latent space, which are ultimately\ndecoded into the corresponding slates. By doing so, we are able to (i) relax\nassumptions required by previous work, and (ii) improve the quality of the\naction selection by modeling full slates instead of independent items, in\nparticular by enabling diversity. Our experiments performed on a wide array of\nsimulated environments confirm the effectiveness of our generative modeling of\nslates over baselines in practical scenarios where the restrictive assumptions\nunderlying the baselines are lifted. Our findings suggest that representation\nlearning using generative models is a promising direction towards generalizable\nRL-based slate recommendation.\n","authors":["Romain Deffayet","Thibaut Thonet","Jean-Michel Renders","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2301.08632v2.pdf","comment":"WSDM 2023, 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.09902v1","updated":"2023-01-24T10:19:24Z","published":"2023-01-24T10:19:24Z","title":"Investigating Labeler Bias in Face Annotation for Machine Learning","summary":"  In a world increasingly reliant on artificial intelligence, it is more\nimportant than ever to consider the ethical implications of artificial\nintelligence on humanity. One key under-explored challenge is labeler bias,\nwhich can create inherently biased datasets for training and subsequently lead\nto inaccurate or unfair decisions in healthcare, employment, education, and law\nenforcement. Hence, we conducted a study to investigate and measure the\nexistence of labeler bias using images of people from different ethnicities and\nsexes in a labeling task. Our results show that participants possess\nstereotypes that influence their decision-making process and that labeler\ndemographics impact assigned labels. We also discuss how labeler bias\ninfluences datasets and, subsequently, the models trained on them. Overall, a\nhigh degree of transparency must be maintained throughout the entire artificial\nintelligence training process to identify and correct biases in the data as\nearly as possible.\n","authors":["Luke Haliburton","Sinksar Ghebremedhin","Robin Welsch","Albrecht Schmidt","Sven Mayer"],"pdf_url":"https://arxiv.org/pdf/2301.09902v1.pdf","comment":"Pre-print currently under review"},{"id":"http://arxiv.org/abs/2301.09880v1","updated":"2023-01-24T09:37:00Z","published":"2023-01-24T09:37:00Z","title":"Probabilistic Bilevel Coreset Selection","summary":"  The goal of coreset selection in supervised learning is to produce a weighted\nsubset of data, so that training only on the subset achieves similar\nperformance as training on the entire dataset. Existing methods achieved\npromising results in resource-constrained scenarios such as continual learning\nand streaming. However, most of the existing algorithms are limited to\ntraditional machine learning models. A few algorithms that can handle large\nmodels adopt greedy search approaches due to the difficulty in solving the\ndiscrete subset selection problem, which is computationally costly when coreset\nbecomes larger and often produces suboptimal results. In this work, for the\nfirst time we propose a continuous probabilistic bilevel formulation of coreset\nselection by learning a probablistic weight for each training sample. The\noverall objective is posed as a bilevel optimization problem, where 1) the\ninner loop samples coresets and train the model to convergence and 2) the outer\nloop updates the sample probability progressively according to the model's\nperformance. Importantly, we develop an efficient solver to the bilevel\noptimization problem via unbiased policy gradient without trouble of implicit\ndifferentiation. We provide the convergence property of our training procedure\nand demonstrate the superiority of our algorithm against various coreset\nselection methods in various tasks, especially in more challenging label-noise\nand class-imbalance scenarios.\n","authors":["Xiao Zhou","Renjie Pi","Weizhong Zhang","Yong Lin","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.09880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09879v1","updated":"2023-01-24T09:36:39Z","published":"2023-01-24T09:36:39Z","title":"Data Augmentation Alone Can Improve Adversarial Training","summary":"  Adversarial training suffers from the issue of robust overfitting, which\nseriously impairs its generalization performance. Data augmentation, which is\neffective at preventing overfitting in standard training, has been observed by\nmany previous works to be ineffective in mitigating overfitting in adversarial\ntraining. This work proves that, contrary to previous findings, data\naugmentation alone can significantly boost accuracy and robustness in\nadversarial training. We find that the hardness and the diversity of data\naugmentation are important factors in combating robust overfitting. In general,\ndiversity can improve both accuracy and robustness, while hardness can boost\nrobustness at the cost of accuracy within a certain limit and degrade them both\nover that limit. To mitigate robust overfitting, we first propose a new crop\ntransformation, Cropshift, which has improved diversity compared to the\nconventional one (Padcrop). We then propose a new data augmentation scheme,\nbased on Cropshift, with much improved diversity and well-balanced hardness.\nEmpirically, our augmentation method achieves the state-of-the-art accuracy and\nrobustness for data augmentations in adversarial training. Furthermore, when\ncombined with weight averaging it matches, or even exceeds, the performance of\nthe best contemporary regularization methods for alleviating robust\noverfitting. Code is available at:\nhttps://github.com/TreeLLi/DA-Alone-Improves-AT.\n","authors":["Lin Li","Michael Spratling"],"pdf_url":"https://arxiv.org/pdf/2301.09879v1.pdf","comment":"published at conference ICLR2023"},{"id":"http://arxiv.org/abs/2203.13273v5","updated":"2023-01-24T09:36:08Z","published":"2022-03-24T18:00:32Z","title":"A DNN Optimizer that Improves over AdaBelief by Suppression of the\n  Adaptive Stepsize Range","summary":"  We make contributions towards improving adaptive-optimizer performance. Our\nimprovements are based on suppression of the range of adaptive stepsizes in the\nAdaBelief optimizer. Firstly, we show that the particular placement of the\nparameter epsilon within the update expressions of AdaBelief reduces the range\nof the adaptive stepsizes, making AdaBelief closer to SGD with momentum.\nSecondly, we extend AdaBelief by further suppressing the range of the adaptive\nstepsizes. To achieve the above goal, we perform mutual layerwise vector\nprojections between the gradient g_t and its first momentum m_t before using\nthem to estimate the second momentum. The new optimization method is referred\nto as Aida. Thirdly, extensive experimental results show that Aida outperforms\nnine optimizers when training transformers and LSTMs for NLP, and VGG and\nResNet for image classification over CIAF10 and CIFAR100 while matching the\nbest performance of the nine methods when training WGAN-GP models for image\ngeneration tasks. Furthermore, Aida produces higher validation accuracies than\nAdaBelief for training ResNet18 over ImageNet. Code is available <a\nhref=\"https://github.com/guoqiang-x-zhang/AidaOptimizer\">at this URL</a>\n","authors":["Guoqiang Zhang","Kenta Niwa","W. Bastiaan Kleijn"],"pdf_url":"https://arxiv.org/pdf/2203.13273v5.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2202.07993v2","updated":"2023-01-24T09:33:37Z","published":"2022-02-16T11:13:37Z","title":"Planckian Jitter: countering the color-crippling effects of color jitter\n  on self-supervised training","summary":"  Several recent works on self-supervised learning are trained by mapping\ndifferent augmentations of the same image to the same feature representation.\nThe data augmentations used are of crucial importance to the quality of learned\nfeature representations. In this paper, we analyze how the color jitter\ntraditionally used in data augmentation negatively impacts the quality of the\ncolor features in learned feature representations. To address this problem, we\npropose a more realistic, physics-based color data augmentation - which we call\nPlanckian Jitter - that creates realistic variations in chromaticity and\nproduces a model robust to illumination changes that can be commonly observed\nin real life, while maintaining the ability to discriminate image content based\non color information. Experiments confirm that such a representation is\ncomplementary to the representations learned with the currently-used color\njitter augmentation and that a simple concatenation leads to significant\nperformance gains on a wide range of downstream datasets. In addition, we\npresent a color sensitivity analysis that documents the impact of different\ntraining methods on model neurons and shows that the performance of the learned\nfeatures is robust with respect to illuminant variations.\n","authors":["Simone Zini","Alex Gomez-Villa","Marco Buzzelli","Bartłomiej Twardowski","Andrew D. Bagdanov","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2202.07993v2.pdf","comment":"Accepted at Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2212.08072v2","updated":"2023-01-24T09:24:23Z","published":"2022-12-13T19:06:00Z","title":"Foresight -- Generative Pretrained Transformer (GPT) for Modelling of\n  Patient Timelines using EHRs","summary":"  Background: Electronic Health Records hold detailed longitudinal information\nabout each patient's health status and general clinical history, a large\nportion of which is stored within the unstructured text. Existing approaches\nfocus mostly on structured data and a subset of single-domain outcomes. We\nexplore how temporal modelling of patients from free text and structured data,\nusing deep generative transformers can be used to forecast a wide range of\nfuture disorders, substances, procedures or findings. Methods: We present\nForesight, a novel transformer-based pipeline that uses named entity\nrecognition and linking tools to convert document text into structured, coded\nconcepts, followed by providing probabilistic forecasts for future medical\nevents such as disorders, substances, procedures and findings. We processed the\nentire free-text portion from three different hospital datasets totalling\n811336 patients covering both physical and mental health. Findings: On tests in\ntwo UK hospitals (King's College Hospital, South London and Maudsley) and the\nUS MIMIC-III dataset precision@10 0.68, 0.76 and 0.88 was achieved for\nforecasting the next disorder in a patient timeline, while precision@10 of\n0.80, 0.81 and 0.91 was achieved for forecasting the next biomedical concept.\nForesight was also validated on 34 synthetic patient timelines by five\nclinicians and achieved relevancy of 97% for the top forecasted candidate\ndisorder. As a generative model, it can forecast follow-on biomedical concepts\nfor as many steps as required. Interpretation: Foresight is a general-purpose\nmodel for biomedical concept modelling that can be used for real-world risk\nforecasting, virtual trials and clinical research to study the progression of\ndisorders, simulate interventions and counterfactuals, and educational\npurposes.\n","authors":["Zeljko Kraljevic","Dan Bean","Anthony Shek","Rebecca Bendayan","Harry Hemingway","Joshua Au Yeung","Alexander Deng","Alfie Baston","Jack Ross","Esther Idowu","James T Teo","Richard J Dobson"],"pdf_url":"https://arxiv.org/pdf/2212.08072v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09870v1","updated":"2023-01-24T09:10:38Z","published":"2023-01-24T09:10:38Z","title":"Context-specific kernel-based hidden Markov model for time series\n  analysis","summary":"  Traditional hidden Markov models have been a useful tool to understand and\nmodel stochastic dynamic linear data; in the case of non-Gaussian data or not\nlinear in mean data, models such as mixture of Gaussian hidden Markov models\nsuffer from the computation of precision matrices and have a lot of unnecessary\nparameters. As a consequence, such models often perform better when it is\nassumed that all variables are independent, a hypothesis that may be\nunrealistic. Hidden Markov models based on kernel density estimation is also\ncapable of modeling non Gaussian data, but they assume independence between\nvariables. In this article, we introduce a new hidden Markov model based on\nkernel density estimation, which is capable of introducing kernel dependencies\nusing context-specific Bayesian networks. The proposed model is described,\ntogether with a learning algorithm based on the expectation-maximization\nalgorithm. Additionally, the model is compared with related HMMs using\nsynthetic and real data. From the results, the benefits in likelihood and\nclassification accuracy from the proposed model are quantified and analyzed.\n","authors":["Carlos Puerto-Santana","Concha Bielza","Pedro Larrañaga","Gustav Eje Henter"],"pdf_url":"https://arxiv.org/pdf/2301.09870v1.pdf","comment":"Keywords: Hidden Markov models, Kernel density estimation, Bayesian\n  networks, Adaptive models, Time series"},{"id":"http://arxiv.org/abs/2301.09862v1","updated":"2023-01-24T08:48:12Z","published":"2023-01-24T08:48:12Z","title":"Same or Different? Diff-Vectors for Authorship Analysis","summary":"  We investigate the effects on authorship identification tasks of a\nfundamental shift in how to conceive the vectorial representations of documents\nthat are given as input to a supervised learner. In ``classic'' authorship\nanalysis a feature vector represents a document, the value of a feature\nrepresents (an increasing function of) the relative frequency of the feature in\nthe document, and the class label represents the author of the document. We\ninstead investigate the situation in which a feature vector represents an\nunordered pair of documents, the value of a feature represents the absolute\ndifference in the relative frequencies (or increasing functions thereof) of the\nfeature in the two documents, and the class label indicates whether the two\ndocuments are from the same author or not. This latter (learner-independent)\ntype of representation has been occasionally used before, but has never been\nstudied systematically. We argue that it is advantageous, and that in some\ncases (e.g., authorship verification) it provides a much larger quantity of\ninformation to the training process than the standard representation. The\nexperiments that we carry out on several publicly available datasets (among\nwhich one that we here make available for the first time) show that feature\nvectors representing pairs of documents (that we here call Diff-Vectors) bring\nabout systematic improvements in the effectiveness of authorship identification\ntasks, and especially so when training data are scarce (as it is often the case\nin real-life authorship identification scenarios). Our experiments tackle\nsame-author verification, authorship verification, and closed-set authorship\nattribution; while DVs are naturally geared for solving the 1st, we also\nprovide two novel methods for solving the 2nd and 3rd that use a solver for the\n1st as a building block.\n","authors":["Silvia Corbara","Alejandro Moreo","Fabrizio Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2301.09862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09860v1","updated":"2023-01-24T08:39:20Z","published":"2023-01-24T08:39:20Z","title":"A predictive physics-aware hybrid reduced order model for reacting flows","summary":"  In this work, a new hybrid predictive Reduced Order Model (ROM) is proposed\nto solve reacting flow problems. This algorithm is based on a dimensionality\nreduction using Proper Orthogonal Decomposition (POD) combined with deep\nlearning architectures. The number of degrees of freedom is reduced from\nthousands of temporal points to a few POD modes with their corresponding\ntemporal coefficients. Two different deep learning architectures have been\ntested to predict the temporal coefficients, based on recursive (RNN) and\nconvolutional (CNN) neural networks. From each architecture, different models\nhave been created to understand the behavior of each parameter of the neural\nnetwork. Results show that these architectures are able to predict the temporal\ncoefficients of the POD modes, as well as the whole snapshots. The RNN shows\nlower prediction error for all the variables analyzed. The model was also found\ncapable of predicting more complex simulations showing transfer learning\ncapabilities.\n","authors":["Adrián Corrochano","Rodolfo S. M. Freitas","Alessandro Parente","Soledad Le Clainche"],"pdf_url":"https://arxiv.org/pdf/2301.09860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.01234v2","updated":"2023-01-24T08:08:11Z","published":"2022-07-04T07:06:45Z","title":"Incorporating functional summary information in Bayesian neural networks\n  using a Dirichlet process likelihood approach","summary":"  Bayesian neural networks (BNNs) can account for both aleatoric and epistemic\nuncertainty. However, in BNNs the priors are often specified over the weights\nwhich rarely reflects true prior knowledge in large and complex neural network\narchitectures. We present a simple approach to incorporate prior knowledge in\nBNNs based on external summary information about the predicted classification\nprobabilities for a given dataset. The available summary information is\nincorporated as augmented data and modeled with a Dirichlet process, and we\nderive the corresponding \\emph{Summary Evidence Lower BOund}. The approach is\nfounded on Bayesian principles, and all hyperparameters have a proper\nprobabilistic interpretation. We show how the method can inform the model about\ntask difficulty and class imbalance. Extensive experiments show that, with\nnegligible computational overhead, our method parallels and in many cases\noutperforms popular alternatives in accuracy, uncertainty calibration, and\nrobustness against corruptions with both balanced and imbalanced data.\n","authors":["Vishnu Raj","Tianyu Cui","Markus Heinonen","Pekka Marttinen"],"pdf_url":"https://arxiv.org/pdf/2207.01234v2.pdf","comment":"Accepted in AISTATS 2023"},{"id":"http://arxiv.org/abs/2301.06418v3","updated":"2023-01-24T08:00:55Z","published":"2023-01-16T13:19:18Z","title":"Mind the Gap -- Modelling Difference Between Censored and Uncensored\n  Electric Vehicle Charging Demand","summary":"  Electric vehicle charging demand models, with charging records as input, will\ninherently be biased toward the supply of available chargers, as the data do\nnot include demand lost from occupied stations and competitors. This lost\ndemand implies that the records only observe a fraction of the total demand,\ni.e. the observations are censored, and actual demand is likely higher than\nwhat the data reflect. Machine learning models often neglect to account for\nthis censored demand when forecasting the charging demand, which limits models'\napplications for future expansions and supply management. We address this gap\nby modelling the charging demand with probabilistic censorship-aware graph\nneural networks, which learn the latent demand distribution in both the spatial\nand temporal dimensions. We use GPS trajectories from cars in Copenhagen,\nDenmark, to study how censoring occurs and much demand is lost due to occupied\ncharging and competing services. We find that censorship varies throughout the\ncity and over time, encouraging spatial and temporal modelling. We find that in\nsome regions of Copenhagen, censorship occurs 61% of the time. Our results show\ncensorship-aware models provide better prediction and uncertainty estimation in\nactual future demand than censorship-unaware models. Our results suggest that\nfuture models based on charging records should account for the censoring to\nexpand the application areas of machine learning models in this supply\nmanagement and infrastructure expansion.\n","authors":["Frederik Boe Hüttel","Filipe Rodrigues","Francisco Câmara Pereira"],"pdf_url":"https://arxiv.org/pdf/2301.06418v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09851v1","updated":"2023-01-24T07:56:44Z","published":"2023-01-24T07:56:44Z","title":"Neighborhood Homophily-Guided Graph Convolutional Network","summary":"  Graph neural networks (GNNs) have achieved remarkable advances in\ngraph-oriented tasks. However, many real-world graphs contain heterophily or\nlow homophily, challenging the homophily assumption of classical GNNs and\nresulting in low performance. Although many studies have emerged to improve the\nuniversality of GNNs, they rarely consider the label reuse and the correlation\nof their proposed metrics and models. In this paper, we first design a new\nmetric, named Neighborhood Homophily (\\textit{NH}), to measure the label\ncomplexity or purity in the neighborhood of nodes. Furthermore, we incorporate\nthis metric into the classical graph convolutional network (GCN) architecture\nand propose \\textbf{N}eighborhood \\textbf{H}omophily-\\textbf{G}uided\n\\textbf{G}raph \\textbf{C}onvolutional \\textbf{N}etwork (\\textbf{NHGCN}). In\nthis framework, nodes are grouped by estimated \\textit{NH} values to achieve\nintra-group weight sharing during message propagation and aggregation. Then the\ngenerated node predictions are used to estimate and update new \\textit{NH}\nvalues. The two processes of metric estimation and model inference are\nalternately optimized to achieve better node classification. Extensive\nexperiments on both homophilous and heterophilous benchmarks demonstrate that\n\\textbf{NHGCN} achieves state-of-the-art overall performance on semi-supervised\nnode classification for the universality problem.\n","authors":["Shengbo Gong","Jiajun Zhou","Chenxuan Xie","Qi Xuan"],"pdf_url":"https://arxiv.org/pdf/2301.09851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02088v2","updated":"2023-01-24T07:19:14Z","published":"2022-06-05T03:14:48Z","title":"Model-Agnostic Confidence Intervals for Feature Importance: A Fast and\n  Powerful Approach Using Minipatch Ensembles","summary":"  To promote new scientific discoveries from complex data sets, feature\nimportance inference has been a long-standing statistical problem. Instead of\ntesting for parameters that are only interpretable for specific models, there\nhas been increasing interest in model-agnostic methods, often in the form of\nfeature occlusion or leave-one-covariate-out (LOCO) inference. Existing\napproaches often make distributional assumptions, which can be difficult to\nverify in practice, or require model refitting and data splitting, which are\ncomputationally intensive and lead to losses in power. In this work, we develop\na novel, mostly model-agnostic and distribution-free inference framework for\nfeature importance that is computationally efficient and statistically\npowerful. Our approach is fast as we avoid model refitting by leveraging a form\nof random observation and feature subsampling called minipatch ensembles; this\napproach also improves statistical power by avoiding data splitting. Our\nframework can be applied on tabular data and with any machine learning\nalgorithm, together with minipatch ensembles, for regression and classification\ntasks. Despite the dependencies induced by using minipatch ensembles, we show\nthat our approach provides asymptotic coverage for the feature importance score\nof any model under mild assumptions. Finally, our same procedure can also be\nleveraged to provide valid confidence intervals for predictions, hence\nproviding fast, simultaneous quantification of the uncertainty of both\npredictions and feature importance. We validate our intervals on a series of\nsynthetic and real data examples, including non-linear settings, showing that\nour approach detects the correct important features and exhibits many\ncomputational and statistical advantages over existing methods.\n","authors":["Luqin Gan","Lili Zheng","Genevera I. Allen"],"pdf_url":"https://arxiv.org/pdf/2206.02088v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09848v1","updated":"2023-01-24T07:12:40Z","published":"2023-01-24T07:12:40Z","title":"Gossiped and Quantized Online Multi-Kernel Learning","summary":"  In instances of online kernel learning where little prior information is\navailable and centralized learning is unfeasible, past research has shown that\ndistributed and online multi-kernel learning provides sub-linear regret as long\nas every pair of nodes in the network can communicate (i.e., the communications\nnetwork is a complete graph). In addition, to manage the communication load,\nwhich is often a performance bottleneck, communications between nodes can be\nquantized. This letter expands on these results to non-fully connected graphs,\nwhich is often the case in wireless sensor networks. To address this challenge,\nwe propose a gossip algorithm and provide a proof that it achieves sub-linear\nregret. Experiments with real datasets confirm our findings.\n","authors":["Tomas Ortega","Hamid Jafarkhani"],"pdf_url":"https://arxiv.org/pdf/2301.09848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08230v2","updated":"2023-01-24T06:39:45Z","published":"2022-12-16T01:38:35Z","title":"Multi-Agent Patrolling with Battery Constraints through Deep\n  Reinforcement Learning","summary":"  Autonomous vehicles are suited for continuous area patrolling problems.\nHowever, finding an optimal patrolling strategy can be challenging for many\nreasons. Firstly, patrolling environments are often complex and can include\nunknown environmental factors. Secondly, autonomous vehicles can have failures\nor hardware constraints, such as limited battery life. Importantly, patrolling\nlarge areas often requires multiple agents that need to collectively coordinate\ntheir actions. In this work, we consider these limitations and propose an\napproach based on model-free, deep multi-agent reinforcement learning. In this\napproach, the agents are trained to automatically recharge themselves when\nrequired, to support continuous collective patrolling. A distributed\nhomogeneous multi-agent architecture is proposed, where all patrolling agents\nexecute identical policies locally based on their local observations and shared\ninformation. This architecture provides a fault-tolerant and robust patrolling\nsystem that can tolerate agent failures and allow supplementary agents to be\nadded to replace failed agents or to increase the overall patrol performance.\nThe solution is validated through simulation experiments from multiple\nperspectives, including the overall patrol performance, the efficiency of\nbattery recharging strategies, and the overall fault tolerance and robustness.\n","authors":["Chenhao Tong","Aaron Harwood","Maria A. Rodriguez","Richard O. Sinnott"],"pdf_url":"https://arxiv.org/pdf/2212.08230v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09834v1","updated":"2023-01-24T06:14:58Z","published":"2023-01-24T06:14:58Z","title":"Implementation of the Critical Wave Groups Method with Computational\n  Fluid Dynamics and Neural Networks","summary":"  Accurate and efficient prediction of extreme ship responses continues to be a\nchallenging problem in ship hydrodynamics. Probabilistic frameworks in\nconjunction with computationally efficient numerical hydrodynamic tools have\nbeen developed that allow researchers and designers to better understand\nextremes. However, the ability of these hydrodynamic tools to represent the\nphysics quantitatively during extreme events is limited. Previous research\nsuccessfully implemented the critical wave groups (CWG) probabilistic method\nwith computational fluid dynamics (CFD). Although the CWG method allows for\nless simulation time than a Monte Carlo approach, the large quantity of\nsimulations required is cost prohibitive. The objective of the present paper is\nto reduce the computational cost of implementing CWG with CFD, through the\nconstruction of long short-term memory (LSTM) neural networks. After training\nthe models with a limited quantity of simulations, the models can provide a\nlarger quantity of predictions to calculate the probability. The new framework\nis demonstrated with a 2-D midship section of the Office of Naval Research\nTumblehome (ONRT) hull in Sea State 7 and beam seas at zero speed. The new\nframework is able to produce predictions that are representative of a purely\nCFD-driven CWG framework, with two orders of magnitude of computational cost\nsavings.\n","authors":["Kevin M. Silva","Kevin J. Maki"],"pdf_url":"https://arxiv.org/pdf/2301.09834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09830v1","updated":"2023-01-24T06:07:55Z","published":"2023-01-24T06:07:55Z","title":"Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware\n  Communication Compression","summary":"  In training of modern large natural language processing (NLP) models, it has\nbecome a common practice to split models using 3D parallelism to multiple GPUs.\nSuch technique, however, suffers from a high overhead of inter-node\ncommunication. Compressing the communication is one way to mitigate the\noverhead by reducing the inter-node traffic volume; however, the existing\ncompression techniques have critical limitations to be applied for NLP models\nwith 3D parallelism in that 1) only the data parallelism traffic is targeted,\nand 2) the existing compression schemes already harm the model quality too\nmuch.\n  In this paper, we present Optimus-CC, a fast and scalable distributed\ntraining framework for large NLP models with aggressive communication\ncompression. Optimus-CC differs from existing communication compression\nframeworks in the following ways: First, we compress pipeline parallel\n(inter-stage) traffic. In specific, we compress the inter-stage backpropagation\nand the embedding synchronization in addition to the existing data-parallel\ntraffic compression methods. Second, we propose techniques to avoid the model\nquality drop that comes from the compression. We further provide mathematical\nand empirical analyses to show that our techniques can successfully suppress\nthe compression error. Lastly, we analyze the pipeline and opt to selectively\ncompress those traffic lying on the critical path. This further helps reduce\nthe compression error. We demonstrate our solution on a GPU cluster, and\nachieve superior speedup from the baseline state-of-the-art solutions for\ndistributed training without sacrificing the model quality.\n","authors":["Jaeyong Song","Jinkyu Yim","Jaewon Jung","Hongsun Jang","Hyung-Jin Kim","Youngsok Kim","Jinho Lee"],"pdf_url":"https://arxiv.org/pdf/2301.09830v1.pdf","comment":"Accepted to ASPLOS'23"},{"id":"http://arxiv.org/abs/2301.09320v2","updated":"2023-01-24T05:48:17Z","published":"2023-01-23T08:41:46Z","title":"A Framework for Evaluating the Impact of Food Security Scenarios","summary":"  This study proposes an approach for predicting the impacts of scenarios on\nfood security and demonstrates its application in a case study. The approach\ninvolves two main steps: (1) scenario definition, in which the end user\nspecifies the assumptions and impacts of the scenario using a scenario\ntemplate, and (2) scenario evaluation, in which a Vector Autoregression (VAR)\nmodel is used in combination with Monte Carlo simulation to generate\npredictions for the impacts of the scenario based on the defined assumptions\nand impacts. The case study is based on a proprietary time series food security\ndatabase created using data from the Food and Agriculture Organization of the\nUnited Nations (FAOSTAT), the World Bank, and the United States Department of\nAgriculture (USDA). The database contains a wide range of data on various\nindicators of food security, such as production, trade, consumption, prices,\navailability, access, and nutritional value. The results show that the proposed\napproach can be used to predict the potential impacts of scenarios on food\nsecurity and that the proprietary time series food security database can be\nused to support this approach. The study provides specific insights on how this\napproach can inform decision-making processes related to food security such as\nfood prices and availability in the case study region.\n","authors":["Rachid Belmeskine","Abed Benaichouche"],"pdf_url":"https://arxiv.org/pdf/2301.09320v2.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.09820v1","updated":"2023-01-24T05:11:17Z","published":"2023-01-24T05:11:17Z","title":"A Stability Analysis of Fine-Tuning a Pre-Trained Model","summary":"  Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,\netc.) has proven to be one of the most promising paradigms in recent NLP\nresearch. However, numerous recent works indicate that fine-tuning suffers from\nthe instability problem, i.e., tuning the same model under the same setting\nresults in significantly different performance. Many recent works have proposed\ndifferent methods to solve this problem, but there is no theoretical\nunderstanding of why and how these methods work. In this paper, we propose a\nnovel theoretical stability analysis of fine-tuning that focuses on two\ncommonly used settings, namely, full fine-tuning and head tuning. We define the\nstability under each setting and prove the corresponding stability bounds. The\ntheoretical bounds explain why and how several existing methods can stabilize\nthe fine-tuning procedure. In addition to being able to explain most of the\nobserved empirical discoveries, our proposed theoretical analysis framework can\nalso help in the design of effective and provable methods. Based on our theory,\nwe propose three novel strategies to stabilize the fine-tuning procedure,\nnamely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self\nUnsupervised Re-Training (SURT). We extensively evaluate our proposed\napproaches on 11 widely used real-world benchmark datasets, as well as hundreds\nof synthetic classification datasets. The experiment results show that our\nproposed methods significantly stabilize the fine-tuning procedure and also\ncorroborate our theoretical analysis.\n","authors":["Zihao Fu","Anthony Man-Cho So","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2301.09820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09819v1","updated":"2023-01-24T05:11:03Z","published":"2023-01-24T05:11:03Z","title":"Model Agnostic Sample Reweighting for Out-of-Distribution Learning","summary":"  Distributionally robust optimization (DRO) and invariant risk minimization\n(IRM) are two popular methods proposed to improve out-of-distribution (OOD)\ngeneralization performance of machine learning models. While effective for\nsmall models, it has been observed that these methods can be vulnerable to\noverfitting with large overparameterized models. This work proposes a\nprincipled method, \\textbf{M}odel \\textbf{A}gnostic sam\\textbf{PL}e\nr\\textbf{E}weighting (\\textbf{MAPLE}), to effectively address OOD problem,\nespecially in overparameterized scenarios. Our key idea is to find an effective\nreweighting of the training samples so that the standard empirical risk\nminimization training of a large model on the weighted training data leads to\nsuperior OOD generalization performance. The overfitting issue is addressed by\nconsidering a bilevel formulation to search for the sample reweighting, in\nwhich the generalization complexity depends on the search space of sample\nweights instead of the model size. We present theoretical analysis in linear\ncase to prove the insensitivity of MAPLE to model size, and empirically verify\nits superiority in surpassing state-of-the-art methods by a large margin. Code\nis available at \\url{https://github.com/x-zho14/MAPLE}.\n","authors":["Xiao Zhou","Yong Lin","Renjie Pi","Weizhong Zhang","Renzhe Xu","Peng Cui","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.09819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09816v1","updated":"2023-01-24T05:01:23Z","published":"2023-01-24T05:01:23Z","title":"SMART: Self-supervised Multi-task pretrAining with contRol Transformers","summary":"  Self-supervised pretraining has been extensively studied in language and\nvision domains, where a unified model can be easily adapted to various\ndownstream tasks by pretraining representations without explicit labels. When\nit comes to sequential decision-making tasks, however, it is difficult to\nproperly design such a pretraining approach that can cope with both\nhigh-dimensional perceptual information and the complexity of sequential\ncontrol over long interaction horizons. The challenge becomes combinatorially\nmore complex if we want to pretrain representations amenable to a large variety\nof tasks. To tackle this problem, in this work, we formulate a general\npretraining-finetuning pipeline for sequential decision making, under which we\npropose a generic pretraining framework \\textit{Self-supervised Multi-task\npretrAining with contRol Transformer (SMART)}. By systematically investigating\npretraining regimes, we carefully design a Control Transformer (CT) coupled\nwith a novel control-centric pretraining objective in a self-supervised manner.\nSMART encourages the representation to capture the common essential information\nrelevant to short-term control and long-term control, which is transferrable\nacross tasks. We show by extensive experiments in DeepMind Control Suite that\nSMART significantly improves the learning efficiency among seen and unseen\ndownstream tasks and domains under different learning scenarios including\nImitation Learning (IL) and Reinforcement Learning (RL). Benefiting from the\nproposed control-centric objective, SMART is resilient to distribution shift\nbetween pretraining and finetuning, and even works well with low-quality\npretraining datasets that are randomly collected.\n","authors":["Yanchao Sun","Shuang Ma","Ratnesh Madaan","Rogerio Bonatti","Furong Huang","Ashish Kapoor"],"pdf_url":"https://arxiv.org/pdf/2301.09816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15076v3","updated":"2023-01-24T04:55:36Z","published":"2022-09-29T19:54:13Z","title":"3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical\n  Transformer for Medical Image Segmentation","summary":"  The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art\nperformances on several 3D volumetric data benchmarks, including 3D medical\nimage segmentation. Hierarchical transformers (e.g., Swin Transformers)\nreintroduced several ConvNet priors and further enhanced the practical\nviability of adapting volumetric segmentation in 3D medical datasets. The\neffectiveness of hybrid approaches is largely credited to the large receptive\nfield for non-local self-attention and the large number of model parameters. In\nthis work, we propose a lightweight volumetric ConvNet, termed 3D UX-Net, which\nadapts the hierarchical transformer using ConvNet modules for robust volumetric\nsegmentation. Specifically, we revisit volumetric depth-wise convolutions with\nlarge kernel size (e.g. starting from $7\\times7\\times7$) to enable the larger\nglobal receptive fields, inspired by Swin Transformer. We further substitute\nthe multi-layer perceptron (MLP) in Swin Transformer blocks with pointwise\ndepth convolutions and enhance model performances with fewer normalization and\nactivation layers, thus reducing the number of model parameters. 3D UX-Net\ncompetes favorably with current SOTA transformers (e.g. SwinUNETR) using three\nchallenging public datasets on volumetric brain and abdominal imaging: 1)\nMICCAI Challenge 2021 FLARE, 2) MICCAI Challenge 2021 FeTA, and 3) MICCAI\nChallenge 2022 AMOS. 3D UX-Net consistently outperforms SwinUNETR with\nimprovement from 0.929 to 0.938 Dice (FLARE2021) and 0.867 to 0.874 Dice\n(Feta2021). We further evaluate the transfer learning capability of 3D UX-Net\nwith AMOS2022 and demonstrates another improvement of $2.27\\%$ Dice (from 0.880\nto 0.900). The source code with our proposed model are available at\nhttps://github.com/MASILab/3DUX-Net.\n","authors":["Ho Hin Lee","Shunxing Bao","Yuankai Huo","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2209.15076v3.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09815v1","updated":"2023-01-24T04:50:55Z","published":"2023-01-24T04:50:55Z","title":"Mixed Effects Random Forests for Personalised Predictions of Clinical\n  Depression Severity","summary":"  This work demonstrates how mixed effects random forests enable accurate\npredictions of depression severity using multimodal physiological and digital\nactivity data collected from an 8-week study involving 31 patients with major\ndepressive disorder. We show that mixed effects random forests outperform\nstandard random forests and personal average baselines when predicting clinical\nHamilton Depression Rating Scale scores (HDRS_17). Compared to the latter\nbaseline, accuracy is significantly improved for each patient by an average of\n0.199-0.276 in terms of mean absolute error (p<0.05). This is noteworthy as\nthese simple baselines frequently outperform machine learning methods in mental\nhealth prediction tasks. We suggest that this improved performance results from\nthe ability of the mixed effects random forest to personalise model parameters\nto individuals in the dataset. However, we find that these improvements pertain\nexclusively to scenarios where labelled patient data are available to the model\nat training time. Investigating methods that improve accuracy when generalising\nto new patients is left as important future work.\n","authors":["Robert A. Lewis","Asma Ghandeharioun","Szymon Fedor","Paola Pedrelli","Rosalind Picard","David Mischoulon"],"pdf_url":"https://arxiv.org/pdf/2301.09815v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2211.02239v2","updated":"2023-01-24T04:44:19Z","published":"2022-11-04T03:16:23Z","title":"Towards Asteroid Detection in Microlensing Surveys with Deep Learning","summary":"  Asteroids are an indelible part of most astronomical surveys though only a\nfew surveys are dedicated to their detection. Over the years, high cadence\nmicrolensing surveys have amassed several terabytes of data while scanning\nprimarily the Galactic Bulge and Magellanic Clouds for microlensing events and\nthus provide a treasure trove of opportunities for scientific data mining. In\nparticular, numerous asteroids have been observed by visual inspection of\nselected images. This paper presents novel deep learning-based solutions for\nthe recovery and discovery of asteroids in the microlensing data gathered by\nthe MOA project. Asteroid tracklets can be clearly seen by combining all the\nobservations on a given night and these tracklets inform the structure of the\ndataset. Known asteroids were identified within these composite images and used\nfor creating the labelled datasets required for supervised learning. Several\ncustom CNN models were developed to identify images with asteroid tracklets.\nModel ensembling was then employed to reduce the variance in the predictions as\nwell as to improve the generalisation error, achieving a recall of 97.67%.\nFurthermore, the YOLOv4 object detector was trained to localize asteroid\ntracklets, achieving a mean Average Precision (mAP) of 90.97%. These trained\nnetworks will be applied to 16 years of MOA archival data to find both known\nand unknown asteroids that have been observed by the survey over the years. The\nmethodologies developed can be adapted for use by other surveys for asteroid\nrecovery and discovery.\n","authors":["Preeti Cowan","Ian A. Bond","Napoleon H. Reyes"],"pdf_url":"https://arxiv.org/pdf/2211.02239v2.pdf","comment":"15 pages, 17 figures, to be published in Astronomy and Computing"},{"id":"http://arxiv.org/abs/2301.09813v1","updated":"2023-01-24T04:43:12Z","published":"2023-01-24T04:43:12Z","title":"Slice-and-Forge: Making Better Use of Caches for Graph Convolutional\n  Network Accelerators","summary":"  Graph convolutional networks (GCNs) are becoming increasingly popular as they\ncan process a wide variety of data formats that prior deep neural networks\ncannot easily support. One key challenge in designing hardware accelerators for\nGCNs is the vast size and randomness in their data access patterns which\ngreatly reduces the effectiveness of the limited on-chip cache. Aimed at\nimproving the effectiveness of the cache by mitigating the irregular data\naccesses, prior studies often employ the vertex tiling techniques used in\ntraditional graph processing applications. While being effective at enhancing\nthe cache efficiency, those approaches are often sensitive to the tiling\nconfigurations where the optimal setting heavily depends on target input\ndatasets. Furthermore, the existing solutions require manual tuning through\ntrial-and-error or rely on sub-optimal analytical models.\n  In this paper, we propose Slice-and-Forge (SnF), an efficient hardware\naccelerator for GCNs which greatly improves the effectiveness of the limited\non-chip cache. SnF chooses a tiling strategy named feature slicing that splits\nthe features into vertical slices and processes them in the outermost loop of\nthe execution. This particular choice results in a repetition of the identical\ncomputational patterns over irregular graph data over multiple rounds. Taking\nadvantage of such repetitions, SnF dynamically tunes its tile size. Our\nexperimental results reveal that SnF can achieve 1.73x higher performance in\ngeomean compared to prior work on multi-engine settings, and 1.46x higher\nperformance in geomean on small scale settings, without the need for off-line\nanalyses.\n","authors":["Mingi Yoo","Jaeyong Song","Hyeyoon Lee","Jounghoo Lee","Namhyung Kim","Youngsok Kim","Jinho Lee"],"pdf_url":"https://arxiv.org/pdf/2301.09813v1.pdf","comment":"Published at PACT'22"},{"id":"http://arxiv.org/abs/2301.09811v1","updated":"2023-01-24T04:29:30Z","published":"2023-01-24T04:29:30Z","title":"Multi-view Kernel PCA for Time series Forecasting","summary":"  In this paper, we propose a kernel principal component analysis model for\nmulti-variate time series forecasting, where the training and prediction\nschemes are derived from the multi-view formulation of Restricted Kernel\nMachines. The training problem is simply an eigenvalue decomposition of the\nsummation of two kernel matrices corresponding to the views of the input and\noutput data. When a linear kernel is used for the output view, it is shown that\nthe forecasting equation takes the form of kernel ridge regression. When that\nkernel is non-linear, a pre-image problem has to be solved to forecast a point\nin the input space. We evaluate the model on several standard time series\ndatasets, perform ablation studies, benchmark with closely related models and\ndiscuss its results.\n","authors":["Arun Pandey","Hannes De Meulemeester","Bart De Moor","Johan A. K. Suykens"],"pdf_url":"https://arxiv.org/pdf/2301.09811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09808v1","updated":"2023-01-24T04:22:13Z","published":"2023-01-24T04:22:13Z","title":"On Dynamic Regret and Constraint Violations in Constrained Online Convex\n  Optimization","summary":"  A constrained version of the online convex optimization (OCO) problem is\nconsidered. With slotted time, for each slot, first an action is chosen.\nSubsequently the loss function and the constraint violation penalty evaluated\nat the chosen action point is revealed. For each slot, both the loss function\nas well as the function defining the constraint set is assumed to be smooth and\nstrongly convex. In addition, once an action is chosen, local information about\na feasible set within a small neighborhood of the current action is also\nrevealed. An algorithm is allowed to compute at most one gradient at its point\nof choice given the described feedback to choose the next action. The goal of\nan algorithm is to simultaneously minimize the dynamic regret (loss incurred\ncompared to the oracle's loss) and the constraint violation penalty (penalty\naccrued compared to the oracle's penalty). We propose an algorithm that follows\nprojected gradient descent over a suitably chosen set around the current\naction. We show that both the dynamic regret and the constraint violation is\norder-wise bounded by the {\\it path-length}, the sum of the distances between\nthe consecutive optimal actions. Moreover, we show that the derived bounds are\nthe best possible.\n","authors":["Rahul Vaze"],"pdf_url":"https://arxiv.org/pdf/2301.09808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09801v1","updated":"2023-01-24T03:55:14Z","published":"2023-01-24T03:55:14Z","title":"Heterogeneous Domain Adaptation for IoT Intrusion Detection: A Geometric\n  Graph Alignment Approach","summary":"  Data scarcity hinders the usability of data-dependent algorithms when\ntackling IoT intrusion detection (IID). To address this, we utilise the data\nrich network intrusion detection (NID) domain to facilitate more accurate\nintrusion detection for IID domains. In this paper, a Geometric Graph Alignment\n(GGA) approach is leveraged to mask the geometric heterogeneities between\ndomains for better intrusion knowledge transfer. Specifically, each intrusion\ndomain is formulated as a graph where vertices and edges represent intrusion\ncategories and category-wise interrelationships, respectively. The overall\nshape is preserved via a confused discriminator incapable to identify adjacency\nmatrices between different intrusion domain graphs. A rotation avoidance\nmechanism and a centre point matching mechanism is used to avoid graph\nmisalignment due to rotation and symmetry, respectively. Besides, category-wise\nsemantic knowledge is transferred to act as vertex-level alignment. To exploit\nthe target data, a pseudo-label election mechanism that jointly considers\nnetwork prediction, geometric property and neighbourhood information is used to\nproduce fine-grained pseudo-label assignment. Upon aligning the intrusion\ngraphs geometrically from different granularities, the transferred intrusion\nknowledge can boost IID performance. Comprehensive experiments on several\nintrusion datasets demonstrate state-of-the-art performance of the GGA approach\nand validate the usefulness of GGA constituting components.\n","authors":["Jiashu Wu","Hao Dai","Yang Wang","Kejiang Ye","Chengzhong Xu"],"pdf_url":"https://arxiv.org/pdf/2301.09801v1.pdf","comment":"Accepted by IEEE Internet of Things Journal"},{"id":"http://arxiv.org/abs/2301.09109v2","updated":"2023-01-24T03:50:02Z","published":"2023-01-22T12:13:25Z","title":"Federated Recommendation with Additive Personalization","summary":"  With rising concerns about privacy, developing recommendation systems in a\nfederated setting become a new paradigm to develop next-generation Internet\nservice architecture. However, existing approaches are usually derived from a\ndistributed recommendation framework with an additional mechanism for privacy\nprotection, thus most of them fail to fully exploit personalization in the new\ncontext of federated recommendation settings. In this paper, we propose a novel\napproach called Federated Recommendation with Additive Personalization (FedRAP)\nto enhance recommendation by learning user embedding and the user's personal\nview of item embeddings. Specifically, the proposed additive personalization is\nto add a personalized item embedding to a sparse global item embedding\naggregated from all users. Moreover, a curriculum learning mechanism has been\napplied for additive personalization on item embeddings by gradually increasing\nregularization weights to mitigate the performance degradation caused by large\nvariances among client-specific item embeddings. A unified formulation has been\nproposed with a sparse regularization of global item embeddings for reducing\ncommunication overhead. Experimental results on four real-world recommendation\ndatasets demonstrate the effectiveness of FedRAP.\n","authors":["Zhiwei Li","Guodong Long","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.09109v2.pdf","comment":"9 pages, conference"},{"id":"http://arxiv.org/abs/2301.09799v1","updated":"2023-01-24T03:47:37Z","published":"2023-01-24T03:47:37Z","title":"LDMIC: Learning-based Distributed Multi-view Image Coding","summary":"  Multi-view image compression plays a critical role in 3D-related\napplications. Existing methods adopt a predictive coding architecture, which\nrequires joint encoding to compress the corresponding disparity as well as\nresidual information. This demands collaboration among cameras and enforces the\nepipolar geometric constraint between different views, which makes it\nchallenging to deploy these methods in distributed camera systems with randomly\noverlapping fields of view. Meanwhile, distributed source coding theory\nindicates that efficient data compression of correlated sources can be achieved\nby independent encoding and joint decoding, which motivates us to design a\nlearning-based distributed multi-view image coding (LDMIC) framework. With\nindependent encoders, LDMIC introduces a simple yet effective joint context\ntransfer module based on the cross-attention mechanism at the decoder to\neffectively capture the global inter-view correlations, which is insensitive to\nthe geometric relationships between images. Experimental results show that\nLDMIC significantly outperforms both traditional and learning-based MIC methods\nwhile enjoying fast encoding speed. Code will be released at\nhttps://github.com/Xinjie-Q/LDMIC.\n","authors":["Xinjie Zhang","Jiawei Shao","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.09799v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2208.10531v2","updated":"2023-01-24T02:50:44Z","published":"2022-08-22T18:18:47Z","title":"RAIN: RegulArization on Input and Network for Black-Box Domain\n  Adaptation","summary":"  Source-Free domain adaptation transits the source-trained model towards\ntarget domain without exposing the source data, trying to dispel these concerns\nabout data privacy and security. However, this paradigm is still at risk of\ndata leakage due to adversarial attacks on the source model. Hence, the\nBlack-Box setting only allows to use the outputs of source model, but still\nsuffers from overfitting on the source domain more severely due to source\nmodel's unseen weights. In this paper, we propose a novel approach named RAIN\n(RegulArization on Input and Network) for Black-Box domain adaptation from both\ninput-level and network-level regularization. For the input-level, we design a\nnew data augmentation technique as Phase MixUp, which highlights task-relevant\nobjects in the interpolations, thus enhancing input-level regularization and\nclass consistency for target models. For network-level, we develop a Subnetwork\nDistillation mechanism to transfer knowledge from the target subnetwork to the\nfull target network via knowledge distillation, which thus alleviates\noverfitting on the source domain by learning diverse target representations.\nExtensive experiments show that our method achieves state-of-the-art\nperformance on several cross-domain benchmarks under both single- and\nmulti-source black-box domain adaptation.\n","authors":["Qucheng Peng","Zhengming Ding","Lingjuan Lyu","Lichao Sun","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2208.10531v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09791v1","updated":"2023-01-24T02:46:46Z","published":"2023-01-24T02:46:46Z","title":"Quantification of Damage Using Indirect Structural Health Monitoring","summary":"  Structural health monitoring is important to make sure bridges do not fail.\nSince direct monitoring can be complicated and expensive, indirect methods have\nbeen a focus on research. Indirect monitoring can be much cheaper and easier to\nconduct, however there are challenges with getting accurate results. This work\nfocuses on damage quantification by using accelerometers. Tests were conducted\non a model bridge and car with four accelerometers attached to to the vehicle.\nDifferent weights were placed on the bridge to simulate different levels of\ndamage, and 31 tests were run for 20 different damage levels. The acceleration\ndata collected was normalized and a Fast-Fourier Transform (FFT) was performed\non that data. Both the normalized acceleration data and the normalized FFT data\nwere inputted into a Non-Linear Principal Component Analysis (separately) and\nthree principal components were extracted for each data set. Support Vector\nRegression (SVR) and Gaussian Process Regression (GPR) were used as the\nsupervised machine learning methods to develop models. Multiple models were\ncreated so that the best one could be selected, and the models were compared by\nlooking at their Mean Squared Errors (MSE). This methodology should be applied\nin the field to measure how effective it can be in real world applications.\n","authors":["Achyuth Madabhushi"],"pdf_url":"https://arxiv.org/pdf/2301.09791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08975v3","updated":"2023-01-24T02:21:22Z","published":"2022-07-18T23:07:53Z","title":"Superficial White Matter Analysis: An Efficient Point-cloud-based Deep\n  Learning Framework with Supervised Contrastive Learning for Consistent\n  Tractography Parcellation across Populations and dMRI Acquisitions","summary":"  Diffusion MRI tractography is an advanced imaging technique that enables in\nvivo mapping of the brain's white matter connections. White matter parcellation\nclassifies tractography streamlines into clusters or anatomically meaningful\ntracts. It enables quantification and visualization of whole-brain\ntractography. Currently, most parcellation methods focus on the deep white\nmatter (DWM), whereas fewer methods address the superficial white matter (SWM)\ndue to its complexity. We propose a novel two-stage deep-learning-based\nframework, Superficial White Matter Analysis (SupWMA), that performs an\nefficient and consistent parcellation of 198 SWM clusters from whole-brain\ntractography. A point-cloud-based network is adapted to our SWM parcellation\ntask, and supervised contrastive learning enables more discriminative\nrepresentations between plausible streamlines and outliers for SWM. We train\nour model on a large-scale tractography dataset including streamline samples\nfrom labeled long- and medium-range (over 40 mm) SWM clusters and anatomically\nimplausible streamline samples, and we perform testing on six independently\nacquired datasets of different ages and health conditions (including neonates\nand patients with space-occupying brain tumors). Compared to several\nstate-of-the-art methods, SupWMA obtains highly consistent and accurate SWM\nparcellation results on all datasets, showing good generalization across the\nlifespan in health and disease. In addition, the computational speed of SupWMA\nis much faster than other methods.\n","authors":["Tengfei Xue","Fan Zhang","Chaoyi Zhang","Yuqian Chen","Yang Song","Alexandra J. Golby","Nikos Makris","Yogesh Rathi","Weidong Cai","Lauren J. O'Donnell"],"pdf_url":"https://arxiv.org/pdf/2207.08975v3.pdf","comment":"Accepted by Medical Image Analysis"},{"id":"http://arxiv.org/abs/2210.10246v2","updated":"2023-01-24T01:37:30Z","published":"2022-10-19T01:59:37Z","title":"Tempo: Accelerating Transformer-Based Model Training through Memory\n  Footprint Reduction","summary":"  Training deep learning models can be computationally expensive. Prior works\nhave shown that increasing the batch size can potentially lead to better\noverall throughput. However, the batch size is frequently limited by the\naccelerator memory capacity due to the activations/feature maps stored for the\ntraining backward pass, as larger batch sizes require larger feature maps to be\nstored. Transformer-based models, which have recently seen a surge in\npopularity due to their good performance and applicability to a variety of\ntasks, have a similar problem. To remedy this issue, we propose Tempo, a new\napproach to efficiently use accelerator (e.g., GPU) memory resources for\ntraining Transformer-based models. Our approach provides drop-in replacements\nfor the GELU, LayerNorm, and Attention layers, reducing the memory usage and\nultimately leading to more efficient training. We implement Tempo and evaluate\nthe throughput, memory usage, and accuracy/loss on the BERT Large pre-training\ntask. We demonstrate that Tempo enables up to 2x higher batch sizes and 16%\nhigher training throughput over the state-of-the-art baseline. We also evaluate\nTempo on GPT2 and RoBERTa models, showing 19% and 26% speedup over the\nbaseline.\n","authors":["Muralidhar Andoorveedu","Zhanda Zhu","Bojian Zheng","Gennady Pekhimenko"],"pdf_url":"https://arxiv.org/pdf/2210.10246v2.pdf","comment":"Accepted to NeurIPS 2022. Fixed some minor typos and added some small\n  clarifications"},{"id":"http://arxiv.org/abs/2301.09776v1","updated":"2023-01-24T01:36:07Z","published":"2023-01-24T01:36:07Z","title":"Differentiable bit-rate estimation for neural-based video codec\n  enhancement","summary":"  Neural networks (NN) can improve standard video compression by pre- and\npost-processing the encoded video. For optimal NN training, the standard codec\nneeds to be replaced with a codec proxy that can provide derivatives of\nestimated bit-rate and distortion, which are used for gradient\nback-propagation. Since entropy coding of standard codecs is designed to take\ninto account non-linear dependencies between transform coefficients, bit-rates\ncannot be well approximated with simple per-coefficient estimators. This paper\npresents a new approach for bit-rate estimation that is similar to the type\nemployed in training end-to-end neural codecs, and able to efficiently take\ninto account those statistical dependencies. It is defined from a mathematical\nmodel that provides closed-form formulas for the estimates and their gradients,\nreducing the computational complexity. Experimental results demonstrate the\nmethod's accuracy in estimating HEVC/H.265 codec bit-rates.\n","authors":["Amir Said","Manish Kumar Singh","Reza Pourreza"],"pdf_url":"https://arxiv.org/pdf/2301.09776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13446v2","updated":"2023-01-24T01:26:51Z","published":"2022-09-27T15:09:13Z","title":"Learning to Counter: Stochastic Feature-based Learning for Diverse\n  Counterfactual Explanations","summary":"  Interpretable machine learning seeks to understand the reasoning process of\ncomplex black-box systems that are long notorious for lack of explainability.\nOne flourishing approach is through counterfactual explanations, which provide\nsuggestions on what a user can do to alter an outcome. Not only must a\ncounterfactual example counter the original prediction from the black-box\nclassifier but it should also satisfy various constraints for practical\napplications. Diversity is one of the critical constraints that however remains\nless discussed. While diverse counterfactuals are ideal, it is computationally\nchallenging to simultaneously address some other constraints. Furthermore,\nthere is a growing privacy concern over the released counterfactual data. To\nthis end, we propose a feature-based learning framework that effectively\nhandles the counterfactual constraints and contributes itself to the limited\npool of private explanation models. We demonstrate the flexibility and\neffectiveness of our method in generating diverse counterfactuals of\nactionability and plausibility. Our counterfactual engine is more efficient\nthan counterparts of the same capacity while yielding the lowest\nre-identification risks.\n","authors":["Vy Vo","Trung Le","Van Nguyen","He Zhao","Edwin Bonilla","Gholamreza Haffari","Dinh Phung"],"pdf_url":"https://arxiv.org/pdf/2209.13446v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01953v2","updated":"2023-01-24T01:20:10Z","published":"2022-10-04T23:00:20Z","title":"Robust Fair Clustering: A Novel Fairness Attack and Defense Framework","summary":"  Clustering algorithms are widely used in many societal resource allocation\napplications, such as loan approvals and candidate recruitment, among others,\nand hence, biased or unfair model outputs can adversely impact individuals that\nrely on these applications. To this end, many fair clustering approaches have\nbeen recently proposed to counteract this issue. Due to the potential for\nsignificant harm, it is essential to ensure that fair clustering algorithms\nprovide consistently fair outputs even under adversarial influence. However,\nfair clustering algorithms have not been studied from an adversarial attack\nperspective. In contrast to previous research, we seek to bridge this gap and\nconduct a robustness analysis against fair clustering by proposing a novel\nblack-box fairness attack. Through comprehensive experiments, we find that\nstate-of-the-art models are highly susceptible to our attack as it can reduce\ntheir fairness performance significantly. Finally, we propose Consensus Fair\nClustering (CFC), the first robust fair clustering approach that transforms\nconsensus clustering into a fair graph partitioning problem, and iteratively\nlearns to generate fair cluster outputs. Experimentally, we observe that CFC is\nhighly robust to the proposed attack and is thus a truly robust fair clustering\nalternative.\n","authors":["Anshuman Chhabra","Peizhao Li","Prasant Mohapatra","Hongfu Liu"],"pdf_url":"https://arxiv.org/pdf/2210.01953v2.pdf","comment":"Accepted to the 11th International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2301.06678v2","updated":"2023-01-24T01:15:13Z","published":"2023-01-17T03:43:19Z","title":"Feature-based Image Matching for Identifying Individual Kākā","summary":"  This report investigates an unsupervised, feature-based image matching\npipeline for the novel application of identifying individual k\\=ak\\=a. Applied\nwith a similarity network for clustering, this addresses a weakness of current\nsupervised approaches to identifying individual birds which struggle to handle\nthe introduction of new individuals to the population. Our approach uses object\nlocalisation to locate k\\=ak\\=a within images and then extracts local features\nthat are invariant to rotation and scale. These features are matched between\nimages with nearest neighbour matching techniques and mismatch removal to\nproduce a similarity score for image match comparison. The results show that\nmatches obtained via the image matching pipeline achieve high accuracy of true\nmatches. We conclude that feature-based image matching could be used with a\nsimilarity network to provide a viable alternative to existing supervised\napproaches.\n","authors":["Fintan O'Sullivan","Kirita-Rose Escott","Rachael C. Shaw","Andrew Lensen"],"pdf_url":"https://arxiv.org/pdf/2301.06678v2.pdf","comment":"42 pages, honour's report from Victoria University of Wellington"},{"id":"http://arxiv.org/abs/2301.08506v2","updated":"2023-01-24T00:48:14Z","published":"2023-01-20T10:33:03Z","title":"Language Agnostic Data-Driven Inverse Text Normalization","summary":"  With the emergence of automatic speech recognition (ASR) models, converting\nthe spoken form text (from ASR) to the written form is in urgent need. This\ninverse text normalization (ITN) problem attracts the attention of researchers\nfrom various fields. Recently, several works show that data-driven ITN methods\ncan output high-quality written form text. Due to the scarcity of labeled\nspoken-written datasets, the studies on non-English data-driven ITN are quite\nlimited. In this work, we propose a language-agnostic data-driven ITN framework\nto fill this gap. Specifically, we leverage the data augmentation in\nconjunction with neural machine translated data for low resource languages.\nMoreover, we design an evaluation method for language agnostic ITN model when\nonly English data is available. Our empirical evaluation shows this language\nagnostic modeling approach is effective for low resource languages while\npreserving the performance for high resource languages.\n","authors":["Szu-Jui Chen","Debjyoti Paul","Yutong Pang","Peng Su","Xuedong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09767v1","updated":"2023-01-24T00:32:56Z","published":"2023-01-24T00:32:56Z","title":"Truveta Mapper: A Zero-shot Ontology Alignment Framework","summary":"  In this paper, a new perspective is suggested for unsupervised Ontology\nMatching (OM) or Ontology Alignment (OA) by treating it as a translation task.\nOntologies are represented as graphs, and the translation is performed from a\nnode in the source ontology graph to a path in the target ontology graph. The\nproposed framework, Truveta Mapper (TM), leverages a multi-task\nsequence-to-sequence transformer model to perform alignment across multiple\nontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables\nthe model to implicitly learn the relationship between different ontologies via\ntransfer-learning without requiring any explicit cross-ontology manually\nlabeled data. This also enables the formulated framework to outperform existing\nsolutions for both runtime latency and alignment quality. The model is\npre-trained and fine-tuned only on publicly available text corpus and\ninner-ontologies data. The proposed solution outperforms state-of-the-art\napproaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented\nnew OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers\nlog-linear complexity in contrast to quadratic in the existing end-to-end\nmethods, and overall makes the OM task efficient and more straightforward\nwithout much post-processing involving mapping extension or mapping repair.\n","authors":["Mariyam Amir","Murchana Baruah","Mahsa Eslamialishah","Sina Ehsani","Alireza Bahramali","Sadra Naddaf-Sh","Saman Zarandioon"],"pdf_url":"https://arxiv.org/pdf/2301.09767v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09766v1","updated":"2023-01-24T00:31:28Z","published":"2023-01-24T00:31:28Z","title":"Constrained Reinforcement Learning for Dexterous Manipulation","summary":"  Existing learning approaches to dexterous manipulation use demonstrations or\ninteractions with the environment to train black-box neural networks that\nprovide little control over how the robot learns the skills or how it would\nperform post training. These approaches pose significant challenges when\nimplemented on physical platforms given that, during initial stages of\ntraining, the robot's behavior could be erratic and potentially harmful to its\nown hardware, the environment, or any humans in the vicinity. A potential way\nto address these limitations is to add constraints during learning that\nrestrict and guide the robot's behavior during training as well as roll outs.\nInspired by the success of constrained approaches in other domains, we\ninvestigate the effects of adding position-based constraints to a 24-DOF robot\nhand learning to perform object relocation using Constrained Policy\nOptimization. We find that a simple geometric constraint can ensure the robot\nlearns to move towards the object sooner than without constraints. Further,\ntraining with this constraint requires a similar number of samples as its\nunconstrained counterpart to master the skill. These findings shed light on how\nsimple constraints can help robots achieve sensible and safe behavior quickly\nand ease concerns surrounding hardware deployment. We also investigate the\neffects of the strictness of these constraints and report findings that provide\ninsights into how different degrees of strictness affect learning outcomes. Our\ncode is available at\nhttps://github.com/GT-STAR-Lab/constrained-rl-dexterous-manipulation.\n","authors":["Abhineet Jain","Jack Kolb","Harish Ravichandar"],"pdf_url":"https://arxiv.org/pdf/2301.09766v1.pdf","comment":"Accepted in the International Workshop on Safe Reinforcement Learning\n  at the 31st International Joint Conference on Artificial Intelligence (IJCAI\n  2022). 6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2211.00471v3","updated":"2023-01-24T00:18:36Z","published":"2022-11-01T14:00:01Z","title":"Exploring Effects of Computational Parameter Changes to Image\n  Recognition Systems","summary":"  Image recognition tasks typically use deep learning and require enormous\nprocessing power, thus relying on hardware accelerators like GPUs and FPGAs for\nfast, timely processing. Failure in real-time image recognition tasks can occur\ndue to incorrect mapping on hardware accelerators, which may lead to timing\nuncertainty and incorrect behavior. Owing to the increased use of image\nrecognition tasks in safety-critical applications like autonomous driving and\nmedical imaging, it is imperative to assess their robustness to changes in the\ncomputational environment as parameters like deep learning frameworks, compiler\noptimizations for code generation, and hardware devices are not regulated with\nvarying impact on model performance and correctness. In this paper we conduct\nrobustness analysis of four popular image recognition models (MobileNetV2,\nResNet101V2, DenseNet121 and InceptionV3) with the ImageNet dataset, assessing\nthe impact of the following parameters in the model's computational\nenvironment: (1) deep learning frameworks; (2) compiler optimizations; and (3)\nhardware devices. We report sensitivity of model performance in terms of output\nlabel and inference time for changes in each of these environment parameters.\nWe find that output label predictions for all four models are sensitive to\nchoice of deep learning framework (by up to 57%) and insensitive to other\nparameters. On the other hand, model inference time was affected by all\nenvironment parameters with changes in hardware device having the most effect.\nThe extent of effect was not uniform across models.\n","authors":["Nikolaos Louloudakis","Perry Gibson","José Cano","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2211.00471v3.pdf","comment":"9 pages, 8 figures, 1 table"}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.10056v1","updated":"2023-01-24T15:00:47Z","published":"2023-01-24T15:00:47Z","title":"Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from\n  Smartphone Cameras with Rolling Shutters and Movable Lenses","summary":"  Our research discovers how the rolling shutter and movable lens structures\nwidely found in smartphone cameras modulate structure-borne sounds onto camera\nimages, creating a point-of-view (POV) optical-acoustic side channel for\nacoustic eavesdropping. The movement of smartphone camera hardware leaks\nacoustic information because images unwittingly modulate ambient sound as\nimperceptible distortions. Our experiments find that the side channel is\nfurther amplified by intrinsic behaviors of Complementary\nmetal-oxide-semiconductor (CMOS) rolling shutters and movable lenses such as in\nOptical Image Stabilization (OIS) and Auto Focus (AF). Our paper characterizes\nthe limits of acoustic information leakage caused by structure-borne sound that\nperturbs the POV of smartphone cameras. In contrast with traditional\noptical-acoustic eavesdropping on vibrating objects, this side channel requires\nno line of sight and no object within the camera's field of view (images of a\nceiling suffice). Our experiments test the limits of this side channel with a\nnovel signal processing pipeline that extracts and recognizes the leaked\nacoustic information. Our evaluation with 10 smartphones on a spoken digit\ndataset reports 80.66%, 91.28%, and 99.67% accuracies on recognizing 10 spoken\ndigits, 20 speakers, and 2 genders respectively. We further systematically\ndiscuss the possible defense strategies and implementations. By modeling,\nmeasuring, and demonstrating the limits of acoustic eavesdropping from\nsmartphone camera image streams, our contributions explain the physics-based\ncausality and possible ways to reduce the threat on current and future devices.\n","authors":["Yan Long","Pirouz Naghavi","Blas Kojusner","Kevin Butler","Sara Rampazzi","Kevin Fu"],"pdf_url":"https://arxiv.org/pdf/2301.10056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08664v2","updated":"2023-01-24T11:04:47Z","published":"2023-01-20T16:30:44Z","title":"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","summary":"  The quality of the video stream is key to neural network-based video\nanalytics. However, low-quality video is inevitably collected by existing\nsurveillance systems because of poor quality cameras or over-compressed/pruned\nvideo streaming protocols, e.g., as a result of upstream bandwidth limit. To\naddress this issue, existing studies use quality enhancers (e.g., neural\nsuper-resolution) to improve the quality of videos (e.g., resolution) and\neventually ensure inference accuracy. Nevertheless, directly applying quality\nenhancers does not work in practice because it will introduce unacceptable\nlatency. In this paper, we present AccDecoder, a novel accelerated decoder for\nreal-time and neural-enhanced video analytics. AccDecoder can select a few\nframes adaptively via Deep Reinforcement Learning (DRL) to enhance the quality\nby neural super-resolution and then up-scale the unselected frames that\nreference them, which leads to 6-21% accuracy improvement. AccDecoder provides\nefficient inference capability via filtering important frames using DRL for\nDNN-based inference and reusing the results for the other frames via extracting\nthe reference relationship among frames and blocks, which results in a latency\nreduction of 20-80% than baselines.\n","authors":["Tingting Yuan","Liang Mi","Weijun Wang","Haipeng Dai","Xiaoming Fu"],"pdf_url":"https://arxiv.org/pdf/2301.08664v2.pdf","comment":"Accepted by 2023 IEEE INFOCOM"},{"id":"http://arxiv.org/abs/2301.09799v1","updated":"2023-01-24T03:47:37Z","published":"2023-01-24T03:47:37Z","title":"LDMIC: Learning-based Distributed Multi-view Image Coding","summary":"  Multi-view image compression plays a critical role in 3D-related\napplications. Existing methods adopt a predictive coding architecture, which\nrequires joint encoding to compress the corresponding disparity as well as\nresidual information. This demands collaboration among cameras and enforces the\nepipolar geometric constraint between different views, which makes it\nchallenging to deploy these methods in distributed camera systems with randomly\noverlapping fields of view. Meanwhile, distributed source coding theory\nindicates that efficient data compression of correlated sources can be achieved\nby independent encoding and joint decoding, which motivates us to design a\nlearning-based distributed multi-view image coding (LDMIC) framework. With\nindependent encoders, LDMIC introduces a simple yet effective joint context\ntransfer module based on the cross-attention mechanism at the decoder to\neffectively capture the global inter-view correlations, which is insensitive to\nthe geometric relationships between images. Experimental results show that\nLDMIC significantly outperforms both traditional and learning-based MIC methods\nwhile enjoying fast encoding speed. Code will be released at\nhttps://github.com/Xinjie-Q/LDMIC.\n","authors":["Xinjie Zhang","Jiawei Shao","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.09799v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09776v1","updated":"2023-01-24T01:36:07Z","published":"2023-01-24T01:36:07Z","title":"Differentiable bit-rate estimation for neural-based video codec\n  enhancement","summary":"  Neural networks (NN) can improve standard video compression by pre- and\npost-processing the encoded video. For optimal NN training, the standard codec\nneeds to be replaced with a codec proxy that can provide derivatives of\nestimated bit-rate and distortion, which are used for gradient\nback-propagation. Since entropy coding of standard codecs is designed to take\ninto account non-linear dependencies between transform coefficients, bit-rates\ncannot be well approximated with simple per-coefficient estimators. This paper\npresents a new approach for bit-rate estimation that is similar to the type\nemployed in training end-to-end neural codecs, and able to efficiently take\ninto account those statistical dependencies. It is defined from a mathematical\nmodel that provides closed-form formulas for the estimates and their gradients,\nreducing the computational complexity. Experimental results demonstrate the\nmethod's accuracy in estimating HEVC/H.265 codec bit-rates.\n","authors":["Amir Said","Manish Kumar Singh","Reza Pourreza"],"pdf_url":"https://arxiv.org/pdf/2301.09776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09772v1","updated":"2023-01-24T01:04:15Z","published":"2023-01-24T01:04:15Z","title":"SONIA: an immersive customizable virtual reality system for the\n  education and exploration of brain networks","summary":"  While mastery of neuroanatomy is important for the investigation of the\nbrain, there is an increasing interest in exploring the neural pathways to\nbetter understand the roles of neural circuitry in brain functions. To tackle\nthe limitations of traditional 2D-display-based neuronavigation software in\nintuitively visualizing complex 3D anatomies, several virtual reality (VR) and\naugmented reality (AR) solutions have been proposed to facilitate\nneuroanatomical education. However, with the increasing knowledge on brain\nconnectivity and the functioning of the sub-systems, there is still a lack of\nsimilar software solutions for the education and exploration of these topics,\nwhich demand more elaborate visualization and interaction strategies. To\naddress this gap, we designed the immerSive custOmizable Neuro learnIng plAform\n(SONIA), a novel user-friendly VR software system with a multi-scale\ninteraction paradigm that allows flexible customization of learning materials.\nWith both quantitative and qualitative evaluations through user studies, the\nproposed system is shown to have high usability, attractive visual design, and\ngood educational value. As the first immersive system that integrates\ncustomizable design and detailed narratives of the brain sub-systems for the\neducation of neuroanatomy and brain connectivity, SONIA showcases new potential\ndirections and provides valuable insights regarding medical learning and\nexploration in VR.\n","authors":["Owen Hellum","Christopher Steele","Yiming Xiao"],"pdf_url":"https://arxiv.org/pdf/2301.09772v1.pdf","comment":null}]}}